[[032m2021-11-26 09:41:09,631[0m INFO] config.save_config_to_yaml Config saved as logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/config.yaml
[[032m2021-11-26 09:41:21,449[0m WARNING] builder.download_and_prepare Reusing dataset super_glue (/home/zhangzhen/.cache/huggingface/datasets/super_glue/boolq/1.0.2/2fb163bca9085c1deb906aff20f00c242227ff704a4e8c9cfdfe820be3abfc83)
[[032m2021-11-26 09:41:43,820[0m WARNING] load.get_module Using the latest cached version of the module from /home/zhangzhen/.cache/huggingface/modules/datasets_modules/datasets/super_glue/2fb163bca9085c1deb906aff20f00c242227ff704a4e8c9cfdfe820be3abfc83 (last modified on Sat Nov 13 16:41:52 2021) since it couldn't be found locally at super_glue., or remotely on the Hugging Face Hub.
[[032m2021-11-26 09:41:43,842[0m WARNING] builder.download_and_prepare Reusing dataset super_glue (/home/zhangzhen/.cache/huggingface/datasets/super_glue/boolq/1.0.2/2fb163bca9085c1deb906aff20f00c242227ff704a4e8c9cfdfe820be3abfc83)
[[032m2021-11-26 09:41:55,108[0m WARNING] load.get_module Using the latest cached version of the module from /home/zhangzhen/.cache/huggingface/modules/datasets_modules/datasets/super_glue/2fb163bca9085c1deb906aff20f00c242227ff704a4e8c9cfdfe820be3abfc83 (last modified on Sat Nov 13 16:41:52 2021) since it couldn't be found locally at super_glue., or remotely on the Hugging Face Hub.
[[032m2021-11-26 09:41:55,128[0m WARNING] builder.download_and_prepare Reusing dataset super_glue (/home/zhangzhen/.cache/huggingface/datasets/super_glue/boolq/1.0.2/2fb163bca9085c1deb906aff20f00c242227ff704a4e8c9cfdfe820be3abfc83)
[[032m2021-11-26 09:41:55,419[0m INFO] data_sampler.sample_per_label Selected examples [1168, 3653, 5575, 882, 8797, 5359, 6011, 5047, 2712, 8376, 1712, 4958, 2391, 418, 2325, 5819, 8964, 8495, 617, 4296, 3908, 6552, 6975, 3197, 7835, 5112, 9125, 7963, 4290, 1160, 8407, 7036, 6679, 3225, 899, 8174, 687, 6747, 1305, 2825, 2950, 6902, 1300, 7584, 6065, 8754, 1888, 7239, 3048, 4072, 8396, 6546, 8579, 8244, 1055, 3995, 2176, 1193, 8102, 7606, 1100, 7837, 7306, 7312]
[[032m2021-11-26 09:41:55,421[0m INFO] data_sampler.sample_per_label Selected examples [971, 143, 117, 638, 568, 231, 2553, 2546, 1464, 1910, 1508, 2018, 2504, 1517, 268, 964, 55, 2103, 348, 943, 2485, 1460, 3235, 63, 128, 2684, 2856, 486, 3016, 425, 812, 2548, 1288, 1835, 2498, 3206, 853, 559, 391, 1729, 1083, 367, 543, 1220, 3043, 1986, 665, 1069, 215, 1133, 1513, 2758, 1738, 3118, 841, 1037, 938, 695, 676, 921, 675, 1679, 1241, 2760]
[[032m2021-11-26 09:41:55,440[0m INFO] reproduciblity.set_seed Global seed set to 100
[[032m2021-11-26 09:42:40,836[0m INFO] prompt_base.from_file using template: {"placeholder":"text_a"} {"placeholder":"text_b", "shortenable":False, "post_processing": lambda x:x+"."} {"mask"}
[[032m2021-11-26 09:42:40,839[0m INFO] prompt_base.from_file using template: {"placeholder":"text_a"} {"placeholder":"text_b", "shortenable":False, "post_processing": lambda x:x+"."} {"mask"}
tokenizing: 0it [00:00, ?it/s]tokenizing: 20it [00:00, 170.57it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors
tokenizing: 48it [00:00, 227.95it/s]tokenizing: 64it [00:00, 206.35it/s]
tokenizing: 0it [00:00, ?it/s]tokenizing: 59it [00:00, 572.34it/s]tokenizing: 64it [00:00, 584.38it/s]
tokenizing: 0it [00:00, ?it/s]tokenizing: 34it [00:00, 321.33it/s]tokenizing: 81it [00:00, 401.38it/s]tokenizing: 122it [00:00, 313.98it/s]tokenizing: 156it [00:00, 261.42it/s]tokenizing: 187it [00:00, 274.00it/s]tokenizing: 216it [00:00, 277.83it/s]tokenizing: 273it [00:00, 360.38it/s]tokenizing: 319it [00:00, 387.88it/s]tokenizing: 360it [00:01, 362.43it/s]tokenizing: 402it [00:01, 377.68it/s]tokenizing: 441it [00:01, 354.05it/s]tokenizing: 479it [00:01, 360.14it/s]tokenizing: 518it [00:01, 361.24it/s]tokenizing: 555it [00:01, 350.37it/s]tokenizing: 591it [00:01, 349.28it/s]tokenizing: 636it [00:01, 371.76it/s]tokenizing: 674it [00:01, 368.52it/s]tokenizing: 712it [00:02, 347.09it/s]tokenizing: 748it [00:02, 205.56it/s]tokenizing: 809it [00:02, 281.09it/s]tokenizing: 864it [00:02, 337.45it/s]tokenizing: 936it [00:02, 425.33it/s]tokenizing: 999it [00:02, 473.14it/s]tokenizing: 1054it [00:02, 439.12it/s]tokenizing: 1104it [00:03, 385.56it/s]tokenizing: 1165it [00:03, 436.74it/s]tokenizing: 1235it [00:03, 501.58it/s]tokenizing: 1290it [00:03, 410.83it/s]tokenizing: 1337it [00:03, 391.98it/s]tokenizing: 1381it [00:03, 372.00it/s]tokenizing: 1421it [00:03, 337.01it/s]tokenizing: 1491it [00:04, 419.34it/s]tokenizing: 1560it [00:04, 485.88it/s]tokenizing: 1629it [00:04, 537.53it/s]tokenizing: 1695it [00:04, 570.40it/s]tokenizing: 1755it [00:04, 558.75it/s]tokenizing: 1813it [00:04, 537.05it/s]tokenizing: 1869it [00:04, 509.36it/s]tokenizing: 1927it [00:04, 526.99it/s]tokenizing: 1981it [00:04, 525.47it/s]tokenizing: 2051it [00:05, 572.39it/s]tokenizing: 2110it [00:05, 565.02it/s]tokenizing: 2169it [00:05, 571.98it/s]tokenizing: 2227it [00:05, 558.16it/s]tokenizing: 2292it [00:05, 584.27it/s]tokenizing: 2351it [00:05, 535.67it/s]tokenizing: 2406it [00:05, 523.59it/s]tokenizing: 2478it [00:05, 577.06it/s]tokenizing: 2538it [00:05, 578.65it/s]tokenizing: 2603it [00:05, 597.48it/s]tokenizing: 2664it [00:06, 498.63it/s]tokenizing: 2717it [00:06, 364.72it/s]tokenizing: 2761it [00:06, 341.34it/s]tokenizing: 2800it [00:06, 315.12it/s]tokenizing: 2835it [00:06, 285.31it/s]tokenizing: 2866it [00:07, 279.13it/s]tokenizing: 2918it [00:07, 323.61it/s]tokenizing: 2980it [00:07, 393.54it/s]tokenizing: 3038it [00:07, 432.53it/s]tokenizing: 3084it [00:07, 425.33it/s]tokenizing: 3137it [00:07, 452.70it/s]tokenizing: 3184it [00:07, 426.80it/s]tokenizing: 3252it [00:07, 494.47it/s]tokenizing: 3270it [00:07, 419.30it/s]
[[032m2021-11-26 09:44:12,242[0m INFO] cuda.model_to_device Using model parallel, spread across device map: {0: [0, 1, 2, 3, 4], 1: [5, 6, 7, 8, 9], 2: [10, 11, 12, 13, 14], 3: [15, 16, 17, 18, 19], 4: [20, 21, 22, 23]}
[[032m2021-11-26 09:44:12,255[0m INFO] main_.trainer Begin model tuning.
train epoch: 0:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 0:   0%|          | 0/8 [00:26<?, ?it/s, loss=0.985]train epoch: 0:  12%|â–ˆâ–Ž        | 1/8 [00:29<03:23, 29.06s/it, loss=0.985]train epoch: 0:  12%|â–ˆâ–Ž        | 1/8 [00:35<03:23, 29.06s/it, loss=0.932]train epoch: 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:35<01:35, 15.99s/it, loss=0.932]train epoch: 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:36<01:35, 15.99s/it, loss=0.75] train epoch: 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:36<00:44,  8.96s/it, loss=0.75]train epoch: 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:36<00:44,  8.96s/it, loss=1.52]train epoch: 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:37<00:22,  5.64s/it, loss=1.52]train epoch: 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:37<00:22,  5.64s/it, loss=0.843]train epoch: 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:37<00:11,  3.81s/it, loss=0.843]train epoch: 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:37<00:11,  3.81s/it, loss=0.829]train epoch: 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:38<00:05,  2.66s/it, loss=0.829]train epoch: 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:38<00:05,  2.66s/it, loss=0.497]train epoch: 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:38<00:01,  1.97s/it, loss=0.497]train epoch: 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:38<00:01,  1.97s/it, loss=1.03] train epoch: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:39<00:00,  1.52s/it, loss=1.03]train epoch: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:39<00:00,  4.89s/it, loss=1.03]
[[032m2021-11-26 09:44:51,411[0m INFO] trainer.training_epoch Training epoch 0, num_steps 8,  avg_loss: 0.9233, total_loss: 7.3865
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.07it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.05it/s]
[[032m2021-11-26 09:44:51,997[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 09:44:51,998[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:45:09,834[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:45:19,774[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 1:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 1:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.99]train epoch: 1:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.18it/s, loss=0.99]train epoch: 1:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.18it/s, loss=0.769]train epoch: 1:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=0.769]train epoch: 1:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=0.577]train epoch: 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.06it/s, loss=0.577]train epoch: 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.06it/s, loss=1.24] train epoch: 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.86it/s, loss=1.24]train epoch: 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.86it/s, loss=1.03]train epoch: 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.94it/s, loss=1.03]train epoch: 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.94it/s, loss=1.08]train epoch: 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.96it/s, loss=1.08]train epoch: 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.96it/s, loss=0.91]train epoch: 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.78it/s, loss=0.91]train epoch: 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.78it/s, loss=0.66]train epoch: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.57it/s, loss=0.66]train epoch: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.76it/s, loss=0.66]
[[032m2021-11-26 09:45:24,339[0m INFO] trainer.training_epoch Training epoch 1, num_steps 16,  avg_loss: 0.9073, total_loss: 7.2585
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.40it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.47it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.21it/s]
[[032m2021-11-26 09:45:26,545[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 09:45:26,545[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:45:44,601[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:45:56,306[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 2:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 2:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.77]train epoch: 2:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.09it/s, loss=0.77]train epoch: 2:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.09it/s, loss=1.27]train epoch: 2:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.18it/s, loss=1.27]train epoch: 2:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.18it/s, loss=0.857]train epoch: 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.85it/s, loss=0.857]train epoch: 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.85it/s, loss=0.641]train epoch: 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.88it/s, loss=0.641]train epoch: 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.88it/s, loss=0.499]train epoch: 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.10it/s, loss=0.499]train epoch: 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.10it/s, loss=1.11] train epoch: 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.34it/s, loss=1.11]train epoch: 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.34it/s, loss=0.822]train epoch: 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=0.822]train epoch: 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=1.22] train epoch: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.26it/s, loss=1.22]train epoch: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=1.22]
[[032m2021-11-26 09:46:00,059[0m INFO] trainer.training_epoch Training epoch 2, num_steps 24,  avg_loss: 0.8981, total_loss: 7.1849
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.68it/s]
[[032m2021-11-26 09:46:01,606[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 09:46:01,606[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:46:20,021[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:46:35,493[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 3:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 3:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.08]train epoch: 3:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:05,  1.40it/s, loss=1.08]train epoch: 3:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:05,  1.40it/s, loss=1.04]train epoch: 3:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.59it/s, loss=1.04]train epoch: 3:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.59it/s, loss=0.934]train epoch: 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.56it/s, loss=0.934]train epoch: 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.56it/s, loss=0.571]train epoch: 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.59it/s, loss=0.571]train epoch: 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:03<00:02,  1.59it/s, loss=0.959]train epoch: 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:02,  1.45it/s, loss=0.959]train epoch: 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:02,  1.45it/s, loss=0.655]train epoch: 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.62it/s, loss=0.655]train epoch: 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:04<00:01,  1.62it/s, loss=0.943]train epoch: 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.64it/s, loss=0.943]train epoch: 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.64it/s, loss=1.03] train epoch: 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.59it/s, loss=1.03]train epoch: 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.57it/s, loss=1.03]
[[032m2021-11-26 09:46:40,628[0m INFO] trainer.training_epoch Training epoch 3, num_steps 32,  avg_loss: 0.9021, total_loss: 7.2169
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.45it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.25it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.58it/s]
[[032m2021-11-26 09:46:41,113[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 09:46:41,113[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:46:58,938[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:47:09,254[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 4:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 4:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.676]train epoch: 4:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.09it/s, loss=0.676]train epoch: 4:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.09it/s, loss=0.589]train epoch: 4:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.24it/s, loss=0.589]train epoch: 4:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.24it/s, loss=1.55] train epoch: 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=1.55]train epoch: 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=0.51]train epoch: 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.70it/s, loss=0.51]train epoch: 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.70it/s, loss=1.04]train epoch: 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.69it/s, loss=1.04]train epoch: 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.69it/s, loss=1.02]train epoch: 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.68it/s, loss=1.02]train epoch: 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.68it/s, loss=1.07]train epoch: 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.67it/s, loss=1.07]train epoch: 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.67it/s, loss=0.853]train epoch: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.72it/s, loss=0.853]train epoch: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.77it/s, loss=0.853]
[[032m2021-11-26 09:47:13,807[0m INFO] trainer.training_epoch Training epoch 4, num_steps 40,  avg_loss: 0.9141, total_loss: 7.3130
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.25it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.99it/s]
[[032m2021-11-26 09:47:14,273[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 09:47:14,274[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:47:30,280[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 5:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 5:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.22]train epoch: 5:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.15it/s, loss=1.22]train epoch: 5:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.15it/s, loss=0.947]train epoch: 5:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.91it/s, loss=0.947]train epoch: 5:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.91it/s, loss=1]    train epoch: 5:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.82it/s, loss=1]train epoch: 5:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.82it/s, loss=0.708]train epoch: 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.62it/s, loss=0.708]train epoch: 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.62it/s, loss=0.648]train epoch: 5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.63it/s, loss=0.648]train epoch: 5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.63it/s, loss=0.884]train epoch: 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.50it/s, loss=0.884]train epoch: 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:04<00:01,  1.50it/s, loss=0.95] train epoch: 5:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.65it/s, loss=0.95]train epoch: 5:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.65it/s, loss=0.912]train epoch: 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.73it/s, loss=0.912]train epoch: 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.70it/s, loss=0.912]
[[032m2021-11-26 09:47:35,011[0m INFO] trainer.training_epoch Training epoch 5, num_steps 48,  avg_loss: 0.9095, total_loss: 7.2757
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.15it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.52it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.77it/s]
[[032m2021-11-26 09:47:35,488[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 09:47:35,489[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:47:54,797[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 6:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 6:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.09]train epoch: 6:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.86it/s, loss=1.09]train epoch: 6:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.86it/s, loss=0.5] train epoch: 6:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.77it/s, loss=0.5]train epoch: 6:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.77it/s, loss=0.582]train epoch: 6:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.68it/s, loss=0.582]train epoch: 6:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.68it/s, loss=1.34] train epoch: 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.59it/s, loss=1.34]train epoch: 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.59it/s, loss=1.17]train epoch: 6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.80it/s, loss=1.17]train epoch: 6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.80it/s, loss=1.07]train epoch: 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.53it/s, loss=1.07]train epoch: 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:04<00:01,  1.53it/s, loss=0.872]train epoch: 6:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.59it/s, loss=0.872]train epoch: 6:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.59it/s, loss=0.837]train epoch: 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.59it/s, loss=0.837]train epoch: 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s, loss=0.837]
[[032m2021-11-26 09:47:59,715[0m INFO] trainer.training_epoch Training epoch 6, num_steps 56,  avg_loss: 0.9337, total_loss: 7.4693
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.48it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.06it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.39it/s]
[[032m2021-11-26 09:48:00,282[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 09:48:00,282[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:48:17,168[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:48:28,250[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 7:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 7:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.05]train epoch: 7:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.03it/s, loss=1.05]train epoch: 7:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.03it/s, loss=0.571]train epoch: 7:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=0.571]train epoch: 7:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=0.47] train epoch: 7:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.42it/s, loss=0.47]train epoch: 7:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.42it/s, loss=1.11]train epoch: 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.65it/s, loss=1.11]train epoch: 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.65it/s, loss=0.643]train epoch: 7:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.73it/s, loss=0.643]train epoch: 7:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.73it/s, loss=0.73] train epoch: 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.69it/s, loss=0.73]train epoch: 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.69it/s, loss=0.807]train epoch: 7:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.68it/s, loss=0.807]train epoch: 7:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.68it/s, loss=1.18] train epoch: 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.75it/s, loss=1.18]train epoch: 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.71it/s, loss=1.18]
[[032m2021-11-26 09:48:32,954[0m INFO] trainer.training_epoch Training epoch 7, num_steps 64,  avg_loss: 0.8208, total_loss: 6.5664
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.42it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.11it/s]
[[032m2021-11-26 09:48:33,465[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 09:48:33,465[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:48:50,435[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:49:02,378[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 8:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 8:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.86]train epoch: 8:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.82it/s, loss=0.86]train epoch: 8:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  1.82it/s, loss=1.01]train epoch: 8:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.51it/s, loss=1.01]train epoch: 8:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.51it/s, loss=0.615]train epoch: 8:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.41it/s, loss=0.615]train epoch: 8:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.41it/s, loss=0.996]train epoch: 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.61it/s, loss=0.996]train epoch: 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.61it/s, loss=0.869]train epoch: 8:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.85it/s, loss=0.869]train epoch: 8:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.85it/s, loss=1.16] train epoch: 8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.88it/s, loss=1.16]train epoch: 8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.88it/s, loss=0.657]train epoch: 8:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.78it/s, loss=0.657]train epoch: 8:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.78it/s, loss=0.924]train epoch: 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.86it/s, loss=0.924]train epoch: 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.75it/s, loss=0.924]
[[032m2021-11-26 09:49:06,960[0m INFO] trainer.training_epoch Training epoch 8, num_steps 72,  avg_loss: 0.8859, total_loss: 7.0868
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.22it/s]
[[032m2021-11-26 09:49:09,468[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 09:49:09,469[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:49:27,212[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:49:39,506[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 9:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 9:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.931]train epoch: 9:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.99it/s, loss=0.931]train epoch: 9:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  1.99it/s, loss=1.26] train epoch: 9:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.61it/s, loss=1.26]train epoch: 9:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.61it/s, loss=0.678]train epoch: 9:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.95it/s, loss=0.678]train epoch: 9:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.95it/s, loss=0.645]train epoch: 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.55it/s, loss=0.645]train epoch: 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.55it/s, loss=1]    train epoch: 9:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.75it/s, loss=1]train epoch: 9:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.75it/s, loss=0.713]train epoch: 9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.70it/s, loss=0.713]train epoch: 9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.70it/s, loss=1.05] train epoch: 9:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.53it/s, loss=1.05]train epoch: 9:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.53it/s, loss=0.57]train epoch: 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.53it/s, loss=0.57]train epoch: 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.62it/s, loss=0.57]
[[032m2021-11-26 09:49:44,455[0m INFO] trainer.training_epoch Training epoch 9, num_steps 80,  avg_loss: 0.8559, total_loss: 6.8468
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.80it/s]
[[032m2021-11-26 09:49:46,104[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 09:49:46,104[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:50:03,945[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:50:14,534[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 10:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 10:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.695]train epoch: 10:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.04it/s, loss=0.695]train epoch: 10:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.04it/s, loss=0.828]train epoch: 10:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.73it/s, loss=0.828]train epoch: 10:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.73it/s, loss=0.554]train epoch: 10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.70it/s, loss=0.554]train epoch: 10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.70it/s, loss=0.484]train epoch: 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.74it/s, loss=0.484]train epoch: 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.74it/s, loss=1.02] train epoch: 10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.75it/s, loss=1.02]train epoch: 10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.75it/s, loss=0.688]train epoch: 10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.68it/s, loss=0.688]train epoch: 10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.68it/s, loss=1.23] train epoch: 10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.79it/s, loss=1.23]train epoch: 10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.79it/s, loss=0.764]train epoch: 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.48it/s, loss=0.764]train epoch: 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s, loss=0.764]
[[032m2021-11-26 09:50:19,465[0m INFO] trainer.training_epoch Training epoch 10, num_steps 88,  avg_loss: 0.7828, total_loss: 6.2622
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.83it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.29it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.67it/s]
[[032m2021-11-26 09:50:21,235[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:50:21,235[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:50:37,440[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:50:48,072[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 11:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 11:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.641]train epoch: 11:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.06it/s, loss=0.641]train epoch: 11:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.06it/s, loss=0.909]train epoch: 11:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.12it/s, loss=0.909]train epoch: 11:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.12it/s, loss=0.804]train epoch: 11:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.87it/s, loss=0.804]train epoch: 11:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.87it/s, loss=0.691]train epoch: 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.89it/s, loss=0.691]train epoch: 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.89it/s, loss=0.633]train epoch: 11:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.98it/s, loss=0.633]train epoch: 11:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.98it/s, loss=1.42] train epoch: 11:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.02it/s, loss=1.42]train epoch: 11:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.02it/s, loss=0.877]train epoch: 11:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.05it/s, loss=0.877]train epoch: 11:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.05it/s, loss=0.987]train epoch: 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.01it/s, loss=0.987]train epoch: 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.00it/s, loss=0.987]
[[032m2021-11-26 09:50:52,127[0m INFO] trainer.training_epoch Training epoch 11, num_steps 96,  avg_loss: 0.8706, total_loss: 6.9647
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.16it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.97it/s]
[[032m2021-11-26 09:50:52,721[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:50:52,722[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:51:06,700[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:51:16,416[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 12:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 12:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.887]train epoch: 12:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=0.887]train epoch: 12:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=0.871]train epoch: 12:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.03it/s, loss=0.871]train epoch: 12:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.03it/s, loss=0.679]train epoch: 12:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.90it/s, loss=0.679]train epoch: 12:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.90it/s, loss=0.855]train epoch: 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.70it/s, loss=0.855]train epoch: 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.70it/s, loss=0.802]train epoch: 12:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.88it/s, loss=0.802]train epoch: 12:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.88it/s, loss=0.986]train epoch: 12:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.57it/s, loss=0.986]train epoch: 12:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.57it/s, loss=0.94] train epoch: 12:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.59it/s, loss=0.94]train epoch: 12:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.59it/s, loss=0.902]train epoch: 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.57it/s, loss=0.902]train epoch: 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.68it/s, loss=0.902]
[[032m2021-11-26 09:51:21,204[0m INFO] trainer.training_epoch Training epoch 12, num_steps 104,  avg_loss: 0.8654, total_loss: 6.9228
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.32it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.01it/s]
[[032m2021-11-26 09:51:21,749[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 09:51:21,749[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:51:37,724[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 13:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 13:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.955]train epoch: 13:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.05it/s, loss=0.955]train epoch: 13:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.05it/s, loss=0.633]train epoch: 13:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.15it/s, loss=0.633]train epoch: 13:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.15it/s, loss=0.632]train epoch: 13:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.20it/s, loss=0.632]train epoch: 13:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.20it/s, loss=0.708]train epoch: 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.08it/s, loss=0.708]train epoch: 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.08it/s, loss=0.82] train epoch: 13:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.05it/s, loss=0.82]train epoch: 13:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.05it/s, loss=0.808]train epoch: 13:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.25it/s, loss=0.808]train epoch: 13:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.25it/s, loss=0.877]train epoch: 13:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s, loss=0.877]train epoch: 13:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s, loss=0.634]train epoch: 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=0.634]train epoch: 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.10it/s, loss=0.634]
[[032m2021-11-26 09:51:41,552[0m INFO] trainer.training_epoch Training epoch 13, num_steps 112,  avg_loss: 0.7583, total_loss: 6.0661
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.44it/s]
[[032m2021-11-26 09:51:42,062[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 09:51:42,062[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:51:57,543[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 14:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 14:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.771]train epoch: 14:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:05,  1.34it/s, loss=0.771]train epoch: 14:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:05,  1.34it/s, loss=0.938]train epoch: 14:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.38it/s, loss=0.938]train epoch: 14:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.38it/s, loss=0.775]train epoch: 14:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.61it/s, loss=0.775]train epoch: 14:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.61it/s, loss=0.963]train epoch: 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.71it/s, loss=0.963]train epoch: 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.71it/s, loss=0.728]train epoch: 14:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.62it/s, loss=0.728]train epoch: 14:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.62it/s, loss=0.707]train epoch: 14:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.80it/s, loss=0.707]train epoch: 14:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.80it/s, loss=0.723]train epoch: 14:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.78it/s, loss=0.723]train epoch: 14:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.78it/s, loss=0.715]train epoch: 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s, loss=0.715]train epoch: 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s, loss=0.715]
[[032m2021-11-26 09:52:02,461[0m INFO] trainer.training_epoch Training epoch 14, num_steps 120,  avg_loss: 0.7900, total_loss: 6.3198
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.73it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.86it/s]
[[032m2021-11-26 09:52:02,999[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:52:03,004[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:52:18,639[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:52:27,959[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 15:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 15:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.706]train epoch: 15:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=0.706]train epoch: 15:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  1.87it/s, loss=0.832]train epoch: 15:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.55it/s, loss=0.832]train epoch: 15:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.55it/s, loss=0.612]train epoch: 15:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.86it/s, loss=0.612]train epoch: 15:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.86it/s, loss=0.579]train epoch: 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.78it/s, loss=0.579]train epoch: 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.78it/s, loss=0.588]train epoch: 15:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.58it/s, loss=0.588]train epoch: 15:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.58it/s, loss=1.1]  train epoch: 15:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.60it/s, loss=1.1]train epoch: 15:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:04<00:01,  1.60it/s, loss=0.947]train epoch: 15:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.68it/s, loss=0.947]train epoch: 15:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.68it/s, loss=0.83] train epoch: 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.82it/s, loss=0.83]train epoch: 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.73it/s, loss=0.83]
[[032m2021-11-26 09:52:32,593[0m INFO] trainer.training_epoch Training epoch 15, num_steps 128,  avg_loss: 0.7739, total_loss: 6.1914
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.61it/s]
[[032m2021-11-26 09:52:32,993[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 09:52:32,993[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:52:48,362[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:52:57,688[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 16:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 16:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.752]train epoch: 16:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.55it/s, loss=0.752]train epoch: 16:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.55it/s, loss=0.79] train epoch: 16:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.88it/s, loss=0.79]train epoch: 16:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.88it/s, loss=0.49]train epoch: 16:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.16it/s, loss=0.49]train epoch: 16:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.16it/s, loss=0.523]train epoch: 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.24it/s, loss=0.523]train epoch: 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.24it/s, loss=0.755]train epoch: 16:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.24it/s, loss=0.755]train epoch: 16:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.24it/s, loss=0.517]train epoch: 16:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.18it/s, loss=0.517]train epoch: 16:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.18it/s, loss=0.783]train epoch: 16:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.01it/s, loss=0.783]train epoch: 16:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.01it/s, loss=0.615]train epoch: 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=0.615]train epoch: 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.13it/s, loss=0.615]
[[032m2021-11-26 09:53:01,477[0m INFO] trainer.training_epoch Training epoch 16, num_steps 136,  avg_loss: 0.6530, total_loss: 5.2242
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]
[[032m2021-11-26 09:53:01,909[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.609375)])
[[032m2021-11-26 09:53:01,909[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:53:15,256[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:53:22,474[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 17:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 17:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.928]train epoch: 17:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.67it/s, loss=0.928]train epoch: 17:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.67it/s, loss=0.749]train epoch: 17:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.14it/s, loss=0.749]train epoch: 17:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.14it/s, loss=0.665]train epoch: 17:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=0.665]train epoch: 17:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=0.649]train epoch: 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=0.649]train epoch: 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=1.05] train epoch: 17:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=1.05]train epoch: 17:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.78it/s, loss=0.685]train epoch: 17:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=0.685]train epoch: 17:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=0.72] train epoch: 17:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=0.72]train epoch: 17:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.78it/s, loss=0.743]train epoch: 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=0.743]train epoch: 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.45it/s, loss=0.743]
[[032m2021-11-26 09:53:25,781[0m INFO] trainer.training_epoch Training epoch 17, num_steps 144,  avg_loss: 0.7740, total_loss: 6.1924
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.74it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.40it/s]
[[032m2021-11-26 09:53:27,908[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.609375)])
[[032m2021-11-26 09:53:27,909[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:53:41,304[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 09:53:50,270[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 18:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 18:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.603]train epoch: 18:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.63it/s, loss=0.603]train epoch: 18:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.63it/s, loss=0.666]train epoch: 18:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:03,  1.99it/s, loss=0.666]train epoch: 18:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.99it/s, loss=0.475]train epoch: 18:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.93it/s, loss=0.475]train epoch: 18:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.93it/s, loss=0.553]train epoch: 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.13it/s, loss=0.553]train epoch: 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.13it/s, loss=0.705]train epoch: 18:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.27it/s, loss=0.705]train epoch: 18:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.27it/s, loss=0.467]train epoch: 18:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.89it/s, loss=0.467]train epoch: 18:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.89it/s, loss=0.883]train epoch: 18:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.86it/s, loss=0.883]train epoch: 18:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.86it/s, loss=0.689]train epoch: 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.06it/s, loss=0.689]train epoch: 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=0.689]
[[032m2021-11-26 09:53:54,210[0m INFO] trainer.training_epoch Training epoch 18, num_steps 152,  avg_loss: 0.6300, total_loss: 5.0401
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.82it/s]
[[032m2021-11-26 09:53:54,821[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 09:53:54,822[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:54:08,107[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 19:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 19:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.603]train epoch: 19:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.41it/s, loss=0.603]train epoch: 19:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.41it/s, loss=0.707]train epoch: 19:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.51it/s, loss=0.707]train epoch: 19:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.51it/s, loss=0.578]train epoch: 19:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.578]train epoch: 19:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.756]train epoch: 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=0.756]train epoch: 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=0.6]  train epoch: 19:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.59it/s, loss=0.6]train epoch: 19:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.59it/s, loss=0.894]train epoch: 19:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.33it/s, loss=0.894]train epoch: 19:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.33it/s, loss=0.553]train epoch: 19:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.16it/s, loss=0.553]train epoch: 19:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.16it/s, loss=0.564]train epoch: 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.38it/s, loss=0.564]train epoch: 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.38it/s, loss=0.564]
[[032m2021-11-26 09:54:11,511[0m INFO] trainer.training_epoch Training epoch 19, num_steps 160,  avg_loss: 0.6567, total_loss: 5.2537
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.81it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.61it/s]
[[032m2021-11-26 09:54:11,955[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 09:54:11,955[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:54:25,536[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 20:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 20:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.501]train epoch: 20:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.66it/s, loss=0.501]train epoch: 20:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.66it/s, loss=0.618]train epoch: 20:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.40it/s, loss=0.618]train epoch: 20:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.40it/s, loss=0.484]train epoch: 20:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.59it/s, loss=0.484]train epoch: 20:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.59it/s, loss=0.827]train epoch: 20:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.97it/s, loss=0.827]train epoch: 20:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.97it/s, loss=0.625]train epoch: 20:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.89it/s, loss=0.625]train epoch: 20:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.89it/s, loss=0.649]train epoch: 20:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.81it/s, loss=0.649]train epoch: 20:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.81it/s, loss=0.635]train epoch: 20:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.08it/s, loss=0.635]train epoch: 20:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.08it/s, loss=0.457]train epoch: 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.32it/s, loss=0.457]train epoch: 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.97it/s, loss=0.457]
[[032m2021-11-26 09:54:29,628[0m INFO] trainer.training_epoch Training epoch 20, num_steps 168,  avg_loss: 0.5996, total_loss: 4.7964
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.84it/s]
[[032m2021-11-26 09:54:30,058[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 09:54:30,059[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:54:41,163[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 21:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 21:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.638]train epoch: 21:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=0.638]train epoch: 21:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=0.552]train epoch: 21:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.87it/s, loss=0.552]train epoch: 21:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.87it/s, loss=0.695]train epoch: 21:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.38it/s, loss=0.695]train epoch: 21:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.38it/s, loss=0.458]train epoch: 21:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.23it/s, loss=0.458]train epoch: 21:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.23it/s, loss=0.385]train epoch: 21:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.11it/s, loss=0.385]train epoch: 21:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.11it/s, loss=0.701]train epoch: 21:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.30it/s, loss=0.701]train epoch: 21:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.30it/s, loss=0.589]train epoch: 21:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=0.589]train epoch: 21:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=0.719]train epoch: 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.05it/s, loss=0.719]train epoch: 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=0.719]
[[032m2021-11-26 09:54:44,793[0m INFO] trainer.training_epoch Training epoch 21, num_steps 176,  avg_loss: 0.5920, total_loss: 4.7356
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.80it/s]
[[032m2021-11-26 09:54:45,322[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:54:45,322[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:54:59,367[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 22:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 22:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.615]train epoch: 22:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.32it/s, loss=0.615]train epoch: 22:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.32it/s, loss=0.488]train epoch: 22:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.72it/s, loss=0.488]train epoch: 22:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.72it/s, loss=0.612]train epoch: 22:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=0.612]train epoch: 22:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=0.689]train epoch: 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.38it/s, loss=0.689]train epoch: 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.38it/s, loss=0.556]train epoch: 22:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.25it/s, loss=0.556]train epoch: 22:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.25it/s, loss=0.589]train epoch: 22:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.10it/s, loss=0.589]train epoch: 22:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.10it/s, loss=0.485]train epoch: 22:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.485]train epoch: 22:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=1.27] train epoch: 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.36it/s, loss=1.27]train epoch: 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.34it/s, loss=1.27]
[[032m2021-11-26 09:55:02,796[0m INFO] trainer.training_epoch Training epoch 22, num_steps 184,  avg_loss: 0.6631, total_loss: 5.3048
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.88it/s]
[[032m2021-11-26 09:55:03,155[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:55:03,155[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:55:15,102[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 23:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 23:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.766]train epoch: 23:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.95it/s, loss=0.766]train epoch: 23:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.95it/s, loss=0.634]train epoch: 23:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.33it/s, loss=0.634]train epoch: 23:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.33it/s, loss=0.594]train epoch: 23:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.51it/s, loss=0.594]train epoch: 23:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.51it/s, loss=0.436]train epoch: 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.25it/s, loss=0.436]train epoch: 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.25it/s, loss=0.609]train epoch: 23:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.90it/s, loss=0.609]train epoch: 23:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.90it/s, loss=0.627]train epoch: 23:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.86it/s, loss=0.627]train epoch: 23:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.86it/s, loss=0.521]train epoch: 23:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.17it/s, loss=0.521]train epoch: 23:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.17it/s, loss=0.574]train epoch: 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.15it/s, loss=0.574]train epoch: 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.12it/s, loss=0.574]
[[032m2021-11-26 09:55:18,886[0m INFO] trainer.training_epoch Training epoch 23, num_steps 192,  avg_loss: 0.5952, total_loss: 4.7620
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29it/s]
[[032m2021-11-26 09:55:19,385[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 09:55:19,385[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:55:31,276[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 24:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 24:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.445]train epoch: 24:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.15it/s, loss=0.445]train epoch: 24:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.15it/s, loss=0.657]train epoch: 24:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.83it/s, loss=0.657]train epoch: 24:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.83it/s, loss=0.398]train epoch: 24:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.398]train epoch: 24:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.583]train epoch: 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=0.583]train epoch: 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.16it/s, loss=0.58] train epoch: 24:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.58]train epoch: 24:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.623]train epoch: 24:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.13it/s, loss=0.623]train epoch: 24:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.13it/s, loss=0.486]train epoch: 24:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.13it/s, loss=0.486]train epoch: 24:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.13it/s, loss=0.573]train epoch: 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=0.573]train epoch: 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.20it/s, loss=0.573]
[[032m2021-11-26 09:55:34,931[0m INFO] trainer.training_epoch Training epoch 24, num_steps 200,  avg_loss: 0.5431, total_loss: 4.3452
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.93it/s]
[[032m2021-11-26 09:55:37,764[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 09:55:37,765[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:55:51,201[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 25:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 25:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.496]train epoch: 25:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=0.496]train epoch: 25:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=0.392]train epoch: 25:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.82it/s, loss=0.392]train epoch: 25:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.82it/s, loss=0.601]train epoch: 25:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.18it/s, loss=0.601]train epoch: 25:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.18it/s, loss=0.352]train epoch: 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.43it/s, loss=0.352]train epoch: 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.43it/s, loss=0.42] train epoch: 25:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.88it/s, loss=0.42]train epoch: 25:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.88it/s, loss=0.601]train epoch: 25:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.97it/s, loss=0.601]train epoch: 25:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.97it/s, loss=0.489]train epoch: 25:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.10it/s, loss=0.489]train epoch: 25:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.10it/s, loss=0.537]train epoch: 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=0.537]train epoch: 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=0.537]
[[032m2021-11-26 09:55:55,149[0m INFO] trainer.training_epoch Training epoch 25, num_steps 208,  avg_loss: 0.4859, total_loss: 3.8875
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.56it/s]
[[032m2021-11-26 09:55:55,802[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:55:55,803[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:56:08,036[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 26:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 26:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.427]train epoch: 26:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.56it/s, loss=0.427]train epoch: 26:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.56it/s, loss=0.624]train epoch: 26:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.63it/s, loss=0.624]train epoch: 26:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.63it/s, loss=0.503]train epoch: 26:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.503]train epoch: 26:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.53] train epoch: 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.18it/s, loss=0.53]train epoch: 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.18it/s, loss=0.425]train epoch: 26:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=0.425]train epoch: 26:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=0.497]train epoch: 26:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.02it/s, loss=0.497]train epoch: 26:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.02it/s, loss=0.44] train epoch: 26:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.99it/s, loss=0.44]train epoch: 26:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.99it/s, loss=0.489]train epoch: 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.17it/s, loss=0.489]train epoch: 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=0.489]
[[032m2021-11-26 09:56:11,970[0m INFO] trainer.training_epoch Training epoch 26, num_steps 216,  avg_loss: 0.4918, total_loss: 3.9343
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.69it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.04it/s]
[[032m2021-11-26 09:56:12,318[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:56:12,318[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:56:25,526[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 27:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 27:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.512]train epoch: 27:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.78it/s, loss=0.512]train epoch: 27:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.78it/s, loss=0.462]train epoch: 27:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.79it/s, loss=0.462]train epoch: 27:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.79it/s, loss=0.564]train epoch: 27:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.99it/s, loss=0.564]train epoch: 27:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.99it/s, loss=0.374]train epoch: 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.18it/s, loss=0.374]train epoch: 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.18it/s, loss=0.511]train epoch: 27:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.38it/s, loss=0.511]train epoch: 27:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.38it/s, loss=0.753]train epoch: 27:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.19it/s, loss=0.753]train epoch: 27:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.19it/s, loss=0.569]train epoch: 27:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.92it/s, loss=0.569]train epoch: 27:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.92it/s, loss=0.341]train epoch: 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.99it/s, loss=0.341]train epoch: 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.03it/s, loss=0.341]
[[032m2021-11-26 09:56:29,474[0m INFO] trainer.training_epoch Training epoch 27, num_steps 224,  avg_loss: 0.5107, total_loss: 4.0855
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.85it/s]
[[032m2021-11-26 09:56:29,943[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:56:29,943[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:56:43,739[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 28:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 28:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.359]train epoch: 28:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.78it/s, loss=0.359]train epoch: 28:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.78it/s, loss=0.492]train epoch: 28:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.37it/s, loss=0.492]train epoch: 28:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.37it/s, loss=0.423]train epoch: 28:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.06it/s, loss=0.423]train epoch: 28:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.06it/s, loss=0.802]train epoch: 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.01it/s, loss=0.802]train epoch: 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=0.461]train epoch: 28:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.26it/s, loss=0.461]train epoch: 28:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.26it/s, loss=0.634]train epoch: 28:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=0.634]train epoch: 28:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=0.24] train epoch: 28:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=0.24]train epoch: 28:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=0.472]train epoch: 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.41it/s, loss=0.472]train epoch: 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.32it/s, loss=0.472]
[[032m2021-11-26 09:56:47,200[0m INFO] trainer.training_epoch Training epoch 28, num_steps 232,  avg_loss: 0.4853, total_loss: 3.8823
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.33it/s]
[[032m2021-11-26 09:56:47,604[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:56:47,604[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:56:57,859[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 29:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 29:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.339]train epoch: 29:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=0.339]train epoch: 29:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=0.464]train epoch: 29:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.02it/s, loss=0.464]train epoch: 29:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.02it/s, loss=0.352]train epoch: 29:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.03it/s, loss=0.352]train epoch: 29:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.03it/s, loss=0.41] train epoch: 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.94it/s, loss=0.41]train epoch: 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.94it/s, loss=0.47]train epoch: 29:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=0.47]train epoch: 29:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=0.384]train epoch: 29:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.09it/s, loss=0.384]train epoch: 29:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.09it/s, loss=0.381]train epoch: 29:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=0.381]train epoch: 29:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=0.434]train epoch: 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.36it/s, loss=0.434]train epoch: 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.72it/s, loss=0.434]
[[032m2021-11-26 09:57:00,810[0m INFO] trainer.training_epoch Training epoch 29, num_steps 240,  avg_loss: 0.4042, total_loss: 3.2335
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.45it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.74it/s]
[[032m2021-11-26 09:57:01,296[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 09:57:01,297[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:57:12,762[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 30:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 30:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.642]train epoch: 30:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.79it/s, loss=0.642]train epoch: 30:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.79it/s, loss=0.453]train epoch: 30:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.92it/s, loss=0.453]train epoch: 30:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.92it/s, loss=0.275]train epoch: 30:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.27it/s, loss=0.275]train epoch: 30:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.27it/s, loss=0.376]train epoch: 30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.35it/s, loss=0.376]train epoch: 30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.35it/s, loss=0.418]train epoch: 30:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.07it/s, loss=0.418]train epoch: 30:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.07it/s, loss=0.5]  train epoch: 30:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.80it/s, loss=0.5]train epoch: 30:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.80it/s, loss=0.309]train epoch: 30:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.97it/s, loss=0.309]train epoch: 30:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.97it/s, loss=0.407]train epoch: 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.99it/s, loss=0.407]train epoch: 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=0.407]
[[032m2021-11-26 09:57:16,761[0m INFO] trainer.training_epoch Training epoch 30, num_steps 248,  avg_loss: 0.4223, total_loss: 3.3787
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.18it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.39it/s]
[[032m2021-11-26 09:57:17,276[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:57:17,276[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:57:29,215[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 31:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 31:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.412]train epoch: 31:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.83it/s, loss=0.412]train epoch: 31:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.83it/s, loss=0.18] train epoch: 31:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.90it/s, loss=0.18]train epoch: 31:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.90it/s, loss=0.402]train epoch: 31:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.90it/s, loss=0.402]train epoch: 31:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.90it/s, loss=0.386]train epoch: 31:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.99it/s, loss=0.386]train epoch: 31:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.99it/s, loss=0.368]train epoch: 31:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=0.368]train epoch: 31:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=0.57] train epoch: 31:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.25it/s, loss=0.57]train epoch: 31:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.25it/s, loss=0.307]train epoch: 31:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.12it/s, loss=0.307]train epoch: 31:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.12it/s, loss=0.339]train epoch: 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=0.339]train epoch: 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.12it/s, loss=0.339]
[[032m2021-11-26 09:57:33,011[0m INFO] trainer.training_epoch Training epoch 31, num_steps 256,  avg_loss: 0.3705, total_loss: 2.9637
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.14it/s]
[[032m2021-11-26 09:57:33,357[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:57:33,357[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:57:44,152[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 32:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 32:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.483]train epoch: 32:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.03it/s, loss=0.483]train epoch: 32:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.03it/s, loss=0.298]train epoch: 32:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.68it/s, loss=0.298]train epoch: 32:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.68it/s, loss=0.373]train epoch: 32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=0.373]train epoch: 32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=0.406]train epoch: 32:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.18it/s, loss=0.406]train epoch: 32:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.18it/s, loss=0.471]train epoch: 32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.93it/s, loss=0.471]train epoch: 32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.93it/s, loss=0.276]train epoch: 32:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.90it/s, loss=0.276]train epoch: 32:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.90it/s, loss=0.217]train epoch: 32:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.89it/s, loss=0.217]train epoch: 32:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.89it/s, loss=0.269]train epoch: 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=0.269]train epoch: 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.00it/s, loss=0.269]
[[032m2021-11-26 09:57:48,159[0m INFO] trainer.training_epoch Training epoch 32, num_steps 264,  avg_loss: 0.3491, total_loss: 2.7928
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.79it/s]
[[032m2021-11-26 09:57:48,544[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:57:48,544[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:58:00,835[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 33:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 33:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.309]train epoch: 33:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=0.309]train epoch: 33:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=0.399]train epoch: 33:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.44it/s, loss=0.399]train epoch: 33:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.44it/s, loss=0.308]train epoch: 33:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.51it/s, loss=0.308]train epoch: 33:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.51it/s, loss=0.44] train epoch: 33:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.21it/s, loss=0.44]train epoch: 33:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.21it/s, loss=0.295]train epoch: 33:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=0.295]train epoch: 33:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=0.1]  train epoch: 33:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=0.1]train epoch: 33:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=0.33]train epoch: 33:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.33]train epoch: 33:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.485]train epoch: 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=0.485]train epoch: 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.19it/s, loss=0.485]
[[032m2021-11-26 09:58:04,499[0m INFO] trainer.training_epoch Training epoch 33, num_steps 272,  avg_loss: 0.3334, total_loss: 2.6670
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.12it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.49it/s]
[[032m2021-11-26 09:58:04,903[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:58:04,903[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:58:17,571[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 34:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 34:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.208]train epoch: 34:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.71it/s, loss=0.208]train epoch: 34:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.71it/s, loss=0.454]train epoch: 34:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:03,  1.94it/s, loss=0.454]train epoch: 34:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.94it/s, loss=0.419]train epoch: 34:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.80it/s, loss=0.419]train epoch: 34:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.80it/s, loss=0.271]train epoch: 34:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.10it/s, loss=0.271]train epoch: 34:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.10it/s, loss=0.233]train epoch: 34:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.35it/s, loss=0.233]train epoch: 34:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.35it/s, loss=0.333]train epoch: 34:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.52it/s, loss=0.333]train epoch: 34:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.52it/s, loss=0.272]train epoch: 34:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.76it/s, loss=0.272]train epoch: 34:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.76it/s, loss=0.171]train epoch: 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.68it/s, loss=0.171]train epoch: 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.42it/s, loss=0.171]
[[032m2021-11-26 09:58:20,893[0m INFO] trainer.training_epoch Training epoch 34, num_steps 280,  avg_loss: 0.2952, total_loss: 2.3614
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.90it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.44it/s]
[[032m2021-11-26 09:58:23,544[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 09:58:23,545[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:58:35,261[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 35:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 35:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.284]train epoch: 35:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.91it/s, loss=0.284]train epoch: 35:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.91it/s, loss=0.314]train epoch: 35:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.03it/s, loss=0.314]train epoch: 35:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.03it/s, loss=0.373]train epoch: 35:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=0.373]train epoch: 35:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=0.336]train epoch: 35:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.19it/s, loss=0.336]train epoch: 35:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.19it/s, loss=0.445]train epoch: 35:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.49it/s, loss=0.445]train epoch: 35:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.49it/s, loss=0.2]  train epoch: 35:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.51it/s, loss=0.2]train epoch: 35:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.51it/s, loss=0.183]train epoch: 35:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s, loss=0.183]train epoch: 35:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s, loss=0.305]train epoch: 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.22it/s, loss=0.305]train epoch: 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=0.305]
[[032m2021-11-26 09:58:38,905[0m INFO] trainer.training_epoch Training epoch 35, num_steps 288,  avg_loss: 0.3050, total_loss: 2.4398
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.08it/s]
[[032m2021-11-26 09:58:39,314[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:58:39,314[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:58:51,199[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 36:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 36:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.279]train epoch: 36:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.77it/s, loss=0.279]train epoch: 36:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.77it/s, loss=0.148]train epoch: 36:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.36it/s, loss=0.148]train epoch: 36:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.36it/s, loss=0.269]train epoch: 36:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.39it/s, loss=0.269]train epoch: 36:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.39it/s, loss=0.321]train epoch: 36:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.24it/s, loss=0.321]train epoch: 36:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.24it/s, loss=0.253]train epoch: 36:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.27it/s, loss=0.253]train epoch: 36:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.27it/s, loss=0.413]train epoch: 36:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.48it/s, loss=0.413]train epoch: 36:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.48it/s, loss=0.345]train epoch: 36:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.44it/s, loss=0.345]train epoch: 36:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.44it/s, loss=0.128]train epoch: 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.06it/s, loss=0.128]train epoch: 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=0.128]
[[032m2021-11-26 09:58:54,847[0m INFO] trainer.training_epoch Training epoch 36, num_steps 296,  avg_loss: 0.2697, total_loss: 2.1573
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.52it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.09it/s]
[[032m2021-11-26 09:58:55,326[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 09:58:55,327[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:59:06,902[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 37:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 37:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.263]train epoch: 37:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.10it/s, loss=0.263]train epoch: 37:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.10it/s, loss=0.172]train epoch: 37:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.67it/s, loss=0.172]train epoch: 37:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.67it/s, loss=0.354]train epoch: 37:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.04it/s, loss=0.354]train epoch: 37:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.04it/s, loss=0.186]train epoch: 37:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.23it/s, loss=0.186]train epoch: 37:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.23it/s, loss=0.394]train epoch: 37:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=0.394]train epoch: 37:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=0.16] train epoch: 37:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=0.16]train epoch: 37:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=0.145]train epoch: 37:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.58it/s, loss=0.145]train epoch: 37:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.58it/s, loss=0.133]train epoch: 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.31it/s, loss=0.133]train epoch: 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.27it/s, loss=0.133]
[[032m2021-11-26 09:59:10,450[0m INFO] trainer.training_epoch Training epoch 37, num_steps 304,  avg_loss: 0.2260, total_loss: 1.8080
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.51it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.47it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.51it/s]
[[032m2021-11-26 09:59:10,890[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:59:10,890[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:59:23,840[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 38:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 38:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.111]train epoch: 38:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=0.111]train epoch: 38:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  1.87it/s, loss=0.185]train epoch: 38:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.51it/s, loss=0.185]train epoch: 38:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.51it/s, loss=0.192]train epoch: 38:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.95it/s, loss=0.192]train epoch: 38:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.95it/s, loss=0.227]train epoch: 38:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=0.227]train epoch: 38:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=0.127]train epoch: 38:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.92it/s, loss=0.127]train epoch: 38:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.92it/s, loss=0.202]train epoch: 38:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.17it/s, loss=0.202]train epoch: 38:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.17it/s, loss=0.159]train epoch: 38:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.159]train epoch: 38:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.179]train epoch: 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.53it/s, loss=0.179]train epoch: 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.17it/s, loss=0.179]
[[032m2021-11-26 09:59:27,544[0m INFO] trainer.training_epoch Training epoch 38, num_steps 312,  avg_loss: 0.1729, total_loss: 1.3835
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.97it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.19it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.09it/s]
[[032m2021-11-26 09:59:28,006[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 09:59:28,006[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 09:59:42,965[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 39:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 39:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.192]train epoch: 39:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.08it/s, loss=0.192]train epoch: 39:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.08it/s, loss=0.425]train epoch: 39:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.64it/s, loss=0.425]train epoch: 39:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.64it/s, loss=0.134]train epoch: 39:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.58it/s, loss=0.134]train epoch: 39:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.58it/s, loss=0.101]train epoch: 39:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.15it/s, loss=0.101]train epoch: 39:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.15it/s, loss=0.162]train epoch: 39:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.96it/s, loss=0.162]train epoch: 39:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.96it/s, loss=0.328]train epoch: 39:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.16it/s, loss=0.328]train epoch: 39:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.16it/s, loss=0.227]train epoch: 39:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.04it/s, loss=0.227]train epoch: 39:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.04it/s, loss=0.0714]train epoch: 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.93it/s, loss=0.0714]train epoch: 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.07it/s, loss=0.0714]
[[032m2021-11-26 09:59:46,848[0m INFO] trainer.training_epoch Training epoch 39, num_steps 320,  avg_loss: 0.2048, total_loss: 1.6386
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.49it/s]
[[032m2021-11-26 09:59:47,341[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 09:59:47,341[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:00:01,383[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 40:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 40:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0902]train epoch: 40:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.80it/s, loss=0.0902]train epoch: 40:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.80it/s, loss=0.156] train epoch: 40:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=0.156]train epoch: 40:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=0.051]train epoch: 40:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.98it/s, loss=0.051]train epoch: 40:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.98it/s, loss=0.145]train epoch: 40:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=0.145]train epoch: 40:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=0.14] train epoch: 40:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=0.14]train epoch: 40:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=0.075]train epoch: 40:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.78it/s, loss=0.075]train epoch: 40:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.78it/s, loss=0.157]train epoch: 40:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  1.88it/s, loss=0.157]train epoch: 40:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.88it/s, loss=0.0888]train epoch: 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.96it/s, loss=0.0888]train epoch: 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.32it/s, loss=0.0888]
[[032m2021-11-26 10:00:04,836[0m INFO] trainer.training_epoch Training epoch 40, num_steps 328,  avg_loss: 0.1129, total_loss: 0.9036
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.71it/s]
[[032m2021-11-26 10:00:05,192[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 10:00:05,193[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:00:18,320[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 41:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 41:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0776]train epoch: 41:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.06it/s, loss=0.0776]train epoch: 41:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.06it/s, loss=0.21]  train epoch: 41:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.04it/s, loss=0.21]train epoch: 41:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.04it/s, loss=0.118]train epoch: 41:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.72it/s, loss=0.118]train epoch: 41:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.72it/s, loss=0.0995]train epoch: 41:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.84it/s, loss=0.0995]train epoch: 41:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.84it/s, loss=0.172] train epoch: 41:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.80it/s, loss=0.172]train epoch: 41:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.80it/s, loss=0.0735]train epoch: 41:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.67it/s, loss=0.0735]train epoch: 41:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.67it/s, loss=0.153] train epoch: 41:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.73it/s, loss=0.153]train epoch: 41:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.73it/s, loss=0.0791]train epoch: 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.94it/s, loss=0.0791]train epoch: 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.87it/s, loss=0.0791]
[[032m2021-11-26 10:00:22,615[0m INFO] trainer.training_epoch Training epoch 41, num_steps 336,  avg_loss: 0.1229, total_loss: 0.9835
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.41it/s]
[[032m2021-11-26 10:00:22,989[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 10:00:22,989[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:00:36,989[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 42:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 42:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.145]train epoch: 42:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.92it/s, loss=0.145]train epoch: 42:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.92it/s, loss=0.0677]train epoch: 42:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.77it/s, loss=0.0677]train epoch: 42:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.77it/s, loss=0.0544]train epoch: 42:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.0544]train epoch: 42:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.13]  train epoch: 42:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=0.13]train epoch: 42:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.16it/s, loss=0.0992]train epoch: 42:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.44it/s, loss=0.0992]train epoch: 42:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.44it/s, loss=0.166] train epoch: 42:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.48it/s, loss=0.166]train epoch: 42:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.48it/s, loss=0.0463]train epoch: 42:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.91it/s, loss=0.0463]train epoch: 42:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.91it/s, loss=0.179] train epoch: 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.99it/s, loss=0.179]train epoch: 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.05it/s, loss=0.179]
[[032m2021-11-26 10:00:40,907[0m INFO] trainer.training_epoch Training epoch 42, num_steps 344,  avg_loss: 0.1109, total_loss: 0.8875
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.61it/s]
[[032m2021-11-26 10:00:45,121[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 10:00:45,121[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:00:59,028[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 43:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 43:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.18]train epoch: 43:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.50it/s, loss=0.18]train epoch: 43:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.50it/s, loss=0.291]train epoch: 43:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.59it/s, loss=0.291]train epoch: 43:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.59it/s, loss=0.106]train epoch: 43:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.68it/s, loss=0.106]train epoch: 43:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.68it/s, loss=0.0457]train epoch: 43:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.67it/s, loss=0.0457]train epoch: 43:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.67it/s, loss=0.0345]train epoch: 43:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.64it/s, loss=0.0345]train epoch: 43:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.64it/s, loss=0.0868]train epoch: 43:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.67it/s, loss=0.0868]train epoch: 43:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.67it/s, loss=0.0492]train epoch: 43:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.82it/s, loss=0.0492]train epoch: 43:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.82it/s, loss=0.172] train epoch: 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.96it/s, loss=0.172]train epoch: 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.77it/s, loss=0.172]
[[032m2021-11-26 10:01:03,555[0m INFO] trainer.training_epoch Training epoch 43, num_steps 352,  avg_loss: 0.1206, total_loss: 0.9652
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.53it/s]
[[032m2021-11-26 10:01:03,951[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:01:03,951[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:01:21,337[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 44:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 44:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.245]train epoch: 44:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.91it/s, loss=0.245]train epoch: 44:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.91it/s, loss=0.0491]train epoch: 44:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.75it/s, loss=0.0491]train epoch: 44:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.75it/s, loss=0.0445]train epoch: 44:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.64it/s, loss=0.0445]train epoch: 44:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.64it/s, loss=0.0339]train epoch: 44:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.74it/s, loss=0.0339]train epoch: 44:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.74it/s, loss=0.114] train epoch: 44:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.89it/s, loss=0.114]train epoch: 44:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.89it/s, loss=0.0233]train epoch: 44:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.82it/s, loss=0.0233]train epoch: 44:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.82it/s, loss=0.228] train epoch: 44:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.02it/s, loss=0.228]train epoch: 44:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.02it/s, loss=0.203]train epoch: 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.04it/s, loss=0.203]train epoch: 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.93it/s, loss=0.203]
[[032m2021-11-26 10:01:25,496[0m INFO] trainer.training_epoch Training epoch 44, num_steps 360,  avg_loss: 0.1177, total_loss: 0.9414
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.21it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.70it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.04it/s]
[[032m2021-11-26 10:01:26,173[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:01:26,173[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:01:41,539[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 45:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 45:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.419]train epoch: 45:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.19it/s, loss=0.419]train epoch: 45:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.19it/s, loss=0.037]train epoch: 45:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.40it/s, loss=0.037]train epoch: 45:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.40it/s, loss=0.0492]train epoch: 45:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=0.0492]train epoch: 45:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=0.0383]train epoch: 45:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.07it/s, loss=0.0383]train epoch: 45:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.07it/s, loss=0.114] train epoch: 45:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.04it/s, loss=0.114]train epoch: 45:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.04it/s, loss=0.058]train epoch: 45:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.84it/s, loss=0.058]train epoch: 45:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.84it/s, loss=0.0398]train epoch: 45:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.08it/s, loss=0.0398]train epoch: 45:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.08it/s, loss=0.0359]train epoch: 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.16it/s, loss=0.0359]train epoch: 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.12it/s, loss=0.0359]
[[032m2021-11-26 10:01:45,374[0m INFO] trainer.training_epoch Training epoch 45, num_steps 368,  avg_loss: 0.0989, total_loss: 0.7909
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.27it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.97it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.63it/s]
[[032m2021-11-26 10:01:46,104[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:01:46,104[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:02:00,926[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 46:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 46:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0569]train epoch: 46:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.80it/s, loss=0.0569]train epoch: 46:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.80it/s, loss=0.0232]train epoch: 46:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.95it/s, loss=0.0232]train epoch: 46:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.95it/s, loss=0.0209]train epoch: 46:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.18it/s, loss=0.0209]train epoch: 46:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.18it/s, loss=0.0327]train epoch: 46:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.40it/s, loss=0.0327]train epoch: 46:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.40it/s, loss=0.0533]train epoch: 46:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.48it/s, loss=0.0533]train epoch: 46:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.48it/s, loss=0.00826]train epoch: 46:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.34it/s, loss=0.00826]train epoch: 46:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.34it/s, loss=0.141]  train epoch: 46:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=0.141]train epoch: 46:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=0.0216]train epoch: 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.33it/s, loss=0.0216]train epoch: 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s, loss=0.0216]
[[032m2021-11-26 10:02:04,447[0m INFO] trainer.training_epoch Training epoch 46, num_steps 376,  avg_loss: 0.0448, total_loss: 0.3583
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.75it/s]
[[032m2021-11-26 10:02:04,849[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:02:04,849[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:02:19,681[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 47:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 47:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0213]train epoch: 47:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.82it/s, loss=0.0213]train epoch: 47:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.82it/s, loss=0.0449]train epoch: 47:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.24it/s, loss=0.0449]train epoch: 47:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.24it/s, loss=0.0504]train epoch: 47:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.79it/s, loss=0.0504]train epoch: 47:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.79it/s, loss=0.019] train epoch: 47:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.10it/s, loss=0.019]train epoch: 47:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.10it/s, loss=0.0169]train epoch: 47:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=0.0169]train epoch: 47:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=0.0238]train epoch: 47:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  2.00it/s, loss=0.0238]train epoch: 47:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  2.00it/s, loss=0.0494]train epoch: 47:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=0.0494]train epoch: 47:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=0.0185]train epoch: 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.83it/s, loss=0.0185]train epoch: 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.99it/s, loss=0.0185]
[[032m2021-11-26 10:02:23,714[0m INFO] trainer.training_epoch Training epoch 47, num_steps 384,  avg_loss: 0.0305, total_loss: 0.2442
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.14it/s]
[[032m2021-11-26 10:02:25,473[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:02:25,474[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:02:41,549[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 48:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 48:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0292]train epoch: 48:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.62it/s, loss=0.0292]train epoch: 48:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.62it/s, loss=0.0216]train epoch: 48:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.27it/s, loss=0.0216]train epoch: 48:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.27it/s, loss=0.014] train epoch: 48:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.23it/s, loss=0.014]train epoch: 48:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.23it/s, loss=0.0155]train epoch: 48:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.17it/s, loss=0.0155]train epoch: 48:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.17it/s, loss=0.00952]train epoch: 48:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.00it/s, loss=0.00952]train epoch: 48:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.00it/s, loss=0.0109] train epoch: 48:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.04it/s, loss=0.0109]train epoch: 48:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.04it/s, loss=0.00588]train epoch: 48:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.11it/s, loss=0.00588]train epoch: 48:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.11it/s, loss=0.0208] train epoch: 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.92it/s, loss=0.0208]train epoch: 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=0.0208]
[[032m2021-11-26 10:02:45,582[0m INFO] trainer.training_epoch Training epoch 48, num_steps 392,  avg_loss: 0.0159, total_loss: 0.1273
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.06it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.31it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.68it/s]
[[032m2021-11-26 10:02:46,142[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:02:46,143[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:02:59,023[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 49:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 49:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0209]train epoch: 49:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.80it/s, loss=0.0209]train epoch: 49:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  1.80it/s, loss=0.0147]train epoch: 49:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.48it/s, loss=0.0147]train epoch: 49:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.48it/s, loss=0.0414]train epoch: 49:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.41it/s, loss=0.0414]train epoch: 49:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.41it/s, loss=0.0328]train epoch: 49:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:03,  1.29it/s, loss=0.0328]train epoch: 49:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:03<00:03,  1.29it/s, loss=0.0159]train epoch: 49:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.50it/s, loss=0.0159]train epoch: 49:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.50it/s, loss=0.0091]train epoch: 49:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.79it/s, loss=0.0091]train epoch: 49:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.79it/s, loss=0.0311]train epoch: 49:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.97it/s, loss=0.0311]train epoch: 49:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.97it/s, loss=0.0191]train epoch: 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.94it/s, loss=0.0191]train epoch: 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.70it/s, loss=0.0191]
[[032m2021-11-26 10:03:03,773[0m INFO] trainer.training_epoch Training epoch 49, num_steps 400,  avg_loss: 0.0231, total_loss: 0.1850
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.43it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.70it/s]
[[032m2021-11-26 10:03:04,261[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:03:04,268[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:03:17,705[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 50:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 50:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00661]train epoch: 50:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.67it/s, loss=0.00661]train epoch: 50:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.67it/s, loss=0.00401]train epoch: 50:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.73it/s, loss=0.00401]train epoch: 50:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.73it/s, loss=0.0269] train epoch: 50:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.09it/s, loss=0.0269]train epoch: 50:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.09it/s, loss=0.0123]train epoch: 50:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.28it/s, loss=0.0123]train epoch: 50:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.28it/s, loss=0.00888]train epoch: 50:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.07it/s, loss=0.00888]train epoch: 50:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.07it/s, loss=0.00489]train epoch: 50:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.10it/s, loss=0.00489]train epoch: 50:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.10it/s, loss=0.00781]train epoch: 50:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=0.00781]train epoch: 50:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=0.00289]train epoch: 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=0.00289]train epoch: 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.20it/s, loss=0.00289]
[[032m2021-11-26 10:03:21,357[0m INFO] trainer.training_epoch Training epoch 50, num_steps 408,  avg_loss: 0.0093, total_loss: 0.0742
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.40it/s]
[[032m2021-11-26 10:03:22,008[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:03:22,009[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:03:33,589[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 51:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 51:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0058]train epoch: 51:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.76it/s, loss=0.0058]train epoch: 51:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.76it/s, loss=0.019] train epoch: 51:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.22it/s, loss=0.019]train epoch: 51:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.22it/s, loss=0.01] train epoch: 51:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.22it/s, loss=0.01]train epoch: 51:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.22it/s, loss=0.171]train epoch: 51:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.99it/s, loss=0.171]train epoch: 51:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.99it/s, loss=0.00118]train epoch: 51:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.90it/s, loss=0.00118]train epoch: 51:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.90it/s, loss=0.00373]train epoch: 51:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.06it/s, loss=0.00373]train epoch: 51:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.06it/s, loss=0.00606]train epoch: 51:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.30it/s, loss=0.00606]train epoch: 51:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.30it/s, loss=0.003]  train epoch: 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.09it/s, loss=0.003]train epoch: 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.08it/s, loss=0.003]
[[032m2021-11-26 10:03:37,453[0m INFO] trainer.training_epoch Training epoch 51, num_steps 416,  avg_loss: 0.0275, total_loss: 0.2198
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.67it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.30it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.45it/s]
[[032m2021-11-26 10:03:41,234[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:03:41,235[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:03:53,556[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 52:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 52:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00422]train epoch: 52:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.38it/s, loss=0.00422]train epoch: 52:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.38it/s, loss=0.0039] train epoch: 52:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.39it/s, loss=0.0039]train epoch: 52:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.39it/s, loss=0.0205]train epoch: 52:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.61it/s, loss=0.0205]train epoch: 52:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.61it/s, loss=0.0067]train epoch: 52:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=0.0067]train epoch: 52:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=0.00195]train epoch: 52:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.79it/s, loss=0.00195]train epoch: 52:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.79it/s, loss=0.00265]train epoch: 52:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.43it/s, loss=0.00265]train epoch: 52:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.43it/s, loss=0.00517]train epoch: 52:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.44it/s, loss=0.00517]train epoch: 52:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.44it/s, loss=0.0151] train epoch: 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.39it/s, loss=0.0151]train epoch: 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=0.0151]
[[032m2021-11-26 10:03:56,793[0m INFO] trainer.training_epoch Training epoch 52, num_steps 424,  avg_loss: 0.0075, total_loss: 0.0601
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.38it/s]
[[032m2021-11-26 10:03:57,164[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:03:57,165[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:04:09,127[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 53:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 53:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00973]train epoch: 53:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.13it/s, loss=0.00973]train epoch: 53:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.13it/s, loss=0.0483] train epoch: 53:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.92it/s, loss=0.0483]train epoch: 53:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.92it/s, loss=0.0061]train epoch: 53:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.0061]train epoch: 53:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.91it/s, loss=0.00111]train epoch: 53:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.92it/s, loss=0.00111]train epoch: 53:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.92it/s, loss=0.00552]train epoch: 53:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.95it/s, loss=0.00552]train epoch: 53:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.95it/s, loss=0.00255]train epoch: 53:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.14it/s, loss=0.00255]train epoch: 53:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.14it/s, loss=0.0321] train epoch: 53:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.97it/s, loss=0.0321]train epoch: 53:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.97it/s, loss=0.000871]train epoch: 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.02it/s, loss=0.000871]train epoch: 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.00it/s, loss=0.000871]
[[032m2021-11-26 10:04:13,141[0m INFO] trainer.training_epoch Training epoch 53, num_steps 432,  avg_loss: 0.0133, total_loss: 0.1063
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.23it/s]
[[032m2021-11-26 10:04:13,523[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:04:13,524[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:04:26,519[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 54:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 54:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00384]train epoch: 54:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=0.00384]train epoch: 54:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=0.00228]train epoch: 54:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.41it/s, loss=0.00228]train epoch: 54:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.41it/s, loss=0.00332]train epoch: 54:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=0.00332]train epoch: 54:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=0.0484] train epoch: 54:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=0.0484]train epoch: 54:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=0.00116]train epoch: 54:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.47it/s, loss=0.00116]train epoch: 54:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.47it/s, loss=0.00739]train epoch: 54:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.23it/s, loss=0.00739]train epoch: 54:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.23it/s, loss=0.00491]train epoch: 54:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.97it/s, loss=0.00491]train epoch: 54:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.97it/s, loss=0.00285]train epoch: 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=0.00285]train epoch: 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.23it/s, loss=0.00285]
[[032m2021-11-26 10:04:30,132[0m INFO] trainer.training_epoch Training epoch 54, num_steps 440,  avg_loss: 0.0093, total_loss: 0.0742
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.69it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.47it/s]
[[032m2021-11-26 10:04:30,543[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:04:30,544[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:04:42,827[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 55:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 55:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00278]train epoch: 55:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.79it/s, loss=0.00278]train epoch: 55:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.79it/s, loss=0.00261]train epoch: 55:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.94it/s, loss=0.00261]train epoch: 55:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.94it/s, loss=0.00707]train epoch: 55:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.16it/s, loss=0.00707]train epoch: 55:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.16it/s, loss=0.00136]train epoch: 55:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.03it/s, loss=0.00136]train epoch: 55:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.03it/s, loss=0.00717]train epoch: 55:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=0.00717]train epoch: 55:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=0.0128] train epoch: 55:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.35it/s, loss=0.0128]train epoch: 55:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.35it/s, loss=0.102] train epoch: 55:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.23it/s, loss=0.102]train epoch: 55:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.23it/s, loss=0.00304]train epoch: 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.16it/s, loss=0.00304]train epoch: 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=0.00304]
[[032m2021-11-26 10:04:46,588[0m INFO] trainer.training_epoch Training epoch 55, num_steps 448,  avg_loss: 0.0174, total_loss: 0.1391
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.09it/s]
[[032m2021-11-26 10:04:47,004[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:04:47,004[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:04:58,703[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 56:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 56:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000855]train epoch: 56:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.26it/s, loss=0.000855]train epoch: 56:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.26it/s, loss=0.00169] train epoch: 56:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.07it/s, loss=0.00169]train epoch: 56:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.07it/s, loss=0.000695]train epoch: 56:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.29it/s, loss=0.000695]train epoch: 56:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.29it/s, loss=0.0761]  train epoch: 56:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=0.0761]train epoch: 56:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=0.00184]train epoch: 56:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.65it/s, loss=0.00184]train epoch: 56:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.65it/s, loss=0.0249] train epoch: 56:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.50it/s, loss=0.0249]train epoch: 56:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.50it/s, loss=0.00794]train epoch: 56:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.24it/s, loss=0.00794]train epoch: 56:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.24it/s, loss=0.134]  train epoch: 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.10it/s, loss=0.134]train epoch: 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.26it/s, loss=0.134]
[[032m2021-11-26 10:05:02,265[0m INFO] trainer.training_epoch Training epoch 56, num_steps 456,  avg_loss: 0.0310, total_loss: 0.2484
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.02it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.75it/s]
[[032m2021-11-26 10:05:02,799[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:05:02,799[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:05:14,290[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 57:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 57:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00108]train epoch: 57:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=0.00108]train epoch: 57:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=0.00295]train epoch: 57:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.68it/s, loss=0.00295]train epoch: 57:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.68it/s, loss=0.00302]train epoch: 57:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.26it/s, loss=0.00302]train epoch: 57:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.26it/s, loss=0.00141]train epoch: 57:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.22it/s, loss=0.00141]train epoch: 57:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.22it/s, loss=0.00154]train epoch: 57:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.46it/s, loss=0.00154]train epoch: 57:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.46it/s, loss=0.0108] train epoch: 57:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.66it/s, loss=0.0108]train epoch: 57:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.66it/s, loss=0.00717]train epoch: 57:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=0.00717]train epoch: 57:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.63it/s, loss=0.00197]train epoch: 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.67it/s, loss=0.00197]train epoch: 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.55it/s, loss=0.00197]
[[032m2021-11-26 10:05:17,435[0m INFO] trainer.training_epoch Training epoch 57, num_steps 464,  avg_loss: 0.0037, total_loss: 0.0299
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.16it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.68it/s]
[[032m2021-11-26 10:05:17,853[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:05:17,853[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:05:28,084[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 58:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 58:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000852]train epoch: 58:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.73it/s, loss=0.000852]train epoch: 58:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.73it/s, loss=0.00258] train epoch: 58:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.51it/s, loss=0.00258]train epoch: 58:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.51it/s, loss=0.00357]train epoch: 58:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.00357]train epoch: 58:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.00291]train epoch: 58:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=0.00291]train epoch: 58:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=0.00144]train epoch: 58:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.63it/s, loss=0.00144]train epoch: 58:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.63it/s, loss=0.0011] train epoch: 58:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.73it/s, loss=0.0011]train epoch: 58:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.73it/s, loss=0.00298]train epoch: 58:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.62it/s, loss=0.00298]train epoch: 58:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.62it/s, loss=0.00104]train epoch: 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=0.00104]train epoch: 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.51it/s, loss=0.00104]
[[032m2021-11-26 10:05:31,282[0m INFO] trainer.training_epoch Training epoch 58, num_steps 472,  avg_loss: 0.0021, total_loss: 0.0165
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.73it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.75it/s]
[[032m2021-11-26 10:05:31,667[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:05:31,667[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:05:44,043[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 59:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 59:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0179]train epoch: 59:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.48it/s, loss=0.0179]train epoch: 59:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.48it/s, loss=0.00213]train epoch: 59:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.74it/s, loss=0.00213]train epoch: 59:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.74it/s, loss=0.00126]train epoch: 59:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=0.00126]train epoch: 59:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=0.000755]train epoch: 59:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.49it/s, loss=0.000755]train epoch: 59:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.49it/s, loss=0.00429] train epoch: 59:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.30it/s, loss=0.00429]train epoch: 59:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.30it/s, loss=0.000814]train epoch: 59:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=0.000814]train epoch: 59:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.42it/s, loss=0.00131] train epoch: 59:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.05it/s, loss=0.00131]train epoch: 59:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.05it/s, loss=0.000867]train epoch: 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.23it/s, loss=0.000867]train epoch: 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.17it/s, loss=0.000867]
[[032m2021-11-26 10:05:47,761[0m INFO] trainer.training_epoch Training epoch 59, num_steps 480,  avg_loss: 0.0037, total_loss: 0.0293
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.02it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.30it/s]
[[032m2021-11-26 10:05:48,423[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:05:48,424[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:06:00,638[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 60:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 60:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.006]train epoch: 60:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.45it/s, loss=0.006]train epoch: 60:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.45it/s, loss=0.00166]train epoch: 60:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.56it/s, loss=0.00166]train epoch: 60:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.56it/s, loss=0.00138]train epoch: 60:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.12it/s, loss=0.00138]train epoch: 60:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.12it/s, loss=0.00147]train epoch: 60:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.81it/s, loss=0.00147]train epoch: 60:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.81it/s, loss=0.000521]train epoch: 60:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.86it/s, loss=0.000521]train epoch: 60:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.86it/s, loss=0.000395]train epoch: 60:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.13it/s, loss=0.000395]train epoch: 60:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.13it/s, loss=0.00045] train epoch: 60:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.17it/s, loss=0.00045]train epoch: 60:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.17it/s, loss=0.000887]train epoch: 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.29it/s, loss=0.000887]train epoch: 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.15it/s, loss=0.000887]
[[032m2021-11-26 10:06:04,368[0m INFO] trainer.training_epoch Training epoch 60, num_steps 488,  avg_loss: 0.0016, total_loss: 0.0128
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.85it/s]
[[032m2021-11-26 10:06:04,770[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:06:04,770[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:06:16,999[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 61:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 61:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00121]train epoch: 61:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.54it/s, loss=0.00121]train epoch: 61:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.54it/s, loss=0.00112]train epoch: 61:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.56it/s, loss=0.00112]train epoch: 61:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.56it/s, loss=0.00751]train epoch: 61:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.79it/s, loss=0.00751]train epoch: 61:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.79it/s, loss=0.000403]train epoch: 61:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.04it/s, loss=0.000403]train epoch: 61:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.04it/s, loss=0.000493]train epoch: 61:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.06it/s, loss=0.000493]train epoch: 61:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  2.06it/s, loss=0.000823]train epoch: 61:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.03it/s, loss=0.000823]train epoch: 61:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.03it/s, loss=0.0015]  train epoch: 61:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.11it/s, loss=0.0015]train epoch: 61:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.11it/s, loss=0.00259]train epoch: 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=0.00259]train epoch: 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.07it/s, loss=0.00259]
[[032m2021-11-26 10:06:20,904[0m INFO] trainer.training_epoch Training epoch 61, num_steps 496,  avg_loss: 0.0020, total_loss: 0.0156
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.17it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.46it/s]
[[032m2021-11-26 10:06:21,274[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:06:21,274[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:06:34,368[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 62:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 62:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000378]train epoch: 62:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.74it/s, loss=0.000378]train epoch: 62:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.74it/s, loss=0.00102] train epoch: 62:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.76it/s, loss=0.00102]train epoch: 62:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.76it/s, loss=0.00124]train epoch: 62:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.57it/s, loss=0.00124]train epoch: 62:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.57it/s, loss=0.000275]train epoch: 62:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.48it/s, loss=0.000275]train epoch: 62:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.48it/s, loss=0.000485]train epoch: 62:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=0.000485]train epoch: 62:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.66it/s, loss=0.000996]train epoch: 62:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.65it/s, loss=0.000996]train epoch: 62:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.65it/s, loss=0.00226] train epoch: 62:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=0.00226]train epoch: 62:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=0.000984]train epoch: 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s, loss=0.000984]train epoch: 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.73it/s, loss=0.000984]
[[032m2021-11-26 10:06:37,309[0m INFO] trainer.training_epoch Training epoch 62, num_steps 504,  avg_loss: 0.0010, total_loss: 0.0076
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.28it/s]
[[032m2021-11-26 10:06:37,648[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:06:37,648[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:06:50,525[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 63:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 63:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000256]train epoch: 63:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=0.000256]train epoch: 63:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=0.00517] train epoch: 63:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.69it/s, loss=0.00517]train epoch: 63:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.69it/s, loss=0.000228]train epoch: 63:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=0.000228]train epoch: 63:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=0.000417]train epoch: 63:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.30it/s, loss=0.000417]train epoch: 63:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.30it/s, loss=0.000213]train epoch: 63:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.000213]train epoch: 63:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.00116] train epoch: 63:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.34it/s, loss=0.00116]train epoch: 63:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.34it/s, loss=0.000275]train epoch: 63:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.47it/s, loss=0.000275]train epoch: 63:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.47it/s, loss=0.00125] train epoch: 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.62it/s, loss=0.00125]train epoch: 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=0.00125]
[[032m2021-11-26 10:06:53,739[0m INFO] trainer.training_epoch Training epoch 63, num_steps 512,  avg_loss: 0.0011, total_loss: 0.0090
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.73it/s]
[[032m2021-11-26 10:06:54,126[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:06:54,126[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:07:06,543[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 64:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 64:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000738]train epoch: 64:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.65it/s, loss=0.000738]train epoch: 64:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.65it/s, loss=0.053]   train epoch: 64:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.88it/s, loss=0.053]train epoch: 64:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.88it/s, loss=0.0014]train epoch: 64:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.99it/s, loss=0.0014]train epoch: 64:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.99it/s, loss=0.000277]train epoch: 64:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=0.000277]train epoch: 64:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=0.00309] train epoch: 64:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=0.00309]train epoch: 64:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=0.000457]train epoch: 64:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=0.000457]train epoch: 64:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=0.000191]train epoch: 64:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=0.000191]train epoch: 64:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=0.00183] train epoch: 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=0.00183]train epoch: 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.84it/s, loss=0.00183]
[[032m2021-11-26 10:07:09,370[0m INFO] trainer.training_epoch Training epoch 64, num_steps 520,  avg_loss: 0.0076, total_loss: 0.0610
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.65it/s]
[[032m2021-11-26 10:07:09,801[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:07:09,802[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:07:21,303[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 65:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 65:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000311]train epoch: 65:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.69it/s, loss=0.000311]train epoch: 65:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.69it/s, loss=0.000739]train epoch: 65:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.79it/s, loss=0.000739]train epoch: 65:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.79it/s, loss=0.000329]train epoch: 65:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.83it/s, loss=0.000329]train epoch: 65:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.83it/s, loss=0.000747]train epoch: 65:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=0.000747]train epoch: 65:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=0.000714]train epoch: 65:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.72it/s, loss=0.000714]train epoch: 65:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.72it/s, loss=0.000876]train epoch: 65:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=0.000876]train epoch: 65:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=0.00105] train epoch: 65:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.87it/s, loss=0.00105]train epoch: 65:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.87it/s, loss=0.000229]train epoch: 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.57it/s, loss=0.000229]train epoch: 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.70it/s, loss=0.000229]
[[032m2021-11-26 10:07:24,285[0m INFO] trainer.training_epoch Training epoch 65, num_steps 528,  avg_loss: 0.0006, total_loss: 0.0050
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.53it/s]
[[032m2021-11-26 10:07:24,679[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:07:24,679[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:07:37,459[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 66:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 66:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000345]train epoch: 66:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.14it/s, loss=0.000345]train epoch: 66:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.14it/s, loss=0.000105]train epoch: 66:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.87it/s, loss=0.000105]train epoch: 66:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.87it/s, loss=0.000226]train epoch: 66:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.000226]train epoch: 66:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.00034] train epoch: 66:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.28it/s, loss=0.00034]train epoch: 66:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.28it/s, loss=0.00111]train epoch: 66:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.47it/s, loss=0.00111]train epoch: 66:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.47it/s, loss=0.000199]train epoch: 66:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=0.000199]train epoch: 66:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=0.000321]train epoch: 66:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.33it/s, loss=0.000321]train epoch: 66:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.33it/s, loss=0.000509]train epoch: 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.32it/s, loss=0.000509]train epoch: 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=0.000509]
[[032m2021-11-26 10:07:40,808[0m INFO] trainer.training_epoch Training epoch 66, num_steps 536,  avg_loss: 0.0004, total_loss: 0.0032
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.73it/s]
[[032m2021-11-26 10:07:41,239[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:07:41,239[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:07:53,227[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 67:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 67:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00128]train epoch: 67:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.53it/s, loss=0.00128]train epoch: 67:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.53it/s, loss=0.00171]train epoch: 67:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.69it/s, loss=0.00171]train epoch: 67:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.69it/s, loss=0.000513]train epoch: 67:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.92it/s, loss=0.000513]train epoch: 67:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.92it/s, loss=0.000424]train epoch: 67:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.49it/s, loss=0.000424]train epoch: 67:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.49it/s, loss=0.0018]  train epoch: 67:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=0.0018]train epoch: 67:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=0.000178]train epoch: 67:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.22it/s, loss=0.000178]train epoch: 67:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.22it/s, loss=0.00199] train epoch: 67:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.35it/s, loss=0.00199]train epoch: 67:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=0.000492]train epoch: 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=0.000492]train epoch: 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.46it/s, loss=0.000492]
[[032m2021-11-26 10:07:56,499[0m INFO] trainer.training_epoch Training epoch 67, num_steps 544,  avg_loss: 0.0010, total_loss: 0.0084
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.82it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.85it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.57it/s]
[[032m2021-11-26 10:07:57,157[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:07:57,157[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:08:10,265[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 68:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 68:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000537]train epoch: 68:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=0.000537]train epoch: 68:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=0.00274] train epoch: 68:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.55it/s, loss=0.00274]train epoch: 68:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.55it/s, loss=0.054]  train epoch: 68:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=0.054]train epoch: 68:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=0.000127]train epoch: 68:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.84it/s, loss=0.000127]train epoch: 68:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.84it/s, loss=0.00186] train epoch: 68:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.42it/s, loss=0.00186]train epoch: 68:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.42it/s, loss=0.00035]train epoch: 68:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.14it/s, loss=0.00035]train epoch: 68:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.14it/s, loss=0.00063]train epoch: 68:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.26it/s, loss=0.00063]train epoch: 68:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.26it/s, loss=0.0021] train epoch: 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=0.0021]train epoch: 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.49it/s, loss=0.0021]
[[032m2021-11-26 10:08:13,493[0m INFO] trainer.training_epoch Training epoch 68, num_steps 552,  avg_loss: 0.0078, total_loss: 0.0623
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.30it/s]
[[032m2021-11-26 10:08:14,054[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:08:14,054[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:08:28,114[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 69:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 69:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000389]train epoch: 69:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.49it/s, loss=0.000389]train epoch: 69:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.49it/s, loss=0.000276]train epoch: 69:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.71it/s, loss=0.000276]train epoch: 69:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.71it/s, loss=0.000468]train epoch: 69:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.03it/s, loss=0.000468]train epoch: 69:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.03it/s, loss=6.84e-5] train epoch: 69:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=6.84e-5]train epoch: 69:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=0.000953]train epoch: 69:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.88it/s, loss=0.000953]train epoch: 69:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.88it/s, loss=0.00149] train epoch: 69:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.74it/s, loss=0.00149]train epoch: 69:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.74it/s, loss=0.0122] train epoch: 69:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=0.0122]train epoch: 69:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=0.000347]train epoch: 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.26it/s, loss=0.000347]train epoch: 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.55it/s, loss=0.000347]
[[032m2021-11-26 10:08:31,266[0m INFO] trainer.training_epoch Training epoch 69, num_steps 560,  avg_loss: 0.0020, total_loss: 0.0162
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.63it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.23it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.33it/s]
[[032m2021-11-26 10:08:31,998[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:08:31,998[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:08:45,598[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 70:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 70:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00124]train epoch: 70:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.68it/s, loss=0.00124]train epoch: 70:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.68it/s, loss=0.000987]train epoch: 70:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.66it/s, loss=0.000987]train epoch: 70:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.66it/s, loss=0.000143]train epoch: 70:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.88it/s, loss=0.000143]train epoch: 70:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.88it/s, loss=0.000688]train epoch: 70:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.14it/s, loss=0.000688]train epoch: 70:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.14it/s, loss=0.000397]train epoch: 70:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.98it/s, loss=0.000397]train epoch: 70:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.98it/s, loss=0.0021]  train epoch: 70:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.05it/s, loss=0.0021]train epoch: 70:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.05it/s, loss=0.000583]train epoch: 70:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s, loss=0.000583]train epoch: 70:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s, loss=0.00154] train epoch: 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.42it/s, loss=0.00154]train epoch: 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.13it/s, loss=0.00154]
[[032m2021-11-26 10:08:49,368[0m INFO] trainer.training_epoch Training epoch 70, num_steps 568,  avg_loss: 0.0010, total_loss: 0.0077
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.77it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.20it/s]
[[032m2021-11-26 10:08:49,881[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:08:49,881[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:09:03,244[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 71:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 71:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000553]train epoch: 71:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.47it/s, loss=0.000553]train epoch: 71:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.47it/s, loss=0.000556]train epoch: 71:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.63it/s, loss=0.000556]train epoch: 71:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.63it/s, loss=0.000722]train epoch: 71:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.09it/s, loss=0.000722]train epoch: 71:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.09it/s, loss=0.000899]train epoch: 71:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.35it/s, loss=0.000899]train epoch: 71:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.35it/s, loss=0.000512]train epoch: 71:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=0.000512]train epoch: 71:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.66it/s, loss=0.000808]train epoch: 71:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.66it/s, loss=0.000808]train epoch: 71:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.66it/s, loss=0.000133]train epoch: 71:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.36it/s, loss=0.000133]train epoch: 71:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.36it/s, loss=0.000273]train epoch: 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.34it/s, loss=0.000273]train epoch: 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=0.000273]
[[032m2021-11-26 10:09:06,587[0m INFO] trainer.training_epoch Training epoch 71, num_steps 576,  avg_loss: 0.0006, total_loss: 0.0045
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.87it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.25it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.87it/s]
[[032m2021-11-26 10:09:08,757[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:09:08,757[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:09:23,953[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 72:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 72:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00112]train epoch: 72:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.87it/s, loss=0.00112]train epoch: 72:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.87it/s, loss=0.000426]train epoch: 72:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.82it/s, loss=0.000426]train epoch: 72:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.82it/s, loss=0.000435]train epoch: 72:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=0.000435]train epoch: 72:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=0.000548]train epoch: 72:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.40it/s, loss=0.000548]train epoch: 72:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.40it/s, loss=0.00149] train epoch: 72:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.52it/s, loss=0.00149]train epoch: 72:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.52it/s, loss=0.000247]train epoch: 72:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.76it/s, loss=0.000247]train epoch: 72:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.76it/s, loss=0.000544]train epoch: 72:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.40it/s, loss=0.000544]train epoch: 72:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.40it/s, loss=6.59e-5] train epoch: 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=6.59e-5]train epoch: 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.37it/s, loss=6.59e-5]
[[032m2021-11-26 10:09:27,340[0m INFO] trainer.training_epoch Training epoch 72, num_steps 584,  avg_loss: 0.0006, total_loss: 0.0049
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.82it/s]
[[032m2021-11-26 10:09:27,773[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:09:27,773[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:09:41,457[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 73:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 73:   0%|          | 0/8 [00:00<?, ?it/s, loss=7.67e-5]train epoch: 73:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.88it/s, loss=7.67e-5]train epoch: 73:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.88it/s, loss=0.000158]train epoch: 73:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.59it/s, loss=0.000158]train epoch: 73:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.59it/s, loss=0.000643]train epoch: 73:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.68it/s, loss=0.000643]train epoch: 73:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.68it/s, loss=0.00011] train epoch: 73:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=0.00011]train epoch: 73:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=0.000277]train epoch: 73:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=0.000277]train epoch: 73:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=0.000147]train epoch: 73:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.50it/s, loss=0.000147]train epoch: 73:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.50it/s, loss=0.593]   train epoch: 73:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=0.593]train epoch: 73:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=0.000226]train epoch: 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.98it/s, loss=0.000226]train epoch: 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=0.000226]
[[032m2021-11-26 10:09:45,458[0m INFO] trainer.training_epoch Training epoch 73, num_steps 592,  avg_loss: 0.0744, total_loss: 0.5950
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.05it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.61it/s]
[[032m2021-11-26 10:09:47,985[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:09:47,985[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:10:01,769[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 74:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 74:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000394]train epoch: 74:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.86it/s, loss=0.000394]train epoch: 74:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.86it/s, loss=0.00161] train epoch: 74:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.79it/s, loss=0.00161]train epoch: 74:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.79it/s, loss=0.000304]train epoch: 74:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.86it/s, loss=0.000304]train epoch: 74:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.86it/s, loss=0.00407] train epoch: 74:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.81it/s, loss=0.00407]train epoch: 74:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.81it/s, loss=0.000127]train epoch: 74:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.82it/s, loss=0.000127]train epoch: 74:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.82it/s, loss=0.0301]  train epoch: 74:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.08it/s, loss=0.0301]train epoch: 74:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.08it/s, loss=0.000128]train epoch: 74:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.92it/s, loss=0.000128]train epoch: 74:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.92it/s, loss=0.182]   train epoch: 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.09it/s, loss=0.182]train epoch: 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.99it/s, loss=0.182]
[[032m2021-11-26 10:10:05,810[0m INFO] trainer.training_epoch Training epoch 74, num_steps 600,  avg_loss: 0.0273, total_loss: 0.2187
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.30it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.31it/s]
[[032m2021-11-26 10:10:06,217[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:10:06,218[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:10:22,462[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 75:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 75:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000274]train epoch: 75:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.05it/s, loss=0.000274]train epoch: 75:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.05it/s, loss=0.00024] train epoch: 75:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.21it/s, loss=0.00024]train epoch: 75:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.21it/s, loss=0.00064]train epoch: 75:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.07it/s, loss=0.00064]train epoch: 75:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.07it/s, loss=0.000149]train epoch: 75:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.12it/s, loss=0.000149]train epoch: 75:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.12it/s, loss=0.000304]train epoch: 75:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.13it/s, loss=0.000304]train epoch: 75:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.13it/s, loss=0.00017] train epoch: 75:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.13it/s, loss=0.00017]train epoch: 75:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.13it/s, loss=0.000228]train epoch: 75:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.25it/s, loss=0.000228]train epoch: 75:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.25it/s, loss=0.000598]train epoch: 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.09it/s, loss=0.000598]train epoch: 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.15it/s, loss=0.000598]
[[032m2021-11-26 10:10:26,206[0m INFO] trainer.training_epoch Training epoch 75, num_steps 608,  avg_loss: 0.0003, total_loss: 0.0026
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.40it/s]
[[032m2021-11-26 10:10:26,897[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:10:26,897[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:10:40,537[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 76:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 76:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000308]train epoch: 76:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.13it/s, loss=0.000308]train epoch: 76:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.13it/s, loss=0.000334]train epoch: 76:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.65it/s, loss=0.000334]train epoch: 76:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.65it/s, loss=0.000238]train epoch: 76:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=0.000238]train epoch: 76:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=0.000483]train epoch: 76:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.13it/s, loss=0.000483]train epoch: 76:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.13it/s, loss=0.000555]train epoch: 76:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.46it/s, loss=0.000555]train epoch: 76:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.46it/s, loss=0.000369]train epoch: 76:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=0.000369]train epoch: 76:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=0.000703]train epoch: 76:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.38it/s, loss=0.000703]train epoch: 76:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.38it/s, loss=0.000515]train epoch: 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.30it/s, loss=0.000515]train epoch: 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.37it/s, loss=0.000515]
[[032m2021-11-26 10:10:43,945[0m INFO] trainer.training_epoch Training epoch 76, num_steps 616,  avg_loss: 0.0004, total_loss: 0.0035
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.84it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.19it/s]
[[032m2021-11-26 10:10:44,474[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:10:44,475[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:10:58,685[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 77:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 77:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000247]train epoch: 77:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.71it/s, loss=0.000247]train epoch: 77:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.71it/s, loss=0.0813]  train epoch: 77:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.64it/s, loss=0.0813]train epoch: 77:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.64it/s, loss=0.000636]train epoch: 77:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.71it/s, loss=0.000636]train epoch: 77:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.71it/s, loss=0.000216]train epoch: 77:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.63it/s, loss=0.000216]train epoch: 77:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.63it/s, loss=0.000375]train epoch: 77:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=0.000375]train epoch: 77:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=9.94e-5] train epoch: 77:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=9.94e-5]train epoch: 77:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=0.000113]train epoch: 77:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.50it/s, loss=0.000113]train epoch: 77:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.50it/s, loss=0.000524]train epoch: 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.96it/s, loss=0.000524]train epoch: 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.27it/s, loss=0.000524]
[[032m2021-11-26 10:11:02,223[0m INFO] trainer.training_epoch Training epoch 77, num_steps 624,  avg_loss: 0.0104, total_loss: 0.0835
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.22it/s]
[[032m2021-11-26 10:11:03,934[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:11:03,934[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:11:19,586[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 78:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 78:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00163]train epoch: 78:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=0.00163]train epoch: 78:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=0.000206]train epoch: 78:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.28it/s, loss=0.000206]train epoch: 78:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.28it/s, loss=0.00103] train epoch: 78:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.54it/s, loss=0.00103]train epoch: 78:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.54it/s, loss=0.000458]train epoch: 78:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=0.000458]train epoch: 78:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=0.000936]train epoch: 78:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.62it/s, loss=0.000936]train epoch: 78:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.62it/s, loss=0.000377]train epoch: 78:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=0.000377]train epoch: 78:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=9.71e-5] train epoch: 78:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.52it/s, loss=9.71e-5]train epoch: 78:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.52it/s, loss=0.00907]train epoch: 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.25it/s, loss=0.00907]train epoch: 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.43it/s, loss=0.00907]
[[032m2021-11-26 10:11:22,883[0m INFO] trainer.training_epoch Training epoch 78, num_steps 632,  avg_loss: 0.0017, total_loss: 0.0138
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.17it/s]
[[032m2021-11-26 10:11:23,233[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:11:23,233[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:11:39,336[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 79:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 79:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000427]train epoch: 79:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.63it/s, loss=0.000427]train epoch: 79:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.63it/s, loss=0.000385]train epoch: 79:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.75it/s, loss=0.000385]train epoch: 79:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.75it/s, loss=0.000587]train epoch: 79:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.67it/s, loss=0.000587]train epoch: 79:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.67it/s, loss=0.000181]train epoch: 79:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.59it/s, loss=0.000181]train epoch: 79:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.59it/s, loss=0.00285] train epoch: 79:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.88it/s, loss=0.00285]train epoch: 79:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.88it/s, loss=0.000338]train epoch: 79:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.14it/s, loss=0.000338]train epoch: 79:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.14it/s, loss=0.000538]train epoch: 79:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.17it/s, loss=0.000538]train epoch: 79:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.17it/s, loss=0.00085] train epoch: 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.26it/s, loss=0.00085]train epoch: 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.99it/s, loss=0.00085]
[[032m2021-11-26 10:11:43,390[0m INFO] trainer.training_epoch Training epoch 79, num_steps 640,  avg_loss: 0.0008, total_loss: 0.0062
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.81it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.49it/s]
[[032m2021-11-26 10:11:43,945[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:11:43,945[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:11:59,464[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 80:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 80:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000753]train epoch: 80:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.23it/s, loss=0.000753]train epoch: 80:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.23it/s, loss=0.000264]train epoch: 80:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.54it/s, loss=0.000264]train epoch: 80:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.54it/s, loss=0.0103]  train epoch: 80:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=0.0103]train epoch: 80:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=9.24e-5]train epoch: 80:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.17it/s, loss=9.24e-5]train epoch: 80:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.17it/s, loss=0.000138]train epoch: 80:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.01it/s, loss=0.000138]train epoch: 80:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.01it/s, loss=0.000273]train epoch: 80:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.28it/s, loss=0.000273]train epoch: 80:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.28it/s, loss=0.00112] train epoch: 80:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.12it/s, loss=0.00112]train epoch: 80:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.12it/s, loss=0.000177]train epoch: 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.33it/s, loss=0.000177]train epoch: 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.27it/s, loss=0.000177]
[[032m2021-11-26 10:12:03,007[0m INFO] trainer.training_epoch Training epoch 80, num_steps 648,  avg_loss: 0.0016, total_loss: 0.0131
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.74it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.04it/s]
[[032m2021-11-26 10:12:03,535[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:12:03,535[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:12:18,827[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 81:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 81:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000112]train epoch: 81:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.32it/s, loss=0.000112]train epoch: 81:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.32it/s, loss=0.00157] train epoch: 81:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.78it/s, loss=0.00157]train epoch: 81:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.78it/s, loss=0.000207]train epoch: 81:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=0.000207]train epoch: 81:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=0.00124] train epoch: 81:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.06it/s, loss=0.00124]train epoch: 81:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.06it/s, loss=0.000331]train epoch: 81:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.01it/s, loss=0.000331]train epoch: 81:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.01it/s, loss=0.00101] train epoch: 81:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.98it/s, loss=0.00101]train epoch: 81:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.98it/s, loss=0.000496]train epoch: 81:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.85it/s, loss=0.000496]train epoch: 81:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.85it/s, loss=0.000431]train epoch: 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.82it/s, loss=0.000431]train epoch: 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.97it/s, loss=0.000431]
[[032m2021-11-26 10:12:22,907[0m INFO] trainer.training_epoch Training epoch 81, num_steps 656,  avg_loss: 0.0007, total_loss: 0.0054
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.68it/s]
[[032m2021-11-26 10:12:23,377[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:12:23,377[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:12:37,750[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 82:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 82:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000329]train epoch: 82:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.07it/s, loss=0.000329]train epoch: 82:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.07it/s, loss=8.22e-5] train epoch: 82:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.32it/s, loss=8.22e-5]train epoch: 82:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.32it/s, loss=0.000122]train epoch: 82:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=0.000122]train epoch: 82:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=0.000449]train epoch: 82:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.79it/s, loss=0.000449]train epoch: 82:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.79it/s, loss=0.000127]train epoch: 82:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.10it/s, loss=0.000127]train epoch: 82:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.10it/s, loss=0.000263]train epoch: 82:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.86it/s, loss=0.000263]train epoch: 82:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.86it/s, loss=0.000802]train epoch: 82:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.73it/s, loss=0.000802]train epoch: 82:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.73it/s, loss=0.000321]train epoch: 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.86it/s, loss=0.000321]train epoch: 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.91it/s, loss=0.000321]
[[032m2021-11-26 10:12:41,957[0m INFO] trainer.training_epoch Training epoch 82, num_steps 664,  avg_loss: 0.0003, total_loss: 0.0025
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.21it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.16it/s]
[[032m2021-11-26 10:12:42,417[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:12:42,417[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:12:58,634[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 83:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 83:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000124]train epoch: 83:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.96it/s, loss=0.000124]train epoch: 83:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.96it/s, loss=0.000252]train epoch: 83:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.31it/s, loss=0.000252]train epoch: 83:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.31it/s, loss=0.000284]train epoch: 83:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.08it/s, loss=0.000284]train epoch: 83:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.08it/s, loss=0.000222]train epoch: 83:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.87it/s, loss=0.000222]train epoch: 83:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.87it/s, loss=5.47e-5] train epoch: 83:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.13it/s, loss=5.47e-5]train epoch: 83:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.13it/s, loss=6.14e-5]train epoch: 83:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.24it/s, loss=6.14e-5]train epoch: 83:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.24it/s, loss=0.000354]train epoch: 83:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.000354]train epoch: 83:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.000173]train epoch: 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.11it/s, loss=0.000173]train epoch: 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.11it/s, loss=0.000173]
[[032m2021-11-26 10:13:02,447[0m INFO] trainer.training_epoch Training epoch 83, num_steps 672,  avg_loss: 0.0002, total_loss: 0.0015
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.59it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.62it/s]
[[032m2021-11-26 10:13:03,013[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:13:03,013[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:13:18,638[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 84:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 84:   0%|          | 0/8 [00:00<?, ?it/s, loss=9.89e-5]train epoch: 84:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.28it/s, loss=9.89e-5]train epoch: 84:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.28it/s, loss=0.000782]train epoch: 84:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.08it/s, loss=0.000782]train epoch: 84:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.08it/s, loss=7e-5]    train epoch: 84:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.69it/s, loss=7e-5]train epoch: 84:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.69it/s, loss=5.04e-5]train epoch: 84:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.98it/s, loss=5.04e-5]train epoch: 84:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.98it/s, loss=0.000179]train epoch: 84:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.96it/s, loss=0.000179]train epoch: 84:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.96it/s, loss=0.000342]train epoch: 84:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.70it/s, loss=0.000342]train epoch: 84:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.70it/s, loss=0.000487]train epoch: 84:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.75it/s, loss=0.000487]train epoch: 84:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.75it/s, loss=0.00141] train epoch: 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.90it/s, loss=0.00141]train epoch: 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.87it/s, loss=0.00141]
[[032m2021-11-26 10:13:22,921[0m INFO] trainer.training_epoch Training epoch 84, num_steps 680,  avg_loss: 0.0004, total_loss: 0.0034
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.75it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.02it/s]
[[032m2021-11-26 10:13:23,435[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:13:23,435[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:13:37,194[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 85:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 85:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000125]train epoch: 85:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.89it/s, loss=0.000125]train epoch: 85:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.89it/s, loss=0.000495]train epoch: 85:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.32it/s, loss=0.000495]train epoch: 85:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.32it/s, loss=0.000106]train epoch: 85:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.31it/s, loss=0.000106]train epoch: 85:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.31it/s, loss=0.0307]  train epoch: 85:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.20it/s, loss=0.0307]train epoch: 85:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.20it/s, loss=0.000873]train epoch: 85:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.22it/s, loss=0.000873]train epoch: 85:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.22it/s, loss=6.8e-5]  train epoch: 85:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.25it/s, loss=6.8e-5]train epoch: 85:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.25it/s, loss=0.000202]train epoch: 85:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=0.000202]train epoch: 85:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=4.74e-5] train epoch: 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=4.74e-5]train epoch: 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.12it/s, loss=4.74e-5]
[[032m2021-11-26 10:13:41,036[0m INFO] trainer.training_epoch Training epoch 85, num_steps 688,  avg_loss: 0.0041, total_loss: 0.0327
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.34it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.60it/s]
[[032m2021-11-26 10:13:41,561[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:13:41,561[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:13:56,104[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 86:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 86:   0%|          | 0/8 [00:00<?, ?it/s, loss=8.26e-5]train epoch: 86:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.01it/s, loss=8.26e-5]train epoch: 86:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.01it/s, loss=0.000176]train epoch: 86:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.86it/s, loss=0.000176]train epoch: 86:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.86it/s, loss=0.000316]train epoch: 86:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.32it/s, loss=0.000316]train epoch: 86:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.32it/s, loss=0.000166]train epoch: 86:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.35it/s, loss=0.000166]train epoch: 86:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.35it/s, loss=0.000936]train epoch: 86:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=0.000936]train epoch: 86:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=0.000362]train epoch: 86:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.52it/s, loss=0.000362]train epoch: 86:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.52it/s, loss=0.000494]train epoch: 86:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.60it/s, loss=0.000494]train epoch: 86:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.60it/s, loss=0.00019] train epoch: 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.65it/s, loss=0.00019]train epoch: 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.44it/s, loss=0.00019]
[[032m2021-11-26 10:13:59,401[0m INFO] trainer.training_epoch Training epoch 86, num_steps 696,  avg_loss: 0.0003, total_loss: 0.0027
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.96it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.84it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.10it/s]
[[032m2021-11-26 10:14:02,713[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:14:02,713[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:14:17,322[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 87:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 87:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000865]train epoch: 87:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.29it/s, loss=0.000865]train epoch: 87:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.29it/s, loss=7.44e-5] train epoch: 87:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.26it/s, loss=7.44e-5]train epoch: 87:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.26it/s, loss=5.82e-5]train epoch: 87:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.81it/s, loss=5.82e-5]train epoch: 87:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.81it/s, loss=0.000215]train epoch: 87:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.76it/s, loss=0.000215]train epoch: 87:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.76it/s, loss=8.03e-5] train epoch: 87:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.07it/s, loss=8.03e-5]train epoch: 87:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.07it/s, loss=0.00064]train epoch: 87:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.11it/s, loss=0.00064]train epoch: 87:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.11it/s, loss=0.000134]train epoch: 87:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.20it/s, loss=0.000134]train epoch: 87:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.20it/s, loss=6.2e-5]  train epoch: 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.44it/s, loss=6.2e-5]train epoch: 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.20it/s, loss=6.2e-5]
[[032m2021-11-26 10:14:20,979[0m INFO] trainer.training_epoch Training epoch 87, num_steps 704,  avg_loss: 0.0003, total_loss: 0.0021
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.50it/s]
[[032m2021-11-26 10:14:21,376[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:14:21,376[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:14:36,455[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 88:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 88:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00141]train epoch: 88:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.42it/s, loss=0.00141]train epoch: 88:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.42it/s, loss=0.000864]train epoch: 88:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.87it/s, loss=0.000864]train epoch: 88:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.87it/s, loss=0.000239]train epoch: 88:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.14it/s, loss=0.000239]train epoch: 88:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.14it/s, loss=2.74e-5] train epoch: 88:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=2.74e-5]train epoch: 88:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=7.21e-5]train epoch: 88:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.46it/s, loss=7.21e-5]train epoch: 88:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.46it/s, loss=0.00032]train epoch: 88:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.22it/s, loss=0.00032]train epoch: 88:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.22it/s, loss=0.00147]train epoch: 88:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.51it/s, loss=0.00147]train epoch: 88:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.51it/s, loss=0.000324]train epoch: 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.59it/s, loss=0.000324]train epoch: 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.56it/s, loss=0.000324]
[[032m2021-11-26 10:14:39,611[0m INFO] trainer.training_epoch Training epoch 88, num_steps 712,  avg_loss: 0.0006, total_loss: 0.0047
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.55it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.23it/s]
[[032m2021-11-26 10:14:40,517[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:14:40,517[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:14:54,649[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 89:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 89:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000728]train epoch: 89:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.98it/s, loss=0.000728]train epoch: 89:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.98it/s, loss=0.00019] train epoch: 89:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.01it/s, loss=0.00019]train epoch: 89:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.01it/s, loss=0.000137]train epoch: 89:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.56it/s, loss=0.000137]train epoch: 89:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.56it/s, loss=4.61e-5] train epoch: 89:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=4.61e-5]train epoch: 89:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=0.000294]train epoch: 89:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.57it/s, loss=0.000294]train epoch: 89:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.57it/s, loss=0.000751]train epoch: 89:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.51it/s, loss=0.000751]train epoch: 89:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.51it/s, loss=0.000226]train epoch: 89:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.32it/s, loss=0.000226]train epoch: 89:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.000171]train epoch: 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.97it/s, loss=0.000171]train epoch: 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s, loss=0.000171]
[[032m2021-11-26 10:14:58,177[0m INFO] trainer.training_epoch Training epoch 89, num_steps 720,  avg_loss: 0.0003, total_loss: 0.0025
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.01it/s]
[[032m2021-11-26 10:14:58,575[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:14:58,576[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:15:13,324[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 90:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 90:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000445]train epoch: 90:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.85it/s, loss=0.000445]train epoch: 90:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.85it/s, loss=8.98e-5] train epoch: 90:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.39it/s, loss=8.98e-5]train epoch: 90:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.39it/s, loss=0.000195]train epoch: 90:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.25it/s, loss=0.000195]train epoch: 90:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.25it/s, loss=0.000221]train epoch: 90:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.44it/s, loss=0.000221]train epoch: 90:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.44it/s, loss=0.000135]train epoch: 90:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.39it/s, loss=0.000135]train epoch: 90:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.39it/s, loss=0.000303]train epoch: 90:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.32it/s, loss=0.000303]train epoch: 90:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.32it/s, loss=0.000708]train epoch: 90:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.29it/s, loss=0.000708]train epoch: 90:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=0.00166] train epoch: 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=0.00166]train epoch: 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.23it/s, loss=0.00166]
[[032m2021-11-26 10:15:16,953[0m INFO] trainer.training_epoch Training epoch 90, num_steps 728,  avg_loss: 0.0005, total_loss: 0.0038
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.49it/s]
[[032m2021-11-26 10:15:17,989[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:15:17,990[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:15:32,332[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 91:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 91:   0%|          | 0/8 [00:00<?, ?it/s, loss=8.25e-5]train epoch: 91:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.33it/s, loss=8.25e-5]train epoch: 91:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.33it/s, loss=0.000322]train epoch: 91:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.93it/s, loss=0.000322]train epoch: 91:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.93it/s, loss=0.000725]train epoch: 91:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.81it/s, loss=0.000725]train epoch: 91:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.81it/s, loss=0.000244]train epoch: 91:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=0.000244]train epoch: 91:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.16it/s, loss=0.204]   train epoch: 91:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=0.204]train epoch: 91:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=0.000135]train epoch: 91:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.77it/s, loss=0.000135]train epoch: 91:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.77it/s, loss=0.000577]train epoch: 91:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.90it/s, loss=0.000577]train epoch: 91:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.90it/s, loss=8.61e-5] train epoch: 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=8.61e-5]train epoch: 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.07it/s, loss=8.61e-5]
[[032m2021-11-26 10:15:36,215[0m INFO] trainer.training_epoch Training epoch 91, num_steps 736,  avg_loss: 0.0257, total_loss: 0.2058
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.60it/s]
[[032m2021-11-26 10:15:36,655[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:15:36,655[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:15:51,653[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 92:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 92:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00038]train epoch: 92:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.73it/s, loss=0.00038]train epoch: 92:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.73it/s, loss=4.42e-5]train epoch: 92:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.55it/s, loss=4.42e-5]train epoch: 92:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.55it/s, loss=0.000129]train epoch: 92:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.63it/s, loss=0.000129]train epoch: 92:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.63it/s, loss=0.00116] train epoch: 92:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.19it/s, loss=0.00116]train epoch: 92:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.19it/s, loss=5.7e-5] train epoch: 92:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.12it/s, loss=5.7e-5]train epoch: 92:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.12it/s, loss=0.000916]train epoch: 92:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.30it/s, loss=0.000916]train epoch: 92:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.30it/s, loss=0.000267]train epoch: 92:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=0.000267]train epoch: 92:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=0.000741]train epoch: 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s, loss=0.000741]train epoch: 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.31it/s, loss=0.000741]
[[032m2021-11-26 10:15:55,127[0m INFO] trainer.training_epoch Training epoch 92, num_steps 744,  avg_loss: 0.0005, total_loss: 0.0037
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.24it/s]
[[032m2021-11-26 10:15:55,947[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:15:55,948[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:16:10,223[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 93:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 93:   0%|          | 0/8 [00:00<?, ?it/s, loss=4.13e-5]train epoch: 93:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.89it/s, loss=4.13e-5]train epoch: 93:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.89it/s, loss=7.83e-5]train epoch: 93:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.63it/s, loss=7.83e-5]train epoch: 93:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.63it/s, loss=0.000305]train epoch: 93:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=0.000305]train epoch: 93:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=0.000438]train epoch: 93:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.66it/s, loss=0.000438]train epoch: 93:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.66it/s, loss=0.00013] train epoch: 93:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.90it/s, loss=0.00013]train epoch: 93:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.90it/s, loss=8.02e-5]train epoch: 93:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.98it/s, loss=8.02e-5]train epoch: 93:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.98it/s, loss=0.000106]train epoch: 93:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.96it/s, loss=0.000106]train epoch: 93:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.96it/s, loss=0.000392]train epoch: 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.88it/s, loss=0.000392]train epoch: 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.95it/s, loss=0.000392]
[[032m2021-11-26 10:16:14,351[0m INFO] trainer.training_epoch Training epoch 93, num_steps 752,  avg_loss: 0.0002, total_loss: 0.0016
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.92it/s]
[[032m2021-11-26 10:16:14,788[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:16:14,788[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:16:28,504[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 94:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 94:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000243]train epoch: 94:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=0.000243]train epoch: 94:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=4.38e-5] train epoch: 94:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.59it/s, loss=4.38e-5]train epoch: 94:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.59it/s, loss=3.07e-5]train epoch: 94:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.91it/s, loss=3.07e-5]train epoch: 94:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.91it/s, loss=7.53e-5]train epoch: 94:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=7.53e-5]train epoch: 94:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=0.000138]train epoch: 94:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=0.000138]train epoch: 94:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=0.000324]train epoch: 94:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=0.000324]train epoch: 94:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=0.000599]train epoch: 94:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.70it/s, loss=0.000599]train epoch: 94:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.70it/s, loss=0.000118]train epoch: 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.66it/s, loss=0.000118]train epoch: 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=0.000118]
[[032m2021-11-26 10:16:31,383[0m INFO] trainer.training_epoch Training epoch 94, num_steps 760,  avg_loss: 0.0002, total_loss: 0.0016
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.60it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.33it/s]
[[032m2021-11-26 10:16:34,094[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:16:34,094[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:16:47,748[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 95:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 95:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.031]train epoch: 95:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.14it/s, loss=0.031]train epoch: 95:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.14it/s, loss=0.000133]train epoch: 95:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.51it/s, loss=0.000133]train epoch: 95:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.51it/s, loss=0.000233]train epoch: 95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=0.000233]train epoch: 95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=0.00187] train epoch: 95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=0.00187]train epoch: 95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=8.38e-5]train epoch: 95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.79it/s, loss=8.38e-5]train epoch: 95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.79it/s, loss=0.000308]train epoch: 95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.72it/s, loss=0.000308]train epoch: 95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.72it/s, loss=0.0491]  train epoch: 95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=0.0491]train epoch: 95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=0.000447]train epoch: 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=0.000447]train epoch: 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.58it/s, loss=0.000447]
[[032m2021-11-26 10:16:50,858[0m INFO] trainer.training_epoch Training epoch 95, num_steps 768,  avg_loss: 0.0104, total_loss: 0.0832
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.58it/s]
[[032m2021-11-26 10:16:51,301[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:16:51,301[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:17:05,602[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 96:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 96:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000987]train epoch: 96:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.18it/s, loss=0.000987]train epoch: 96:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.18it/s, loss=0.000126]train epoch: 96:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.03it/s, loss=0.000126]train epoch: 96:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.03it/s, loss=0.000119]train epoch: 96:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=0.000119]train epoch: 96:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=0.0013]  train epoch: 96:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.37it/s, loss=0.0013]train epoch: 96:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.37it/s, loss=0.0111]train epoch: 96:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.02it/s, loss=0.0111]train epoch: 96:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.02it/s, loss=8.94e-5]train epoch: 96:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.01it/s, loss=8.94e-5]train epoch: 96:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.01it/s, loss=5.93e-5]train epoch: 96:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.28it/s, loss=5.93e-5]train epoch: 96:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.28it/s, loss=0.000199]train epoch: 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.72it/s, loss=0.000199]train epoch: 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.97it/s, loss=0.000199]
[[032m2021-11-26 10:17:09,689[0m INFO] trainer.training_epoch Training epoch 96, num_steps 776,  avg_loss: 0.0017, total_loss: 0.0140
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.64it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.90it/s]
[[032m2021-11-26 10:17:11,853[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:17:11,853[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:17:26,565[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 97:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 97:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00112]train epoch: 97:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.10it/s, loss=0.00112]train epoch: 97:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.10it/s, loss=0.000114]train epoch: 97:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.57it/s, loss=0.000114]train epoch: 97:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.57it/s, loss=4.82e-5] train epoch: 97:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.15it/s, loss=4.82e-5]train epoch: 97:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.15it/s, loss=0.000207]train epoch: 97:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.13it/s, loss=0.000207]train epoch: 97:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.13it/s, loss=0.000236]train epoch: 97:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=0.000236]train epoch: 97:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=4.5e-5]  train epoch: 97:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.48it/s, loss=4.5e-5]train epoch: 97:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.48it/s, loss=6.87e-5]train epoch: 97:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.67it/s, loss=6.87e-5]train epoch: 97:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.67it/s, loss=0.000246]train epoch: 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.83it/s, loss=0.000246]train epoch: 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=0.000246]
[[032m2021-11-26 10:17:29,751[0m INFO] trainer.training_epoch Training epoch 97, num_steps 784,  avg_loss: 0.0003, total_loss: 0.0021
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.01it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.43it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.48it/s]
[[032m2021-11-26 10:17:30,257[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:17:30,257[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:17:43,995[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 98:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 98:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000232]train epoch: 98:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.45it/s, loss=0.000232]train epoch: 98:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.45it/s, loss=0.000279]train epoch: 98:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.13it/s, loss=0.000279]train epoch: 98:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.13it/s, loss=0.000294]train epoch: 98:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=0.000294]train epoch: 98:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=0.000263]train epoch: 98:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=0.000263]train epoch: 98:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=0.000236]train epoch: 98:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.32it/s, loss=0.000236]train epoch: 98:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.32it/s, loss=0.000438]train epoch: 98:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.15it/s, loss=0.000438]train epoch: 98:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.15it/s, loss=7.18e-5] train epoch: 98:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.73it/s, loss=7.18e-5]train epoch: 98:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.73it/s, loss=0.000333]train epoch: 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.72it/s, loss=0.000333]train epoch: 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.97it/s, loss=0.000333]
[[032m2021-11-26 10:17:48,070[0m INFO] trainer.training_epoch Training epoch 98, num_steps 792,  avg_loss: 0.0003, total_loss: 0.0021
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.89it/s]
[[032m2021-11-26 10:17:50,164[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:17:50,164[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:18:04,143[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 99:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 99:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000198]train epoch: 99:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=0.000198]train epoch: 99:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=0.000191]train epoch: 99:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.90it/s, loss=0.000191]train epoch: 99:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.90it/s, loss=9.44e-5] train epoch: 99:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.23it/s, loss=9.44e-5]train epoch: 99:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.23it/s, loss=0.000313]train epoch: 99:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.24it/s, loss=0.000313]train epoch: 99:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.24it/s, loss=0.000123]train epoch: 99:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=0.000123]train epoch: 99:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=0.000277]train epoch: 99:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=0.000277]train epoch: 99:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=0.000193]train epoch: 99:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.54it/s, loss=0.000193]train epoch: 99:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.54it/s, loss=4.76e-5] train epoch: 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.66it/s, loss=4.76e-5]train epoch: 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.42it/s, loss=4.76e-5]
[[032m2021-11-26 10:18:07,460[0m INFO] trainer.training_epoch Training epoch 99, num_steps 800,  avg_loss: 0.0002, total_loss: 0.0014
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.70it/s]
[[032m2021-11-26 10:18:07,873[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:18:07,873[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:18:21,580[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 100:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 100:   0%|          | 0/8 [00:00<?, ?it/s, loss=3.53e-5]train epoch: 100:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.56it/s, loss=3.53e-5]train epoch: 100:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.56it/s, loss=0.000146]train epoch: 100:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.50it/s, loss=0.000146]train epoch: 100:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.50it/s, loss=0.000589]train epoch: 100:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.44it/s, loss=0.000589]train epoch: 100:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.44it/s, loss=0.000544]train epoch: 100:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=0.000544]train epoch: 100:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=0.000258]train epoch: 100:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.45it/s, loss=0.000258]train epoch: 100:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.45it/s, loss=0.000139]train epoch: 100:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.10it/s, loss=0.000139]train epoch: 100:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.10it/s, loss=9.57e-5] train epoch: 100:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.31it/s, loss=9.57e-5]train epoch: 100:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.31it/s, loss=0.000356]train epoch: 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.41it/s, loss=0.000356]train epoch: 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.39it/s, loss=0.000356]
[[032m2021-11-26 10:18:24,940[0m INFO] trainer.training_epoch Training epoch 100, num_steps 808,  avg_loss: 0.0003, total_loss: 0.0022
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.83it/s]
[[032m2021-11-26 10:18:28,034[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:18:28,034[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:18:43,275[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 101:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 101:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000235]train epoch: 101:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.13it/s, loss=0.000235]train epoch: 101:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.13it/s, loss=7.08e-5] train epoch: 101:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.04it/s, loss=7.08e-5]train epoch: 101:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.04it/s, loss=0.000764]train epoch: 101:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.15it/s, loss=0.000764]train epoch: 101:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.15it/s, loss=0.000179]train epoch: 101:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.23it/s, loss=0.000179]train epoch: 101:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.23it/s, loss=0.00034] train epoch: 101:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.24it/s, loss=0.00034]train epoch: 101:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.24it/s, loss=0.00181]train epoch: 101:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.05it/s, loss=0.00181]train epoch: 101:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.05it/s, loss=0.000253]train epoch: 101:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.25it/s, loss=0.000253]train epoch: 101:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.25it/s, loss=0.000426]train epoch: 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.55it/s, loss=0.000426]train epoch: 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.30it/s, loss=0.000426]
[[032m2021-11-26 10:18:46,765[0m INFO] trainer.training_epoch Training epoch 101, num_steps 816,  avg_loss: 0.0005, total_loss: 0.0041
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.58it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.86it/s]
[[032m2021-11-26 10:18:47,365[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:18:47,365[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:19:01,874[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 102:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 102:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000214]train epoch: 102:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.76it/s, loss=0.000214]train epoch: 102:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.76it/s, loss=7.39e-5] train epoch: 102:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.40it/s, loss=7.39e-5]train epoch: 102:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.40it/s, loss=0.000646]train epoch: 102:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.30it/s, loss=0.000646]train epoch: 102:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.30it/s, loss=0.000378]train epoch: 102:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.20it/s, loss=0.000378]train epoch: 102:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.20it/s, loss=0.000113]train epoch: 102:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.17it/s, loss=0.000113]train epoch: 102:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.17it/s, loss=3.9e-5]  train epoch: 102:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.99it/s, loss=3.9e-5]train epoch: 102:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.99it/s, loss=0.000195]train epoch: 102:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.98it/s, loss=0.000195]train epoch: 102:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.98it/s, loss=3.4e-5]  train epoch: 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.90it/s, loss=3.4e-5]train epoch: 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.02it/s, loss=3.4e-5]
[[032m2021-11-26 10:19:05,863[0m INFO] trainer.training_epoch Training epoch 102, num_steps 824,  avg_loss: 0.0002, total_loss: 0.0017
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.31it/s]
[[032m2021-11-26 10:19:06,402[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:19:06,403[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:19:20,815[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 103:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 103:   0%|          | 0/8 [00:00<?, ?it/s, loss=5.11e-5]train epoch: 103:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.77it/s, loss=5.11e-5]train epoch: 103:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.77it/s, loss=0.000126]train epoch: 103:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.87it/s, loss=0.000126]train epoch: 103:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.87it/s, loss=0.0165]  train epoch: 103:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.0165]train epoch: 103:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.28it/s, loss=0.000507]train epoch: 103:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.85it/s, loss=0.000507]train epoch: 103:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.85it/s, loss=3.19e-5] train epoch: 103:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.82it/s, loss=3.19e-5]train epoch: 103:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.82it/s, loss=0.000235]train epoch: 103:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.13it/s, loss=0.000235]train epoch: 103:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.13it/s, loss=0.000146]train epoch: 103:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.42it/s, loss=0.000146]train epoch: 103:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.42it/s, loss=4.99e-5] train epoch: 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=4.99e-5]train epoch: 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.16it/s, loss=4.99e-5]
[[032m2021-11-26 10:19:24,539[0m INFO] trainer.training_epoch Training epoch 103, num_steps 832,  avg_loss: 0.0022, total_loss: 0.0177
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.71it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.99it/s]
[[032m2021-11-26 10:19:25,016[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:19:25,017[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:19:39,287[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 104:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 104:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000197]train epoch: 104:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.07it/s, loss=0.000197]train epoch: 104:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.07it/s, loss=0.00025] train epoch: 104:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.90it/s, loss=0.00025]train epoch: 104:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.90it/s, loss=0.00682]train epoch: 104:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.47it/s, loss=0.00682]train epoch: 104:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.47it/s, loss=0.000407]train epoch: 104:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=0.000407]train epoch: 104:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=0.000236]train epoch: 104:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.18it/s, loss=0.000236]train epoch: 104:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.18it/s, loss=4.79e-5] train epoch: 104:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.16it/s, loss=4.79e-5]train epoch: 104:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.16it/s, loss=0.000128]train epoch: 104:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.24it/s, loss=0.000128]train epoch: 104:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.24it/s, loss=9.09e-5] train epoch: 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.09it/s, loss=9.09e-5]train epoch: 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.25it/s, loss=9.09e-5]
[[032m2021-11-26 10:19:42,875[0m INFO] trainer.training_epoch Training epoch 104, num_steps 840,  avg_loss: 0.0010, total_loss: 0.0082
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.68it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.81it/s]
[[032m2021-11-26 10:19:44,627[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:19:44,627[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:19:57,361[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 105:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 105:   0%|          | 0/8 [00:00<?, ?it/s, loss=3.68e-5]train epoch: 105:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=3.68e-5]train epoch: 105:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=8.78e-5]train epoch: 105:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=8.78e-5]train epoch: 105:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=0.000166]train epoch: 105:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.79it/s, loss=0.000166]train epoch: 105:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.79it/s, loss=0.000471]train epoch: 105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=0.000471]train epoch: 105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=0.00105] train epoch: 105:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.42it/s, loss=0.00105]train epoch: 105:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.42it/s, loss=0.00017]train epoch: 105:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=0.00017]train epoch: 105:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=4.41e-5]train epoch: 105:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.74it/s, loss=4.41e-5]train epoch: 105:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.74it/s, loss=0.000133]train epoch: 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=0.000133]train epoch: 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=0.000133]
[[032m2021-11-26 10:20:00,240[0m INFO] trainer.training_epoch Training epoch 105, num_steps 848,  avg_loss: 0.0003, total_loss: 0.0022
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.41it/s]
[[032m2021-11-26 10:20:00,582[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:20:00,582[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:20:11,631[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 106:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 106:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000114]train epoch: 106:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.51it/s, loss=0.000114]train epoch: 106:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.51it/s, loss=6.55e-5] train epoch: 106:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.89it/s, loss=6.55e-5]train epoch: 106:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.89it/s, loss=2.37e-5]train epoch: 106:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=2.37e-5]train epoch: 106:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=0.000193]train epoch: 106:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=0.000193]train epoch: 106:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=0.00017] train epoch: 106:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.13it/s, loss=0.00017]train epoch: 106:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.13it/s, loss=8.73e-5]train epoch: 106:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.63it/s, loss=8.73e-5]train epoch: 106:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.63it/s, loss=0.000222]train epoch: 106:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.42it/s, loss=0.000222]train epoch: 106:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.42it/s, loss=0.000288]train epoch: 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.10it/s, loss=0.000288]train epoch: 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.45it/s, loss=0.000288]
[[032m2021-11-26 10:20:14,915[0m INFO] trainer.training_epoch Training epoch 106, num_steps 856,  avg_loss: 0.0001, total_loss: 0.0012
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.55it/s]
[[032m2021-11-26 10:20:15,352[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:20:15,352[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:20:28,088[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 107:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 107:   0%|          | 0/8 [00:00<?, ?it/s, loss=9.99e-5]train epoch: 107:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.94it/s, loss=9.99e-5]train epoch: 107:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.94it/s, loss=8.66e-5]train epoch: 107:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.94it/s, loss=8.66e-5]train epoch: 107:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.94it/s, loss=0.000155]train epoch: 107:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.96it/s, loss=0.000155]train epoch: 107:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.96it/s, loss=2.87e-5] train epoch: 107:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.32it/s, loss=2.87e-5]train epoch: 107:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.32it/s, loss=0.000324]train epoch: 107:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=0.000324]train epoch: 107:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=3.84e-5] train epoch: 107:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.79it/s, loss=3.84e-5]train epoch: 107:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.79it/s, loss=0.000147]train epoch: 107:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=0.000147]train epoch: 107:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=0.000118]train epoch: 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  3.02it/s, loss=0.000118]train epoch: 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s, loss=0.000118]
[[032m2021-11-26 10:20:31,192[0m INFO] trainer.training_epoch Training epoch 107, num_steps 864,  avg_loss: 0.0001, total_loss: 0.0010
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.87it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.81it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.52it/s]
[[032m2021-11-26 10:20:31,737[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:20:31,737[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:20:42,519[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 108:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 108:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000117]train epoch: 108:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.52it/s, loss=0.000117]train epoch: 108:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.52it/s, loss=0.00143] train epoch: 108:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=0.00143]train epoch: 108:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=0.00021]train epoch: 108:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.77it/s, loss=0.00021]train epoch: 108:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.77it/s, loss=0.041]  train epoch: 108:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.51it/s, loss=0.041]train epoch: 108:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.51it/s, loss=0.00012]train epoch: 108:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=0.00012]train epoch: 108:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=5.52e-5]train epoch: 108:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.96it/s, loss=5.52e-5]train epoch: 108:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.96it/s, loss=7.07e-5]train epoch: 108:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.23it/s, loss=7.07e-5]train epoch: 108:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.23it/s, loss=0.000222]train epoch: 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.43it/s, loss=0.000222]train epoch: 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.38it/s, loss=0.000222]
[[032m2021-11-26 10:20:45,895[0m INFO] trainer.training_epoch Training epoch 108, num_steps 872,  avg_loss: 0.0054, total_loss: 0.0432
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.36it/s]
[[032m2021-11-26 10:20:46,232[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:20:46,232[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:20:57,327[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 109:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 109:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000487]train epoch: 109:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.89it/s, loss=0.000487]train epoch: 109:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.89it/s, loss=3.73e-5] train epoch: 109:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=3.73e-5]train epoch: 109:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=0.000131]train epoch: 109:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.87it/s, loss=0.000131]train epoch: 109:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.87it/s, loss=0.000382]train epoch: 109:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.23it/s, loss=0.000382]train epoch: 109:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.23it/s, loss=0.0215]  train epoch: 109:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.11it/s, loss=0.0215]train epoch: 109:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.11it/s, loss=4.09e-5]train epoch: 109:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.10it/s, loss=4.09e-5]train epoch: 109:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.10it/s, loss=2.84e-5]train epoch: 109:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.32it/s, loss=2.84e-5]train epoch: 109:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=0.000311]train epoch: 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.58it/s, loss=0.000311]train epoch: 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.45it/s, loss=0.000311]
[[032m2021-11-26 10:21:00,606[0m INFO] trainer.training_epoch Training epoch 109, num_steps 880,  avg_loss: 0.0029, total_loss: 0.0229
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.85it/s]
[[032m2021-11-26 10:21:00,973[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:21:00,973[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:21:12,473[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 110:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 110:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00013]train epoch: 110:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.10it/s, loss=0.00013]train epoch: 110:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.10it/s, loss=0.000243]train epoch: 110:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.63it/s, loss=0.000243]train epoch: 110:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.63it/s, loss=9.66e-5] train epoch: 110:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.84it/s, loss=9.66e-5]train epoch: 110:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.84it/s, loss=0.000103]train epoch: 110:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.99it/s, loss=0.000103]train epoch: 110:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.99it/s, loss=0.000265]train epoch: 110:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.16it/s, loss=0.000265]train epoch: 110:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.16it/s, loss=0.000152]train epoch: 110:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=0.000152]train epoch: 110:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=0.000153]train epoch: 110:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=0.000153]train epoch: 110:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.72it/s, loss=0.000245]train epoch: 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.86it/s, loss=0.000245]train epoch: 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.49it/s, loss=0.000245]
[[032m2021-11-26 10:21:15,696[0m INFO] trainer.training_epoch Training epoch 110, num_steps 888,  avg_loss: 0.0002, total_loss: 0.0014
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.77it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.14it/s]
[[032m2021-11-26 10:21:16,042[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:21:16,042[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:21:27,388[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 111:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 111:   0%|          | 0/8 [00:00<?, ?it/s, loss=2.94e-5]train epoch: 111:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.53it/s, loss=2.94e-5]train epoch: 111:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.53it/s, loss=0.00041]train epoch: 111:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.43it/s, loss=0.00041]train epoch: 111:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.43it/s, loss=0.000222]train epoch: 111:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=0.000222]train epoch: 111:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=0.000406]train epoch: 111:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.67it/s, loss=0.000406]train epoch: 111:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.67it/s, loss=0.000126]train epoch: 111:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.47it/s, loss=0.000126]train epoch: 111:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.47it/s, loss=0.000181]train epoch: 111:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.62it/s, loss=0.000181]train epoch: 111:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.62it/s, loss=0.000118]train epoch: 111:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.70it/s, loss=0.000118]train epoch: 111:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.70it/s, loss=0.000351]train epoch: 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=0.000351]train epoch: 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=0.000351]
[[032m2021-11-26 10:21:30,232[0m INFO] trainer.training_epoch Training epoch 111, num_steps 896,  avg_loss: 0.0002, total_loss: 0.0018
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.93it/s]
[[032m2021-11-26 10:21:30,590[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:21:30,591[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:21:42,253[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 112:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 112:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000544]train epoch: 112:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.26it/s, loss=0.000544]train epoch: 112:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.26it/s, loss=9.89e-5] train epoch: 112:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.85it/s, loss=9.89e-5]train epoch: 112:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.85it/s, loss=0.000251]train epoch: 112:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.87it/s, loss=0.000251]train epoch: 112:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.87it/s, loss=0.000929]train epoch: 112:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=0.000929]train epoch: 112:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=0.542]   train epoch: 112:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.64it/s, loss=0.542]train epoch: 112:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.64it/s, loss=7.88e-5]train epoch: 112:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=7.88e-5]train epoch: 112:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=0.000387]train epoch: 112:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.21it/s, loss=0.000387]train epoch: 112:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.21it/s, loss=0.000136]train epoch: 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.17it/s, loss=0.000136]train epoch: 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.39it/s, loss=0.000136]
[[032m2021-11-26 10:21:45,635[0m INFO] trainer.training_epoch Training epoch 112, num_steps 904,  avg_loss: 0.0680, total_loss: 0.5444
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.53it/s]
[[032m2021-11-26 10:21:45,998[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:21:45,999[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:21:58,225[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 113:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 113:   0%|          | 0/8 [00:00<?, ?it/s, loss=7.08e-5]train epoch: 113:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.37it/s, loss=7.08e-5]train epoch: 113:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.37it/s, loss=7.23e-5]train epoch: 113:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.38it/s, loss=7.23e-5]train epoch: 113:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.38it/s, loss=0.000119]train epoch: 113:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.15it/s, loss=0.000119]train epoch: 113:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.15it/s, loss=9.49e-5] train epoch: 113:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=9.49e-5]train epoch: 113:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=8.41e-5]train epoch: 113:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.54it/s, loss=8.41e-5]train epoch: 113:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.54it/s, loss=0.000187]train epoch: 113:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.29it/s, loss=0.000187]train epoch: 113:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.29it/s, loss=0.000195]train epoch: 113:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.35it/s, loss=0.000195]train epoch: 113:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.35it/s, loss=0.000307]train epoch: 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=0.000307]train epoch: 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.59it/s, loss=0.000307]
[[032m2021-11-26 10:22:01,320[0m INFO] trainer.training_epoch Training epoch 113, num_steps 912,  avg_loss: 0.0001, total_loss: 0.0011
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.37it/s]
[[032m2021-11-26 10:22:01,660[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:22:01,661[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:22:13,137[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 114:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 114:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000163]train epoch: 114:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.86it/s, loss=0.000163]train epoch: 114:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.86it/s, loss=4.92e-5] train epoch: 114:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.14it/s, loss=4.92e-5]train epoch: 114:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.14it/s, loss=0.000222]train epoch: 114:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.98it/s, loss=0.000222]train epoch: 114:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.98it/s, loss=6.65e-5] train epoch: 114:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.11it/s, loss=6.65e-5]train epoch: 114:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.11it/s, loss=0.000197]train epoch: 114:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.000197]train epoch: 114:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=6.89e-5] train epoch: 114:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.70it/s, loss=6.89e-5]train epoch: 114:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.70it/s, loss=7.96e-5]train epoch: 114:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.94it/s, loss=7.96e-5]train epoch: 114:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.94it/s, loss=0.000127]train epoch: 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.68it/s, loss=0.000127]train epoch: 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.51it/s, loss=0.000127]
[[032m2021-11-26 10:22:16,339[0m INFO] trainer.training_epoch Training epoch 114, num_steps 920,  avg_loss: 0.0001, total_loss: 0.0010
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.41it/s]
[[032m2021-11-26 10:22:16,680[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:22:16,681[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:22:28,736[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 115:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 115:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000267]train epoch: 115:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.41it/s, loss=0.000267]train epoch: 115:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.41it/s, loss=0.000164]train epoch: 115:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:03,  1.97it/s, loss=0.000164]train epoch: 115:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.97it/s, loss=0.000121]train epoch: 115:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=0.000121]train epoch: 115:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=0.000263]train epoch: 115:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.19it/s, loss=0.000263]train epoch: 115:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.19it/s, loss=8.59e-5] train epoch: 115:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.50it/s, loss=8.59e-5]train epoch: 115:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.50it/s, loss=0.00019]train epoch: 115:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.77it/s, loss=0.00019]train epoch: 115:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.77it/s, loss=9.71e-5]train epoch: 115:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=9.71e-5]train epoch: 115:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=3.85e-5]train epoch: 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  3.05it/s, loss=3.85e-5]train epoch: 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.63it/s, loss=3.85e-5]
[[032m2021-11-26 10:22:31,794[0m INFO] trainer.training_epoch Training epoch 115, num_steps 928,  avg_loss: 0.0002, total_loss: 0.0012
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.98it/s]
[[032m2021-11-26 10:22:32,177[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:22:32,177[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:22:43,924[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 116:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 116:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000148]train epoch: 116:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.19it/s, loss=0.000148]train epoch: 116:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.19it/s, loss=0.000189]train epoch: 116:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=0.000189]train epoch: 116:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=0.000254]train epoch: 116:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.84it/s, loss=0.000254]train epoch: 116:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.84it/s, loss=0.000129]train epoch: 116:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=0.000129]train epoch: 116:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=0.000112]train epoch: 116:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.36it/s, loss=0.000112]train epoch: 116:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=0.000108]train epoch: 116:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.31it/s, loss=0.000108]train epoch: 116:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.31it/s, loss=5.54e-5] train epoch: 116:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.53it/s, loss=5.54e-5]train epoch: 116:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.53it/s, loss=0.000347]train epoch: 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.64it/s, loss=0.000347]train epoch: 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.64it/s, loss=0.000347]
[[032m2021-11-26 10:22:46,974[0m INFO] trainer.training_epoch Training epoch 116, num_steps 936,  avg_loss: 0.0002, total_loss: 0.0013
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.13it/s]
[[032m2021-11-26 10:22:47,318[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:22:47,319[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:22:59,769[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 117:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 117:   0%|          | 0/8 [00:00<?, ?it/s, loss=7.03e-5]train epoch: 117:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.13it/s, loss=7.03e-5]train epoch: 117:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.13it/s, loss=7.87e-5]train epoch: 117:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.42it/s, loss=7.87e-5]train epoch: 117:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.42it/s, loss=0.000137]train epoch: 117:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.11it/s, loss=0.000137]train epoch: 117:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.11it/s, loss=4.07e-5] train epoch: 117:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.81it/s, loss=4.07e-5]train epoch: 117:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.81it/s, loss=8.09e-5]train epoch: 117:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.02it/s, loss=8.09e-5]train epoch: 117:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.02it/s, loss=5.59e-5]train epoch: 117:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.35it/s, loss=5.59e-5]train epoch: 117:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.35it/s, loss=0.000237]train epoch: 117:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.57it/s, loss=0.000237]train epoch: 117:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.57it/s, loss=8.17e-5] train epoch: 117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.74it/s, loss=8.17e-5]train epoch: 117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=8.17e-5]
[[032m2021-11-26 10:23:03,107[0m INFO] trainer.training_epoch Training epoch 117, num_steps 944,  avg_loss: 0.0001, total_loss: 0.0008
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.77it/s]
[[032m2021-11-26 10:23:03,495[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:23:03,496[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:23:14,804[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 118:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 118:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.00014]train epoch: 118:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.50it/s, loss=0.00014]train epoch: 118:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.50it/s, loss=0.000664]train epoch: 118:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.78it/s, loss=0.000664]train epoch: 118:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.78it/s, loss=0.000126]train epoch: 118:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.89it/s, loss=0.000126]train epoch: 118:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.89it/s, loss=0.000941]train epoch: 118:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=0.000941]train epoch: 118:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=2.13e-5] train epoch: 118:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=2.13e-5]train epoch: 118:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=0.000154]train epoch: 118:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.09it/s, loss=0.000154]train epoch: 118:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.09it/s, loss=0.000135]train epoch: 118:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=0.000135]train epoch: 118:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=0.00036] train epoch: 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=0.00036]train epoch: 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.07it/s, loss=0.00036]
[[032m2021-11-26 10:23:17,419[0m INFO] trainer.training_epoch Training epoch 118, num_steps 952,  avg_loss: 0.0003, total_loss: 0.0025
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.22it/s]
[[032m2021-11-26 10:23:17,824[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:23:17,825[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:23:29,460[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 119:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 119:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000183]train epoch: 119:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=0.000183]train epoch: 119:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=0.000162]train epoch: 119:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.48it/s, loss=0.000162]train epoch: 119:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.48it/s, loss=6.22e-5] train epoch: 119:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=6.22e-5]train epoch: 119:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=0.000386]train epoch: 119:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.05it/s, loss=0.000386]train epoch: 119:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.05it/s, loss=0.000651]train epoch: 119:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.25it/s, loss=0.000651]train epoch: 119:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.25it/s, loss=0.000249]train epoch: 119:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.50it/s, loss=0.000249]train epoch: 119:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.50it/s, loss=8.19e-5] train epoch: 119:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=8.19e-5]train epoch: 119:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.63it/s, loss=0.000218]train epoch: 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.85it/s, loss=0.000218]train epoch: 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=0.000218]
[[032m2021-11-26 10:23:32,616[0m INFO] trainer.training_epoch Training epoch 119, num_steps 960,  avg_loss: 0.0002, total_loss: 0.0020
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.37it/s]
[[032m2021-11-26 10:23:32,984[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:23:32,985[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:23:43,724[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 120:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 120:   0%|          | 0/8 [00:00<?, ?it/s, loss=9.49e-5]train epoch: 120:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.77it/s, loss=9.49e-5]train epoch: 120:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.77it/s, loss=0.000117]train epoch: 120:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=0.000117]train epoch: 120:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=0.000202]train epoch: 120:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.05it/s, loss=0.000202]train epoch: 120:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.05it/s, loss=0.000171]train epoch: 120:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.93it/s, loss=0.000171]train epoch: 120:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.93it/s, loss=6.55e-5] train epoch: 120:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.73it/s, loss=6.55e-5]train epoch: 120:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.73it/s, loss=0.000108]train epoch: 120:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.49it/s, loss=0.000108]train epoch: 120:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.49it/s, loss=0.000159]train epoch: 120:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.19it/s, loss=0.000159]train epoch: 120:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s, loss=0.000241]train epoch: 120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.38it/s, loss=0.000241]train epoch: 120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.53it/s, loss=0.000241]
[[032m2021-11-26 10:23:46,896[0m INFO] trainer.training_epoch Training epoch 120, num_steps 968,  avg_loss: 0.0001, total_loss: 0.0012
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.60it/s]
[[032m2021-11-26 10:23:47,254[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:23:47,254[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:23:58,714[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 121:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 121:   0%|          | 0/8 [00:00<?, ?it/s, loss=8.86e-5]train epoch: 121:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=8.86e-5]train epoch: 121:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=0.000479]train epoch: 121:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=0.000479]train epoch: 121:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=0.00039] train epoch: 121:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.08it/s, loss=0.00039]train epoch: 121:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.08it/s, loss=0.000395]train epoch: 121:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=0.000395]train epoch: 121:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=8.41e-5] train epoch: 121:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=8.41e-5]train epoch: 121:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=0.000102]train epoch: 121:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.92it/s, loss=0.000102]train epoch: 121:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=0.000126]train epoch: 121:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.88it/s, loss=0.000126]train epoch: 121:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.88it/s, loss=5.21e-5] train epoch: 121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.83it/s, loss=5.21e-5]train epoch: 121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=5.21e-5]
[[032m2021-11-26 10:24:01,412[0m INFO] trainer.training_epoch Training epoch 121, num_steps 976,  avg_loss: 0.0002, total_loss: 0.0017
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.48it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.15it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.48it/s]
[[032m2021-11-26 10:24:01,999[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:24:01,999[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:24:14,001[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 122:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 122:   0%|          | 0/8 [00:00<?, ?it/s, loss=3.97e-5]train epoch: 122:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=3.97e-5]train epoch: 122:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=0.000564]train epoch: 122:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.82it/s, loss=0.000564]train epoch: 122:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.82it/s, loss=0.000276]train epoch: 122:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.18it/s, loss=0.000276]train epoch: 122:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.18it/s, loss=0.000297]train epoch: 122:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.21it/s, loss=0.000297]train epoch: 122:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.21it/s, loss=5.91e-5] train epoch: 122:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=5.91e-5]train epoch: 122:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.000103]train epoch: 122:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.66it/s, loss=0.000103]train epoch: 122:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.66it/s, loss=6.77e-5] train epoch: 122:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=6.77e-5]train epoch: 122:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=8.37e-5]train epoch: 122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.80it/s, loss=8.37e-5]train epoch: 122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.62it/s, loss=8.37e-5]
[[032m2021-11-26 10:24:17,066[0m INFO] trainer.training_epoch Training epoch 122, num_steps 984,  avg_loss: 0.0002, total_loss: 0.0015
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.90it/s]
[[032m2021-11-26 10:24:17,418[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:24:17,418[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:24:28,670[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 123:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 123:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000208]train epoch: 123:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.63it/s, loss=0.000208]train epoch: 123:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.63it/s, loss=0.000125]train epoch: 123:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=0.000125]train epoch: 123:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=7.28e-5] train epoch: 123:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=7.28e-5]train epoch: 123:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.89it/s, loss=2.48e-5]train epoch: 123:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.06it/s, loss=2.48e-5]train epoch: 123:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.06it/s, loss=0.000527]train epoch: 123:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.000527]train epoch: 123:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=0.000266]train epoch: 123:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=0.000266]train epoch: 123:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=0.000253]train epoch: 123:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=0.000253]train epoch: 123:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.81it/s, loss=9.29e-5] train epoch: 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.98it/s, loss=9.29e-5]train epoch: 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=9.29e-5]
[[032m2021-11-26 10:24:31,918[0m INFO] trainer.training_epoch Training epoch 123, num_steps 992,  avg_loss: 0.0002, total_loss: 0.0016
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.47it/s]
[[032m2021-11-26 10:24:32,253[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:24:32,254[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:24:44,138[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 124:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 124:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.000585]train epoch: 124:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.71it/s, loss=0.000585]train epoch: 124:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.71it/s, loss=0.000254]train epoch: 124:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.76it/s, loss=0.000254]train epoch: 124:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.76it/s, loss=3.79e-5] train epoch: 124:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.14it/s, loss=3.79e-5]train epoch: 124:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.14it/s, loss=0.000293]train epoch: 124:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.51it/s, loss=0.000293]train epoch: 124:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.51it/s, loss=4.57e-5] train epoch: 124:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.75it/s, loss=4.57e-5]train epoch: 124:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.75it/s, loss=0.000439]train epoch: 124:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=0.000439]train epoch: 124:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=0.000146]train epoch: 124:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.80it/s, loss=0.000146]train epoch: 124:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.80it/s, loss=0.00019] train epoch: 124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.84it/s, loss=0.00019][[032m2021-11-26 10:24:47,270[0m INFO] trainer.training_epoch Training epoch 124, num_steps 1000, avg_loss: 0.0002, total_loss: 0.0020
train epoch: 124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.56it/s, loss=0.00019]
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.27it/s]
[[032m2021-11-26 10:24:47,638[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:24:47,639[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:24:58,714[0m INFO] trainer.save_checkpoint Save Checkpoint finished
[[032m2021-11-26 10:24:58,715[0m INFO] trainer.fit Stop training by reaching maximum num_training_steps
[[032m2021-11-26 10:24:58,715[0m INFO] trainer.load_checkpoint Loading Checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:25:03,080[0m INFO] trainer.load_checkpoint Load Checkpoint finished, the current validation metric: 0.609375
test:   0%|          | 0/205 [00:00<?, ?it/s]test:   1%|          | 2/205 [00:00<00:19, 10.60it/s]test:   2%|â–         | 4/205 [00:00<00:21,  9.17it/s]test:   2%|â–         | 5/205 [00:00<00:25,  7.82it/s]test:   3%|â–Ž         | 6/205 [00:00<00:30,  6.56it/s]test:   3%|â–Ž         | 7/205 [00:00<00:29,  6.76it/s]test:   4%|â–         | 8/205 [00:01<00:27,  7.21it/s]test:   5%|â–         | 10/205 [00:01<00:23,  8.26it/s]test:   6%|â–Œ         | 12/205 [00:01<00:20,  9.32it/s]test:   7%|â–‹         | 14/205 [00:01<00:18, 10.15it/s]test:   8%|â–Š         | 16/205 [00:01<00:18, 10.20it/s]test:   9%|â–‰         | 18/205 [00:01<00:17, 10.54it/s]test:  10%|â–‰         | 20/205 [00:02<00:16, 10.98it/s]test:  11%|â–ˆ         | 22/205 [00:02<00:16, 10.98it/s]test:  12%|â–ˆâ–        | 24/205 [00:02<00:16, 11.17it/s]test:  13%|â–ˆâ–Ž        | 26/205 [00:02<00:16, 10.54it/s]test:  14%|â–ˆâ–Ž        | 28/205 [00:02<00:16, 10.89it/s]test:  15%|â–ˆâ–        | 30/205 [00:03<00:15, 11.05it/s]test:  16%|â–ˆâ–Œ        | 32/205 [00:03<00:16, 10.73it/s]test:  17%|â–ˆâ–‹        | 34/205 [00:03<00:16, 10.27it/s]test:  18%|â–ˆâ–Š        | 36/205 [00:03<00:17,  9.77it/s]test:  18%|â–ˆâ–Š        | 37/205 [00:03<00:19,  8.59it/s]test:  19%|â–ˆâ–Š        | 38/205 [00:04<00:20,  8.26it/s]test:  19%|â–ˆâ–‰        | 39/205 [00:04<00:20,  8.22it/s]test:  20%|â–ˆâ–‰        | 40/205 [00:04<00:20,  7.94it/s]test:  20%|â–ˆâ–ˆ        | 42/205 [00:04<00:17,  9.06it/s]test:  21%|â–ˆâ–ˆâ–       | 44/205 [00:04<00:16,  9.77it/s]test:  22%|â–ˆâ–ˆâ–       | 46/205 [00:04<00:15, 10.56it/s]test:  23%|â–ˆâ–ˆâ–Ž       | 48/205 [00:04<00:14, 10.58it/s]test:  24%|â–ˆâ–ˆâ–       | 50/205 [00:05<00:14, 11.01it/s]test:  25%|â–ˆâ–ˆâ–Œ       | 52/205 [00:05<00:13, 11.12it/s]test:  26%|â–ˆâ–ˆâ–‹       | 54/205 [00:05<00:14, 10.19it/s]test:  27%|â–ˆâ–ˆâ–‹       | 56/205 [00:05<00:13, 10.74it/s]test:  28%|â–ˆâ–ˆâ–Š       | 58/205 [00:05<00:13, 11.28it/s]test:  29%|â–ˆâ–ˆâ–‰       | 60/205 [00:06<00:12, 11.66it/s]test:  30%|â–ˆâ–ˆâ–ˆ       | 62/205 [00:06<00:12, 11.70it/s]test:  31%|â–ˆâ–ˆâ–ˆ       | 64/205 [00:06<00:12, 11.71it/s]test:  32%|â–ˆâ–ˆâ–ˆâ–      | 66/205 [00:06<00:11, 11.72it/s]test:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 68/205 [00:06<00:12, 11.11it/s]test:  34%|â–ˆâ–ˆâ–ˆâ–      | 70/205 [00:06<00:12, 10.47it/s]test:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/205 [00:07<00:11, 11.12it/s]test:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 74/205 [00:07<00:12, 10.61it/s]test:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 76/205 [00:07<00:12, 10.03it/s]test:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 78/205 [00:07<00:12, 10.24it/s]test:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 80/205 [00:07<00:11, 10.75it/s]test:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/205 [00:08<00:11, 10.76it/s]test:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 84/205 [00:08<00:12, 10.07it/s]test:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/205 [00:08<00:11, 10.61it/s]test:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 88/205 [00:08<00:10, 11.19it/s]test:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 90/205 [00:08<00:10, 11.48it/s]test:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 92/205 [00:08<00:09, 11.49it/s]test:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 94/205 [00:09<00:10, 10.18it/s]test:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 96/205 [00:09<00:11,  9.36it/s]test:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 97/205 [00:09<00:11,  9.30it/s]test:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 98/205 [00:09<00:12,  8.65it/s]test:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 100/205 [00:09<00:11,  9.44it/s]test:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 102/205 [00:10<00:10,  9.74it/s]test:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 103/205 [00:10<00:10,  9.69it/s]test:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 105/205 [00:10<00:10,  9.52it/s]test:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 106/205 [00:10<00:11,  8.83it/s]test:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/205 [00:10<00:11,  8.84it/s]test:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 108/205 [00:10<00:10,  8.88it/s]test:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 110/205 [00:10<00:09,  9.67it/s]test:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 112/205 [00:11<00:09,  9.74it/s]test:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 113/205 [00:11<00:09,  9.28it/s]test:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 115/205 [00:11<00:09,  9.77it/s]test:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 116/205 [00:11<00:09,  9.23it/s]test:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 118/205 [00:11<00:08,  9.90it/s]test:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 120/205 [00:11<00:08, 10.61it/s]test:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 122/205 [00:12<00:07, 11.16it/s]test:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 124/205 [00:12<00:07, 11.39it/s]test:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126/205 [00:12<00:06, 11.42it/s]test:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/205 [00:12<00:06, 11.61it/s]test:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 130/205 [00:12<00:06, 11.13it/s]test:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 132/205 [00:12<00:06, 11.56it/s]test:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 134/205 [00:13<00:05, 11.98it/s]test:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 136/205 [00:13<00:06, 11.27it/s]test:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 138/205 [00:13<00:06,  9.93it/s]test:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 140/205 [00:13<00:06,  9.34it/s]test:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 141/205 [00:13<00:07,  8.64it/s]test:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 142/205 [00:14<00:07,  8.24it/s]test:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 143/205 [00:14<00:07,  7.79it/s]test:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 144/205 [00:14<00:07,  8.07it/s]test:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 146/205 [00:14<00:06,  9.21it/s]test:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/205 [00:14<00:05, 10.15it/s]test:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 150/205 [00:14<00:05, 10.78it/s]test:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 152/205 [00:15<00:04, 10.84it/s]test:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 154/205 [00:15<00:04, 11.15it/s]test:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 156/205 [00:15<00:04, 11.28it/s]test:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 158/205 [00:15<00:04, 10.88it/s]test:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 160/205 [00:15<00:04, 11.15it/s]test:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 162/205 [00:15<00:03, 11.02it/s]test:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 164/205 [00:16<00:03, 10.75it/s]test:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 166/205 [00:16<00:03, 10.53it/s]test:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/205 [00:16<00:03, 10.84it/s]test:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 170/205 [00:16<00:03, 10.54it/s]test:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 172/205 [00:16<00:03,  9.86it/s]test:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 174/205 [00:17<00:02, 10.40it/s]test:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 176/205 [00:17<00:02, 10.42it/s]test:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 178/205 [00:17<00:02, 10.65it/s]test:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 180/205 [00:17<00:02, 11.19it/s]test:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 182/205 [00:17<00:01, 11.62it/s]test:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 184/205 [00:17<00:01, 11.80it/s]test:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 186/205 [00:18<00:01, 12.01it/s]test:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/205 [00:18<00:01, 11.75it/s]test:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 190/205 [00:18<00:01, 11.93it/s]test:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 192/205 [00:18<00:01, 12.19it/s]test:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 194/205 [00:18<00:00, 12.18it/s]test:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 196/205 [00:18<00:00, 11.90it/s]test:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 198/205 [00:19<00:00, 11.32it/s]test:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 200/205 [00:19<00:00, 11.45it/s]test:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 202/205 [00:19<00:00, 11.29it/s]test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 204/205 [00:19<00:00, 11.37it/s]test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 205/205 [00:19<00:00, 10.36it/s]
[[032m2021-11-26 10:25:23,562[0m INFO] trainer.inference_epoch test Performance: OrderedDict([('micro-f1', 0.536697247706422)])
[[032m2021-11-26 10:25:23,562[0m INFO] trainer.load_checkpoint Loading Checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:25:27,528[0m INFO] trainer.load_checkpoint Load Checkpoint finished, the current validation metric: 0.609375
[[032m2021-11-26 10:25:29,735[0m INFO] cuda.model_to_device Using model parallel, spread across device map: {0: [0, 1, 2, 3, 4], 1: [5, 6, 7, 8, 9], 2: [10, 11, 12, 13, 14], 3: [15, 16, 17, 18, 19], 4: [20, 21, 22, 23]}
[[032m2021-11-26 10:25:29,743[0m INFO] main_.trainer Begin distillation.
train epoch: 0:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3049, 0.6951],
        [0.4988, 0.5012],
        [0.7953, 0.2047],
        [0.4305, 0.5695],
        [0.5445, 0.4555],
        [0.4383, 0.5617],
        [0.3141, 0.6859],
        [0.7454, 0.2546]], device='cuda:0')

prompt tensor([[0.4648, 0.5352],
        [0.6353, 0.3647],
        [0.9738, 0.0262],
        [0.6280, 0.3720],
        [0.9154, 0.0846],
        [0.5735, 0.4265],
        [0.8400, 0.1600],
        [0.8032, 0.1968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 0:   0%|          | 0/8 [00:01<?, ?it/s, loss=31.9]train epoch: 0:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:12,  1.82s/it, loss=31.9]train epoch: 0:  12%|â–ˆâ–Ž        | 1/8 [00:02<00:12,  1.82s/it, loss=35.4]train epoch: 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:02<00:06,  1.03s/it, loss=35.4]train epoch: 0:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:02<00:06,  1.03s/it, loss=32.6]train epoch: 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.42it/s, loss=32.6]train epoch: 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.42it/s, loss=33.8]train epoch: 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.93it/s, loss=33.8]train epoch: 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:03<00:02,  1.93it/s, loss=41.9]train epoch: 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  2.43it/s, loss=41.9]train epoch: 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  2.43it/s, loss=30]  train epoch: 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.80it/s, loss=30]train epoch: 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.80it/s, loss=32.6]train epoch: 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  3.20it/s, loss=32.6]train epoch: 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  3.20it/s, loss=32.2]train epoch: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  3.50it/s, loss=32.2]train epoch: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.12it/s, loss=32.2]
[[032m2021-11-26 10:25:33,522[0m INFO] trainer.training_epoch Training epoch 0, num_steps 8,  avg_loss: 33.7925, total_loss: 270.3398
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.52it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.58it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.85it/s]
[[032m2021-11-26 10:25:34,137[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:25:34,137[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:35,177[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:25:35,754[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 1:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 1:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.7]train epoch: 1:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=33.7]train epoch: 1:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=30.6]train epoch: 1:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.59it/s, loss=30.6]train epoch: 1:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.59it/s, loss=28.6]train epoch: 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=28.6]train epoch: 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=30.3]train epoch: 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.96it/s, loss=30.3]train epoch: 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s, loss=25.7]train epoch: 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=25.7]train epoch: 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=34.1]train epoch: 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.97it/s, loss=34.1]train epoch: 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.97it/s, loss=36.9]train epoch: 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.42it/s, loss=36.9]train epoch: 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.42it/s, loss=29.8]train epoch: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.29it/s, loss=29.8]train epoch: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s, loss=29.8]
[[032m2021-11-26 10:25:38,536[0m INFO] trainer.training_epoch Training epoch 1, num_steps 16,  avg_loss: 31.2288, total_loss: 249.8301
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.38it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.19it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.82it/s]
[[032m2021-11-26 10:25:39,022[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:25:39,023[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:39,246[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:25:39,353[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 2:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 2:   0%|          | 0/8 [00:00<?, ?it/s, loss=39.8]train epoch: 2:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=39.8]train epoch: 2:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=35.1]train epoch: 2:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=35.1]train epoch: 2:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=33.6]train epoch: 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.08it/s, loss=33.6]train epoch: 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.08it/s, loss=32.8]train epoch: 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=32.8]train epoch: 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=25.7]train epoch: 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.55it/s, loss=25.7]train epoch: 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=39.8]train epoch: 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.45it/s, loss=39.8]train epoch: 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.45it/s, loss=29.7]train epoch: 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=29.7]train epoch: 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=29.6]train epoch: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.00it/s, loss=29.6]train epoch: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.01it/s, loss=29.6]
[[032m2021-11-26 10:25:42,014[0m INFO] trainer.training_epoch Training epoch 2, num_steps 24,  avg_loss: 33.2588, total_loss: 266.0703
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.51it/s]
[[032m2021-11-26 10:25:42,412[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:25:42,413[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:42,632[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 3:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 3:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.1]train epoch: 3:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.72it/s, loss=34.1]train epoch: 3:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.72it/s, loss=36.4]train epoch: 3:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=36.4]train epoch: 3:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=41.4]train epoch: 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.23it/s, loss=41.4]train epoch: 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.23it/s, loss=33.6]train epoch: 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.09it/s, loss=33.6]train epoch: 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.09it/s, loss=30.1]train epoch: 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.02it/s, loss=30.1]train epoch: 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.02it/s, loss=32.8]train epoch: 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=32.8]train epoch: 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.14it/s, loss=31.7]train epoch: 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=31.7]train epoch: 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=30.3]train epoch: 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=30.3]train epoch: 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=30.3]
[[032m2021-11-26 10:25:45,029[0m INFO] trainer.training_epoch Training epoch 3, num_steps 32,  avg_loss: 33.8045, total_loss: 270.4361
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.22it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.37it/s]
[[032m2021-11-26 10:25:45,481[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:25:45,481[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:45,699[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 4:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 4:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.3]train epoch: 4:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=37.3]train epoch: 4:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=35.8]train epoch: 4:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=35.8]train epoch: 4:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=38]  train epoch: 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=38]train epoch: 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=29.8]train epoch: 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.19it/s, loss=29.8]train epoch: 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.19it/s, loss=34.1]train epoch: 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=34.1]train epoch: 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=41.3]train epoch: 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.20it/s, loss=41.3]train epoch: 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.20it/s, loss=28.1]train epoch: 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=28.1]train epoch: 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=37.8]train epoch: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s, loss=37.8]train epoch: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=37.8]
[[032m2021-11-26 10:25:48,101[0m INFO] trainer.training_epoch Training epoch 4, num_steps 40,  avg_loss: 35.2638, total_loss: 282.1104
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.90it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.01it/s]
[[032m2021-11-26 10:25:48,498[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:25:48,499[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:48,705[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 5:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 5:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.6]train epoch: 5:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=33.6]train epoch: 5:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=32]  train epoch: 5:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.11it/s, loss=32]train epoch: 5:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.11it/s, loss=31.5]train epoch: 5:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.17it/s, loss=31.5]train epoch: 5:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.17it/s, loss=37.5]train epoch: 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.97it/s, loss=37.5]train epoch: 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s, loss=28.7]train epoch: 5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.88it/s, loss=28.7]train epoch: 5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.88it/s, loss=29.8]train epoch: 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.75it/s, loss=29.8]train epoch: 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=38.4]train epoch: 5:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.82it/s, loss=38.4]train epoch: 5:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.82it/s, loss=28]  train epoch: 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.01it/s, loss=28]train epoch: 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s, loss=28]
[[032m2021-11-26 10:25:51,232[0m INFO] trainer.training_epoch Training epoch 5, num_steps 48,  avg_loss: 32.4441, total_loss: 259.5531
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.34it/s]
[[032m2021-11-26 10:25:51,650[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:25:51,651[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:51,881[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 6:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 6:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.6]train epoch: 6:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.54it/s, loss=22.6]train epoch: 6:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.54it/s, loss=22.2]train epoch: 6:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.59it/s, loss=22.2]train epoch: 6:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.59it/s, loss=30.5]train epoch: 6:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.37it/s, loss=30.5]train epoch: 6:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.37it/s, loss=25.1]train epoch: 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.35it/s, loss=25.1]train epoch: 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.35it/s, loss=33.5]train epoch: 6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.51it/s, loss=33.5]train epoch: 6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.51it/s, loss=38.5]train epoch: 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=38.5]train epoch: 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=30.3]train epoch: 6:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s, loss=30.3]train epoch: 6:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s, loss=31.2]train epoch: 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.51it/s, loss=31.2]train epoch: 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=31.2]
[[032m2021-11-26 10:25:54,532[0m INFO] trainer.training_epoch Training epoch 6, num_steps 56,  avg_loss: 29.2354, total_loss: 233.8830
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.84it/s]
[[032m2021-11-26 10:25:54,923[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:25:54,924[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:55,141[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:25:55,246[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 7:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 7:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.5]train epoch: 7:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=30.5]train epoch: 7:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=38.3]train epoch: 7:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.67it/s, loss=38.3]train epoch: 7:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.67it/s, loss=28.4]train epoch: 7:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.59it/s, loss=28.4]train epoch: 7:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.59it/s, loss=30.2]train epoch: 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.52it/s, loss=30.2]train epoch: 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.52it/s, loss=29.8]train epoch: 7:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.85it/s, loss=29.8]train epoch: 7:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.85it/s, loss=30.3]train epoch: 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.00it/s, loss=30.3]train epoch: 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.00it/s, loss=35.8]train epoch: 7:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=35.8]train epoch: 7:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=36.9]train epoch: 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.70it/s, loss=36.9]train epoch: 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=36.9]
[[032m2021-11-26 10:25:57,719[0m INFO] trainer.training_epoch Training epoch 7, num_steps 64,  avg_loss: 32.5399, total_loss: 260.3193
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.50it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.11it/s]
[[032m2021-11-26 10:25:58,175[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:25:58,175[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:25:58,388[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:25:58,498[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 8:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 8:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.8]train epoch: 8:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=31.8]train epoch: 8:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=39.3]train epoch: 8:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.31it/s, loss=39.3]train epoch: 8:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.31it/s, loss=28.8]train epoch: 8:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.78it/s, loss=28.8]train epoch: 8:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.78it/s, loss=26.7]train epoch: 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=26.7]train epoch: 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=34.9]train epoch: 8:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=34.9]train epoch: 8:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=40.5]train epoch: 8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.57it/s, loss=40.5]train epoch: 8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.57it/s, loss=32.8]train epoch: 8:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.73it/s, loss=32.8]train epoch: 8:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.73it/s, loss=28.2]train epoch: 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=28.2]train epoch: 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=28.2]
[[032m2021-11-26 10:26:00,961[0m INFO] trainer.training_epoch Training epoch 8, num_steps 72,  avg_loss: 32.8671, total_loss: 262.9369
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.35it/s]
[[032m2021-11-26 10:26:01,331[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:26:01,331[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:01,567[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 9:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 9:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.9]train epoch: 9:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=32.9]train epoch: 9:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=41]  train epoch: 9:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.80it/s, loss=41]train epoch: 9:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.80it/s, loss=33.1]train epoch: 9:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.57it/s, loss=33.1]train epoch: 9:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.57it/s, loss=29.5]train epoch: 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=29.5]train epoch: 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=31.7]train epoch: 9:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=31.7]train epoch: 9:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=31.8]train epoch: 9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=31.8]train epoch: 9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.68it/s, loss=40.9]train epoch: 9:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.86it/s, loss=40.9]train epoch: 9:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.86it/s, loss=34.4]train epoch: 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=34.4]train epoch: 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=34.4]
[[032m2021-11-26 10:26:03,837[0m INFO] trainer.training_epoch Training epoch 9, num_steps 80,  avg_loss: 34.4049, total_loss: 275.2394
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.52it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.22it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.50it/s]
[[032m2021-11-26 10:26:04,392[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:26:04,392[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:04,762[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 10:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 10:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.4]train epoch: 10:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.08it/s, loss=31.4]train epoch: 10:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.08it/s, loss=36.9]train epoch: 10:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.68it/s, loss=36.9]train epoch: 10:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.68it/s, loss=26.6]train epoch: 10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.92it/s, loss=26.6]train epoch: 10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.92it/s, loss=32.3]train epoch: 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.35it/s, loss=32.3]train epoch: 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.35it/s, loss=31]  train epoch: 10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.18it/s, loss=31]train epoch: 10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.18it/s, loss=28.3]train epoch: 10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.49it/s, loss=28.3]train epoch: 10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.49it/s, loss=30.6]train epoch: 10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.70it/s, loss=30.6]train epoch: 10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.70it/s, loss=28.8]train epoch: 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.91it/s, loss=28.8]train epoch: 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=28.8]
[[032m2021-11-26 10:26:07,133[0m INFO] trainer.training_epoch Training epoch 10, num_steps 88,  avg_loss: 30.7418, total_loss: 245.9347
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.19it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.47it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.39it/s]
[[032m2021-11-26 10:26:07,737[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:26:07,737[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:08,086[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 11:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 11:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.9]train epoch: 11:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.94it/s, loss=33.9]train epoch: 11:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.94it/s, loss=27.6]train epoch: 11:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.73it/s, loss=27.6]train epoch: 11:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.73it/s, loss=42.8]train epoch: 11:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=42.8]train epoch: 11:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=30.3]train epoch: 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=30.3]train epoch: 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=27.6]train epoch: 11:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.39it/s, loss=27.6]train epoch: 11:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.39it/s, loss=38]  train epoch: 11:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.65it/s, loss=38]train epoch: 11:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.65it/s, loss=31.3]train epoch: 11:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.60it/s, loss=31.3]train epoch: 11:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.60it/s, loss=26.4]train epoch: 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.42it/s, loss=26.4]train epoch: 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=26.4]
[[032m2021-11-26 10:26:10,525[0m INFO] trainer.training_epoch Training epoch 11, num_steps 96,  avg_loss: 32.2374, total_loss: 257.8993
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.54it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.53it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.93it/s]
[[032m2021-11-26 10:26:11,152[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:26:11,153[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:11,444[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:26:11,562[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 12:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 12:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.9]train epoch: 12:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.52it/s, loss=29.9]train epoch: 12:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.52it/s, loss=37.1]train epoch: 12:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.36it/s, loss=37.1]train epoch: 12:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.36it/s, loss=26.5]train epoch: 12:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.91it/s, loss=26.5]train epoch: 12:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.91it/s, loss=27.9]train epoch: 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.87it/s, loss=27.9]
model tensor([[0.3141, 0.6859],
        [0.4716, 0.5284],
        [0.5418, 0.4582],
        [0.3744, 0.6256],
        [0.4988, 0.5012],
        [0.3473, 0.6527],
        [0.2477, 0.7523],
        [0.4593, 0.5407]], device='cuda:0')

prompt tensor([[0.3848, 0.6152],
        [0.4264, 0.5736],
        [0.7873, 0.2127],
        [0.7795, 0.2205],
        [0.6529, 0.3471],
        [0.7860, 0.2140],
        [0.6320, 0.3680],
        [0.6170, 0.3830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.87it/s, loss=28.6]train epoch: 12:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s, loss=28.6]train epoch: 12:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s, loss=29.2]train epoch: 12:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s, loss=29.2]train epoch: 12:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.33it/s, loss=35.8]train epoch: 12:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=35.8]train epoch: 12:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=34.5]train epoch: 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.50it/s, loss=34.5]train epoch: 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.06it/s, loss=34.5]
[[032m2021-11-26 10:26:14,188[0m INFO] trainer.training_epoch Training epoch 12, num_steps 104,  avg_loss: 31.1846, total_loss: 249.4771
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.33it/s]
[[032m2021-11-26 10:26:14,601[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:26:14,602[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:14,824[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 13:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 13:   0%|          | 0/8 [00:00<?, ?it/s, loss=39.3]train epoch: 13:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.02it/s, loss=39.3]train epoch: 13:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.02it/s, loss=33.9]train epoch: 13:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.44it/s, loss=33.9]train epoch: 13:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.44it/s, loss=27]  train epoch: 13:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.54it/s, loss=27]train epoch: 13:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.54it/s, loss=24.8]train epoch: 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.29it/s, loss=24.8]train epoch: 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.29it/s, loss=30.8]train epoch: 13:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=30.8]train epoch: 13:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=23.6]train epoch: 13:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.95it/s, loss=23.6]train epoch: 13:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=30.2]train epoch: 13:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=30.2]train epoch: 13:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=28.6]train epoch: 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=28.6]train epoch: 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=28.6]
[[032m2021-11-26 10:26:17,287[0m INFO] trainer.training_epoch Training epoch 13, num_steps 112,  avg_loss: 29.7946, total_loss: 238.3569
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.06it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.47it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.15it/s]
[[032m2021-11-26 10:26:17,702[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:26:17,702[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:17,915[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:26:18,008[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 14:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 14:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.4]train epoch: 14:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=29.4]train epoch: 14:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=35.3]train epoch: 14:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=35.3]train epoch: 14:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=24.7]train epoch: 14:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.76it/s, loss=24.7]train epoch: 14:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.76it/s, loss=28.7]train epoch: 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=28.7]train epoch: 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=25.7]train epoch: 14:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.20it/s, loss=25.7]train epoch: 14:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.20it/s, loss=30]  train epoch: 14:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s, loss=30]train epoch: 14:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s, loss=29.6]train epoch: 14:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.56it/s, loss=29.6]train epoch: 14:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.56it/s, loss=37.4]train epoch: 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.71it/s, loss=37.4]train epoch: 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=37.4]
[[032m2021-11-26 10:26:20,255[0m INFO] trainer.training_epoch Training epoch 14, num_steps 120,  avg_loss: 30.1050, total_loss: 240.8400
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.53it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.88it/s]
[[032m2021-11-26 10:26:20,685[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:26:20,686[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:20,917[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 15:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 15:   0%|          | 0/8 [00:00<?, ?it/s, loss=38.9]train epoch: 15:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=38.9]train epoch: 15:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=29.8]train epoch: 15:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.74it/s, loss=29.8]train epoch: 15:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.74it/s, loss=35]  train epoch: 15:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.74it/s, loss=35]train epoch: 15:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.74it/s, loss=41.5]train epoch: 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=41.5]train epoch: 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=27]  train epoch: 15:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=27]train epoch: 15:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=31]train epoch: 15:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s, loss=31]train epoch: 15:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.38it/s, loss=25]train epoch: 15:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=25]train epoch: 15:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=31]train epoch: 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s, loss=31]train epoch: 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=31]
[[032m2021-11-26 10:26:23,443[0m INFO] trainer.training_epoch Training epoch 15, num_steps 128,  avg_loss: 32.3927, total_loss: 259.1419
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.59it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.20it/s]
[[032m2021-11-26 10:26:23,902[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:26:23,903[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:24,123[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 16:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 16:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.2]train epoch: 16:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.49it/s, loss=34.2]train epoch: 16:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.49it/s, loss=30.2]train epoch: 16:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=30.2]train epoch: 16:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=30]  train epoch: 16:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.89it/s, loss=30]train epoch: 16:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.89it/s, loss=33.1]train epoch: 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=33.1]train epoch: 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=36]  train epoch: 16:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.86it/s, loss=36]train epoch: 16:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.86it/s, loss=27.8]train epoch: 16:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.15it/s, loss=27.8]train epoch: 16:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.15it/s, loss=27.7]train epoch: 16:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.10it/s, loss=27.7]train epoch: 16:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.10it/s, loss=33.8]train epoch: 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=33.8]train epoch: 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=33.8]
[[032m2021-11-26 10:26:26,415[0m INFO] trainer.training_epoch Training epoch 16, num_steps 136,  avg_loss: 31.5981, total_loss: 252.7849
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.92it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.47it/s]
[[032m2021-11-26 10:26:26,857[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:26:26,858[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:27,074[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:26:27,171[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 17:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 17:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.4]train epoch: 17:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=33.4]train epoch: 17:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=29]  train epoch: 17:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.40it/s, loss=29]train epoch: 17:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.40it/s, loss=23.1]train epoch: 17:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.11it/s, loss=23.1]train epoch: 17:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.11it/s, loss=29.2]train epoch: 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=29.2]train epoch: 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=28.5]train epoch: 17:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=28.5]train epoch: 17:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=24.7]train epoch: 17:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.83it/s, loss=24.7]train epoch: 17:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=34.5]train epoch: 17:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=34.5]train epoch: 17:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=24.8]train epoch: 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.05it/s, loss=24.8]train epoch: 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=24.8]
[[032m2021-11-26 10:26:29,745[0m INFO] trainer.training_epoch Training epoch 17, num_steps 144,  avg_loss: 28.4106, total_loss: 227.2848
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.41it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.21it/s]
[[032m2021-11-26 10:26:30,203[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:26:30,203[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:30,424[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 18:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 18:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.9]train epoch: 18:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.47it/s, loss=34.9]train epoch: 18:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.47it/s, loss=22.3]train epoch: 18:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=22.3]train epoch: 18:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=36.6]train epoch: 18:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=36.6]train epoch: 18:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=23.6]train epoch: 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.79it/s, loss=23.6]train epoch: 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.79it/s, loss=28.2]train epoch: 18:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.26it/s, loss=28.2]train epoch: 18:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.26it/s, loss=28]  train epoch: 18:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=28]train epoch: 18:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=29.3]train epoch: 18:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=29.3]train epoch: 18:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=28.7]train epoch: 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=28.7]train epoch: 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s, loss=28.7]
[[032m2021-11-26 10:26:33,107[0m INFO] trainer.training_epoch Training epoch 18, num_steps 152,  avg_loss: 28.9529, total_loss: 231.6231
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.28it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.08it/s]
[[032m2021-11-26 10:26:33,569[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:26:33,569[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:33,784[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 19:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 19:   0%|          | 0/8 [00:00<?, ?it/s, loss=42.2]train epoch: 19:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.34it/s, loss=42.2]train epoch: 19:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.34it/s, loss=28.6]train epoch: 19:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.49it/s, loss=28.6]train epoch: 19:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.49it/s, loss=37.1]train epoch: 19:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.65it/s, loss=37.1]train epoch: 19:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.65it/s, loss=21.9]train epoch: 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.15it/s, loss=21.9]train epoch: 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.15it/s, loss=27.6]train epoch: 19:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.72it/s, loss=27.6]train epoch: 19:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.72it/s, loss=27.6]train epoch: 19:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.08it/s, loss=27.6]train epoch: 19:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.08it/s, loss=34.9]train epoch: 19:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=34.9]train epoch: 19:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=23.9]train epoch: 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.51it/s, loss=23.9]train epoch: 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=23.9]
[[032m2021-11-26 10:26:36,187[0m INFO] trainer.training_epoch Training epoch 19, num_steps 160,  avg_loss: 30.4647, total_loss: 243.7176
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.71it/s]
[[032m2021-11-26 10:26:36,622[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:26:36,622[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:36,842[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 20:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 20:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.4]train epoch: 20:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.78it/s, loss=28.4]train epoch: 20:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.78it/s, loss=31.5]train epoch: 20:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=31.5]train epoch: 20:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=32.8]train epoch: 20:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.75it/s, loss=32.8]train epoch: 20:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.75it/s, loss=24.3]train epoch: 20:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.57it/s, loss=24.3]train epoch: 20:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.57it/s, loss=27]  train epoch: 20:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.74it/s, loss=27]train epoch: 20:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.74it/s, loss=27.9]train epoch: 20:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.92it/s, loss=27.9]train epoch: 20:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=23.7]train epoch: 20:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=23.7]train epoch: 20:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=31.9]train epoch: 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=31.9]train epoch: 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=31.9]
[[032m2021-11-26 10:26:39,336[0m INFO] trainer.training_epoch Training epoch 20, num_steps 168,  avg_loss: 28.4387, total_loss: 227.5098
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.05it/s]
[[032m2021-11-26 10:26:39,720[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:26:39,721[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:39,952[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:26:40,063[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 21:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 21:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 21:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=23.6]train epoch: 21:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=23]  train epoch: 21:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=23]train epoch: 21:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.79it/s, loss=27.2]train epoch: 21:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=27.2]train epoch: 21:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=28.5]train epoch: 21:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.43it/s, loss=28.5]train epoch: 21:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.43it/s, loss=26.3]train epoch: 21:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.67it/s, loss=26.3]train epoch: 21:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.67it/s, loss=22.2]train epoch: 21:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.02it/s, loss=22.2]train epoch: 21:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.02it/s, loss=38.3]train epoch: 21:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.34it/s, loss=38.3]train epoch: 21:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.34it/s, loss=26.7]train epoch: 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=26.7]train epoch: 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s, loss=26.7]
[[032m2021-11-26 10:26:42,592[0m INFO] trainer.training_epoch Training epoch 21, num_steps 176,  avg_loss: 26.9764, total_loss: 215.8108
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.28it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.10it/s]
[[032m2021-11-26 10:26:43,014[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:26:43,014[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:43,255[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:26:43,359[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 22:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 22:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.5]train epoch: 22:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=29.5]train epoch: 22:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=30.3]train epoch: 22:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=30.3]train epoch: 22:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=39.1]train epoch: 22:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.05it/s, loss=39.1]train epoch: 22:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.05it/s, loss=27]  train epoch: 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.19it/s, loss=27]train epoch: 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.19it/s, loss=30.7]train epoch: 22:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.50it/s, loss=30.7]train epoch: 22:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.50it/s, loss=30.6]train epoch: 22:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.78it/s, loss=30.6]train epoch: 22:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.78it/s, loss=35.8]train epoch: 22:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.81it/s, loss=35.8]train epoch: 22:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.81it/s, loss=18.1]train epoch: 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.78it/s, loss=18.1]train epoch: 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=18.1]
[[032m2021-11-26 10:26:45,585[0m INFO] trainer.training_epoch Training epoch 22, num_steps 184,  avg_loss: 30.1399, total_loss: 241.1190
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.38it/s]
[[032m2021-11-26 10:26:45,993[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:26:45,993[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:46,227[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 23:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 23:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.5]train epoch: 23:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=24.5]train epoch: 23:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=30.6]train epoch: 23:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.21it/s, loss=30.6]train epoch: 23:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.21it/s, loss=22.2]train epoch: 23:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.49it/s, loss=22.2]train epoch: 23:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.49it/s, loss=27.8]train epoch: 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=27.8]train epoch: 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=28.5]train epoch: 23:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=28.5]train epoch: 23:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=26.8]train epoch: 23:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s, loss=26.8]train epoch: 23:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.30it/s, loss=35.3]train epoch: 23:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.57it/s, loss=35.3]train epoch: 23:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.57it/s, loss=34.8]train epoch: 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.87it/s, loss=34.8]train epoch: 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=34.8]
[[032m2021-11-26 10:26:48,453[0m INFO] trainer.training_epoch Training epoch 23, num_steps 192,  avg_loss: 28.8285, total_loss: 230.6277
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.89it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.04it/s]
[[032m2021-11-26 10:26:48,871[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:26:48,871[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:49,097[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 24:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 24:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.5]train epoch: 24:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.72it/s, loss=19.5]train epoch: 24:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.72it/s, loss=30.3]train epoch: 24:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=30.3]train epoch: 24:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=24.7]train epoch: 24:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.05it/s, loss=24.7]train epoch: 24:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.05it/s, loss=32.1]train epoch: 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=32.1]train epoch: 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=26.5]train epoch: 24:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=26.5]train epoch: 24:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=25.3]train epoch: 24:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.57it/s, loss=25.3]train epoch: 24:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.57it/s, loss=30.5]train epoch: 24:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.69it/s, loss=30.5]train epoch: 24:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=27.2]train epoch: 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.91it/s, loss=27.2]train epoch: 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=27.2]
[[032m2021-11-26 10:26:51,328[0m INFO] trainer.training_epoch Training epoch 24, num_steps 200,  avg_loss: 27.0107, total_loss: 216.0856
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.00it/s]
[[032m2021-11-26 10:26:51,749[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:26:51,749[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:51,972[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 25:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.6717, 0.3283],
        [0.5715, 0.4285],
        [0.5964, 0.4036],
        [0.3498, 0.6502],
        [0.3053, 0.6947],
        [0.3141, 0.6859],
        [0.2477, 0.7523],
        [0.3884, 0.6116]], device='cuda:0')

prompt tensor([[0.5602, 0.4398],
        [0.5752, 0.4248],
        [0.5824, 0.4176],
        [0.4699, 0.5301],
        [0.6756, 0.3244],
        [0.8314, 0.1686],
        [0.6834, 0.3166],
        [0.3122, 0.6878]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 25:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.7]train epoch: 25:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.06it/s, loss=30.7]train epoch: 25:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.06it/s, loss=16.2]train epoch: 25:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=16.2]train epoch: 25:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=31.4]train epoch: 25:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.74it/s, loss=31.4]train epoch: 25:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.74it/s, loss=22.7]train epoch: 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=22.7]train epoch: 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=35.4]train epoch: 25:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=35.4]train epoch: 25:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=31]  train epoch: 25:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.13it/s, loss=31]train epoch: 25:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.13it/s, loss=24.6]train epoch: 25:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=24.6]train epoch: 25:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=37]  train epoch: 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=37]train epoch: 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=37]
[[032m2021-11-26 10:26:54,406[0m INFO] trainer.training_epoch Training epoch 25, num_steps 208,  avg_loss: 28.6249, total_loss: 228.9989
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.15it/s]
[[032m2021-11-26 10:26:54,860[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:26:54,861[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:55,080[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 26:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 26:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.3]train epoch: 26:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.67it/s, loss=22.3]train epoch: 26:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.67it/s, loss=35]  train epoch: 26:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.82it/s, loss=35]train epoch: 26:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.82it/s, loss=29.5]train epoch: 26:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.18it/s, loss=29.5]train epoch: 26:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.18it/s, loss=36.9]train epoch: 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.31it/s, loss=36.9]train epoch: 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.31it/s, loss=30]  train epoch: 26:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.08it/s, loss=30]train epoch: 26:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.08it/s, loss=20.7]train epoch: 26:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.27it/s, loss=20.7]train epoch: 26:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.27it/s, loss=26.4]train epoch: 26:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.54it/s, loss=26.4]train epoch: 26:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.54it/s, loss=27.8]train epoch: 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.51it/s, loss=27.8]train epoch: 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=27.8]
[[032m2021-11-26 10:26:57,415[0m INFO] trainer.training_epoch Training epoch 26, num_steps 216,  avg_loss: 28.5699, total_loss: 228.5596
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.53it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.51it/s]
[[032m2021-11-26 10:26:57,855[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:26:57,856[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:26:58,080[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:26:58,174[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 27:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 27:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.9]train epoch: 27:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=28.9]train epoch: 27:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=33.1]train epoch: 27:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=33.1]train epoch: 27:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=25.9]train epoch: 27:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.81it/s, loss=25.9]train epoch: 27:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.81it/s, loss=29.7]train epoch: 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.46it/s, loss=29.7]train epoch: 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.46it/s, loss=31.4]train epoch: 27:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.59it/s, loss=31.4]train epoch: 27:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.59it/s, loss=30]  train epoch: 27:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=30]train epoch: 27:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=23.3]train epoch: 27:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=23.3]train epoch: 27:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=30.5]train epoch: 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.67it/s, loss=30.5]train epoch: 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=30.5]
[[032m2021-11-26 10:27:00,669[0m INFO] trainer.training_epoch Training epoch 27, num_steps 224,  avg_loss: 29.1197, total_loss: 232.9577
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.11it/s]
[[032m2021-11-26 10:27:01,048[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:27:01,048[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:01,276[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 28:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 28:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.3]train epoch: 28:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=34.3]train epoch: 28:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=31.6]train epoch: 28:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.23it/s, loss=31.6]train epoch: 28:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.23it/s, loss=24.4]train epoch: 28:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=24.4]train epoch: 28:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=28.1]train epoch: 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.28it/s, loss=28.1]train epoch: 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.28it/s, loss=28.3]train epoch: 28:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.45it/s, loss=28.3]train epoch: 28:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.45it/s, loss=32.7]train epoch: 28:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.94it/s, loss=32.7]train epoch: 28:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.94it/s, loss=34.2]train epoch: 28:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=34.2]train epoch: 28:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=30.9]train epoch: 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s, loss=30.9]train epoch: 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=30.9]
[[032m2021-11-26 10:27:03,965[0m INFO] trainer.training_epoch Training epoch 28, num_steps 232,  avg_loss: 30.5667, total_loss: 244.5334
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.27it/s]
[[032m2021-11-26 10:27:04,374[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:27:04,375[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:04,596[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 29:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 29:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.8]train epoch: 29:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.75it/s, loss=34.8]train epoch: 29:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.75it/s, loss=20.6]train epoch: 29:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.44it/s, loss=20.6]train epoch: 29:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.44it/s, loss=32.1]train epoch: 29:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=32.1]train epoch: 29:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=34]  train epoch: 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=34]train epoch: 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=30.3]train epoch: 29:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=30.3]train epoch: 29:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=19.6]train epoch: 29:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s, loss=19.6]train epoch: 29:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.32it/s, loss=32.2]train epoch: 29:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.62it/s, loss=32.2]train epoch: 29:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.62it/s, loss=25.7]train epoch: 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s, loss=25.7]train epoch: 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.36it/s, loss=25.7]
[[032m2021-11-26 10:27:06,980[0m INFO] trainer.training_epoch Training epoch 29, num_steps 240,  avg_loss: 28.6634, total_loss: 229.3071
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.90it/s]
[[032m2021-11-26 10:27:07,362[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:27:07,362[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:07,579[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:27:07,675[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 30:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 30:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 30:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.83it/s, loss=27.3]train epoch: 30:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.83it/s, loss=22.4]train epoch: 30:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.29it/s, loss=22.4]train epoch: 30:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.29it/s, loss=32.3]train epoch: 30:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.59it/s, loss=32.3]train epoch: 30:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.59it/s, loss=35.7]train epoch: 30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=35.7]train epoch: 30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=22.6]train epoch: 30:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=22.6]train epoch: 30:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=31.8]train epoch: 30:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.34it/s, loss=31.8]train epoch: 30:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.34it/s, loss=30.4]train epoch: 30:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=30.4]train epoch: 30:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=28.7]train epoch: 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=28.7]train epoch: 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.20it/s, loss=28.7]
[[032m2021-11-26 10:27:10,185[0m INFO] trainer.training_epoch Training epoch 30, num_steps 248,  avg_loss: 28.8945, total_loss: 231.1563
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.74it/s]
[[032m2021-11-26 10:27:10,582[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:27:10,583[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:10,799[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 31:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 31:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.6]train epoch: 31:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.25it/s, loss=34.6]train epoch: 31:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.25it/s, loss=28.7]train epoch: 31:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.52it/s, loss=28.7]train epoch: 31:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.52it/s, loss=27.5]train epoch: 31:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.90it/s, loss=27.5]train epoch: 31:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.90it/s, loss=28.9]train epoch: 31:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=28.9]train epoch: 31:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=28.1]train epoch: 31:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=28.1]train epoch: 31:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.66it/s, loss=31.9]train epoch: 31:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.03it/s, loss=31.9]train epoch: 31:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.03it/s, loss=27.9]train epoch: 31:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=27.9]train epoch: 31:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=31.5]train epoch: 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.68it/s, loss=31.5]train epoch: 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.23it/s, loss=31.5]
[[032m2021-11-26 10:27:13,278[0m INFO] trainer.training_epoch Training epoch 31, num_steps 256,  avg_loss: 29.8961, total_loss: 239.1684
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.78it/s]
[[032m2021-11-26 10:27:13,664[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:27:13,665[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:13,883[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 32:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 32:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.4]train epoch: 32:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=36.4]train epoch: 32:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=23.1]train epoch: 32:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.86it/s, loss=23.1]train epoch: 32:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.86it/s, loss=27]  train epoch: 32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=27]train epoch: 32:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=30.2]train epoch: 32:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.60it/s, loss=30.2]train epoch: 32:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.60it/s, loss=25.8]train epoch: 32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=25.8]train epoch: 32:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.94it/s, loss=33]  train epoch: 32:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=33]train epoch: 32:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=22.8]train epoch: 32:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=22.8]train epoch: 32:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=28]  train epoch: 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.79it/s, loss=28]train epoch: 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=28]
[[032m2021-11-26 10:27:16,357[0m INFO] trainer.training_epoch Training epoch 32, num_steps 264,  avg_loss: 28.2907, total_loss: 226.3253
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.62it/s]
[[032m2021-11-26 10:27:16,839[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:27:16,840[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:17,053[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 33:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 33:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.3]train epoch: 33:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.72it/s, loss=35.3]train epoch: 33:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.72it/s, loss=33.7]train epoch: 33:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=33.7]train epoch: 33:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=36]  train epoch: 33:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.71it/s, loss=36]train epoch: 33:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.71it/s, loss=23]train epoch: 33:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.21it/s, loss=23]train epoch: 33:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.21it/s, loss=29.7]train epoch: 33:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=29.7]train epoch: 33:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=28.1]train epoch: 33:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.73it/s, loss=28.1]train epoch: 33:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.73it/s, loss=33.3]train epoch: 33:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=33.3]train epoch: 33:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=23.5]train epoch: 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=23.5]train epoch: 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=23.5]
[[032m2021-11-26 10:27:19,505[0m INFO] trainer.training_epoch Training epoch 33, num_steps 272,  avg_loss: 30.3246, total_loss: 242.5969
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.07it/s]
[[032m2021-11-26 10:27:19,918[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:27:19,918[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:20,147[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 34:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 34:   0%|          | 0/8 [00:00<?, ?it/s, loss=21]train epoch: 34:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=21]train epoch: 34:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=22]train epoch: 34:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=22]train epoch: 34:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=26.4]train epoch: 34:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=26.4]train epoch: 34:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=29.4]train epoch: 34:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.95it/s, loss=29.4]train epoch: 34:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s, loss=30.3]train epoch: 34:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=30.3]train epoch: 34:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=38.5]train epoch: 34:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.59it/s, loss=38.5]train epoch: 34:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.59it/s, loss=30.1]train epoch: 34:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.91it/s, loss=30.1]train epoch: 34:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.91it/s, loss=29.9]train epoch: 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=29.9]train epoch: 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=29.9]
[[032m2021-11-26 10:27:22,408[0m INFO] trainer.training_epoch Training epoch 34, num_steps 280,  avg_loss: 28.4564, total_loss: 227.6510
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.43it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.06it/s]
[[032m2021-11-26 10:27:22,824[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:27:22,825[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:23,036[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 35:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 35:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.1]train epoch: 35:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=21.1]train epoch: 35:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=29.7]train epoch: 35:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=29.7]train epoch: 35:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=27.9]train epoch: 35:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=27.9]train epoch: 35:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.00it/s, loss=33.5]train epoch: 35:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.68it/s, loss=33.5]train epoch: 35:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.68it/s, loss=26]  train epoch: 35:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.77it/s, loss=26]train epoch: 35:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.77it/s, loss=22.6]train epoch: 35:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=22.6]train epoch: 35:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=30.2]train epoch: 35:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=30.2]train epoch: 35:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=28.6]train epoch: 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.01it/s, loss=28.6]train epoch: 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.08it/s, loss=28.6]
[[032m2021-11-26 10:27:25,640[0m INFO] trainer.training_epoch Training epoch 35, num_steps 288,  avg_loss: 27.4517, total_loss: 219.6135
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.51it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.79it/s]
[[032m2021-11-26 10:27:26,110[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:27:26,111[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:26,328[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 36:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 36:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 36:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.84it/s, loss=27.3]train epoch: 36:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.84it/s, loss=22.7]train epoch: 36:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=22.7]train epoch: 36:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=36.4]train epoch: 36:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=36.4]train epoch: 36:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=33.6]train epoch: 36:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.32it/s, loss=33.6]train epoch: 36:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.32it/s, loss=28.7]train epoch: 36:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=28.7]train epoch: 36:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=31.2]train epoch: 36:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=31.2]train epoch: 36:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=30]  train epoch: 36:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.13it/s, loss=30]train epoch: 36:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.13it/s, loss=25.5]train epoch: 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.83it/s, loss=25.5]train epoch: 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.11it/s, loss=25.5]
[[032m2021-11-26 10:27:28,280[0m INFO] trainer.training_epoch Training epoch 36, num_steps 296,  avg_loss: 29.4134, total_loss: 235.3069
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.81it/s]
[[032m2021-11-26 10:27:28,812[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:27:28,812[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:29,032[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 37:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 37:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.5]train epoch: 37:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=32.5]train epoch: 37:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=30.1]train epoch: 37:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.85it/s, loss=30.1]train epoch: 37:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.85it/s, loss=34.6]train epoch: 37:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.75it/s, loss=34.6]train epoch: 37:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.75it/s, loss=27.7]train epoch: 37:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.51it/s, loss=27.7]
model tensor([[0.5557, 0.4443],
        [0.5258, 0.4742],
        [0.3391, 0.6609],
        [0.5439, 0.4561],
        [0.2156, 0.7844],
        [0.4469, 0.5531],
        [0.5443, 0.4557],
        [0.3841, 0.6159]], device='cuda:0')

prompt tensor([[0.7357, 0.2643],
        [0.6098, 0.3902],
        [0.5638, 0.4362],
        [0.6380, 0.3620],
        [0.4985, 0.5015],
        [0.7909, 0.2091],
        [0.5533, 0.4467],
        [0.4312, 0.5688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 37:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.51it/s, loss=28.6]train epoch: 37:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=28.6]train epoch: 37:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=27.9]train epoch: 37:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.89it/s, loss=27.9]train epoch: 37:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.89it/s, loss=31.5]train epoch: 37:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.12it/s, loss=31.5]train epoch: 37:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.12it/s, loss=36.5]train epoch: 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.08it/s, loss=36.5]train epoch: 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=36.5]
[[032m2021-11-26 10:27:31,245[0m INFO] trainer.training_epoch Training epoch 37, num_steps 304,  avg_loss: 31.1759, total_loss: 249.4075
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.42it/s]
[[032m2021-11-26 10:27:31,805[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.421875)])
[[032m2021-11-26 10:27:31,805[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:32,054[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 38:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 38:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.3]train epoch: 38:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.98it/s, loss=25.3]train epoch: 38:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.98it/s, loss=29.6]train epoch: 38:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.61it/s, loss=29.6]train epoch: 38:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.61it/s, loss=25.7]train epoch: 38:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.07it/s, loss=25.7]train epoch: 38:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.07it/s, loss=33.1]train epoch: 38:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.21it/s, loss=33.1]train epoch: 38:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.21it/s, loss=32.3]train epoch: 38:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=32.3]train epoch: 38:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=27.6]train epoch: 38:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.64it/s, loss=27.6]train epoch: 38:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.64it/s, loss=27.6]train epoch: 38:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.05it/s, loss=27.6]train epoch: 38:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=33.3]train epoch: 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=33.3]train epoch: 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s, loss=33.3]
[[032m2021-11-26 10:27:34,376[0m INFO] trainer.training_epoch Training epoch 38, num_steps 312,  avg_loss: 29.3254, total_loss: 234.6033
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.87it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.45it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.91it/s]
[[032m2021-11-26 10:27:34,901[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.4375)])
[[032m2021-11-26 10:27:34,901[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:35,137[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 39:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 39:   0%|          | 0/8 [00:00<?, ?it/s, loss=29]train epoch: 39:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=29]train epoch: 39:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=24.9]train epoch: 39:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.40it/s, loss=24.9]train epoch: 39:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.40it/s, loss=30]  train epoch: 39:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.70it/s, loss=30]train epoch: 39:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.70it/s, loss=24.2]train epoch: 39:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.03it/s, loss=24.2]train epoch: 39:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.03it/s, loss=30.6]train epoch: 39:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.22it/s, loss=30.6]train epoch: 39:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.22it/s, loss=26.7]train epoch: 39:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=26.7]train epoch: 39:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=27.3]train epoch: 39:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.08it/s, loss=27.3]train epoch: 39:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.08it/s, loss=28.9]train epoch: 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.67it/s, loss=28.9]train epoch: 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=28.9]
[[032m2021-11-26 10:27:37,185[0m INFO] trainer.training_epoch Training epoch 39, num_steps 320,  avg_loss: 27.7081, total_loss: 221.6651
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.39it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.86it/s]
[[032m2021-11-26 10:27:37,711[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:27:37,711[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:37,970[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 40:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 40:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.4]train epoch: 40:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=25.4]train epoch: 40:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=36.8]train epoch: 40:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.03it/s, loss=36.8]train epoch: 40:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.03it/s, loss=31.8]train epoch: 40:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=31.8]train epoch: 40:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=27.5]train epoch: 40:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.24it/s, loss=27.5]train epoch: 40:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.24it/s, loss=29.4]train epoch: 40:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.00it/s, loss=29.4]train epoch: 40:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.00it/s, loss=25.7]train epoch: 40:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.05it/s, loss=25.7]train epoch: 40:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.05it/s, loss=34.8]train epoch: 40:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.22it/s, loss=34.8]train epoch: 40:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=27.8]train epoch: 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.68it/s, loss=27.8]train epoch: 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=27.8]
[[032m2021-11-26 10:27:40,460[0m INFO] trainer.training_epoch Training epoch 40, num_steps 328,  avg_loss: 29.9046, total_loss: 239.2369
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.87it/s]
[[032m2021-11-26 10:27:40,843[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:27:40,843[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:41,062[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 41:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 41:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.5]train epoch: 41:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=31.5]train epoch: 41:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=37]  train epoch: 41:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.89it/s, loss=37]train epoch: 41:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.89it/s, loss=31.2]train epoch: 41:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=31.2]train epoch: 41:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.50it/s, loss=24.6]train epoch: 41:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=24.6]train epoch: 41:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=23.5]train epoch: 41:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=23.5]train epoch: 41:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=29.6]train epoch: 41:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.81it/s, loss=29.6]train epoch: 41:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.81it/s, loss=31.9]train epoch: 41:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.48it/s, loss=31.9]train epoch: 41:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.48it/s, loss=33.3]train epoch: 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=33.3]train epoch: 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=33.3]
[[032m2021-11-26 10:27:43,194[0m INFO] trainer.training_epoch Training epoch 41, num_steps 336,  avg_loss: 30.3354, total_loss: 242.6832
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.56it/s]
[[032m2021-11-26 10:27:43,638[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.4375)])
[[032m2021-11-26 10:27:43,639[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:43,853[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 42:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 42:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.9]train epoch: 42:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=32.9]train epoch: 42:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=24.7]train epoch: 42:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.87it/s, loss=24.7]train epoch: 42:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.87it/s, loss=25.1]train epoch: 42:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.94it/s, loss=25.1]train epoch: 42:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.94it/s, loss=29.7]train epoch: 42:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.16it/s, loss=29.7]train epoch: 42:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.16it/s, loss=28]  train epoch: 42:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.10it/s, loss=28]train epoch: 42:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.10it/s, loss=36.7]train epoch: 42:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.73it/s, loss=36.7]train epoch: 42:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.73it/s, loss=27.6]train epoch: 42:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=27.6]train epoch: 42:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=18.5]train epoch: 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=18.5]train epoch: 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=18.5]
[[032m2021-11-26 10:27:46,301[0m INFO] trainer.training_epoch Training epoch 42, num_steps 344,  avg_loss: 27.8904, total_loss: 223.1229
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.35it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.41it/s]
[[032m2021-11-26 10:27:46,742[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:27:46,742[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:46,952[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 43:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 43:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.5]train epoch: 43:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=31.5]train epoch: 43:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=32]  train epoch: 43:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.75it/s, loss=32]train epoch: 43:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.75it/s, loss=26.5]train epoch: 43:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=26.5]train epoch: 43:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.01it/s, loss=24.7]train epoch: 43:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=24.7]train epoch: 43:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=27.4]train epoch: 43:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=27.4]train epoch: 43:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.78it/s, loss=30.3]train epoch: 43:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.32it/s, loss=30.3]train epoch: 43:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.32it/s, loss=28]  train epoch: 43:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.66it/s, loss=28]train epoch: 43:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.66it/s, loss=32.5]train epoch: 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=32.5]train epoch: 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.01it/s, loss=32.5]
[[032m2021-11-26 10:27:49,619[0m INFO] trainer.training_epoch Training epoch 43, num_steps 352,  avg_loss: 29.1119, total_loss: 232.8948
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.98it/s]
[[032m2021-11-26 10:27:50,036[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:27:50,037[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:50,268[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 44:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 44:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.8]train epoch: 44:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=30.8]train epoch: 44:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=33.3]train epoch: 44:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.60it/s, loss=33.3]train epoch: 44:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.60it/s, loss=35.9]train epoch: 44:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.88it/s, loss=35.9]train epoch: 44:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.88it/s, loss=29.8]train epoch: 44:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s, loss=29.8]train epoch: 44:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s, loss=26]  train epoch: 44:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.84it/s, loss=26]train epoch: 44:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.84it/s, loss=33.7]train epoch: 44:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.34it/s, loss=33.7]train epoch: 44:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.34it/s, loss=33.3]train epoch: 44:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.55it/s, loss=33.3]train epoch: 44:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.55it/s, loss=32.3]train epoch: 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.71it/s, loss=32.3]train epoch: 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.77it/s, loss=32.3]
[[032m2021-11-26 10:27:52,397[0m INFO] trainer.training_epoch Training epoch 44, num_steps 360,  avg_loss: 31.8878, total_loss: 255.1025
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.92it/s]
[[032m2021-11-26 10:27:52,817[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:27:52,817[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:53,036[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:27:53,137[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 45:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 45:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 45:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=30.2]train epoch: 45:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=34.3]train epoch: 45:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=34.3]train epoch: 45:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=26.3]train epoch: 45:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.89it/s, loss=26.3]train epoch: 45:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.89it/s, loss=26.6]train epoch: 45:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=26.6]train epoch: 45:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=24.9]train epoch: 45:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=24.9]train epoch: 45:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=23.9]train epoch: 45:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.95it/s, loss=23.9]train epoch: 45:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=30.4]train epoch: 45:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s, loss=30.4]train epoch: 45:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s, loss=27.8]train epoch: 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.48it/s, loss=27.8]train epoch: 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=27.8]
[[032m2021-11-26 10:27:55,501[0m INFO] trainer.training_epoch Training epoch 45, num_steps 368,  avg_loss: 28.0352, total_loss: 224.2813
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.16it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.72it/s]
[[032m2021-11-26 10:27:55,975[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:27:55,976[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:56,196[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:27:56,300[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 46:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 46:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.1]train epoch: 46:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=26.1]train epoch: 46:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=35.3]train epoch: 46:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.21it/s, loss=35.3]train epoch: 46:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.21it/s, loss=28.3]train epoch: 46:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.50it/s, loss=28.3]train epoch: 46:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.50it/s, loss=36]  train epoch: 46:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.93it/s, loss=36]train epoch: 46:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.93it/s, loss=28.6]train epoch: 46:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=28.6]train epoch: 46:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=26.8]train epoch: 46:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.52it/s, loss=26.8]train epoch: 46:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.52it/s, loss=23.1]train epoch: 46:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.71it/s, loss=23.1]train epoch: 46:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.71it/s, loss=37.6]train epoch: 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.69it/s, loss=37.6]train epoch: 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=37.6]
[[032m2021-11-26 10:27:58,548[0m INFO] trainer.training_epoch Training epoch 46, num_steps 376,  avg_loss: 30.2230, total_loss: 241.7842
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.02it/s]
[[032m2021-11-26 10:27:58,928[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:27:58,928[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:27:59,150[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:27:59,248[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 47:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 47:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.8]train epoch: 47:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=23.8]train epoch: 47:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=35.1]train epoch: 47:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=35.1]train epoch: 47:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=32.9]train epoch: 47:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.59it/s, loss=32.9]train epoch: 47:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.59it/s, loss=29.6]train epoch: 47:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=29.6]train epoch: 47:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=26.3]train epoch: 47:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.19it/s, loss=26.3]train epoch: 47:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.19it/s, loss=31.4]train epoch: 47:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s, loss=31.4]train epoch: 47:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s, loss=28.6]train epoch: 47:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.61it/s, loss=28.6]train epoch: 47:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.61it/s, loss=30.2]train epoch: 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.78it/s, loss=30.2]train epoch: 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=30.2]
[[032m2021-11-26 10:28:01,480[0m INFO] trainer.training_epoch Training epoch 47, num_steps 384,  avg_loss: 29.7381, total_loss: 237.9044
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.38it/s]
[[032m2021-11-26 10:28:01,848[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:01,849[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:02,080[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 48:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 48:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.1]train epoch: 48:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=34.1]train epoch: 48:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=30.5]train epoch: 48:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.39it/s, loss=30.5]train epoch: 48:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.39it/s, loss=26.3]train epoch: 48:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.32it/s, loss=26.3]train epoch: 48:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.32it/s, loss=29.1]train epoch: 48:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.46it/s, loss=29.1]train epoch: 48:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.46it/s, loss=29.7]train epoch: 48:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.52it/s, loss=29.7]train epoch: 48:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.52it/s, loss=27]  train epoch: 48:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=27]train epoch: 48:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=34.8]train epoch: 48:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=34.8]train epoch: 48:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=32.5]train epoch: 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=32.5]train epoch: 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s, loss=32.5]
[[032m2021-11-26 10:28:04,847[0m INFO] trainer.training_epoch Training epoch 48, num_steps 392,  avg_loss: 30.4748, total_loss: 243.7980
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.32it/s]
[[032m2021-11-26 10:28:05,252[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:05,252[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:05,472[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 49:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 49:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.4]train epoch: 49:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.36it/s, loss=24.4]train epoch: 49:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.36it/s, loss=22.9]train epoch: 49:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.64it/s, loss=22.9]train epoch: 49:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.64it/s, loss=31.7]train epoch: 49:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=31.7]train epoch: 49:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.10it/s, loss=33.3]train epoch: 49:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.64it/s, loss=33.3]train epoch: 49:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.64it/s, loss=30.2]train epoch: 49:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=30.2]train epoch: 49:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=31.3]train epoch: 49:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.84it/s, loss=31.3]train epoch: 49:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.84it/s, loss=33.3]train epoch: 49:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.01it/s, loss=33.3]train epoch: 49:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.01it/s, loss=26.2]train epoch: 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.20it/s, loss=26.2]train epoch: 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=26.2]
[[032m2021-11-26 10:28:07,518[0m INFO] trainer.training_epoch Training epoch 49, num_steps 400,  avg_loss: 29.1659, total_loss: 233.3270
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.00it/s]
[[032m2021-11-26 10:28:07,934[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:07,934[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:08,151[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 50:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.4335, 0.5665],
        [0.6717, 0.3283],
        [0.3295, 0.6705],
        [0.5445, 0.4555],
        [0.2534, 0.7466],
        [0.5560, 0.4440],
        [0.6493, 0.3507],
        [0.6310, 0.3690]], device='cuda:0')

prompt tensor([[0.4175, 0.5825],
        [0.7301, 0.2699],
        [0.5538, 0.4462],
        [0.6842, 0.3158],
        [0.7357, 0.2643],
        [0.5162, 0.4838],
        [0.7162, 0.2838],
        [0.4756, 0.5244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 50:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.3]train epoch: 50:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=22.3]train epoch: 50:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=28.6]train epoch: 50:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=28.6]train epoch: 50:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=26]  train epoch: 50:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.17it/s, loss=26]train epoch: 50:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.17it/s, loss=32.6]train epoch: 50:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.94it/s, loss=32.6]train epoch: 50:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.94it/s, loss=26.7]train epoch: 50:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=26.7]train epoch: 50:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=26.8]train epoch: 50:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.13it/s, loss=26.8]train epoch: 50:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.13it/s, loss=24.3]train epoch: 50:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=24.3]train epoch: 50:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=24.2]train epoch: 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.68it/s, loss=24.2]train epoch: 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=24.2]
[[032m2021-11-26 10:28:10,554[0m INFO] trainer.training_epoch Training epoch 50, num_steps 408,  avg_loss: 26.4381, total_loss: 211.5048
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.91it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.88it/s]
[[032m2021-11-26 10:28:10,976[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:10,977[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:11,186[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 51:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 51:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.6]train epoch: 51:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=24.6]train epoch: 51:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=30.6]train epoch: 51:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.76it/s, loss=30.6]train epoch: 51:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.76it/s, loss=28.2]train epoch: 51:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.32it/s, loss=28.2]train epoch: 51:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.32it/s, loss=23.8]train epoch: 51:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=23.8]train epoch: 51:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=26.2]train epoch: 51:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.72it/s, loss=26.2]train epoch: 51:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.72it/s, loss=36.9]train epoch: 51:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.28it/s, loss=36.9]train epoch: 51:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.28it/s, loss=33.7]train epoch: 51:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.74it/s, loss=33.7]train epoch: 51:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.74it/s, loss=36.8]train epoch: 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=36.8]train epoch: 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.01it/s, loss=36.8]
[[032m2021-11-26 10:28:13,846[0m INFO] trainer.training_epoch Training epoch 51, num_steps 416,  avg_loss: 30.1120, total_loss: 240.8958
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.76it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.83it/s]
[[032m2021-11-26 10:28:14,233[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:14,234[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:14,463[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 52:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 52:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.2]train epoch: 52:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.77it/s, loss=32.2]train epoch: 52:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.77it/s, loss=29]  train epoch: 52:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.78it/s, loss=29]train epoch: 52:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.78it/s, loss=26.4]train epoch: 52:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.23it/s, loss=26.4]train epoch: 52:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.23it/s, loss=35.8]train epoch: 52:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.71it/s, loss=35.8]train epoch: 52:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.71it/s, loss=29.9]train epoch: 52:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=29.9]train epoch: 52:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=27.7]train epoch: 52:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.83it/s, loss=27.7]train epoch: 52:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=36.9]train epoch: 52:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.12it/s, loss=36.9]train epoch: 52:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.12it/s, loss=27.8]train epoch: 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.36it/s, loss=27.8]train epoch: 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=27.8]
[[032m2021-11-26 10:28:16,772[0m INFO] trainer.training_epoch Training epoch 52, num_steps 424,  avg_loss: 30.7020, total_loss: 245.6160
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.30it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.74it/s]
[[032m2021-11-26 10:28:17,161[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:17,161[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:17,371[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 53:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 53:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.5]train epoch: 53:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=28.5]train epoch: 53:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=33.6]train epoch: 53:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=33.6]train epoch: 53:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=26.2]train epoch: 53:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.38it/s, loss=26.2]train epoch: 53:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.38it/s, loss=26.4]train epoch: 53:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.35it/s, loss=26.4]train epoch: 53:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.35it/s, loss=31.1]train epoch: 53:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s, loss=31.1]train epoch: 53:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s, loss=28.9]train epoch: 53:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s, loss=28.9]train epoch: 53:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s, loss=25.1]train epoch: 53:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.61it/s, loss=25.1]train epoch: 53:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.61it/s, loss=29]  train epoch: 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=29]train epoch: 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=29]
[[032m2021-11-26 10:28:19,572[0m INFO] trainer.training_epoch Training epoch 53, num_steps 432,  avg_loss: 28.5898, total_loss: 228.7181
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.10it/s]
[[032m2021-11-26 10:28:19,991[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:28:19,991[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:20,214[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 54:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 54:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.1]train epoch: 54:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=30.1]train epoch: 54:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=27.3]train epoch: 54:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.20it/s, loss=27.3]train epoch: 54:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.20it/s, loss=37.4]train epoch: 54:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.52it/s, loss=37.4]train epoch: 54:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.52it/s, loss=26.2]train epoch: 54:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.55it/s, loss=26.2]train epoch: 54:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.55it/s, loss=31.1]train epoch: 54:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.37it/s, loss=31.1]train epoch: 54:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.37it/s, loss=36]  train epoch: 54:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.60it/s, loss=36]train epoch: 54:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.60it/s, loss=17.8]train epoch: 54:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.82it/s, loss=17.8]train epoch: 54:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.82it/s, loss=27.6]train epoch: 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=27.6]train epoch: 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.78it/s, loss=27.6]
[[032m2021-11-26 10:28:22,336[0m INFO] trainer.training_epoch Training epoch 54, num_steps 440,  avg_loss: 29.1754, total_loss: 233.4032
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.21it/s]
[[032m2021-11-26 10:28:22,787[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:22,788[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:23,009[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 55:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 55:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.6]train epoch: 55:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=24.6]train epoch: 55:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=30]  train epoch: 55:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=30]train epoch: 55:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=28.4]train epoch: 55:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.20it/s, loss=28.4]train epoch: 55:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.20it/s, loss=31.3]train epoch: 55:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=31.3]train epoch: 55:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=28]  train epoch: 55:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=28]train epoch: 55:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=26.5]train epoch: 55:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.60it/s, loss=26.5]train epoch: 55:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.60it/s, loss=28.1]train epoch: 55:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.72it/s, loss=28.1]train epoch: 55:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.72it/s, loss=32.9]train epoch: 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.86it/s, loss=32.9]train epoch: 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=32.9]
[[032m2021-11-26 10:28:25,243[0m INFO] trainer.training_epoch Training epoch 55, num_steps 448,  avg_loss: 28.7187, total_loss: 229.7498
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.48it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.08it/s]
[[032m2021-11-26 10:28:25,662[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:28:25,662[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:25,888[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:28:25,978[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 56:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 56:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.1]train epoch: 56:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.81it/s, loss=23.1]train epoch: 56:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.81it/s, loss=27]  train epoch: 56:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=27]train epoch: 56:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=30.8]train epoch: 56:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.55it/s, loss=30.8]train epoch: 56:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.55it/s, loss=45.8]train epoch: 56:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s, loss=45.8]train epoch: 56:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s, loss=23.9]train epoch: 56:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.71it/s, loss=23.9]train epoch: 56:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.71it/s, loss=24.8]train epoch: 56:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.95it/s, loss=24.8]train epoch: 56:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=25.1]train epoch: 56:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=25.1]train epoch: 56:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=31.9]train epoch: 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s, loss=31.9]train epoch: 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s, loss=31.9]
[[032m2021-11-26 10:28:28,489[0m INFO] trainer.training_epoch Training epoch 56, num_steps 456,  avg_loss: 29.0308, total_loss: 232.2464
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.74it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.60it/s]
[[032m2021-11-26 10:28:28,882[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:28:28,883[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:29,101[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 57:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 57:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.5]train epoch: 57:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=31.5]train epoch: 57:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=32.5]train epoch: 57:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.30it/s, loss=32.5]train epoch: 57:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.30it/s, loss=22.9]train epoch: 57:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=22.9]train epoch: 57:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.15it/s, loss=24.2]train epoch: 57:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=24.2]train epoch: 57:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=22.8]train epoch: 57:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.17it/s, loss=22.8]train epoch: 57:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.17it/s, loss=33]  train epoch: 57:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.25it/s, loss=33]train epoch: 57:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.25it/s, loss=26.9]train epoch: 57:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=26.9]train epoch: 57:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=32.8]train epoch: 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=32.8]train epoch: 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=32.8]
[[032m2021-11-26 10:28:31,348[0m INFO] trainer.training_epoch Training epoch 57, num_steps 464,  avg_loss: 28.3335, total_loss: 226.6683
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.84it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.72it/s]
[[032m2021-11-26 10:28:31,739[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:28:31,739[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:31,959[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:28:32,054[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 58:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 58:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 58:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=29.3]train epoch: 58:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=25.4]train epoch: 58:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.30it/s, loss=25.4]train epoch: 58:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.30it/s, loss=25.1]train epoch: 58:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.62it/s, loss=25.1]train epoch: 58:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.62it/s, loss=27.9]train epoch: 58:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=27.9]train epoch: 58:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=34]  train epoch: 58:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.58it/s, loss=34]train epoch: 58:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.58it/s, loss=29.6]train epoch: 58:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.90it/s, loss=29.6]train epoch: 58:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.90it/s, loss=39.4]train epoch: 58:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=39.4]train epoch: 58:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=24.6]train epoch: 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.56it/s, loss=24.6]train epoch: 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s, loss=24.6]
[[032m2021-11-26 10:28:34,603[0m INFO] trainer.training_epoch Training epoch 58, num_steps 472,  avg_loss: 29.4071, total_loss: 235.2567
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.32it/s]
[[032m2021-11-26 10:28:34,978[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:28:34,978[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:35,199[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:28:35,303[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 59:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 59:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.5]train epoch: 59:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=29.5]train epoch: 59:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=24.7]train epoch: 59:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.94it/s, loss=24.7]train epoch: 59:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.94it/s, loss=27.6]train epoch: 59:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.89it/s, loss=27.6]train epoch: 59:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.89it/s, loss=22.6]train epoch: 59:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.07it/s, loss=22.6]train epoch: 59:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.07it/s, loss=32.2]train epoch: 59:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.19it/s, loss=32.2]train epoch: 59:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.19it/s, loss=25.8]train epoch: 59:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.58it/s, loss=25.8]train epoch: 59:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.58it/s, loss=30.8]train epoch: 59:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.87it/s, loss=30.8]train epoch: 59:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.87it/s, loss=38.7]train epoch: 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.09it/s, loss=38.7]train epoch: 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=38.7]
[[032m2021-11-26 10:28:37,537[0m INFO] trainer.training_epoch Training epoch 59, num_steps 480,  avg_loss: 28.9871, total_loss: 231.8967
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.21it/s]
[[032m2021-11-26 10:28:37,946[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:28:37,947[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:38,168[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:28:38,413[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 60:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 60:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.1]train epoch: 60:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=23.1]train epoch: 60:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=25.1]train epoch: 60:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.78it/s, loss=25.1]train epoch: 60:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.78it/s, loss=31.9]train epoch: 60:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=31.9]train epoch: 60:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=20.4]train epoch: 60:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=20.4]train epoch: 60:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=34.6]train epoch: 60:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=34.6]train epoch: 60:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=25.7]train epoch: 60:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.42it/s, loss=25.7]train epoch: 60:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.42it/s, loss=24.2]train epoch: 60:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.72it/s, loss=24.2]train epoch: 60:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.72it/s, loss=35.1]train epoch: 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=35.1]train epoch: 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=35.1]
[[032m2021-11-26 10:28:40,847[0m INFO] trainer.training_epoch Training epoch 60, num_steps 488,  avg_loss: 27.5000, total_loss: 220.0000
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.64it/s]
[[032m2021-11-26 10:28:41,240[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:28:41,241[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:41,465[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:28:41,594[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 61:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 61:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.2]train epoch: 61:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.23it/s, loss=36.2]train epoch: 61:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.23it/s, loss=34.1]train epoch: 61:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.26it/s, loss=34.1]train epoch: 61:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.26it/s, loss=38.1]train epoch: 61:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.70it/s, loss=38.1]train epoch: 61:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.70it/s, loss=32.9]train epoch: 61:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=32.9]train epoch: 61:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=33.2]train epoch: 61:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=33.2]train epoch: 61:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=25.2]train epoch: 61:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.56it/s, loss=25.2]train epoch: 61:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.56it/s, loss=30.8]train epoch: 61:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.83it/s, loss=30.8]train epoch: 61:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.83it/s, loss=25.9]train epoch: 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=25.9]train epoch: 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=25.9]
[[032m2021-11-26 10:28:43,989[0m INFO] trainer.training_epoch Training epoch 61, num_steps 496,  avg_loss: 32.0694, total_loss: 256.5550
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.26it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.69it/s]
[[032m2021-11-26 10:28:44,417[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:28:44,417[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:44,632[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 62:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 62:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.2]train epoch: 62:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.21it/s, loss=22.2]train epoch: 62:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.21it/s, loss=25.7]train epoch: 62:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.20it/s, loss=25.7]train epoch: 62:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.20it/s, loss=26.4]train epoch: 62:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.96it/s, loss=26.4]train epoch: 62:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.96it/s, loss=33.5]train epoch: 62:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=33.5]
model tensor([[0.6269, 0.3731],
        [0.4716, 0.5284],
        [0.4305, 0.5695],
        [0.4593, 0.5407],
        [0.7454, 0.2546],
        [0.4335, 0.5665],
        [0.2534, 0.7466],
        [0.3884, 0.6116]], device='cuda:0')

prompt tensor([[0.8604, 0.1396],
        [0.5234, 0.4766],
        [0.2240, 0.7760],
        [0.6304, 0.3696],
        [0.7396, 0.2604],
        [0.7862, 0.2138],
        [0.4726, 0.5274],
        [0.5316, 0.4684]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 62:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=26.2]train epoch: 62:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=26.2]train epoch: 62:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=18.9]train epoch: 62:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.77it/s, loss=18.9]train epoch: 62:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.77it/s, loss=25.7]train epoch: 62:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.91it/s, loss=25.7]train epoch: 62:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.91it/s, loss=32.2]train epoch: 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.01it/s, loss=32.2]train epoch: 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=32.2]
[[032m2021-11-26 10:28:46,836[0m INFO] trainer.training_epoch Training epoch 62, num_steps 504,  avg_loss: 26.3576, total_loss: 210.8607
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.31it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.77it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.79it/s]
[[032m2021-11-26 10:28:47,265[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:28:47,265[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:47,555[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 63:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 63:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.1]train epoch: 63:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=23.1]train epoch: 63:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=23.6]train epoch: 63:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.37it/s, loss=23.6]train epoch: 63:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.37it/s, loss=25.2]train epoch: 63:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=25.2]train epoch: 63:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=26.1]train epoch: 63:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.55it/s, loss=26.1]train epoch: 63:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.55it/s, loss=23.8]train epoch: 63:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.64it/s, loss=23.8]train epoch: 63:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.64it/s, loss=29]  train epoch: 63:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.87it/s, loss=29]train epoch: 63:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.87it/s, loss=30.1]train epoch: 63:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.99it/s, loss=30.1]train epoch: 63:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.99it/s, loss=31.5]train epoch: 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.19it/s, loss=31.5]train epoch: 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.80it/s, loss=31.5]
[[032m2021-11-26 10:28:49,677[0m INFO] trainer.training_epoch Training epoch 63, num_steps 512,  avg_loss: 26.5445, total_loss: 212.3564
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.62it/s]
[[032m2021-11-26 10:28:50,109[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:28:50,109[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:50,343[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 64:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 64:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.6]train epoch: 64:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.77it/s, loss=32.6]train epoch: 64:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.77it/s, loss=26.7]train epoch: 64:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.87it/s, loss=26.7]train epoch: 64:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.87it/s, loss=24.6]train epoch: 64:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.93it/s, loss=24.6]train epoch: 64:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.93it/s, loss=31.3]train epoch: 64:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.07it/s, loss=31.3]train epoch: 64:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.07it/s, loss=27.2]train epoch: 64:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.44it/s, loss=27.2]train epoch: 64:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.44it/s, loss=28.1]train epoch: 64:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.80it/s, loss=28.1]train epoch: 64:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.80it/s, loss=29]  train epoch: 64:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.03it/s, loss=29]train epoch: 64:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.03it/s, loss=21.4]train epoch: 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=21.4]train epoch: 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=21.4]
[[032m2021-11-26 10:28:52,572[0m INFO] trainer.training_epoch Training epoch 64, num_steps 520,  avg_loss: 27.6270, total_loss: 221.0158
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.85it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.00it/s]
[[032m2021-11-26 10:28:53,032[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:28:53,033[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:53,250[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 65:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 65:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.8]train epoch: 65:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.31it/s, loss=32.8]train epoch: 65:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.31it/s, loss=24.8]train epoch: 65:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.79it/s, loss=24.8]train epoch: 65:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.79it/s, loss=23.8]train epoch: 65:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.59it/s, loss=23.8]train epoch: 65:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.59it/s, loss=29.9]train epoch: 65:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.37it/s, loss=29.9]train epoch: 65:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.37it/s, loss=34.3]train epoch: 65:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=34.3]train epoch: 65:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=25.3]train epoch: 65:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=25.3]train epoch: 65:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=31.7]train epoch: 65:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.46it/s, loss=31.7]train epoch: 65:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.46it/s, loss=30.5]train epoch: 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.71it/s, loss=30.5]train epoch: 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.66it/s, loss=30.5]
[[032m2021-11-26 10:28:55,440[0m INFO] trainer.training_epoch Training epoch 65, num_steps 528,  avg_loss: 29.1350, total_loss: 233.0804
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.39it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.63it/s]
[[032m2021-11-26 10:28:55,872[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:28:55,872[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:56,081[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 66:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 66:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.4]train epoch: 66:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.08it/s, loss=21.4]train epoch: 66:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.08it/s, loss=32.1]train epoch: 66:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=32.1]train epoch: 66:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=31.6]train epoch: 66:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.85it/s, loss=31.6]train epoch: 66:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.85it/s, loss=27.6]train epoch: 66:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=27.6]train epoch: 66:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=30.8]train epoch: 66:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.68it/s, loss=30.8]train epoch: 66:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.68it/s, loss=27.5]train epoch: 66:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.15it/s, loss=27.5]train epoch: 66:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.15it/s, loss=30.6]train epoch: 66:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=30.6]train epoch: 66:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=35.8]train epoch: 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=35.8]train epoch: 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=35.8]
[[032m2021-11-26 10:28:58,430[0m INFO] trainer.training_epoch Training epoch 66, num_steps 536,  avg_loss: 29.6845, total_loss: 237.4761
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.06it/s]
[[032m2021-11-26 10:28:58,809[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:28:58,809[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:28:59,030[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 67:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 67:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.5]train epoch: 67:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=26.5]train epoch: 67:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=35]  train epoch: 67:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.11it/s, loss=35]train epoch: 67:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.11it/s, loss=25.2]train epoch: 67:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.45it/s, loss=25.2]train epoch: 67:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.45it/s, loss=28.3]train epoch: 67:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=28.3]train epoch: 67:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=27.9]train epoch: 67:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=27.9]train epoch: 67:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=23.8]train epoch: 67:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.28it/s, loss=23.8]train epoch: 67:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.28it/s, loss=28.3]train epoch: 67:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.65it/s, loss=28.3]train epoch: 67:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.65it/s, loss=24.7]train epoch: 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.75it/s, loss=24.7]train epoch: 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=24.7]
[[032m2021-11-26 10:29:01,370[0m INFO] trainer.training_epoch Training epoch 67, num_steps 544,  avg_loss: 27.4582, total_loss: 219.6658
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.33it/s]
[[032m2021-11-26 10:29:01,774[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:29:01,775[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:01,995[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 68:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 68:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.6]train epoch: 68:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=36.6]train epoch: 68:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=38.4]train epoch: 68:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.90it/s, loss=38.4]train epoch: 68:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.90it/s, loss=31.3]train epoch: 68:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=31.3]train epoch: 68:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=26.8]train epoch: 68:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=26.8]train epoch: 68:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=26.4]train epoch: 68:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=26.4]train epoch: 68:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=27.8]train epoch: 68:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.21it/s, loss=27.8]train epoch: 68:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.21it/s, loss=26.7]train epoch: 68:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.52it/s, loss=26.7]train epoch: 68:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.52it/s, loss=23.4]train epoch: 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.78it/s, loss=23.4]train epoch: 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=23.4]
[[032m2021-11-26 10:29:04,363[0m INFO] trainer.training_epoch Training epoch 68, num_steps 552,  avg_loss: 29.6804, total_loss: 237.4433
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.66it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.64it/s]
[[032m2021-11-26 10:29:04,755[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:29:04,755[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:04,976[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 69:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 69:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 69:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.12it/s, loss=27.3]train epoch: 69:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.12it/s, loss=32.7]train epoch: 69:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.78it/s, loss=32.7]train epoch: 69:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.78it/s, loss=25.5]train epoch: 69:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.78it/s, loss=25.5]train epoch: 69:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.78it/s, loss=23.9]train epoch: 69:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.18it/s, loss=23.9]train epoch: 69:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.18it/s, loss=39.3]train epoch: 69:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.47it/s, loss=39.3]train epoch: 69:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.47it/s, loss=35.6]train epoch: 69:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=35.6]train epoch: 69:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=36.7]train epoch: 69:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.79it/s, loss=36.7]train epoch: 69:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.79it/s, loss=30.4]train epoch: 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.00it/s, loss=30.4]train epoch: 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=30.4]
[[032m2021-11-26 10:29:07,066[0m INFO] trainer.training_epoch Training epoch 69, num_steps 560,  avg_loss: 31.4349, total_loss: 251.4794
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.71it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.84it/s]
[[032m2021-11-26 10:29:07,449[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:29:07,450[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:07,673[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 70:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 70:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.9]train epoch: 70:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=26.9]train epoch: 70:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=28.2]train epoch: 70:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.96it/s, loss=28.2]train epoch: 70:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.96it/s, loss=25]  train epoch: 70:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=25]train epoch: 70:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=37.4]train epoch: 70:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=37.4]train epoch: 70:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=23.1]train epoch: 70:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=23.1]train epoch: 70:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=31.8]train epoch: 70:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=31.8]train epoch: 70:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.14it/s, loss=36.3]train epoch: 70:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.49it/s, loss=36.3]train epoch: 70:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.49it/s, loss=23.7]train epoch: 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=23.7]train epoch: 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=23.7]
[[032m2021-11-26 10:29:10,072[0m INFO] trainer.training_epoch Training epoch 70, num_steps 568,  avg_loss: 29.0551, total_loss: 232.4407
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.92it/s]
[[032m2021-11-26 10:29:10,455[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:29:10,455[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:10,676[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 71:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 71:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.3]train epoch: 71:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.89it/s, loss=25.3]train epoch: 71:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.89it/s, loss=28.4]train epoch: 71:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.80it/s, loss=28.4]train epoch: 71:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.80it/s, loss=29.4]train epoch: 71:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.28it/s, loss=29.4]train epoch: 71:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.28it/s, loss=25.2]train epoch: 71:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.98it/s, loss=25.2]train epoch: 71:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.98it/s, loss=21.9]train epoch: 71:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=21.9]train epoch: 71:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=31.6]train epoch: 71:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.63it/s, loss=31.6]train epoch: 71:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.63it/s, loss=26.5]train epoch: 71:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.68it/s, loss=26.5]train epoch: 71:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.68it/s, loss=33.6]train epoch: 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s, loss=33.6]train epoch: 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.58it/s, loss=33.6]
[[032m2021-11-26 10:29:12,916[0m INFO] trainer.training_epoch Training epoch 71, num_steps 576,  avg_loss: 27.7381, total_loss: 221.9045
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.81it/s]
[[032m2021-11-26 10:29:13,303[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:29:13,304[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:13,525[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 72:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 72:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.8]train epoch: 72:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=25.8]train epoch: 72:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=29.1]train epoch: 72:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.98it/s, loss=29.1]train epoch: 72:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.98it/s, loss=27.4]train epoch: 72:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.60it/s, loss=27.4]train epoch: 72:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.60it/s, loss=35.2]train epoch: 72:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.57it/s, loss=35.2]train epoch: 72:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.57it/s, loss=35.9]train epoch: 72:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=35.9]train epoch: 72:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=23.7]train epoch: 72:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.21it/s, loss=23.7]train epoch: 72:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.21it/s, loss=23.1]train epoch: 72:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.53it/s, loss=23.1]train epoch: 72:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.53it/s, loss=23.3]train epoch: 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.72it/s, loss=23.3]train epoch: 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=23.3]
[[032m2021-11-26 10:29:15,760[0m INFO] trainer.training_epoch Training epoch 72, num_steps 584,  avg_loss: 27.9479, total_loss: 223.5830
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.69it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.19it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.87it/s]
[[032m2021-11-26 10:29:16,186[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:29:16,186[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:16,397[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 73:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 73:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.6]train epoch: 73:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=32.6]train epoch: 73:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=33.7]train epoch: 73:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.71it/s, loss=33.7]train epoch: 73:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.71it/s, loss=28.2]train epoch: 73:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=28.2]train epoch: 73:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=25.5]train epoch: 73:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.81it/s, loss=25.5]train epoch: 73:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=38.3]train epoch: 73:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=38.3]train epoch: 73:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=27.5]train epoch: 73:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.99it/s, loss=27.5]train epoch: 73:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.99it/s, loss=30.6]train epoch: 73:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.01it/s, loss=30.6]train epoch: 73:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.01it/s, loss=30.5]train epoch: 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=30.5]train epoch: 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=30.5]
[[032m2021-11-26 10:29:18,694[0m INFO] trainer.training_epoch Training epoch 73, num_steps 592,  avg_loss: 30.8611, total_loss: 246.8888
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.65it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.97it/s]
[[032m2021-11-26 10:29:19,116[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:29:19,116[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:19,333[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 74:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 74:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.2]train epoch: 74:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.07it/s, loss=36.2]train epoch: 74:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.07it/s, loss=24.8]train epoch: 74:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.85it/s, loss=24.8]train epoch: 74:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.85it/s, loss=19.7]train epoch: 74:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.84it/s, loss=19.7]train epoch: 74:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.84it/s, loss=22.9]train epoch: 74:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.24it/s, loss=22.9]train epoch: 74:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.24it/s, loss=34.6]train epoch: 74:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.69it/s, loss=34.6]train epoch: 74:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.69it/s, loss=21.5]train epoch: 74:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.45it/s, loss=21.5]train epoch: 74:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.45it/s, loss=32.2]train epoch: 74:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.01it/s, loss=32.2]train epoch: 74:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.01it/s, loss=23]  train epoch: 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.64it/s, loss=23]train epoch: 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=23]
[[032m2021-11-26 10:29:21,793[0m INFO] trainer.training_epoch Training epoch 74, num_steps 600,  avg_loss: 26.8709, total_loss: 214.9671
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.75it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.93it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.33it/s]
[[032m2021-11-26 10:29:22,242[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:29:22,242[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:22,454[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 75:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.6731, 0.3269],
        [0.6310, 0.3690],
        [0.5702, 0.4298],
        [0.5445, 0.4555],
        [0.4305, 0.5695],
        [0.4201, 0.5799],
        [0.3049, 0.6951],
        [0.7036, 0.2964]], device='cuda:0')

prompt tensor([[0.8956, 0.1044],
        [0.7800, 0.2200],
        [0.7535, 0.2465],
        [0.7685, 0.2315],
        [0.5933, 0.4067],
        [0.4349, 0.5651],
        [0.4919, 0.5081],
        [0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 75:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.7]train epoch: 75:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.70it/s, loss=22.7]train epoch: 75:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.70it/s, loss=33.2]train epoch: 75:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.66it/s, loss=33.2]train epoch: 75:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.66it/s, loss=19.9]train epoch: 75:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.54it/s, loss=19.9]train epoch: 75:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.54it/s, loss=27.1]train epoch: 75:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.33it/s, loss=27.1]train epoch: 75:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.33it/s, loss=25.3]train epoch: 75:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.62it/s, loss=25.3]train epoch: 75:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.62it/s, loss=30.2]train epoch: 75:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.04it/s, loss=30.2]train epoch: 75:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.04it/s, loss=34.2]train epoch: 75:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=34.2]train epoch: 75:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=33.4]train epoch: 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=33.4]train epoch: 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=33.4]
[[032m2021-11-26 10:29:24,926[0m INFO] trainer.training_epoch Training epoch 75, num_steps 608,  avg_loss: 28.2491, total_loss: 225.9925
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.59it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.86it/s]
[[032m2021-11-26 10:29:25,395[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:29:25,395[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:25,610[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 76:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 76:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 76:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=24.9]train epoch: 76:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=37.6]train epoch: 76:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=37.6]train epoch: 76:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=35.5]train epoch: 76:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.87it/s, loss=35.5]train epoch: 76:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.87it/s, loss=23.2]train epoch: 76:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.14it/s, loss=23.2]train epoch: 76:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.14it/s, loss=40.3]train epoch: 76:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=40.3]train epoch: 76:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=31.7]train epoch: 76:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=31.7]train epoch: 76:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.43it/s, loss=30.8]train epoch: 76:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.98it/s, loss=30.8]train epoch: 76:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.98it/s, loss=35.2]train epoch: 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s, loss=35.2]train epoch: 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=35.2]
[[032m2021-11-26 10:29:27,963[0m INFO] trainer.training_epoch Training epoch 76, num_steps 616,  avg_loss: 32.4039, total_loss: 259.2315
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.86it/s]
[[032m2021-11-26 10:29:28,320[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:29:28,320[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:28,535[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 77:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 77:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.2]train epoch: 77:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=27.2]train epoch: 77:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=25.8]train epoch: 77:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=25.8]train epoch: 77:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=33.9]train epoch: 77:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s, loss=33.9]train epoch: 77:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.13it/s, loss=28.9]train epoch: 77:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.51it/s, loss=28.9]train epoch: 77:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.51it/s, loss=26.1]train epoch: 77:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=26.1]train epoch: 77:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=23.6]train epoch: 77:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.98it/s, loss=23.6]train epoch: 77:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=27.4]train epoch: 77:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=27.4]train epoch: 77:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=29.1]train epoch: 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.76it/s, loss=29.1]train epoch: 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s, loss=29.1]
[[032m2021-11-26 10:29:31,172[0m INFO] trainer.training_epoch Training epoch 77, num_steps 624,  avg_loss: 27.7554, total_loss: 222.0430
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.72it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.48it/s]
[[032m2021-11-26 10:29:31,611[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:29:31,612[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:31,832[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 78:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 78:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.3]train epoch: 78:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=37.3]train epoch: 78:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=30.4]train epoch: 78:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.68it/s, loss=30.4]train epoch: 78:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.68it/s, loss=33.5]train epoch: 78:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.67it/s, loss=33.5]train epoch: 78:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.67it/s, loss=27.2]train epoch: 78:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.62it/s, loss=27.2]train epoch: 78:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.62it/s, loss=24]  train epoch: 78:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=24]train epoch: 78:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=26.9]train epoch: 78:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s, loss=26.9]train epoch: 78:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.38it/s, loss=27.6]train epoch: 78:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.55it/s, loss=27.6]train epoch: 78:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.55it/s, loss=34.2]train epoch: 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=34.2]train epoch: 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=34.2]
[[032m2021-11-26 10:29:34,324[0m INFO] trainer.training_epoch Training epoch 78, num_steps 632,  avg_loss: 30.1345, total_loss: 241.0758
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.30it/s]
[[032m2021-11-26 10:29:34,769[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:29:34,770[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:34,986[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 79:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 79:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.8]train epoch: 79:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=24.8]train epoch: 79:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=27.8]train epoch: 79:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.86it/s, loss=27.8]train epoch: 79:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.86it/s, loss=25.4]train epoch: 79:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.73it/s, loss=25.4]train epoch: 79:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.73it/s, loss=27.2]train epoch: 79:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.01it/s, loss=27.2]train epoch: 79:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.01it/s, loss=32.8]train epoch: 79:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.96it/s, loss=32.8]train epoch: 79:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.96it/s, loss=42.5]train epoch: 79:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.19it/s, loss=42.5]train epoch: 79:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.19it/s, loss=26.6]train epoch: 79:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.52it/s, loss=26.6]train epoch: 79:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.52it/s, loss=32]  train epoch: 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s, loss=32]train epoch: 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.87it/s, loss=32]
[[032m2021-11-26 10:29:37,776[0m INFO] trainer.training_epoch Training epoch 79, num_steps 640,  avg_loss: 29.8879, total_loss: 239.1036
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.72it/s]
[[032m2021-11-26 10:29:38,165[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:29:38,166[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:38,394[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 80:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 80:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.9]train epoch: 80:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=30.9]train epoch: 80:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=23]  train epoch: 80:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=23]train epoch: 80:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=26.6]train epoch: 80:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.12it/s, loss=26.6]train epoch: 80:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.12it/s, loss=24.9]train epoch: 80:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=24.9]train epoch: 80:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=30.1]train epoch: 80:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.10it/s, loss=30.1]train epoch: 80:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.10it/s, loss=29]  train epoch: 80:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.99it/s, loss=29]train epoch: 80:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.99it/s, loss=28.2]train epoch: 80:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=28.2]train epoch: 80:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=29.7]train epoch: 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.42it/s, loss=29.7]train epoch: 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=29.7]
[[032m2021-11-26 10:29:40,814[0m INFO] trainer.training_epoch Training epoch 80, num_steps 648,  avg_loss: 27.7989, total_loss: 222.3915
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.83it/s]
[[032m2021-11-26 10:29:41,199[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:29:41,200[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:41,415[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 81:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 81:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.4]train epoch: 81:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=32.4]train epoch: 81:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=36.5]train epoch: 81:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.85it/s, loss=36.5]train epoch: 81:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.85it/s, loss=22.9]train epoch: 81:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.72it/s, loss=22.9]train epoch: 81:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.72it/s, loss=32.8]train epoch: 81:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.55it/s, loss=32.8]train epoch: 81:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.55it/s, loss=30.9]train epoch: 81:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.93it/s, loss=30.9]train epoch: 81:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.93it/s, loss=26.2]train epoch: 81:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.34it/s, loss=26.2]train epoch: 81:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.34it/s, loss=33.9]train epoch: 81:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=33.9]train epoch: 81:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=31.3]train epoch: 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.70it/s, loss=31.3]train epoch: 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=31.3]
[[032m2021-11-26 10:29:43,823[0m INFO] trainer.training_epoch Training epoch 81, num_steps 656,  avg_loss: 30.8577, total_loss: 246.8619
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.22it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.33it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.76it/s]
[[032m2021-11-26 10:29:44,297[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:29:44,297[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:44,514[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 82:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 82:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.4]train epoch: 82:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.16it/s, loss=30.4]train epoch: 82:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.16it/s, loss=27.3]train epoch: 82:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.64it/s, loss=27.3]train epoch: 82:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.64it/s, loss=33.9]train epoch: 82:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.38it/s, loss=33.9]train epoch: 82:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.38it/s, loss=33.3]train epoch: 82:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.83it/s, loss=33.3]train epoch: 82:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.83it/s, loss=36.8]train epoch: 82:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.29it/s, loss=36.8]train epoch: 82:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.29it/s, loss=26.4]train epoch: 82:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.52it/s, loss=26.4]train epoch: 82:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.52it/s, loss=37.4]train epoch: 82:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.73it/s, loss=37.4]train epoch: 82:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.73it/s, loss=34.6]train epoch: 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.87it/s, loss=34.6]train epoch: 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.38it/s, loss=34.6]
[[032m2021-11-26 10:29:46,890[0m INFO] trainer.training_epoch Training epoch 82, num_steps 664,  avg_loss: 32.5155, total_loss: 260.1237
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.99it/s]
[[032m2021-11-26 10:29:47,308[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:29:47,309[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:47,544[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 83:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 83:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.5]train epoch: 83:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=32.5]train epoch: 83:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=23.4]train epoch: 83:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.59it/s, loss=23.4]train epoch: 83:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.59it/s, loss=24.7]train epoch: 83:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.76it/s, loss=24.7]train epoch: 83:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.76it/s, loss=31.3]train epoch: 83:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=31.3]train epoch: 83:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=29.4]train epoch: 83:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=29.4]train epoch: 83:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=28.6]train epoch: 83:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s, loss=28.6]train epoch: 83:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.36it/s, loss=24.9]train epoch: 83:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=24.9]train epoch: 83:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=28.9]train epoch: 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=28.9]train epoch: 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=28.9]
[[032m2021-11-26 10:29:49,944[0m INFO] trainer.training_epoch Training epoch 83, num_steps 672,  avg_loss: 27.9756, total_loss: 223.8049
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.47it/s]
[[032m2021-11-26 10:29:50,312[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:29:50,313[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:50,551[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 84:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 84:   0%|          | 0/8 [00:00<?, ?it/s, loss=16]train epoch: 84:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=16]train epoch: 84:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=24.8]train epoch: 84:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.73it/s, loss=24.8]train epoch: 84:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.73it/s, loss=34.1]train epoch: 84:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.14it/s, loss=34.1]train epoch: 84:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.14it/s, loss=31.7]train epoch: 84:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=31.7]train epoch: 84:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=20]  train epoch: 84:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.45it/s, loss=20]train epoch: 84:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.45it/s, loss=29.6]train epoch: 84:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=29.6]train epoch: 84:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=23]  train epoch: 84:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=23]train epoch: 84:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=27.3]train epoch: 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=27.3]train epoch: 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s, loss=27.3]
[[032m2021-11-26 10:29:53,192[0m INFO] trainer.training_epoch Training epoch 84, num_steps 680,  avg_loss: 25.8190, total_loss: 206.5522
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.15it/s]
[[032m2021-11-26 10:29:53,568[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:29:53,569[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:53,798[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 85:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 85:   0%|          | 0/8 [00:00<?, ?it/s, loss=24]train epoch: 85:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.33it/s, loss=24]train epoch: 85:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.33it/s, loss=26.5]train epoch: 85:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.49it/s, loss=26.5]train epoch: 85:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.49it/s, loss=29.9]train epoch: 85:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.92it/s, loss=29.9]train epoch: 85:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.92it/s, loss=31.6]train epoch: 85:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=31.6]train epoch: 85:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=26]  train epoch: 85:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=26]train epoch: 85:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=30]train epoch: 85:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.24it/s, loss=30]train epoch: 85:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.24it/s, loss=27]train epoch: 85:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.31it/s, loss=27]train epoch: 85:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.31it/s, loss=31.3]train epoch: 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.63it/s, loss=31.3]train epoch: 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=31.3]
[[032m2021-11-26 10:29:56,196[0m INFO] trainer.training_epoch Training epoch 85, num_steps 688,  avg_loss: 28.2912, total_loss: 226.3298
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.08it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.23it/s]
[[032m2021-11-26 10:29:56,604[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:29:56,604[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:56,821[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 86:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 86:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.3]train epoch: 86:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=26.3]train epoch: 86:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=25.7]train epoch: 86:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=25.7]train epoch: 86:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=27.4]train epoch: 86:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s, loss=27.4]train epoch: 86:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.20it/s, loss=22.2]train epoch: 86:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.84it/s, loss=22.2]train epoch: 86:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.84it/s, loss=25.3]train epoch: 86:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.77it/s, loss=25.3]train epoch: 86:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.77it/s, loss=27.9]train epoch: 86:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.93it/s, loss=27.9]train epoch: 86:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.93it/s, loss=29.9]train epoch: 86:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=29.9]train epoch: 86:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=26.6]train epoch: 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=26.6]train epoch: 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=26.6]
[[032m2021-11-26 10:29:59,289[0m INFO] trainer.training_epoch Training epoch 86, num_steps 696,  avg_loss: 26.3959, total_loss: 211.1670
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.77it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.71it/s]
[[032m2021-11-26 10:29:59,716[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:29:59,716[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:29:59,930[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 87:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 87:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.2]train epoch: 87:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=22.2]train epoch: 87:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=35.5]train epoch: 87:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.12it/s, loss=35.5]train epoch: 87:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.12it/s, loss=25.1]train epoch: 87:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.82it/s, loss=25.1]train epoch: 87:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.82it/s, loss=29.6]train epoch: 87:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=29.6]
model tensor([[0.3953, 0.6047],
        [0.5650, 0.4350],
        [0.3744, 0.6256],
        [0.4404, 0.5596],
        [0.5445, 0.4555],
        [0.7342, 0.2658],
        [0.3141, 0.6859],
        [0.4469, 0.5531]], device='cuda:0')

prompt tensor([[0.4508, 0.5492],
        [0.7582, 0.2418],
        [0.7773, 0.2227],
        [0.7816, 0.2184],
        [0.7346, 0.2654],
        [0.7129, 0.2871],
        [0.6983, 0.3017],
        [0.7355, 0.2645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 87:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=29]  train epoch: 87:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.55it/s, loss=29]train epoch: 87:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=23.3]train epoch: 87:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=23.3]train epoch: 87:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=41.4]train epoch: 87:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=41.4]train epoch: 87:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=29.4]train epoch: 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=29.4]train epoch: 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=29.4]
[[032m2021-11-26 10:30:02,448[0m INFO] trainer.training_epoch Training epoch 87, num_steps 704,  avg_loss: 29.4459, total_loss: 235.5669
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.48it/s]
[[032m2021-11-26 10:30:02,845[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:30:02,845[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:03,072[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 88:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 88:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.1]train epoch: 88:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=33.1]train epoch: 88:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=28.5]train epoch: 88:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.61it/s, loss=28.5]train epoch: 88:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.61it/s, loss=31]  train epoch: 88:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.75it/s, loss=31]train epoch: 88:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.75it/s, loss=30.5]train epoch: 88:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.94it/s, loss=30.5]train epoch: 88:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.94it/s, loss=27.9]train epoch: 88:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=27.9]train epoch: 88:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=27.5]train epoch: 88:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.69it/s, loss=27.5]train epoch: 88:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.69it/s, loss=27.2]train epoch: 88:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=27.2]train epoch: 88:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.95it/s, loss=37.8]train epoch: 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.74it/s, loss=37.8]train epoch: 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.58it/s, loss=37.8]
[[032m2021-11-26 10:30:05,315[0m INFO] trainer.training_epoch Training epoch 88, num_steps 712,  avg_loss: 30.4398, total_loss: 243.5181
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.95it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.74it/s]
[[032m2021-11-26 10:30:05,702[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:30:05,703[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:05,920[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 89:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 89:   0%|          | 0/8 [00:00<?, ?it/s, loss=30]train epoch: 89:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=30]train epoch: 89:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=28.5]train epoch: 89:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=28.5]train epoch: 89:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=29]  train epoch: 89:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.31it/s, loss=29]train epoch: 89:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.31it/s, loss=23.4]train epoch: 89:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=23.4]train epoch: 89:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=25.5]train epoch: 89:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=25.5]train epoch: 89:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=31.8]train epoch: 89:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.88it/s, loss=31.8]train epoch: 89:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=18.8]train epoch: 89:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.17it/s, loss=18.8]train epoch: 89:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.17it/s, loss=29.3]train epoch: 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=29.3]train epoch: 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=29.3]
[[032m2021-11-26 10:30:08,282[0m INFO] trainer.training_epoch Training epoch 89, num_steps 720,  avg_loss: 27.0471, total_loss: 216.3770
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.61it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.26it/s]
[[032m2021-11-26 10:30:08,653[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:30:08,653[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:08,881[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 90:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 90:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.7]train epoch: 90:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.01it/s, loss=19.7]train epoch: 90:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.01it/s, loss=32.4]train epoch: 90:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.44it/s, loss=32.4]train epoch: 90:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.44it/s, loss=29.6]train epoch: 90:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.72it/s, loss=29.6]train epoch: 90:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.72it/s, loss=31.1]train epoch: 90:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.58it/s, loss=31.1]train epoch: 90:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.58it/s, loss=26.2]train epoch: 90:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.44it/s, loss=26.2]train epoch: 90:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.44it/s, loss=36.7]train epoch: 90:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.24it/s, loss=36.7]train epoch: 90:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.24it/s, loss=22.6]train epoch: 90:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=22.6]train epoch: 90:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=19.4]train epoch: 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=19.4]train epoch: 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.48it/s, loss=19.4]
[[032m2021-11-26 10:30:11,185[0m INFO] trainer.training_epoch Training epoch 90, num_steps 728,  avg_loss: 27.2064, total_loss: 217.6514
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.09it/s]
[[032m2021-11-26 10:30:11,568[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:30:11,569[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:11,792[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 91:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 91:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 91:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.06it/s, loss=30.2]train epoch: 91:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.06it/s, loss=25.1]train epoch: 91:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.90it/s, loss=25.1]train epoch: 91:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.90it/s, loss=21.4]train epoch: 91:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s, loss=21.4]train epoch: 91:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.13it/s, loss=22.2]train epoch: 91:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.25it/s, loss=22.2]train epoch: 91:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.25it/s, loss=36.4]train epoch: 91:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s, loss=36.4]train epoch: 91:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s, loss=23.7]train epoch: 91:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.90it/s, loss=23.7]train epoch: 91:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.90it/s, loss=28.8]train epoch: 91:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=28.8]train epoch: 91:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=29.5]train epoch: 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=29.5]train epoch: 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.44it/s, loss=29.5]
[[032m2021-11-26 10:30:14,126[0m INFO] trainer.training_epoch Training epoch 91, num_steps 736,  avg_loss: 27.1599, total_loss: 217.2789
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.52it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.05it/s]
[[032m2021-11-26 10:30:14,539[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:30:14,539[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:14,762[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 92:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 92:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.5]train epoch: 92:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=36.5]train epoch: 92:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=29.8]train epoch: 92:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=29.8]train epoch: 92:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=26.4]train epoch: 92:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.40it/s, loss=26.4]train epoch: 92:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.40it/s, loss=31.4]train epoch: 92:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.78it/s, loss=31.4]train epoch: 92:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s, loss=27.6]train epoch: 92:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=27.6]train epoch: 92:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=30.1]train epoch: 92:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.11it/s, loss=30.1]train epoch: 92:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.11it/s, loss=33.5]train epoch: 92:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=33.5]train epoch: 92:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=26.8]train epoch: 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=26.8]train epoch: 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=26.8]
[[032m2021-11-26 10:30:17,058[0m INFO] trainer.training_epoch Training epoch 92, num_steps 744,  avg_loss: 30.2795, total_loss: 242.2363
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.90it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.83it/s]
[[032m2021-11-26 10:30:17,446[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:30:17,447[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:17,657[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 93:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 93:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.2]train epoch: 93:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=29.2]train epoch: 93:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=22.9]train epoch: 93:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.72it/s, loss=22.9]train epoch: 93:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.72it/s, loss=30.3]train epoch: 93:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s, loss=30.3]train epoch: 93:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s, loss=32.5]train epoch: 93:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.81it/s, loss=32.5]train epoch: 93:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=25.6]train epoch: 93:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=25.6]train epoch: 93:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=30.7]train epoch: 93:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.80it/s, loss=30.7]train epoch: 93:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=35.3]train epoch: 93:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=35.3]train epoch: 93:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=31.6]train epoch: 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=31.6]train epoch: 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=31.6]
[[032m2021-11-26 10:30:20,055[0m INFO] trainer.training_epoch Training epoch 93, num_steps 752,  avg_loss: 29.7452, total_loss: 237.9616
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.35it/s]
[[032m2021-11-26 10:30:20,424[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:30:20,425[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:20,648[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 94:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 94:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.9]train epoch: 94:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=30.9]train epoch: 94:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=24.2]train epoch: 94:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=24.2]train epoch: 94:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=36.5]train epoch: 94:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=36.5]train epoch: 94:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=25.9]train epoch: 94:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.21it/s, loss=25.9]train epoch: 94:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.21it/s, loss=22.7]train epoch: 94:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=22.7]train epoch: 94:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=29.5]train epoch: 94:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.09it/s, loss=29.5]train epoch: 94:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.09it/s, loss=25.8]train epoch: 94:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.63it/s, loss=25.8]train epoch: 94:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.63it/s, loss=24.6]train epoch: 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=24.6]train epoch: 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=24.6]
[[032m2021-11-26 10:30:22,735[0m INFO] trainer.training_epoch Training epoch 94, num_steps 760,  avg_loss: 27.5019, total_loss: 220.0154
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.64it/s]
[[032m2021-11-26 10:30:23,129[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.453125)])
[[032m2021-11-26 10:30:23,129[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:23,361[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 95:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 95:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.5]train epoch: 95:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.37it/s, loss=30.5]train epoch: 95:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.37it/s, loss=29.4]train epoch: 95:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=29.4]train epoch: 95:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=18.7]train epoch: 95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.22it/s, loss=18.7]train epoch: 95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.22it/s, loss=25.5]train epoch: 95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.30it/s, loss=25.5]train epoch: 95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.30it/s, loss=26]  train epoch: 95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=26]train epoch: 95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=23.9]train epoch: 95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=23.9]train epoch: 95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.14it/s, loss=29.9]train epoch: 95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.97it/s, loss=29.9]train epoch: 95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.97it/s, loss=20.1]train epoch: 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.57it/s, loss=20.1]train epoch: 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=20.1]
[[032m2021-11-26 10:30:25,911[0m INFO] trainer.training_epoch Training epoch 95, num_steps 768,  avg_loss: 25.5170, total_loss: 204.1362
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.24it/s]
[[032m2021-11-26 10:30:26,362[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:30:26,363[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:26,585[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 96:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 96:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.2]train epoch: 96:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=26.2]train epoch: 96:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=28.5]train epoch: 96:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.75it/s, loss=28.5]train epoch: 96:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.75it/s, loss=28.3]train epoch: 96:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=28.3]train epoch: 96:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=21.4]train epoch: 96:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.94it/s, loss=21.4]train epoch: 96:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s, loss=22.2]train epoch: 96:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.21it/s, loss=22.2]train epoch: 96:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.21it/s, loss=25.3]train epoch: 96:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.08it/s, loss=25.3]train epoch: 96:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.08it/s, loss=21.9]train epoch: 96:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.24it/s, loss=21.9]train epoch: 96:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s, loss=24.2]train epoch: 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=24.2]train epoch: 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.54it/s, loss=24.2]
[[032m2021-11-26 10:30:28,851[0m INFO] trainer.training_epoch Training epoch 96, num_steps 776,  avg_loss: 24.7519, total_loss: 198.0150
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.49it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.68it/s]
[[032m2021-11-26 10:30:29,240[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:30:29,240[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:29,454[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 97:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 97:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.4]train epoch: 97:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.91it/s, loss=26.4]train epoch: 97:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.91it/s, loss=26.5]train epoch: 97:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.80it/s, loss=26.5]train epoch: 97:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.80it/s, loss=30.6]train epoch: 97:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.62it/s, loss=30.6]train epoch: 97:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.62it/s, loss=27.2]train epoch: 97:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=27.2]train epoch: 97:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=30.7]train epoch: 97:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=30.7]train epoch: 97:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=27.7]train epoch: 97:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.01it/s, loss=27.7]train epoch: 97:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.01it/s, loss=30.9]train epoch: 97:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.29it/s, loss=30.9]train epoch: 97:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.29it/s, loss=33.5]train epoch: 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.69it/s, loss=33.5]train epoch: 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=33.5]
[[032m2021-11-26 10:30:31,867[0m INFO] trainer.training_epoch Training epoch 97, num_steps 784,  avg_loss: 29.2087, total_loss: 233.6697
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.69it/s]
[[032m2021-11-26 10:30:32,260[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:30:32,261[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:32,477[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 98:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 98:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.9]train epoch: 98:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.37it/s, loss=19.9]train epoch: 98:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.37it/s, loss=41.8]train epoch: 98:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=41.8]train epoch: 98:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=34.5]train epoch: 98:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.54it/s, loss=34.5]train epoch: 98:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.54it/s, loss=31]  train epoch: 98:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.09it/s, loss=31]train epoch: 98:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.09it/s, loss=29.8]train epoch: 98:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=29.8]train epoch: 98:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=30.2]train epoch: 98:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.88it/s, loss=30.2]train epoch: 98:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.88it/s, loss=29.6]train epoch: 98:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.91it/s, loss=29.6]train epoch: 98:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.91it/s, loss=27.5]train epoch: 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.83it/s, loss=27.5]train epoch: 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=27.5]
[[032m2021-11-26 10:30:34,490[0m INFO] trainer.training_epoch Training epoch 98, num_steps 792,  avg_loss: 30.5297, total_loss: 244.2379
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.03it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.06it/s]
[[032m2021-11-26 10:30:34,904[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:30:34,905[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:35,130[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 99:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 99:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 99:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=29.3]train epoch: 99:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=26]  train epoch: 99:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.40it/s, loss=26]train epoch: 99:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.40it/s, loss=23.3]train epoch: 99:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.14it/s, loss=23.3]train epoch: 99:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.14it/s, loss=23.8]train epoch: 99:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.46it/s, loss=23.8]train epoch: 99:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.46it/s, loss=36.9]train epoch: 99:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=36.9]train epoch: 99:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=33.2]train epoch: 99:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.54it/s, loss=33.2]train epoch: 99:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.54it/s, loss=26.8]train epoch: 99:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.55it/s, loss=26.8]train epoch: 99:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.55it/s, loss=31.9]train epoch: 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.61it/s, loss=31.9]train epoch: 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.72it/s, loss=31.9]
[[032m2021-11-26 10:30:37,287[0m INFO] trainer.training_epoch Training epoch 99, num_steps 800,  avg_loss: 28.8875, total_loss: 231.1000
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.87it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.55it/s]
[[032m2021-11-26 10:30:37,682[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:30:37,683[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:37,903[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 100:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.4335, 0.5665],
        [0.5951, 0.4049],
        [0.3806, 0.6194],
        [0.4593, 0.5407],
        [0.3690, 0.6310],
        [0.5951, 0.4049],
        [0.6054, 0.3946],
        [0.5258, 0.4742]], device='cuda:0')

prompt tensor([[0.6495, 0.3505],
        [0.5180, 0.4820],
        [0.5581, 0.4419],
        [0.4340, 0.5660],
        [0.5899, 0.4101],
        [0.6390, 0.3610],
        [0.7517, 0.2483],
        [0.4903, 0.5097]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 100:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.1]train epoch: 100:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.92it/s, loss=31.1]train epoch: 100:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.92it/s, loss=30]  train epoch: 100:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.81it/s, loss=30]train epoch: 100:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.81it/s, loss=27.6]train epoch: 100:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s, loss=27.6]train epoch: 100:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s, loss=30.2]train epoch: 100:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.08it/s, loss=30.2]train epoch: 100:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.08it/s, loss=23.2]train epoch: 100:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=23.2]train epoch: 100:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=21.5]train epoch: 100:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.28it/s, loss=21.5]train epoch: 100:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.28it/s, loss=26]  train epoch: 100:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.28it/s, loss=26]train epoch: 100:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.28it/s, loss=28.5]train epoch: 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.31it/s, loss=28.5]train epoch: 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.33it/s, loss=28.5]
[[032m2021-11-26 10:30:39,757[0m INFO] trainer.training_epoch Training epoch 100, num_steps 808,  avg_loss: 27.2636, total_loss: 218.1088
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.95it/s]
[[032m2021-11-26 10:30:40,174[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:30:40,174[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:40,388[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 101:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 101:   0%|          | 0/8 [00:00<?, ?it/s, loss=30]train epoch: 101:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=30]train epoch: 101:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=25.4]train epoch: 101:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.58it/s, loss=25.4]train epoch: 101:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.58it/s, loss=25]  train epoch: 101:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s, loss=25]train epoch: 101:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s, loss=25.9]train epoch: 101:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.24it/s, loss=25.9]train epoch: 101:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.24it/s, loss=33.9]train epoch: 101:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.08it/s, loss=33.9]train epoch: 101:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.08it/s, loss=28]  train epoch: 101:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.82it/s, loss=28]train epoch: 101:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.82it/s, loss=29.7]train epoch: 101:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.16it/s, loss=29.7]train epoch: 101:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.16it/s, loss=34.8]train epoch: 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=34.8]train epoch: 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.77it/s, loss=34.8]
[[032m2021-11-26 10:30:42,517[0m INFO] trainer.training_epoch Training epoch 101, num_steps 816,  avg_loss: 29.0896, total_loss: 232.7171
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.16it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.39it/s]
[[032m2021-11-26 10:30:42,930[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:30:42,930[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:43,144[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 102:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 102:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.4]train epoch: 102:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=33.4]train epoch: 102:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.97it/s, loss=25]  train epoch: 102:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=25]train epoch: 102:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=30.2]train epoch: 102:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.53it/s, loss=30.2]train epoch: 102:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.53it/s, loss=23.4]train epoch: 102:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.03it/s, loss=23.4]train epoch: 102:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.03it/s, loss=27.8]train epoch: 102:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=27.8]train epoch: 102:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=29.3]train epoch: 102:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=29.3]train epoch: 102:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.14it/s, loss=32]  train epoch: 102:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=32]train epoch: 102:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=21.4]train epoch: 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.38it/s, loss=21.4]train epoch: 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.56it/s, loss=21.4]
[[032m2021-11-26 10:30:45,400[0m INFO] trainer.training_epoch Training epoch 102, num_steps 824,  avg_loss: 27.8021, total_loss: 222.4168
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.54it/s]
[[032m2021-11-26 10:30:45,798[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:30:45,799[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:46,014[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 103:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 103:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.8]train epoch: 103:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.16it/s, loss=24.8]train epoch: 103:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.16it/s, loss=31.9]train epoch: 103:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.69it/s, loss=31.9]train epoch: 103:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.69it/s, loss=33.1]train epoch: 103:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.02it/s, loss=33.1]train epoch: 103:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.02it/s, loss=31.1]train epoch: 103:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.58it/s, loss=31.1]train epoch: 103:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.58it/s, loss=27.5]train epoch: 103:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=27.5]train epoch: 103:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=31.2]train epoch: 103:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s, loss=31.2]train epoch: 103:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s, loss=25.9]train epoch: 103:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.31it/s, loss=25.9]train epoch: 103:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.31it/s, loss=33.2]train epoch: 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.51it/s, loss=33.2]train epoch: 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=33.2]
[[032m2021-11-26 10:30:48,232[0m INFO] trainer.training_epoch Training epoch 103, num_steps 832,  avg_loss: 29.8263, total_loss: 238.6101
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.45it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.68it/s]
[[032m2021-11-26 10:30:48,621[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:30:48,622[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:48,837[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:30:48,935[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 104:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 104:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.6]train epoch: 104:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=26.6]train epoch: 104:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=30.9]train epoch: 104:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=30.9]train epoch: 104:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=34.4]train epoch: 104:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.41it/s, loss=34.4]train epoch: 104:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.41it/s, loss=24.1]train epoch: 104:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=24.1]train epoch: 104:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=21.5]train epoch: 104:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.63it/s, loss=21.5]train epoch: 104:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.63it/s, loss=30.4]train epoch: 104:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.07it/s, loss=30.4]train epoch: 104:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.07it/s, loss=29.7]train epoch: 104:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.95it/s, loss=29.7]train epoch: 104:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.95it/s, loss=38.1]train epoch: 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=38.1]train epoch: 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=38.1]
[[032m2021-11-26 10:30:51,374[0m INFO] trainer.training_epoch Training epoch 104, num_steps 840,  avg_loss: 29.4609, total_loss: 235.6870
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.74it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.96it/s]
[[032m2021-11-26 10:30:51,792[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:30:51,792[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:52,013[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 105:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 105:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.4]train epoch: 105:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.21it/s, loss=31.4]train epoch: 105:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.21it/s, loss=31.4]train epoch: 105:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.72it/s, loss=31.4]train epoch: 105:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.72it/s, loss=26.6]train epoch: 105:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.88it/s, loss=26.6]train epoch: 105:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.88it/s, loss=31.3]train epoch: 105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=31.3]train epoch: 105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=31.2]train epoch: 105:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=31.2]train epoch: 105:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=32]  train epoch: 105:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.97it/s, loss=32]train epoch: 105:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.97it/s, loss=36.9]train epoch: 105:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s, loss=36.9]train epoch: 105:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s, loss=26.2]train epoch: 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s, loss=26.2]train epoch: 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=26.2]
[[032m2021-11-26 10:30:54,456[0m INFO] trainer.training_epoch Training epoch 105, num_steps 848,  avg_loss: 30.8586, total_loss: 246.8689
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.80it/s]
[[032m2021-11-26 10:30:54,842[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:30:54,842[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:55,063[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 106:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 106:   0%|          | 0/8 [00:00<?, ?it/s, loss=29]train epoch: 106:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=29]train epoch: 106:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=38]train epoch: 106:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.45it/s, loss=38]train epoch: 106:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.45it/s, loss=36.2]train epoch: 106:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.68it/s, loss=36.2]train epoch: 106:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.68it/s, loss=23.2]train epoch: 106:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=23.2]train epoch: 106:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=25.6]train epoch: 106:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=25.6]train epoch: 106:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.66it/s, loss=25.1]train epoch: 106:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=25.1]train epoch: 106:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=31.9]train epoch: 106:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=31.9]train epoch: 106:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=30.3]train epoch: 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s, loss=30.3]train epoch: 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=30.3]
[[032m2021-11-26 10:30:57,635[0m INFO] trainer.training_epoch Training epoch 106, num_steps 856,  avg_loss: 29.9046, total_loss: 239.2366
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.78it/s]
[[032m2021-11-26 10:30:58,021[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:30:58,021[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:30:58,238[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 107:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 107:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 107:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.11it/s, loss=24.9]train epoch: 107:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.11it/s, loss=25.2]train epoch: 107:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=25.2]train epoch: 107:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=22.9]train epoch: 107:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.87it/s, loss=22.9]train epoch: 107:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.87it/s, loss=26.2]train epoch: 107:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.43it/s, loss=26.2]train epoch: 107:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.43it/s, loss=29.6]train epoch: 107:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=29.6]train epoch: 107:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=32.3]train epoch: 107:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.22it/s, loss=32.3]train epoch: 107:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=26.4]train epoch: 107:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.95it/s, loss=26.4]train epoch: 107:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.95it/s, loss=26.4]train epoch: 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s, loss=26.4]train epoch: 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=26.4]
[[032m2021-11-26 10:31:00,659[0m INFO] trainer.training_epoch Training epoch 107, num_steps 864,  avg_loss: 26.7241, total_loss: 213.7929
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.09it/s]
[[032m2021-11-26 10:31:01,114[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:01,114[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:01,335[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 108:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 108:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.2]train epoch: 108:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=27.2]train epoch: 108:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=31.4]train epoch: 108:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.67it/s, loss=31.4]train epoch: 108:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.67it/s, loss=29.1]train epoch: 108:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=29.1]train epoch: 108:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=27.3]train epoch: 108:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.77it/s, loss=27.3]train epoch: 108:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=31.6]train epoch: 108:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.87it/s, loss=31.6]train epoch: 108:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.87it/s, loss=27.7]train epoch: 108:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.57it/s, loss=27.7]train epoch: 108:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.57it/s, loss=30.4]train epoch: 108:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=30.4]train epoch: 108:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=30.2]train epoch: 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s, loss=30.2]train epoch: 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.30it/s, loss=30.2]
[[032m2021-11-26 10:31:03,769[0m INFO] trainer.training_epoch Training epoch 108, num_steps 872,  avg_loss: 29.3737, total_loss: 234.9896
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.09it/s]
[[032m2021-11-26 10:31:04,235[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:31:04,235[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:04,458[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 109:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 109:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.7]train epoch: 109:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=30.7]train epoch: 109:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=25.9]train epoch: 109:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=25.9]train epoch: 109:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=23.8]train epoch: 109:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.70it/s, loss=23.8]train epoch: 109:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.70it/s, loss=33]  train epoch: 109:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.18it/s, loss=33]train epoch: 109:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.18it/s, loss=21.4]train epoch: 109:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.99it/s, loss=21.4]train epoch: 109:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.99it/s, loss=27.4]train epoch: 109:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.64it/s, loss=27.4]train epoch: 109:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.64it/s, loss=38]  train epoch: 109:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.64it/s, loss=38]train epoch: 109:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.64it/s, loss=26.6]train epoch: 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s, loss=26.6]train epoch: 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=26.6]
[[032m2021-11-26 10:31:06,956[0m INFO] trainer.training_epoch Training epoch 109, num_steps 880,  avg_loss: 28.3449, total_loss: 226.7591
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.47it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.04it/s]
[[032m2021-11-26 10:31:07,337[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:31:07,337[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:07,550[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 110:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 110:   0%|          | 0/8 [00:00<?, ?it/s, loss=41.1]train epoch: 110:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.21it/s, loss=41.1]train epoch: 110:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.21it/s, loss=28.7]train epoch: 110:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=28.7]train epoch: 110:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=31.3]train epoch: 110:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=31.3]train epoch: 110:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=20.6]train epoch: 110:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.38it/s, loss=20.6]train epoch: 110:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.38it/s, loss=29.9]train epoch: 110:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=29.9]train epoch: 110:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=30.9]train epoch: 110:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.36it/s, loss=30.9]train epoch: 110:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.36it/s, loss=29]  train epoch: 110:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.92it/s, loss=29]train epoch: 110:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.92it/s, loss=27]train epoch: 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=27]train epoch: 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s, loss=27]
[[032m2021-11-26 10:31:09,651[0m INFO] trainer.training_epoch Training epoch 110, num_steps 888,  avg_loss: 29.8231, total_loss: 238.5846
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.76it/s]
[[032m2021-11-26 10:31:10,199[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:10,199[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:10,578[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 111:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 111:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.1]train epoch: 111:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.05it/s, loss=29.1]train epoch: 111:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.05it/s, loss=23.6]train epoch: 111:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=23.6]train epoch: 111:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=27.6]train epoch: 111:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.23it/s, loss=27.6]train epoch: 111:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.23it/s, loss=29.3]train epoch: 111:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.28it/s, loss=29.3]train epoch: 111:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.28it/s, loss=28.4]train epoch: 111:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.24it/s, loss=28.4]train epoch: 111:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.24it/s, loss=27]  train epoch: 111:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=27]train epoch: 111:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=25.3]train epoch: 111:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.06it/s, loss=25.3]train epoch: 111:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.06it/s, loss=33.4]train epoch: 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=33.4]train epoch: 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.88it/s, loss=33.4]
[[032m2021-11-26 10:31:12,648[0m INFO] trainer.training_epoch Training epoch 111, num_steps 896,  avg_loss: 27.9632, total_loss: 223.7059
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.78it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.03it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.21it/s]
[[032m2021-11-26 10:31:13,324[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:13,325[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:13,636[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 112:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 112:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.7]train epoch: 112:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.23it/s, loss=26.7]train epoch: 112:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.23it/s, loss=30.6]train epoch: 112:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=30.6]train epoch: 112:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=36.2]train epoch: 112:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=36.2]train epoch: 112:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=29.1]train epoch: 112:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.70it/s, loss=29.1]
model tensor([[0.2534, 0.7466],
        [0.3053, 0.6947],
        [0.3498, 0.6502],
        [0.5650, 0.4350],
        [0.5439, 0.4561],
        [0.3295, 0.6705],
        [0.3841, 0.6159],
        [0.3806, 0.6194]], device='cuda:0')

prompt tensor([[0.6007, 0.3993],
        [0.4505, 0.5495],
        [0.6272, 0.3728],
        [0.7105, 0.2895],
        [0.7429, 0.2571],
        [0.5681, 0.4319],
        [0.8517, 0.1483],
        [0.7063, 0.2937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 112:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.70it/s, loss=28.5]train epoch: 112:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.69it/s, loss=28.5]train epoch: 112:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.69it/s, loss=30.5]train epoch: 112:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.51it/s, loss=30.5]train epoch: 112:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.51it/s, loss=30.5]train epoch: 112:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=30.5]train epoch: 112:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=33.8]train epoch: 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.86it/s, loss=33.8]train epoch: 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.20it/s, loss=33.8]
[[032m2021-11-26 10:31:15,549[0m INFO] trainer.training_epoch Training epoch 112, num_steps 904,  avg_loss: 30.7346, total_loss: 245.8768
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.02it/s]
[[032m2021-11-26 10:31:16,180[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:16,180[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:16,585[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 113:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 113:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.9]train epoch: 113:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=26.9]train epoch: 113:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=29.5]train epoch: 113:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.78it/s, loss=29.5]train epoch: 113:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.78it/s, loss=22.6]train epoch: 113:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.09it/s, loss=22.6]train epoch: 113:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.09it/s, loss=27.9]train epoch: 113:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.25it/s, loss=27.9]train epoch: 113:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.25it/s, loss=34.6]train epoch: 113:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=34.6]train epoch: 113:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=26.7]train epoch: 113:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.06it/s, loss=26.7]train epoch: 113:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.06it/s, loss=24.4]train epoch: 113:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.03it/s, loss=24.4]train epoch: 113:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.03it/s, loss=40.5]train epoch: 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.14it/s, loss=40.5]train epoch: 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.06it/s, loss=40.5]
[[032m2021-11-26 10:31:18,560[0m INFO] trainer.training_epoch Training epoch 113, num_steps 912,  avg_loss: 29.1498, total_loss: 233.1982
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.43it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.95it/s]
[[032m2021-11-26 10:31:19,095[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:19,096[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:19,674[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 114:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 114:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.3]train epoch: 114:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.16it/s, loss=23.3]train epoch: 114:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.16it/s, loss=26.9]train epoch: 114:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=26.9]train epoch: 114:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=31.3]train epoch: 114:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.32it/s, loss=31.3]train epoch: 114:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.32it/s, loss=27]  train epoch: 114:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.30it/s, loss=27]train epoch: 114:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.30it/s, loss=38.3]train epoch: 114:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.13it/s, loss=38.3]train epoch: 114:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.13it/s, loss=34.5]train epoch: 114:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=34.5]train epoch: 114:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=28.9]train epoch: 114:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.44it/s, loss=28.9]train epoch: 114:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.44it/s, loss=22.5]train epoch: 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=22.5]train epoch: 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.17it/s, loss=22.5]
[[032m2021-11-26 10:31:21,596[0m INFO] trainer.training_epoch Training epoch 114, num_steps 920,  avg_loss: 29.0996, total_loss: 232.7969
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.45it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.18it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.47it/s]
[[032m2021-11-26 10:31:22,244[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:22,245[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:22,582[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 115:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 115:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.7]train epoch: 115:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.27it/s, loss=19.7]train epoch: 115:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.27it/s, loss=20.6]train epoch: 115:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=20.6]train epoch: 115:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=31.6]train epoch: 115:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=31.6]train epoch: 115:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=22.6]train epoch: 115:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.34it/s, loss=22.6]train epoch: 115:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.34it/s, loss=32.3]train epoch: 115:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=32.3]train epoch: 115:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=29.2]train epoch: 115:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=29.2]train epoch: 115:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=25.9]train epoch: 115:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.32it/s, loss=25.9]train epoch: 115:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.32it/s, loss=32.2]train epoch: 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.05it/s, loss=32.2]train epoch: 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.67it/s, loss=32.2]
[[032m2021-11-26 10:31:24,768[0m INFO] trainer.training_epoch Training epoch 115, num_steps 928,  avg_loss: 26.7619, total_loss: 214.0950
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.64it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.18it/s]
[[032m2021-11-26 10:31:25,289[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:31:25,289[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:25,871[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 116:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 116:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.6]train epoch: 116:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=26.6]train epoch: 116:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.58it/s, loss=34.5]train epoch: 116:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=34.5]train epoch: 116:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=24.8]train epoch: 116:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=24.8]train epoch: 116:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=31]  train epoch: 116:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.53it/s, loss=31]train epoch: 116:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.53it/s, loss=25]train epoch: 116:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=25]train epoch: 116:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=23.8]train epoch: 116:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.43it/s, loss=23.8]train epoch: 116:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.43it/s, loss=24.7]train epoch: 116:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=24.7]train epoch: 116:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=30.9]train epoch: 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.19it/s, loss=30.9]train epoch: 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.29it/s, loss=30.9]
[[032m2021-11-26 10:31:27,741[0m INFO] trainer.training_epoch Training epoch 116, num_steps 936,  avg_loss: 27.6705, total_loss: 221.3639
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.57it/s]
[[032m2021-11-26 10:31:28,229[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:31:28,229[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:28,479[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 117:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 117:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 117:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=27.3]train epoch: 117:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=35.8]train epoch: 117:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=35.8]train epoch: 117:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=28.9]train epoch: 117:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.45it/s, loss=28.9]train epoch: 117:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.45it/s, loss=15.9]train epoch: 117:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.58it/s, loss=15.9]train epoch: 117:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.58it/s, loss=32.1]train epoch: 117:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=32.1]train epoch: 117:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=35.3]train epoch: 117:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=35.3]train epoch: 117:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=26.2]train epoch: 117:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=26.2]train epoch: 117:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=28.6]train epoch: 117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.63it/s, loss=28.6]train epoch: 117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.03it/s, loss=28.6]
[[032m2021-11-26 10:31:30,471[0m INFO] trainer.training_epoch Training epoch 117, num_steps 944,  avg_loss: 28.7590, total_loss: 230.0720
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.97it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.95it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.77it/s]
[[032m2021-11-26 10:31:31,205[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:31:31,206[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:31,549[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 118:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 118:   0%|          | 0/8 [00:00<?, ?it/s, loss=17.9]train epoch: 118:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.27it/s, loss=17.9]train epoch: 118:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.27it/s, loss=21.9]train epoch: 118:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=21.9]train epoch: 118:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=38.6]train epoch: 118:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=38.6]train epoch: 118:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=21.6]train epoch: 118:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.36it/s, loss=21.6]train epoch: 118:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.36it/s, loss=25.6]train epoch: 118:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=25.6]train epoch: 118:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=32.7]train epoch: 118:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.08it/s, loss=32.7]train epoch: 118:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.08it/s, loss=41.8]train epoch: 118:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=41.8]train epoch: 118:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=24.8]train epoch: 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.97it/s, loss=24.8]train epoch: 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.15it/s, loss=24.8]
[[032m2021-11-26 10:31:33,483[0m INFO] trainer.training_epoch Training epoch 118, num_steps 952,  avg_loss: 28.0896, total_loss: 224.7170
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.87it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.17it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.61it/s]
[[032m2021-11-26 10:31:34,120[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:31:34,120[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:34,385[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 119:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 119:   0%|          | 0/8 [00:00<?, ?it/s, loss=22]train epoch: 119:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.83it/s, loss=22]train epoch: 119:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.83it/s, loss=31.6]train epoch: 119:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.86it/s, loss=31.6]train epoch: 119:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.86it/s, loss=25.4]train epoch: 119:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.93it/s, loss=25.4]train epoch: 119:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.93it/s, loss=27.7]train epoch: 119:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=27.7]train epoch: 119:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=27.4]train epoch: 119:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=27.4]train epoch: 119:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=23.5]train epoch: 119:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=23.5]train epoch: 119:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=28.1]train epoch: 119:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.21it/s, loss=28.1]train epoch: 119:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.21it/s, loss=35.4]train epoch: 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.13it/s, loss=35.4]train epoch: 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.05it/s, loss=35.4]
[[032m2021-11-26 10:31:36,368[0m INFO] trainer.training_epoch Training epoch 119, num_steps 960,  avg_loss: 27.6403, total_loss: 221.1224
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.64it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.02it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.19it/s]
[[032m2021-11-26 10:31:36,952[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:31:36,952[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:37,732[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 120:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 120:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 120:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=25.5]train epoch: 120:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=24]  train epoch: 120:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=24]train epoch: 120:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=26.7]train epoch: 120:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.31it/s, loss=26.7]train epoch: 120:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.31it/s, loss=29.7]train epoch: 120:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.44it/s, loss=29.7]train epoch: 120:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.44it/s, loss=31.2]train epoch: 120:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=31.2]train epoch: 120:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=29.4]train epoch: 120:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=29.4]train epoch: 120:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=27.5]train epoch: 120:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.25it/s, loss=27.5]train epoch: 120:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.25it/s, loss=27.7]train epoch: 120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.36it/s, loss=27.7]train epoch: 120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.33it/s, loss=27.7]
[[032m2021-11-26 10:31:39,608[0m INFO] trainer.training_epoch Training epoch 120, num_steps 968,  avg_loss: 27.7377, total_loss: 221.9019
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.53it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.91it/s]
[[032m2021-11-26 10:31:40,137[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:31:40,137[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:40,671[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 121:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 121:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.8]train epoch: 121:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=31.8]train epoch: 121:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=26.1]train epoch: 121:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=26.1]train epoch: 121:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=29.6]train epoch: 121:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.19it/s, loss=29.6]train epoch: 121:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.19it/s, loss=30.6]train epoch: 121:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.20it/s, loss=30.6]train epoch: 121:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.20it/s, loss=23.2]train epoch: 121:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s, loss=23.2]train epoch: 121:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s, loss=22.5]train epoch: 121:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.79it/s, loss=22.5]train epoch: 121:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.79it/s, loss=31.3]train epoch: 121:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.69it/s, loss=31.3]train epoch: 121:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=31.6]train epoch: 121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=31.6]train epoch: 121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.91it/s, loss=31.6]
[[032m2021-11-26 10:31:42,722[0m INFO] trainer.training_epoch Training epoch 121, num_steps 976,  avg_loss: 28.3406, total_loss: 226.7251
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.81it/s]
[[032m2021-11-26 10:31:43,145[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:43,145[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:43,405[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 122:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 122:   0%|          | 0/8 [00:00<?, ?it/s, loss=28]train epoch: 122:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.75it/s, loss=28]train epoch: 122:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.75it/s, loss=28.4]train epoch: 122:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.09it/s, loss=28.4]train epoch: 122:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.09it/s, loss=31.4]train epoch: 122:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.82it/s, loss=31.4]train epoch: 122:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.82it/s, loss=31.4]train epoch: 122:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s, loss=31.4]train epoch: 122:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s, loss=30.4]train epoch: 122:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=30.4]train epoch: 122:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=25.2]train epoch: 122:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=25.2]train epoch: 122:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=22.2]train epoch: 122:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=22.2]train epoch: 122:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=28.3]train epoch: 122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.18it/s, loss=28.3]train epoch: 122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.11it/s, loss=28.3]
[[032m2021-11-26 10:31:45,359[0m INFO] trainer.training_epoch Training epoch 122, num_steps 984,  avg_loss: 28.1666, total_loss: 225.3328
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.21it/s]
[[032m2021-11-26 10:31:45,752[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:31:45,753[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:46,226[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 123:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 123:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.7]train epoch: 123:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.23it/s, loss=32.7]train epoch: 123:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.23it/s, loss=26.6]train epoch: 123:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=26.6]train epoch: 123:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=25.3]train epoch: 123:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.39it/s, loss=25.3]train epoch: 123:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.39it/s, loss=26.5]train epoch: 123:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.66it/s, loss=26.5]train epoch: 123:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.66it/s, loss=29.5]train epoch: 123:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=29.5]train epoch: 123:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=29.9]train epoch: 123:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.02it/s, loss=29.9]train epoch: 123:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.02it/s, loss=22.8]train epoch: 123:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=22.8]train epoch: 123:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.12it/s, loss=33.1]train epoch: 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.14it/s, loss=33.1]train epoch: 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=33.1]
[[032m2021-11-26 10:31:48,365[0m INFO] trainer.training_epoch Training epoch 123, num_steps 992,  avg_loss: 28.2937, total_loss: 226.3498
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.23it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.70it/s]
[[032m2021-11-26 10:31:48,755[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:31:48,755[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:49,365[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 124:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 124:   0%|          | 0/8 [00:00<?, ?it/s, loss=31]train epoch: 124:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=31]train epoch: 124:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=34.4]train epoch: 124:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=34.4]train epoch: 124:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=26.6]train epoch: 124:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.67it/s, loss=26.6]train epoch: 124:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.67it/s, loss=31.1]train epoch: 124:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.85it/s, loss=31.1]train epoch: 124:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.85it/s, loss=25.5]train epoch: 124:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.01it/s, loss=25.5]train epoch: 124:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.01it/s, loss=26]  train epoch: 124:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.10it/s, loss=26]train epoch: 124:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.10it/s, loss=24.6]train epoch: 124:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.20it/s, loss=24.6]train epoch: 124:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.20it/s, loss=34.4]train epoch: 124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.10it/s, loss=34.4]train epoch: 124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.90it/s, loss=34.4]
[[032m2021-11-26 10:31:51,439[0m INFO] trainer.training_epoch Training epoch 124, num_steps 1000,  avg_loss: 29.2064, total_loss: 233.6509
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.40it/s]
[[032m2021-11-26 10:31:51,885[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:31:51,886[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:52,422[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:31:52,708[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 125:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.6349, 0.3651],
        [0.3391, 0.6609],
        [0.3295, 0.6705],
        [0.6717, 0.3283],
        [0.4716, 0.5284],
        [0.4988, 0.5012],
        [0.5501, 0.4499],
        [0.3953, 0.6047]], device='cuda:0')

prompt tensor([[0.7453, 0.2547],
        [0.3282, 0.6718],
        [0.5825, 0.4175],
        [0.7792, 0.2208],
        [0.7034, 0.2966],
        [0.5206, 0.4794],
        [0.7476, 0.2524],
        [0.7617, 0.2383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 125:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.1]train epoch: 125:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.67it/s, loss=32.1]train epoch: 125:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.67it/s, loss=26]  train epoch: 125:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.18it/s, loss=26]train epoch: 125:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.18it/s, loss=26]train epoch: 125:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.33it/s, loss=26]train epoch: 125:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.33it/s, loss=38]train epoch: 125:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.53it/s, loss=38]train epoch: 125:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.53it/s, loss=26.4]train epoch: 125:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.73it/s, loss=26.4]train epoch: 125:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.73it/s, loss=27.1]train epoch: 125:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.90it/s, loss=27.1]train epoch: 125:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.90it/s, loss=27.5]train epoch: 125:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.86it/s, loss=27.5]train epoch: 125:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.86it/s, loss=31.4]train epoch: 125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=31.4]train epoch: 125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=31.4]
[[032m2021-11-26 10:31:54,842[0m INFO] trainer.training_epoch Training epoch 125, num_steps 1008,  avg_loss: 29.3241, total_loss: 234.5928
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.80it/s]
[[032m2021-11-26 10:31:55,228[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:31:55,228[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:55,472[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 126:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 126:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.6]train epoch: 126:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.80it/s, loss=20.6]train epoch: 126:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.80it/s, loss=31.5]train epoch: 126:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.92it/s, loss=31.5]train epoch: 126:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.92it/s, loss=28.3]train epoch: 126:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.11it/s, loss=28.3]train epoch: 126:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.11it/s, loss=27.9]train epoch: 126:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=27.9]train epoch: 126:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=25.4]train epoch: 126:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.40it/s, loss=25.4]train epoch: 126:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.40it/s, loss=23.7]train epoch: 126:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.74it/s, loss=23.7]train epoch: 126:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.74it/s, loss=25.8]train epoch: 126:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.89it/s, loss=25.8]train epoch: 126:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.89it/s, loss=24.4]train epoch: 126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.03it/s, loss=24.4]train epoch: 126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=24.4]
[[032m2021-11-26 10:31:57,698[0m INFO] trainer.training_epoch Training epoch 126, num_steps 1016,  avg_loss: 25.9476, total_loss: 207.5807
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.00it/s]
[[032m2021-11-26 10:31:58,077[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:31:58,077[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:31:58,297[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:31:58,489[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 127:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 127:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.4]train epoch: 127:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.17it/s, loss=32.4]train epoch: 127:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.17it/s, loss=24.6]train epoch: 127:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.15it/s, loss=24.6]train epoch: 127:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.15it/s, loss=28.6]train epoch: 127:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.79it/s, loss=28.6]train epoch: 127:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.79it/s, loss=29.7]train epoch: 127:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=29.7]train epoch: 127:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=31.4]train epoch: 127:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=31.4]train epoch: 127:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=23.2]train epoch: 127:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.52it/s, loss=23.2]train epoch: 127:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.52it/s, loss=22.4]train epoch: 127:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.79it/s, loss=22.4]train epoch: 127:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.79it/s, loss=32.5]train epoch: 127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.85it/s, loss=32.5]train epoch: 127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.44it/s, loss=32.5]
[[032m2021-11-26 10:32:00,824[0m INFO] trainer.training_epoch Training epoch 127, num_steps 1024,  avg_loss: 28.0912, total_loss: 224.7295
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.16it/s]
[[032m2021-11-26 10:32:01,234[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:01,235[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:01,457[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 128:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 128:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.9]train epoch: 128:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=37.9]train epoch: 128:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=26.2]train epoch: 128:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.80it/s, loss=26.2]train epoch: 128:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.80it/s, loss=25]  train epoch: 128:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=25]train epoch: 128:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=31.9]train epoch: 128:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=31.9]train epoch: 128:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=26.9]train epoch: 128:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.85it/s, loss=26.9]train epoch: 128:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.85it/s, loss=24.5]train epoch: 128:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=24.5]train epoch: 128:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.16it/s, loss=28.9]train epoch: 128:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=28.9]train epoch: 128:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=26.8]train epoch: 128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=26.8]train epoch: 128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=26.8]
[[032m2021-11-26 10:32:03,902[0m INFO] trainer.training_epoch Training epoch 128, num_steps 1032,  avg_loss: 28.5151, total_loss: 228.1212
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.61it/s]
[[032m2021-11-26 10:32:04,260[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:32:04,261[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:04,481[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 129:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 129:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.6]train epoch: 129:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=28.6]train epoch: 129:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=24.4]train epoch: 129:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=24.4]train epoch: 129:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=25.5]train epoch: 129:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.71it/s, loss=25.5]train epoch: 129:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.71it/s, loss=27.7]train epoch: 129:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=27.7]train epoch: 129:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=28.6]train epoch: 129:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.45it/s, loss=28.6]train epoch: 129:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.45it/s, loss=28.2]train epoch: 129:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.88it/s, loss=28.2]train epoch: 129:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=34]  train epoch: 129:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=34]train epoch: 129:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=33.3]train epoch: 129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=33.3]train epoch: 129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s, loss=33.3]
[[032m2021-11-26 10:32:07,016[0m INFO] trainer.training_epoch Training epoch 129, num_steps 1040,  avg_loss: 28.7784, total_loss: 230.2273
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.75it/s]
[[032m2021-11-26 10:32:07,411[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:32:07,411[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:07,617[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 130:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 130:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.1]train epoch: 130:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.69it/s, loss=34.1]train epoch: 130:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.69it/s, loss=25.6]train epoch: 130:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.17it/s, loss=25.6]train epoch: 130:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.17it/s, loss=29]  train epoch: 130:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.60it/s, loss=29]train epoch: 130:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.60it/s, loss=22.5]train epoch: 130:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=22.5]train epoch: 130:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=26.8]train epoch: 130:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.46it/s, loss=26.8]train epoch: 130:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.46it/s, loss=30]  train epoch: 130:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.04it/s, loss=30]train epoch: 130:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.04it/s, loss=27.2]train epoch: 130:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s, loss=27.2]train epoch: 130:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s, loss=31.8]train epoch: 130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=31.8]train epoch: 130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=31.8]
[[032m2021-11-26 10:32:09,916[0m INFO] trainer.training_epoch Training epoch 130, num_steps 1048,  avg_loss: 28.3698, total_loss: 226.9584
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.87it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.82it/s]
[[032m2021-11-26 10:32:10,300[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:32:10,300[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:10,522[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 131:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 131:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.8]train epoch: 131:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.82it/s, loss=21.8]train epoch: 131:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.82it/s, loss=31.1]train epoch: 131:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.82it/s, loss=31.1]train epoch: 131:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.82it/s, loss=30]  train epoch: 131:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.59it/s, loss=30]train epoch: 131:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.59it/s, loss=35.6]train epoch: 131:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=35.6]train epoch: 131:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=28.8]train epoch: 131:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.84it/s, loss=28.8]train epoch: 131:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.84it/s, loss=26.4]train epoch: 131:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.05it/s, loss=26.4]train epoch: 131:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.05it/s, loss=36.6]train epoch: 131:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=36.6]train epoch: 131:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=24.1]train epoch: 131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.71it/s, loss=24.1]train epoch: 131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=24.1]
[[032m2021-11-26 10:32:12,974[0m INFO] trainer.training_epoch Training epoch 131, num_steps 1056,  avg_loss: 29.3031, total_loss: 234.4249
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.98it/s]
[[032m2021-11-26 10:32:13,354[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:32:13,355[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:13,568[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 132:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 132:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.9]train epoch: 132:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=19.9]train epoch: 132:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=27.3]train epoch: 132:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.10it/s, loss=27.3]train epoch: 132:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.10it/s, loss=30]  train epoch: 132:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.77it/s, loss=30]train epoch: 132:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.77it/s, loss=27.2]train epoch: 132:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=27.2]train epoch: 132:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=21.1]train epoch: 132:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.58it/s, loss=21.1]train epoch: 132:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.58it/s, loss=34.4]train epoch: 132:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=34.4]train epoch: 132:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=28.6]train epoch: 132:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=28.6]train epoch: 132:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=28.7]train epoch: 132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=28.7]train epoch: 132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s, loss=28.7]
[[032m2021-11-26 10:32:16,108[0m INFO] trainer.training_epoch Training epoch 132, num_steps 1064,  avg_loss: 27.1434, total_loss: 217.1475
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.87it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.06it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.79it/s]
[[032m2021-11-26 10:32:16,580[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:16,580[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:16,799[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 133:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 133:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.1]train epoch: 133:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.48it/s, loss=34.1]train epoch: 133:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.48it/s, loss=37.7]train epoch: 133:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.17it/s, loss=37.7]train epoch: 133:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.17it/s, loss=22]  train epoch: 133:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.61it/s, loss=22]train epoch: 133:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.61it/s, loss=33.4]train epoch: 133:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=33.4]train epoch: 133:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=28.5]train epoch: 133:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.05it/s, loss=28.5]train epoch: 133:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.05it/s, loss=29.2]train epoch: 133:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s, loss=29.2]train epoch: 133:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.33it/s, loss=30.5]train epoch: 133:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.63it/s, loss=30.5]train epoch: 133:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.63it/s, loss=26.5]train epoch: 133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.88it/s, loss=26.5]train epoch: 133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=26.5]
[[032m2021-11-26 10:32:19,179[0m INFO] trainer.training_epoch Training epoch 133, num_steps 1072,  avg_loss: 30.2339, total_loss: 241.8713
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.21it/s]
[[032m2021-11-26 10:32:19,589[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:32:19,589[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:19,801[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:32:19,886[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 134:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 134:   0%|          | 0/8 [00:00<?, ?it/s, loss=17.5]train epoch: 134:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.71it/s, loss=17.5]train epoch: 134:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.71it/s, loss=30.6]train epoch: 134:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=30.6]train epoch: 134:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=28.1]train epoch: 134:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.38it/s, loss=28.1]train epoch: 134:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.38it/s, loss=21.8]train epoch: 134:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=21.8]train epoch: 134:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=28.9]train epoch: 134:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=28.9]train epoch: 134:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=21.3]train epoch: 134:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.44it/s, loss=21.3]train epoch: 134:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.44it/s, loss=27.8]train epoch: 134:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.77it/s, loss=27.8]train epoch: 134:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.77it/s, loss=23.1]train epoch: 134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.63it/s, loss=23.1]train epoch: 134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.72it/s, loss=23.1]
[[032m2021-11-26 10:32:22,040[0m INFO] trainer.training_epoch Training epoch 134, num_steps 1080,  avg_loss: 24.8860, total_loss: 199.0877
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.07it/s]
[[032m2021-11-26 10:32:22,454[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:22,455[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:22,671[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 135:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 135:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.8]train epoch: 135:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=23.8]train epoch: 135:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=27.5]train epoch: 135:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.62it/s, loss=27.5]train epoch: 135:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.62it/s, loss=29]  train epoch: 135:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.48it/s, loss=29]train epoch: 135:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.48it/s, loss=26.2]train epoch: 135:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.45it/s, loss=26.2]train epoch: 135:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.45it/s, loss=26.9]train epoch: 135:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=26.9]train epoch: 135:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=34.4]train epoch: 135:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.76it/s, loss=34.4]train epoch: 135:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.76it/s, loss=24.6]train epoch: 135:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.76it/s, loss=24.6]train epoch: 135:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.76it/s, loss=28.3]train epoch: 135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=28.3]train epoch: 135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.90it/s, loss=28.3]
[[032m2021-11-26 10:32:24,727[0m INFO] trainer.training_epoch Training epoch 135, num_steps 1088,  avg_loss: 27.5816, total_loss: 220.6528
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.55it/s]
[[032m2021-11-26 10:32:25,131[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:25,132[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:25,394[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 136:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 136:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.7]train epoch: 136:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.54it/s, loss=25.7]train epoch: 136:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.54it/s, loss=27.9]train epoch: 136:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=27.9]train epoch: 136:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=26.4]train epoch: 136:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=26.4]train epoch: 136:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=27.7]train epoch: 136:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.35it/s, loss=27.7]train epoch: 136:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.35it/s, loss=21.1]train epoch: 136:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.33it/s, loss=21.1]train epoch: 136:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.33it/s, loss=24.2]train epoch: 136:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.46it/s, loss=24.2]train epoch: 136:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.46it/s, loss=22.3]train epoch: 136:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.04it/s, loss=22.3]train epoch: 136:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.04it/s, loss=28.9]train epoch: 136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.76it/s, loss=28.9]train epoch: 136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.06it/s, loss=28.9]
[[032m2021-11-26 10:32:27,370[0m INFO] trainer.training_epoch Training epoch 136, num_steps 1096,  avg_loss: 25.5096, total_loss: 204.0768
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.51it/s]
[[032m2021-11-26 10:32:27,828[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:32:27,828[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:28,222[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 137:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 137:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.1]train epoch: 137:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=33.1]train epoch: 137:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=25.1]train epoch: 137:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.94it/s, loss=25.1]train epoch: 137:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.94it/s, loss=29.6]train epoch: 137:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.77it/s, loss=29.6]train epoch: 137:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.77it/s, loss=28]  train epoch: 137:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.08it/s, loss=28]
model tensor([[0.3049, 0.6951],
        [0.3498, 0.6502],
        [0.7645, 0.2355],
        [0.3053, 0.6947],
        [0.4593, 0.5407],
        [0.2477, 0.7523],
        [0.2873, 0.7127],
        [0.7036, 0.2964]], device='cuda:0')

prompt tensor([[0.4736, 0.5264],
        [0.4848, 0.5152],
        [0.8992, 0.1008],
        [0.5119, 0.4881],
        [0.3870, 0.6130],
        [0.3675, 0.6325],
        [0.4942, 0.5058],
        [0.6702, 0.3298]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 137:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.08it/s, loss=29]train epoch: 137:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=29]train epoch: 137:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=30.9]train epoch: 137:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.23it/s, loss=30.9]train epoch: 137:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.23it/s, loss=26.8]train epoch: 137:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.29it/s, loss=26.8]train epoch: 137:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.29it/s, loss=23.5]train epoch: 137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.07it/s, loss=23.5]train epoch: 137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.10it/s, loss=23.5]
[[032m2021-11-26 10:32:30,177[0m INFO] trainer.training_epoch Training epoch 137, num_steps 1104,  avg_loss: 28.2555, total_loss: 226.0441
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.45it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.05it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.11it/s]
[[032m2021-11-26 10:32:30,777[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:32:30,777[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:31,255[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 138:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 138:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.8]train epoch: 138:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.17it/s, loss=27.8]train epoch: 138:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.17it/s, loss=23.6]train epoch: 138:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.40it/s, loss=23.6]train epoch: 138:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.40it/s, loss=28.3]train epoch: 138:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.70it/s, loss=28.3]train epoch: 138:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.70it/s, loss=34.2]train epoch: 138:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=34.2]train epoch: 138:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=34.7]train epoch: 138:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=34.7]train epoch: 138:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=24.9]train epoch: 138:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=24.9]train epoch: 138:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=32.2]train epoch: 138:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.09it/s, loss=32.2]train epoch: 138:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.09it/s, loss=25.1]train epoch: 138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.07it/s, loss=25.1]train epoch: 138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=25.1]
[[032m2021-11-26 10:32:33,314[0m INFO] trainer.training_epoch Training epoch 138, num_steps 1112,  avg_loss: 28.8430, total_loss: 230.7441
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.40it/s]
[[032m2021-11-26 10:32:33,757[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:33,757[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:34,006[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 139:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 139:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.4]train epoch: 139:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.67it/s, loss=32.4]train epoch: 139:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.67it/s, loss=30]  train epoch: 139:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=30]train epoch: 139:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=31]train epoch: 139:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s, loss=31]train epoch: 139:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s, loss=30.8]train epoch: 139:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.43it/s, loss=30.8]train epoch: 139:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.43it/s, loss=28.7]train epoch: 139:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=28.7]train epoch: 139:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=27]  train epoch: 139:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=27]train epoch: 139:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=33.2]train epoch: 139:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.35it/s, loss=33.2]train epoch: 139:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.35it/s, loss=29.1]train epoch: 139: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.41it/s, loss=29.1]train epoch: 139: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.35it/s, loss=29.1]
[[032m2021-11-26 10:32:35,851[0m INFO] trainer.training_epoch Training epoch 139, num_steps 1120,  avg_loss: 30.2697, total_loss: 242.1575
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.16it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.38it/s]
[[032m2021-11-26 10:32:36,347[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:36,347[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:36,575[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 140:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 140:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.4]train epoch: 140:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.19it/s, loss=27.4]train epoch: 140:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.19it/s, loss=29.2]train epoch: 140:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.64it/s, loss=29.2]train epoch: 140:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.64it/s, loss=19.8]train epoch: 140:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.83it/s, loss=19.8]train epoch: 140:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.83it/s, loss=29.9]train epoch: 140:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.84it/s, loss=29.9]train epoch: 140:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.84it/s, loss=31.3]train epoch: 140:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=31.3]train epoch: 140:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=28.9]train epoch: 140:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.92it/s, loss=28.9]train epoch: 140:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=28.1]train epoch: 140:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=28.1]train epoch: 140:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=27.7]train epoch: 140: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=27.7]train epoch: 140: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=27.7]
[[032m2021-11-26 10:32:38,873[0m INFO] trainer.training_epoch Training epoch 140, num_steps 1128,  avg_loss: 27.7948, total_loss: 222.3584
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.59it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.96it/s]
[[032m2021-11-26 10:32:39,335[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:39,335[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:39,545[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 141:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 141:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.7]train epoch: 141:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=23.7]train epoch: 141:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=31.6]train epoch: 141:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.44it/s, loss=31.6]train epoch: 141:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.44it/s, loss=24.9]train epoch: 141:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.25it/s, loss=24.9]train epoch: 141:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.25it/s, loss=25.7]train epoch: 141:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.28it/s, loss=25.7]train epoch: 141:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.28it/s, loss=21]  train epoch: 141:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.61it/s, loss=21]train epoch: 141:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.61it/s, loss=37.3]train epoch: 141:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.93it/s, loss=37.3]train epoch: 141:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.93it/s, loss=32]  train epoch: 141:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.15it/s, loss=32]train epoch: 141:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.15it/s, loss=32.5]train epoch: 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=32.5]train epoch: 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=32.5]
[[032m2021-11-26 10:32:42,020[0m INFO] trainer.training_epoch Training epoch 141, num_steps 1136,  avg_loss: 28.5979, total_loss: 228.7831
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.32it/s]
[[032m2021-11-26 10:32:42,423[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:42,423[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:42,644[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 142:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 142:   0%|          | 0/8 [00:00<?, ?it/s, loss=24]train epoch: 142:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=24]train epoch: 142:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=31.9]train epoch: 142:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.92it/s, loss=31.9]train epoch: 142:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.92it/s, loss=21.1]train epoch: 142:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.11it/s, loss=21.1]train epoch: 142:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.11it/s, loss=30.3]train epoch: 142:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.31it/s, loss=30.3]train epoch: 142:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.31it/s, loss=28.3]train epoch: 142:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.64it/s, loss=28.3]train epoch: 142:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.64it/s, loss=27.7]train epoch: 142:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.85it/s, loss=27.7]train epoch: 142:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.85it/s, loss=29.9]train epoch: 142:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.91it/s, loss=29.9]train epoch: 142:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.91it/s, loss=25.5]train epoch: 142: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.05it/s, loss=25.5]train epoch: 142: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.71it/s, loss=25.5]
[[032m2021-11-26 10:32:44,804[0m INFO] trainer.training_epoch Training epoch 142, num_steps 1144,  avg_loss: 27.3145, total_loss: 218.5157
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.12it/s]
[[032m2021-11-26 10:32:45,179[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:32:45,180[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:45,418[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:32:45,569[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 143:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 143:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.5]train epoch: 143:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.77it/s, loss=27.5]train epoch: 143:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.77it/s, loss=24]  train epoch: 143:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=24]train epoch: 143:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=26.2]train epoch: 143:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.96it/s, loss=26.2]train epoch: 143:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.96it/s, loss=22.8]train epoch: 143:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.05it/s, loss=22.8]train epoch: 143:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.05it/s, loss=23.7]train epoch: 143:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=23.7]train epoch: 143:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=31.1]train epoch: 143:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.50it/s, loss=31.1]train epoch: 143:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.50it/s, loss=27.8]train epoch: 143:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.84it/s, loss=27.8]train epoch: 143:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.84it/s, loss=31.2]train epoch: 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=31.2]train epoch: 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.61it/s, loss=31.2]
[[032m2021-11-26 10:32:47,794[0m INFO] trainer.training_epoch Training epoch 143, num_steps 1152,  avg_loss: 26.7875, total_loss: 214.3000
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.39it/s]
[[032m2021-11-26 10:32:48,161[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:48,161[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:48,728[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 144:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 144:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 144:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.98it/s, loss=25]train epoch: 144:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.98it/s, loss=31.9]train epoch: 144:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.67it/s, loss=31.9]train epoch: 144:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.67it/s, loss=23]  train epoch: 144:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.74it/s, loss=23]train epoch: 144:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.74it/s, loss=26.3]train epoch: 144:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.89it/s, loss=26.3]train epoch: 144:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.89it/s, loss=31.5]train epoch: 144:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.87it/s, loss=31.5]train epoch: 144:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.87it/s, loss=24.9]train epoch: 144:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=24.9]train epoch: 144:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=31.2]train epoch: 144:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.32it/s, loss=31.2]train epoch: 144:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.32it/s, loss=28.2]train epoch: 144: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.41it/s, loss=28.2]train epoch: 144: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.08it/s, loss=28.2]
[[032m2021-11-26 10:32:50,701[0m INFO] trainer.training_epoch Training epoch 144, num_steps 1160,  avg_loss: 27.7467, total_loss: 221.9735
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.57it/s]
[[032m2021-11-26 10:32:51,144[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:32:51,145[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:51,440[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:32:51,681[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 145:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 145:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.2]train epoch: 145:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.55it/s, loss=29.2]train epoch: 145:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.55it/s, loss=22.9]train epoch: 145:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.45it/s, loss=22.9]train epoch: 145:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.45it/s, loss=29]  train epoch: 145:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.40it/s, loss=29]train epoch: 145:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.40it/s, loss=33.8]train epoch: 145:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s, loss=33.8]train epoch: 145:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s, loss=31.7]train epoch: 145:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=31.7]train epoch: 145:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=28.5]train epoch: 145:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.18it/s, loss=28.5]train epoch: 145:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.18it/s, loss=40.1]train epoch: 145:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.33it/s, loss=40.1]train epoch: 145:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.33it/s, loss=26.6]train epoch: 145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.29it/s, loss=26.6]train epoch: 145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=26.6]
[[032m2021-11-26 10:32:53,728[0m INFO] trainer.training_epoch Training epoch 145, num_steps 1168,  avg_loss: 30.2150, total_loss: 241.7203
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.81it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.77it/s]
[[032m2021-11-26 10:32:54,230[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:32:54,231[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:54,768[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:32:54,937[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 146:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 146:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.4]train epoch: 146:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.48it/s, loss=28.4]train epoch: 146:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.48it/s, loss=27]  train epoch: 146:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.05it/s, loss=27]train epoch: 146:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.05it/s, loss=23.7]train epoch: 146:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.22it/s, loss=23.7]train epoch: 146:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.22it/s, loss=25.7]train epoch: 146:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.03it/s, loss=25.7]train epoch: 146:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.03it/s, loss=28.7]train epoch: 146:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.27it/s, loss=28.7]train epoch: 146:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.27it/s, loss=23.3]train epoch: 146:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.24it/s, loss=23.3]train epoch: 146:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.24it/s, loss=23.4]train epoch: 146:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=23.4]train epoch: 146:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.12it/s, loss=26.1]train epoch: 146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.00it/s, loss=26.1]train epoch: 146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=26.1]
[[032m2021-11-26 10:32:57,170[0m INFO] trainer.training_epoch Training epoch 146, num_steps 1176,  avg_loss: 25.7665, total_loss: 206.1321
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.88it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.09it/s]
[[032m2021-11-26 10:32:57,630[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:32:57,631[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:32:57,880[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 147:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 147:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.9]train epoch: 147:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.07it/s, loss=30.9]train epoch: 147:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.07it/s, loss=24.3]train epoch: 147:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.61it/s, loss=24.3]train epoch: 147:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.61it/s, loss=35.4]train epoch: 147:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.56it/s, loss=35.4]train epoch: 147:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.56it/s, loss=27.4]train epoch: 147:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.38it/s, loss=27.4]train epoch: 147:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.38it/s, loss=32.4]train epoch: 147:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=32.4]train epoch: 147:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=26.3]train epoch: 147:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.30it/s, loss=26.3]train epoch: 147:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.30it/s, loss=33.5]train epoch: 147:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=33.5]train epoch: 147:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=22.4]train epoch: 147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=22.4]train epoch: 147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=22.4]
[[032m2021-11-26 10:32:59,891[0m INFO] trainer.training_epoch Training epoch 147, num_steps 1184,  avg_loss: 29.0615, total_loss: 232.4918
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.84it/s]
[[032m2021-11-26 10:33:00,362[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:00,362[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:00,836[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 148:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 148:   0%|          | 0/8 [00:00<?, ?it/s, loss=27]train epoch: 148:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=27]train epoch: 148:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=25.8]train epoch: 148:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.51it/s, loss=25.8]train epoch: 148:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.51it/s, loss=23.9]train epoch: 148:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s, loss=23.9]train epoch: 148:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s, loss=26.3]train epoch: 148:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.25it/s, loss=26.3]train epoch: 148:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.25it/s, loss=24.1]train epoch: 148:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.39it/s, loss=24.1]train epoch: 148:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.39it/s, loss=28.3]train epoch: 148:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.35it/s, loss=28.3]train epoch: 148:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.35it/s, loss=33.7]train epoch: 148:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.35it/s, loss=33.7]train epoch: 148:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.35it/s, loss=27.1]train epoch: 148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.35it/s, loss=27.1]train epoch: 148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.37it/s, loss=27.1]
[[032m2021-11-26 10:33:02,674[0m INFO] trainer.training_epoch Training epoch 148, num_steps 1192,  avg_loss: 27.0167, total_loss: 216.1336
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.31it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.83it/s]
[[032m2021-11-26 10:33:03,096[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:33:03,096[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:03,655[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:33:03,820[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 149:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 149:   0%|          | 0/8 [00:00<?, ?it/s, loss=16.5]train epoch: 149:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.78it/s, loss=16.5]train epoch: 149:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.78it/s, loss=28.6]train epoch: 149:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.85it/s, loss=28.6]train epoch: 149:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.85it/s, loss=24.5]train epoch: 149:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=24.5]train epoch: 149:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=28.3]train epoch: 149:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.37it/s, loss=28.3]train epoch: 149:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.37it/s, loss=33.1]train epoch: 149:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.45it/s, loss=33.1]train epoch: 149:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.45it/s, loss=31.1]train epoch: 149:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=31.1]train epoch: 149:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=37.2]train epoch: 149:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.30it/s, loss=37.2]train epoch: 149:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.30it/s, loss=28.1]train epoch: 149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.21it/s, loss=28.1]train epoch: 149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.22it/s, loss=28.1]
[[032m2021-11-26 10:33:05,721[0m INFO] trainer.training_epoch Training epoch 149, num_steps 1200,  avg_loss: 28.4136, total_loss: 227.3086
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.70it/s]
[[032m2021-11-26 10:33:06,156[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:33:06,157[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:06,711[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:33:06,981[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 150:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.4716, 0.5284],
        [0.5557, 0.4443],
        [0.5951, 0.4049],
        [0.3184, 0.6816],
        [0.4587, 0.5413],
        [0.8361, 0.1639],
        [0.3690, 0.6310],
        [0.3049, 0.6951]], device='cuda:0')

prompt tensor([[0.7278, 0.2722],
        [0.7357, 0.2643],
        [0.5438, 0.4562],
        [0.6392, 0.3608],
        [0.5880, 0.4120],
        [0.7464, 0.2536],
        [0.3121, 0.6879],
        [0.3328, 0.6672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 150:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 150:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.96it/s, loss=25]train epoch: 150:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.96it/s, loss=26.1]train epoch: 150:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.77it/s, loss=26.1]train epoch: 150:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.77it/s, loss=25.9]train epoch: 150:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=25.9]train epoch: 150:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=27.6]train epoch: 150:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=27.6]train epoch: 150:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=23.4]train epoch: 150:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=23.4]train epoch: 150:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=36.9]train epoch: 150:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.18it/s, loss=36.9]train epoch: 150:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.18it/s, loss=27.4]train epoch: 150:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.20it/s, loss=27.4]train epoch: 150:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.20it/s, loss=23.8]train epoch: 150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.10it/s, loss=23.8]train epoch: 150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.09it/s, loss=23.8]
[[032m2021-11-26 10:33:08,957[0m INFO] trainer.training_epoch Training epoch 150, num_steps 1208,  avg_loss: 27.0104, total_loss: 216.0834
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.45it/s]
[[032m2021-11-26 10:33:09,455[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:33:09,455[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:09,808[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 151:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 151:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 151:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=30.2]train epoch: 151:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=23.3]train epoch: 151:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=23.3]train epoch: 151:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=38.3]train epoch: 151:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.37it/s, loss=38.3]train epoch: 151:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.37it/s, loss=24.4]train epoch: 151:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.24it/s, loss=24.4]train epoch: 151:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.24it/s, loss=28.2]train epoch: 151:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.41it/s, loss=28.2]train epoch: 151:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.41it/s, loss=30.9]train epoch: 151:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.42it/s, loss=30.9]train epoch: 151:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.42it/s, loss=27.8]train epoch: 151:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.19it/s, loss=27.8]train epoch: 151:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.19it/s, loss=23.6]train epoch: 151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.75it/s, loss=23.6]train epoch: 151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.09it/s, loss=23.6]
[[032m2021-11-26 10:33:11,772[0m INFO] trainer.training_epoch Training epoch 151, num_steps 1216,  avg_loss: 28.3411, total_loss: 226.7290
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.83it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.21it/s]
[[032m2021-11-26 10:33:12,222[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:33:12,222[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:12,599[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 152:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 152:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.4]train epoch: 152:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.10it/s, loss=25.4]train epoch: 152:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.10it/s, loss=24.7]train epoch: 152:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=24.7]train epoch: 152:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=26.5]train epoch: 152:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=26.5]train epoch: 152:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=28.4]train epoch: 152:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.25it/s, loss=28.4]train epoch: 152:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.25it/s, loss=32.2]train epoch: 152:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=32.2]train epoch: 152:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=26]  train epoch: 152:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.39it/s, loss=26]train epoch: 152:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.39it/s, loss=30.4]train epoch: 152:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.53it/s, loss=30.4]train epoch: 152:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.53it/s, loss=25.7]train epoch: 152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.36it/s, loss=25.7]train epoch: 152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.42it/s, loss=25.7]
[[032m2021-11-26 10:33:14,416[0m INFO] trainer.training_epoch Training epoch 152, num_steps 1224,  avg_loss: 27.4089, total_loss: 219.2708
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.98it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.60it/s]
[[032m2021-11-26 10:33:14,917[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:14,918[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:15,421[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 153:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 153:   0%|          | 0/8 [00:00<?, ?it/s, loss=32]train epoch: 153:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.30it/s, loss=32]train epoch: 153:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.30it/s, loss=29.9]train epoch: 153:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.95it/s, loss=29.9]train epoch: 153:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.95it/s, loss=24.6]train epoch: 153:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=24.6]train epoch: 153:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=18.8]train epoch: 153:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.09it/s, loss=18.8]train epoch: 153:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.09it/s, loss=28.7]train epoch: 153:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.22it/s, loss=28.7]train epoch: 153:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.22it/s, loss=31.7]train epoch: 153:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=31.7]train epoch: 153:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=27.9]train epoch: 153:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=27.9]train epoch: 153:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.17it/s, loss=24.7]train epoch: 153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=24.7]train epoch: 153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=24.7]
[[032m2021-11-26 10:33:17,639[0m INFO] trainer.training_epoch Training epoch 153, num_steps 1232,  avg_loss: 27.2929, total_loss: 218.3431
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.78it/s]
[[032m2021-11-26 10:33:18,167[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:18,167[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:18,384[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 154:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 154:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.4]train epoch: 154:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=37.4]train epoch: 154:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=33.8]train epoch: 154:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=33.8]train epoch: 154:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=30.5]train epoch: 154:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=30.5]train epoch: 154:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=26.9]train epoch: 154:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.22it/s, loss=26.9]train epoch: 154:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.22it/s, loss=20.3]train epoch: 154:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.24it/s, loss=20.3]train epoch: 154:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.24it/s, loss=23]  train epoch: 154:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.38it/s, loss=23]train epoch: 154:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.38it/s, loss=28.5]train epoch: 154:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.49it/s, loss=28.5]train epoch: 154:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.49it/s, loss=30.4]train epoch: 154: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.14it/s, loss=30.4]train epoch: 154: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.29it/s, loss=30.4]
[[032m2021-11-26 10:33:20,256[0m INFO] trainer.training_epoch Training epoch 154, num_steps 1240,  avg_loss: 28.8406, total_loss: 230.7244
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.81it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.20it/s]
[[032m2021-11-26 10:33:20,762[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:20,762[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:21,013[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 155:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 155:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 155:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.62it/s, loss=27.3]train epoch: 155:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.62it/s, loss=26.9]train epoch: 155:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=26.9]train epoch: 155:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=27.3]train epoch: 155:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=27.3]train epoch: 155:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=27.9]train epoch: 155:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.47it/s, loss=27.9]train epoch: 155:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.47it/s, loss=26.5]train epoch: 155:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=26.5]train epoch: 155:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=28.5]train epoch: 155:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.16it/s, loss=28.5]train epoch: 155:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.16it/s, loss=31.2]train epoch: 155:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.09it/s, loss=31.2]train epoch: 155:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.09it/s, loss=29.6]train epoch: 155: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=29.6]train epoch: 155: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.17it/s, loss=29.6]
[[032m2021-11-26 10:33:22,935[0m INFO] trainer.training_epoch Training epoch 155, num_steps 1248,  avg_loss: 28.1473, total_loss: 225.1785
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.54it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.46it/s]
[[032m2021-11-26 10:33:23,429[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:23,429[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:23,714[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 156:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 156:   0%|          | 0/8 [00:00<?, ?it/s, loss=22]train epoch: 156:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.92it/s, loss=22]train epoch: 156:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.92it/s, loss=39.9]train epoch: 156:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=39.9]train epoch: 156:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=32.3]train epoch: 156:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=32.3]train epoch: 156:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=23.7]train epoch: 156:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.49it/s, loss=23.7]train epoch: 156:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.49it/s, loss=30.7]train epoch: 156:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=30.7]train epoch: 156:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=26.1]train epoch: 156:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=26.1]train epoch: 156:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=23.8]train epoch: 156:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.44it/s, loss=23.8]train epoch: 156:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.44it/s, loss=31]  train epoch: 156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.56it/s, loss=31]train epoch: 156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.52it/s, loss=31]
[[032m2021-11-26 10:33:25,490[0m INFO] trainer.training_epoch Training epoch 156, num_steps 1256,  avg_loss: 28.6698, total_loss: 229.3582
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.78it/s]
[[032m2021-11-26 10:33:25,960[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:25,961[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:26,398[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 157:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 157:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 157:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.21it/s, loss=29.3]train epoch: 157:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.21it/s, loss=27.8]train epoch: 157:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.94it/s, loss=27.8]train epoch: 157:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.94it/s, loss=24.9]train epoch: 157:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.47it/s, loss=24.9]train epoch: 157:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.47it/s, loss=31.5]train epoch: 157:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=31.5]train epoch: 157:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=29.1]train epoch: 157:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=29.1]train epoch: 157:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=27.6]train epoch: 157:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=27.6]train epoch: 157:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=31.4]train epoch: 157:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=31.4]train epoch: 157:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.17it/s, loss=29.9]train epoch: 157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.10it/s, loss=29.9]train epoch: 157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.70it/s, loss=29.9]
[[032m2021-11-26 10:33:28,569[0m INFO] trainer.training_epoch Training epoch 157, num_steps 1264,  avg_loss: 28.9444, total_loss: 231.5554
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.33it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.11it/s]
[[032m2021-11-26 10:33:29,388[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:29,388[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:29,883[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 158:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 158:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.6]train epoch: 158:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.24it/s, loss=28.6]train epoch: 158:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.24it/s, loss=37.8]train epoch: 158:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=37.8]train epoch: 158:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=26.5]train epoch: 158:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=26.5]train epoch: 158:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=25.5]train epoch: 158:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.32it/s, loss=25.5]train epoch: 158:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.32it/s, loss=27.3]train epoch: 158:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.50it/s, loss=27.3]train epoch: 158:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.50it/s, loss=24]  train epoch: 158:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.51it/s, loss=24]train epoch: 158:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.51it/s, loss=28.1]train epoch: 158:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.01it/s, loss=28.1]train epoch: 158:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.01it/s, loss=31.2]train epoch: 158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=31.2]train epoch: 158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.88it/s, loss=31.2]
[[032m2021-11-26 10:33:31,953[0m INFO] trainer.training_epoch Training epoch 158, num_steps 1272,  avg_loss: 28.6204, total_loss: 228.9630
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.48it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.63it/s]
[[032m2021-11-26 10:33:32,437[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:32,438[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:32,763[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 159:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 159:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 159:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=25.5]train epoch: 159:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=35.3]train epoch: 159:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=35.3]train epoch: 159:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=27.9]train epoch: 159:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s, loss=27.9]train epoch: 159:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s, loss=26.9]train epoch: 159:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.57it/s, loss=26.9]train epoch: 159:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.57it/s, loss=29.2]train epoch: 159:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=29.2]train epoch: 159:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=26.9]train epoch: 159:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.26it/s, loss=26.9]train epoch: 159:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.26it/s, loss=33]  train epoch: 159:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.00it/s, loss=33]train epoch: 159:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.00it/s, loss=27.7]train epoch: 159: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=27.7]train epoch: 159: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=27.7]
[[032m2021-11-26 10:33:34,812[0m INFO] trainer.training_epoch Training epoch 159, num_steps 1280,  avg_loss: 29.0454, total_loss: 232.3632
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.88it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.35it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.50it/s]
[[032m2021-11-26 10:33:35,446[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:35,446[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:35,668[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 160:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 160:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.8]train epoch: 160:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=27.8]train epoch: 160:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=21.9]train epoch: 160:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.69it/s, loss=21.9]train epoch: 160:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.69it/s, loss=30.1]train epoch: 160:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s, loss=30.1]train epoch: 160:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s, loss=28.2]train epoch: 160:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.58it/s, loss=28.2]train epoch: 160:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.58it/s, loss=20]  train epoch: 160:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.44it/s, loss=20]train epoch: 160:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.44it/s, loss=29.8]train epoch: 160:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=29.8]train epoch: 160:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=32.4]train epoch: 160:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.05it/s, loss=32.4]train epoch: 160:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.05it/s, loss=27.7]train epoch: 160: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.10it/s, loss=27.7]train epoch: 160: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.28it/s, loss=27.7]
[[032m2021-11-26 10:33:37,544[0m INFO] trainer.training_epoch Training epoch 160, num_steps 1288,  avg_loss: 27.2367, total_loss: 217.8933
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.88it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.93it/s]
[[032m2021-11-26 10:33:38,006[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:38,007[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:38,388[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 161:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 161:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 161:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.31it/s, loss=25.5]train epoch: 161:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.31it/s, loss=29.4]train epoch: 161:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.34it/s, loss=29.4]train epoch: 161:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.34it/s, loss=28.7]train epoch: 161:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.44it/s, loss=28.7]train epoch: 161:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.44it/s, loss=28.4]train epoch: 161:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.66it/s, loss=28.4]train epoch: 161:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.66it/s, loss=33]  train epoch: 161:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=33]train epoch: 161:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=24.5]train epoch: 161:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=24.5]train epoch: 161:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=33.2]train epoch: 161:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.08it/s, loss=33.2]train epoch: 161:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.08it/s, loss=27]  train epoch: 161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s, loss=27]train epoch: 161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.83it/s, loss=27]
[[032m2021-11-26 10:33:40,482[0m INFO] trainer.training_epoch Training epoch 161, num_steps 1296,  avg_loss: 28.7225, total_loss: 229.7804
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.66it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.01it/s]
[[032m2021-11-26 10:33:40,900[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:40,900[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:41,230[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 162:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 162:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.9]train epoch: 162:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=32.9]train epoch: 162:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=31.1]train epoch: 162:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=31.1]train epoch: 162:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=37.2]train epoch: 162:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.37it/s, loss=37.2]train epoch: 162:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.37it/s, loss=29.1]train epoch: 162:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=29.1]
model tensor([[0.5951, 0.4049],
        [0.5560, 0.4440],
        [0.5445, 0.4555],
        [0.4305, 0.5695],
        [0.7454, 0.2546],
        [0.3806, 0.6194],
        [0.7953, 0.2047],
        [0.4201, 0.5799]], device='cuda:0')

prompt tensor([[0.8611, 0.1389],
        [0.7244, 0.2756],
        [0.7371, 0.2629],
        [0.7068, 0.2932],
        [0.8333, 0.1667],
        [0.6884, 0.3116],
        [0.9010, 0.0990],
        [0.4850, 0.5150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 162:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=27.7]train epoch: 162:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=27.7]train epoch: 162:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=27.6]train epoch: 162:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.11it/s, loss=27.6]train epoch: 162:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.11it/s, loss=25.7]train epoch: 162:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=25.7]train epoch: 162:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=22.5]train epoch: 162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.19it/s, loss=22.5]train epoch: 162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.00it/s, loss=22.5]
[[032m2021-11-26 10:33:43,233[0m INFO] trainer.training_epoch Training epoch 162, num_steps 1304,  avg_loss: 29.2211, total_loss: 233.7688
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.99it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.50it/s]
[[032m2021-11-26 10:33:43,597[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:33:43,597[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:44,106[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 163:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 163:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.7]train epoch: 163:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=20.7]train epoch: 163:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=29.5]train epoch: 163:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.07it/s, loss=29.5]train epoch: 163:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.07it/s, loss=28]  train epoch: 163:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.19it/s, loss=28]train epoch: 163:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.19it/s, loss=38.8]train epoch: 163:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=38.8]train epoch: 163:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=22.5]train epoch: 163:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=22.5]train epoch: 163:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=31]  train epoch: 163:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.10it/s, loss=31]train epoch: 163:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.10it/s, loss=26.1]train epoch: 163:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.28it/s, loss=26.1]train epoch: 163:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.28it/s, loss=31.9]train epoch: 163: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.14it/s, loss=31.9]train epoch: 163: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.85it/s, loss=31.9]
[[032m2021-11-26 10:33:46,217[0m INFO] trainer.training_epoch Training epoch 163, num_steps 1312,  avg_loss: 28.5597, total_loss: 228.4777
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.10it/s]
[[032m2021-11-26 10:33:46,681[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:33:46,682[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:47,196[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 164:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 164:   0%|          | 0/8 [00:00<?, ?it/s, loss=24]train epoch: 164:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.85it/s, loss=24]train epoch: 164:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.85it/s, loss=28.5]train epoch: 164:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.17it/s, loss=28.5]train epoch: 164:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.17it/s, loss=26.5]train epoch: 164:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=26.5]train epoch: 164:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=33.7]train epoch: 164:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=33.7]train epoch: 164:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=34.2]train epoch: 164:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.71it/s, loss=34.2]train epoch: 164:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.71it/s, loss=26.7]train epoch: 164:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.89it/s, loss=26.7]train epoch: 164:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.89it/s, loss=26.4]train epoch: 164:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.99it/s, loss=26.4]train epoch: 164:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.99it/s, loss=24.3]train epoch: 164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.08it/s, loss=24.3]train epoch: 164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.78it/s, loss=24.3]
[[032m2021-11-26 10:33:49,323[0m INFO] trainer.training_epoch Training epoch 164, num_steps 1320,  avg_loss: 28.0352, total_loss: 224.2812
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.27it/s]
[[032m2021-11-26 10:33:49,694[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:33:49,694[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:49,960[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 165:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 165:   0%|          | 0/8 [00:00<?, ?it/s, loss=40.5]train epoch: 165:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.25it/s, loss=40.5]train epoch: 165:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.25it/s, loss=27.4]train epoch: 165:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.32it/s, loss=27.4]train epoch: 165:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.32it/s, loss=27.6]train epoch: 165:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=27.6]train epoch: 165:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=26.7]train epoch: 165:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.16it/s, loss=26.7]train epoch: 165:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.16it/s, loss=34.9]train epoch: 165:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=34.9]train epoch: 165:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=29.9]train epoch: 165:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=29.9]train epoch: 165:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.68it/s, loss=25.5]train epoch: 165:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.89it/s, loss=25.5]train epoch: 165:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.89it/s, loss=29.1]train epoch: 165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s, loss=29.1]train epoch: 165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=29.1]
[[032m2021-11-26 10:33:52,316[0m INFO] trainer.training_epoch Training epoch 165, num_steps 1328,  avg_loss: 30.1895, total_loss: 241.5158
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.06it/s]
[[032m2021-11-26 10:33:52,774[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:52,775[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:52,992[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 166:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 166:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.6]train epoch: 166:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=27.6]train epoch: 166:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=20.4]train epoch: 166:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=20.4]train epoch: 166:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=37.4]train epoch: 166:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.48it/s, loss=37.4]train epoch: 166:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.48it/s, loss=25.5]train epoch: 166:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=25.5]train epoch: 166:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=30.1]train epoch: 166:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.31it/s, loss=30.1]train epoch: 166:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.31it/s, loss=29.5]train epoch: 166:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.56it/s, loss=29.5]train epoch: 166:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.56it/s, loss=32.4]train epoch: 166:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=32.4]train epoch: 166:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=25.3]train epoch: 166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s, loss=25.3]train epoch: 166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=25.3]
[[032m2021-11-26 10:33:55,284[0m INFO] trainer.training_epoch Training epoch 166, num_steps 1336,  avg_loss: 28.5263, total_loss: 228.2102
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.20it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.69it/s]
[[032m2021-11-26 10:33:55,716[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:55,716[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:55,938[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 167:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 167:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.4]train epoch: 167:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.18it/s, loss=27.4]train epoch: 167:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.18it/s, loss=30.1]train epoch: 167:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=30.1]train epoch: 167:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=29.7]train epoch: 167:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.25it/s, loss=29.7]train epoch: 167:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.25it/s, loss=27]  train epoch: 167:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.83it/s, loss=27]train epoch: 167:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s, loss=31.8]train epoch: 167:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=31.8]train epoch: 167:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=21.8]train epoch: 167:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.82it/s, loss=21.8]train epoch: 167:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.82it/s, loss=38.2]train epoch: 167:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.09it/s, loss=38.2]train epoch: 167:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.09it/s, loss=21.6]train epoch: 167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.16it/s, loss=21.6]train epoch: 167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.09it/s, loss=21.6]
[[032m2021-11-26 10:33:57,899[0m INFO] trainer.training_epoch Training epoch 167, num_steps 1344,  avg_loss: 28.4475, total_loss: 227.5801
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.15it/s]
[[032m2021-11-26 10:33:58,272[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:33:58,272[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:33:58,495[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 168:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 168:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.5]train epoch: 168:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=29.5]train epoch: 168:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=32.1]train epoch: 168:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.77it/s, loss=32.1]train epoch: 168:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.77it/s, loss=30]  train epoch: 168:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.52it/s, loss=30]train epoch: 168:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.52it/s, loss=22.2]train epoch: 168:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.75it/s, loss=22.2]train epoch: 168:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.75it/s, loss=27.3]train epoch: 168:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=27.3]train epoch: 168:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=21.7]train epoch: 168:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.06it/s, loss=21.7]train epoch: 168:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.06it/s, loss=32.2]train epoch: 168:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=32.2]train epoch: 168:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=19.7]train epoch: 168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=19.7]train epoch: 168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=19.7]
[[032m2021-11-26 10:34:00,937[0m INFO] trainer.training_epoch Training epoch 168, num_steps 1352,  avg_loss: 26.8361, total_loss: 214.6892
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.33it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.52it/s]
[[032m2021-11-26 10:34:01,331[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:34:01,331[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:01,548[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 169:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 169:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.4]train epoch: 169:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=27.4]train epoch: 169:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=23.8]train epoch: 169:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=23.8]train epoch: 169:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=32.6]train epoch: 169:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=32.6]train epoch: 169:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=31]  train epoch: 169:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.82it/s, loss=31]train epoch: 169:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.82it/s, loss=24.3]train epoch: 169:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=24.3]train epoch: 169:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=36.1]train epoch: 169:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.24it/s, loss=36.1]train epoch: 169:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.24it/s, loss=26]  train epoch: 169:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.06it/s, loss=26]train epoch: 169:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.06it/s, loss=32.4]train epoch: 169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s, loss=32.4]train epoch: 169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=32.4]
[[032m2021-11-26 10:34:03,868[0m INFO] trainer.training_epoch Training epoch 169, num_steps 1360,  avg_loss: 29.1980, total_loss: 233.5843
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.83it/s]
[[032m2021-11-26 10:34:04,254[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:04,254[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:04,467[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 170:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 170:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.1]train epoch: 170:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.06it/s, loss=23.1]train epoch: 170:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.06it/s, loss=30.9]train epoch: 170:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.64it/s, loss=30.9]train epoch: 170:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.64it/s, loss=23.2]train epoch: 170:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=23.2]train epoch: 170:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=30.7]train epoch: 170:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.19it/s, loss=30.7]train epoch: 170:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.19it/s, loss=23.1]train epoch: 170:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.81it/s, loss=23.1]train epoch: 170:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.81it/s, loss=31.1]train epoch: 170:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.71it/s, loss=31.1]train epoch: 170:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.71it/s, loss=26.1]train epoch: 170:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.63it/s, loss=26.1]train epoch: 170:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.63it/s, loss=27.7]train epoch: 170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=27.7]train epoch: 170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.73it/s, loss=27.7]
[[032m2021-11-26 10:34:06,615[0m INFO] trainer.training_epoch Training epoch 170, num_steps 1368,  avg_loss: 26.9822, total_loss: 215.8579
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.71it/s]
[[032m2021-11-26 10:34:07,010[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:07,010[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:07,236[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 171:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 171:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.2]train epoch: 171:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.27it/s, loss=21.2]train epoch: 171:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.27it/s, loss=29.9]train epoch: 171:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=29.9]train epoch: 171:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=25.6]train epoch: 171:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.46it/s, loss=25.6]train epoch: 171:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.46it/s, loss=23.7]train epoch: 171:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.53it/s, loss=23.7]train epoch: 171:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.53it/s, loss=26.3]train epoch: 171:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.56it/s, loss=26.3]train epoch: 171:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.56it/s, loss=27.8]train epoch: 171:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.36it/s, loss=27.8]train epoch: 171:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.36it/s, loss=32.4]train epoch: 171:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=32.4]train epoch: 171:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=22.2]train epoch: 171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.85it/s, loss=22.2]train epoch: 171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.16it/s, loss=22.2]
[[032m2021-11-26 10:34:09,167[0m INFO] trainer.training_epoch Training epoch 171, num_steps 1376,  avg_loss: 26.1485, total_loss: 209.1884
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.15it/s]
[[032m2021-11-26 10:34:09,762[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:09,762[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:09,998[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 172:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 172:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.1]train epoch: 172:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=26.1]train epoch: 172:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=32.1]train epoch: 172:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=32.1]train epoch: 172:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=30.4]train epoch: 172:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=30.4]train epoch: 172:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=22.6]train epoch: 172:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.20it/s, loss=22.6]train epoch: 172:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.20it/s, loss=21.3]train epoch: 172:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.16it/s, loss=21.3]train epoch: 172:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.16it/s, loss=25.6]train epoch: 172:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.30it/s, loss=25.6]train epoch: 172:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.30it/s, loss=27.9]train epoch: 172:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.32it/s, loss=27.9]train epoch: 172:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.32it/s, loss=31.6]train epoch: 172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.24it/s, loss=31.6]train epoch: 172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.26it/s, loss=31.6]
[[032m2021-11-26 10:34:11,880[0m INFO] trainer.training_epoch Training epoch 172, num_steps 1384,  avg_loss: 27.1908, total_loss: 217.5265
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.49it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.91it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.35it/s]
[[032m2021-11-26 10:34:12,451[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:12,451[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:13,029[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 173:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 173:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.3]train epoch: 173:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.70it/s, loss=36.3]train epoch: 173:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.70it/s, loss=24.7]train epoch: 173:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=24.7]train epoch: 173:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=39.4]train epoch: 173:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=39.4]train epoch: 173:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=32.3]train epoch: 173:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.31it/s, loss=32.3]train epoch: 173:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.31it/s, loss=21.3]train epoch: 173:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=21.3]train epoch: 173:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=24.2]train epoch: 173:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.43it/s, loss=24.2]train epoch: 173:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.43it/s, loss=27.7]train epoch: 173:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.37it/s, loss=27.7]train epoch: 173:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.37it/s, loss=32.3]train epoch: 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.23it/s, loss=32.3]train epoch: 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.32it/s, loss=32.3]
[[032m2021-11-26 10:34:14,888[0m INFO] trainer.training_epoch Training epoch 173, num_steps 1392,  avg_loss: 29.7777, total_loss: 238.2217
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.22it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.56it/s]
[[032m2021-11-26 10:34:15,285[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:15,285[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:15,706[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 174:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 174:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 174:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=29.3]train epoch: 174:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=33.6]train epoch: 174:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.50it/s, loss=33.6]train epoch: 174:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.50it/s, loss=36.2]train epoch: 174:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.49it/s, loss=36.2]train epoch: 174:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.49it/s, loss=17.5]train epoch: 174:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s, loss=17.5]train epoch: 174:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s, loss=33.6]train epoch: 174:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=33.6]train epoch: 174:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=28]  train epoch: 174:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.27it/s, loss=28]train epoch: 174:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.27it/s, loss=25.6]train epoch: 174:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.15it/s, loss=25.6]train epoch: 174:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.15it/s, loss=23.2]train epoch: 174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.10it/s, loss=23.2]train epoch: 174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s, loss=23.2]
[[032m2021-11-26 10:34:17,740[0m INFO] trainer.training_epoch Training epoch 174, num_steps 1400,  avg_loss: 28.3809, total_loss: 227.0468
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.36it/s]
[[032m2021-11-26 10:34:18,107[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:18,107[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:18,516[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 175:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.4667, 0.5333],
        [0.4013, 0.5987],
        [0.3489, 0.6511],
        [0.5501, 0.4499],
        [0.6349, 0.3651],
        [0.3141, 0.6859],
        [0.4335, 0.5665],
        [0.4201, 0.5799]], device='cuda:0')

prompt tensor([[0.6129, 0.3871],
        [0.7519, 0.2481],
        [0.5328, 0.4672],
        [0.4405, 0.5595],
        [0.7221, 0.2779],
        [0.4918, 0.5082],
        [0.3536, 0.6464],
        [0.4016, 0.5984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 175:   0%|          | 0/8 [00:00<?, ?it/s, loss=38.1]train epoch: 175:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.31it/s, loss=38.1]train epoch: 175:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.31it/s, loss=25.9]train epoch: 175:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.04it/s, loss=25.9]train epoch: 175:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.04it/s, loss=33]  train epoch: 175:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.00it/s, loss=33]train epoch: 175:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.00it/s, loss=33.8]train epoch: 175:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.39it/s, loss=33.8]train epoch: 175:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.39it/s, loss=27.7]train epoch: 175:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.63it/s, loss=27.7]train epoch: 175:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.63it/s, loss=22.7]train epoch: 175:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=22.7]train epoch: 175:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=24.1]train epoch: 175:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.04it/s, loss=24.1]train epoch: 175:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.04it/s, loss=26.2]train epoch: 175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.24it/s, loss=26.2]train epoch: 175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=26.2]
[[032m2021-11-26 10:34:20,656[0m INFO] trainer.training_epoch Training epoch 175, num_steps 1408,  avg_loss: 28.9416, total_loss: 231.5326
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.31it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.59it/s]
[[032m2021-11-26 10:34:21,052[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:21,052[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:21,392[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 176:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 176:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.4]train epoch: 176:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=22.4]train epoch: 176:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=23.7]train epoch: 176:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=23.7]train epoch: 176:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=23.9]train epoch: 176:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.38it/s, loss=23.9]train epoch: 176:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.38it/s, loss=33.2]train epoch: 176:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.36it/s, loss=33.2]train epoch: 176:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.36it/s, loss=30.7]train epoch: 176:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s, loss=30.7]train epoch: 176:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s, loss=27]  train epoch: 176:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.77it/s, loss=27]train epoch: 176:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.77it/s, loss=26.1]train epoch: 176:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.90it/s, loss=26.1]train epoch: 176:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.90it/s, loss=19.8]train epoch: 176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.06it/s, loss=19.8]train epoch: 176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.93it/s, loss=19.8]
[[032m2021-11-26 10:34:23,439[0m INFO] trainer.training_epoch Training epoch 176, num_steps 1416,  avg_loss: 25.8471, total_loss: 206.7771
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.07it/s]
[[032m2021-11-26 10:34:23,820[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:23,821[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:24,075[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 177:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 177:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 177:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.01it/s, loss=30.2]train epoch: 177:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.01it/s, loss=27.6]train epoch: 177:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.17it/s, loss=27.6]train epoch: 177:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.17it/s, loss=27.4]train epoch: 177:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=27.4]train epoch: 177:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=29]  train epoch: 177:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=29]train epoch: 177:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=35]train epoch: 177:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.66it/s, loss=35]train epoch: 177:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.66it/s, loss=26.1]train epoch: 177:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.76it/s, loss=26.1]train epoch: 177:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.76it/s, loss=28.6]train epoch: 177:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.90it/s, loss=28.6]train epoch: 177:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.90it/s, loss=28.1]train epoch: 177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=28.1]train epoch: 177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.79it/s, loss=28.1]
[[032m2021-11-26 10:34:26,191[0m INFO] trainer.training_epoch Training epoch 177, num_steps 1424,  avg_loss: 28.9974, total_loss: 231.9789
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.31it/s]
[[032m2021-11-26 10:34:26,560[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:26,560[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:26,774[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 178:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 178:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.9]train epoch: 178:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.14it/s, loss=28.9]train epoch: 178:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.14it/s, loss=31.8]train epoch: 178:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.55it/s, loss=31.8]train epoch: 178:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.55it/s, loss=29.9]train epoch: 178:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.03it/s, loss=29.9]train epoch: 178:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.03it/s, loss=34.6]train epoch: 178:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=34.6]train epoch: 178:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=27.2]train epoch: 178:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.29it/s, loss=27.2]train epoch: 178:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.29it/s, loss=33.7]train epoch: 178:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.63it/s, loss=33.7]train epoch: 178:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.63it/s, loss=25.3]train epoch: 178:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=25.3]train epoch: 178:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=25.8]train epoch: 178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=25.8]train epoch: 178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s, loss=25.8]
[[032m2021-11-26 10:34:29,099[0m INFO] trainer.training_epoch Training epoch 178, num_steps 1432,  avg_loss: 29.6604, total_loss: 237.2829
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.35it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.00it/s]
[[032m2021-11-26 10:34:29,514[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:34:29,515[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:29,731[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 179:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 179:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.2]train epoch: 179:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.27it/s, loss=28.2]train epoch: 179:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.27it/s, loss=27.5]train epoch: 179:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=27.5]train epoch: 179:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=27]  train epoch: 179:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=27]train epoch: 179:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=33.1]train epoch: 179:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=33.1]train epoch: 179:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=34.4]train epoch: 179:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=34.4]train epoch: 179:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=24.7]train epoch: 179:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=24.7]train epoch: 179:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=32]  train epoch: 179:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.81it/s, loss=32]train epoch: 179:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.81it/s, loss=27]train epoch: 179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.05it/s, loss=27]train epoch: 179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=27]
[[032m2021-11-26 10:34:31,839[0m INFO] trainer.training_epoch Training epoch 179, num_steps 1440,  avg_loss: 29.2405, total_loss: 233.9243
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.40it/s]
[[032m2021-11-26 10:34:32,206[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:34:32,206[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:32,431[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 180:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 180:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.5]train epoch: 180:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=30.5]train epoch: 180:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.25it/s, loss=25.2]train epoch: 180:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.09it/s, loss=25.2]train epoch: 180:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.09it/s, loss=29.3]train epoch: 180:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.83it/s, loss=29.3]train epoch: 180:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.83it/s, loss=29.8]train epoch: 180:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=29.8]train epoch: 180:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=25.6]train epoch: 180:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.07it/s, loss=25.6]train epoch: 180:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.07it/s, loss=32.8]train epoch: 180:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s, loss=32.8]train epoch: 180:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.40it/s, loss=26.2]train epoch: 180:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.71it/s, loss=26.2]train epoch: 180:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.71it/s, loss=31.2]train epoch: 180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s, loss=31.2]train epoch: 180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=31.2]
[[032m2021-11-26 10:34:34,740[0m INFO] trainer.training_epoch Training epoch 180, num_steps 1448,  avg_loss: 28.8303, total_loss: 230.6425
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.82it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.53it/s]
[[032m2021-11-26 10:34:35,178[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:34:35,179[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:35,398[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 181:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 181:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.9]train epoch: 181:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.89it/s, loss=29.9]train epoch: 181:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.89it/s, loss=24.2]train epoch: 181:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.43it/s, loss=24.2]train epoch: 181:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.43it/s, loss=28.2]train epoch: 181:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.81it/s, loss=28.2]train epoch: 181:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.81it/s, loss=27.3]train epoch: 181:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.10it/s, loss=27.3]train epoch: 181:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.10it/s, loss=28.1]train epoch: 181:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=28.1]train epoch: 181:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=31.9]train epoch: 181:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s, loss=31.9]train epoch: 181:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.36it/s, loss=34.4]train epoch: 181:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.70it/s, loss=34.4]train epoch: 181:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.70it/s, loss=36.4]train epoch: 181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.85it/s, loss=36.4]train epoch: 181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=36.4]
[[032m2021-11-26 10:34:37,690[0m INFO] trainer.training_epoch Training epoch 181, num_steps 1456,  avg_loss: 30.0387, total_loss: 240.3098
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.25it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.52it/s]
[[032m2021-11-26 10:34:38,096[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:34:38,097[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:38,317[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 182:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 182:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.9]train epoch: 182:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=31.9]train epoch: 182:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=35.1]train epoch: 182:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=35.1]train epoch: 182:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=33]  train epoch: 182:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.84it/s, loss=33]train epoch: 182:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.84it/s, loss=24]train epoch: 182:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=24]train epoch: 182:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=29]train epoch: 182:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=29]train epoch: 182:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=21.9]train epoch: 182:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.50it/s, loss=21.9]train epoch: 182:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.50it/s, loss=22.1]train epoch: 182:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.73it/s, loss=22.1]train epoch: 182:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.73it/s, loss=27.8]train epoch: 182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.00it/s, loss=27.8]train epoch: 182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.61it/s, loss=27.8]
[[032m2021-11-26 10:34:40,541[0m INFO] trainer.training_epoch Training epoch 182, num_steps 1464,  avg_loss: 28.0940, total_loss: 224.7517
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.16it/s]
[[032m2021-11-26 10:34:40,913[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:40,913[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:41,129[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 183:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 183:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 183:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.24it/s, loss=29.8]train epoch: 183:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.24it/s, loss=28.3]train epoch: 183:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=28.3]train epoch: 183:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=22.7]train epoch: 183:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.95it/s, loss=22.7]train epoch: 183:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.95it/s, loss=27.8]train epoch: 183:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=27.8]train epoch: 183:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=24.1]train epoch: 183:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=24.1]train epoch: 183:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=31.5]train epoch: 183:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s, loss=31.5]train epoch: 183:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s, loss=28.2]train epoch: 183:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.67it/s, loss=28.2]train epoch: 183:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.67it/s, loss=29.1]train epoch: 183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.79it/s, loss=29.1]train epoch: 183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.61it/s, loss=29.1]
[[032m2021-11-26 10:34:43,348[0m INFO] trainer.training_epoch Training epoch 183, num_steps 1472,  avg_loss: 27.7020, total_loss: 221.6161
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.35it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.47it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.81it/s]
[[032m2021-11-26 10:34:43,777[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:43,777[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:43,995[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 184:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 184:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 184:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.06it/s, loss=25]train epoch: 184:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.06it/s, loss=29.2]train epoch: 184:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=29.2]train epoch: 184:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=25.6]train epoch: 184:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=25.6]train epoch: 184:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=24.2]train epoch: 184:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.15it/s, loss=24.2]train epoch: 184:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.15it/s, loss=41.9]train epoch: 184:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.05it/s, loss=41.9]train epoch: 184:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.05it/s, loss=21.3]train epoch: 184:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.29it/s, loss=21.3]train epoch: 184:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.29it/s, loss=26]  train epoch: 184:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.62it/s, loss=26]train epoch: 184:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.62it/s, loss=22]train epoch: 184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.75it/s, loss=22]train epoch: 184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.54it/s, loss=22]
[[032m2021-11-26 10:34:46,260[0m INFO] trainer.training_epoch Training epoch 184, num_steps 1480,  avg_loss: 26.8954, total_loss: 215.1630
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.40it/s]
[[032m2021-11-26 10:34:46,627[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:46,627[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:46,832[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 185:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 185:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.5]train epoch: 185:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=33.5]train epoch: 185:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=32.9]train epoch: 185:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.63it/s, loss=32.9]train epoch: 185:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.63it/s, loss=22.9]train epoch: 185:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.52it/s, loss=22.9]train epoch: 185:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.52it/s, loss=27.5]train epoch: 185:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.62it/s, loss=27.5]train epoch: 185:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.62it/s, loss=23.1]train epoch: 185:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.84it/s, loss=23.1]train epoch: 185:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.84it/s, loss=28.1]train epoch: 185:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=28.1]train epoch: 185:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.14it/s, loss=22.6]train epoch: 185:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=22.6]train epoch: 185:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=35]  train epoch: 185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=35]train epoch: 185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=35]
[[032m2021-11-26 10:34:49,268[0m INFO] trainer.training_epoch Training epoch 185, num_steps 1488,  avg_loss: 28.1908, total_loss: 225.5261
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.12it/s]
[[032m2021-11-26 10:34:49,647[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:34:49,647[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:49,868[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 186:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 186:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.4]train epoch: 186:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.25it/s, loss=29.4]train epoch: 186:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.25it/s, loss=35.2]train epoch: 186:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.89it/s, loss=35.2]train epoch: 186:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.89it/s, loss=30]  train epoch: 186:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.09it/s, loss=30]train epoch: 186:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.09it/s, loss=30.1]train epoch: 186:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.02it/s, loss=30.1]train epoch: 186:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.02it/s, loss=31.7]train epoch: 186:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=31.7]train epoch: 186:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=21.5]train epoch: 186:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s, loss=21.5]train epoch: 186:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s, loss=21.7]train epoch: 186:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.22it/s, loss=21.7]train epoch: 186:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=28.3]train epoch: 186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=28.3]train epoch: 186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=28.3]
[[032m2021-11-26 10:34:52,177[0m INFO] trainer.training_epoch Training epoch 186, num_steps 1496,  avg_loss: 28.4846, total_loss: 227.8770
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.53it/s]
[[032m2021-11-26 10:34:52,619[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:52,619[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:52,841[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 187:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 187:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.2]train epoch: 187:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.28it/s, loss=27.2]train epoch: 187:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.28it/s, loss=27.8]train epoch: 187:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.71it/s, loss=27.8]train epoch: 187:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.71it/s, loss=23.2]train epoch: 187:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.28it/s, loss=23.2]train epoch: 187:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.28it/s, loss=26.9]train epoch: 187:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.43it/s, loss=26.9]
model tensor([[0.5258, 0.4742],
        [0.6310, 0.3690],
        [0.8361, 0.1639],
        [0.7454, 0.2546],
        [0.4335, 0.5665],
        [0.5964, 0.4036],
        [0.3053, 0.6947],
        [0.2873, 0.7127]], device='cuda:0')

prompt tensor([[0.5578, 0.4422],
        [0.7170, 0.2830],
        [0.8648, 0.1352],
        [0.7979, 0.2021],
        [0.5719, 0.4281],
        [0.4901, 0.5099],
        [0.5785, 0.4215],
        [0.5316, 0.4684]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 187:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.43it/s, loss=21.4]train epoch: 187:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=21.4]train epoch: 187:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=28]  train epoch: 187:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s, loss=28]train epoch: 187:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s, loss=26.2]train epoch: 187:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.50it/s, loss=26.2]train epoch: 187:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=29.7]train epoch: 187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.75it/s, loss=29.7]train epoch: 187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=29.7]
[[032m2021-11-26 10:34:55,056[0m INFO] trainer.training_epoch Training epoch 187, num_steps 1504,  avg_loss: 26.3161, total_loss: 210.5288
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.54it/s]
[[032m2021-11-26 10:34:55,496[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:34:55,497[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:55,722[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 188:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 188:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.9]train epoch: 188:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.52it/s, loss=30.9]train epoch: 188:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.52it/s, loss=26.5]train epoch: 188:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.56it/s, loss=26.5]train epoch: 188:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.56it/s, loss=35.9]train epoch: 188:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=35.9]train epoch: 188:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=30.2]train epoch: 188:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.27it/s, loss=30.2]train epoch: 188:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.27it/s, loss=23.2]train epoch: 188:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.82it/s, loss=23.2]train epoch: 188:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.82it/s, loss=23.7]train epoch: 188:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.84it/s, loss=23.7]train epoch: 188:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.84it/s, loss=25.8]train epoch: 188:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.92it/s, loss=25.8]train epoch: 188:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.92it/s, loss=23.3]train epoch: 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=23.3]train epoch: 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.72it/s, loss=23.3]
[[032m2021-11-26 10:34:57,877[0m INFO] trainer.training_epoch Training epoch 188, num_steps 1512,  avg_loss: 27.4268, total_loss: 219.4143
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.19it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.88it/s]
[[032m2021-11-26 10:34:58,348[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:34:58,348[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:34:58,572[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 189:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 189:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.7]train epoch: 189:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=22.7]train epoch: 189:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=22.1]train epoch: 189:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.94it/s, loss=22.1]train epoch: 189:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.94it/s, loss=34.4]train epoch: 189:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=34.4]train epoch: 189:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=38.6]train epoch: 189:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.48it/s, loss=38.6]train epoch: 189:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.48it/s, loss=28.1]train epoch: 189:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=28.1]train epoch: 189:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=22.9]train epoch: 189:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=22.9]train epoch: 189:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=26.9]train epoch: 189:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.41it/s, loss=26.9]train epoch: 189:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.41it/s, loss=28.6]train epoch: 189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.26it/s, loss=28.6]train epoch: 189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.40it/s, loss=28.6]
[[032m2021-11-26 10:35:00,394[0m INFO] trainer.training_epoch Training epoch 189, num_steps 1520,  avg_loss: 28.0251, total_loss: 224.2005
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.59it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.19it/s]
[[032m2021-11-26 10:35:00,807[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:35:00,808[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:01,181[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 190:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 190:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.6]train epoch: 190:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=31.6]train epoch: 190:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=29.5]train epoch: 190:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=29.5]train epoch: 190:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=26.4]train epoch: 190:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.06it/s, loss=26.4]train epoch: 190:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.06it/s, loss=23.9]train epoch: 190:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.20it/s, loss=23.9]train epoch: 190:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.20it/s, loss=22.1]train epoch: 190:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.35it/s, loss=22.1]train epoch: 190:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.35it/s, loss=29.9]train epoch: 190:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.39it/s, loss=29.9]train epoch: 190:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.39it/s, loss=20.6]train epoch: 190:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.45it/s, loss=20.6]train epoch: 190:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.45it/s, loss=17.3]train epoch: 190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.32it/s, loss=17.3]train epoch: 190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.33it/s, loss=17.3]
[[032m2021-11-26 10:35:03,037[0m INFO] trainer.training_epoch Training epoch 190, num_steps 1528,  avg_loss: 25.1485, total_loss: 201.1877
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.22it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.28it/s]
[[032m2021-11-26 10:35:03,546[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:35:03,547[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:04,170[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 191:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 191:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.2]train epoch: 191:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.26it/s, loss=31.2]train epoch: 191:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.26it/s, loss=30]  train epoch: 191:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=30]train epoch: 191:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=28.7]train epoch: 191:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=28.7]train epoch: 191:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=27.3]train epoch: 191:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.21it/s, loss=27.3]train epoch: 191:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.21it/s, loss=32.2]train epoch: 191:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.27it/s, loss=32.2]train epoch: 191:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.27it/s, loss=18.9]train epoch: 191:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.43it/s, loss=18.9]train epoch: 191:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.43it/s, loss=28]  train epoch: 191:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.43it/s, loss=28]train epoch: 191:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.43it/s, loss=35.3]train epoch: 191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.28it/s, loss=35.3]train epoch: 191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.27it/s, loss=35.3]
[[032m2021-11-26 10:35:06,049[0m INFO] trainer.training_epoch Training epoch 191, num_steps 1536,  avg_loss: 28.9279, total_loss: 231.4229
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.20it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.15it/s]
[[032m2021-11-26 10:35:06,748[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:35:06,749[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:07,130[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 192:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 192:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.3]train epoch: 192:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.49it/s, loss=19.3]train epoch: 192:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.49it/s, loss=23.6]train epoch: 192:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=23.6]train epoch: 192:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=26.4]train epoch: 192:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.97it/s, loss=26.4]train epoch: 192:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.97it/s, loss=27.2]train epoch: 192:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.06it/s, loss=27.2]train epoch: 192:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.06it/s, loss=30]  train epoch: 192:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=30]train epoch: 192:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=31.1]train epoch: 192:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.42it/s, loss=31.1]train epoch: 192:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.42it/s, loss=25.2]train epoch: 192:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.32it/s, loss=25.2]train epoch: 192:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.32it/s, loss=37.4]train epoch: 192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.90it/s, loss=37.4]train epoch: 192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.03it/s, loss=37.4]
[[032m2021-11-26 10:35:09,127[0m INFO] trainer.training_epoch Training epoch 192, num_steps 1544,  avg_loss: 27.5199, total_loss: 220.1593
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.29it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.16it/s]
[[032m2021-11-26 10:35:09,797[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:09,797[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:10,292[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 193:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 193:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.4]train epoch: 193:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.81it/s, loss=27.4]train epoch: 193:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.81it/s, loss=39.7]train epoch: 193:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=39.7]train epoch: 193:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=27.9]train epoch: 193:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=27.9]train epoch: 193:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.00it/s, loss=29.5]train epoch: 193:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.82it/s, loss=29.5]train epoch: 193:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.82it/s, loss=27.4]train epoch: 193:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.07it/s, loss=27.4]train epoch: 193:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.07it/s, loss=26.7]train epoch: 193:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.08it/s, loss=26.7]train epoch: 193:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.08it/s, loss=34.1]train epoch: 193:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=34.1]train epoch: 193:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=27.5]train epoch: 193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.04it/s, loss=27.5]train epoch: 193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.00it/s, loss=27.5]
[[032m2021-11-26 10:35:12,297[0m INFO] trainer.training_epoch Training epoch 193, num_steps 1552,  avg_loss: 30.0229, total_loss: 240.1830
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.71it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.58it/s]
[[032m2021-11-26 10:35:12,733[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:12,733[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:13,206[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 194:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 194:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.4]train epoch: 194:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.92it/s, loss=31.4]train epoch: 194:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.92it/s, loss=33.5]train epoch: 194:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=33.5]train epoch: 194:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=31.5]train epoch: 194:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=31.5]train epoch: 194:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=26]  train epoch: 194:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.21it/s, loss=26]train epoch: 194:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.21it/s, loss=25]train epoch: 194:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=25]train epoch: 194:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=26.9]train epoch: 194:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=26.9]train epoch: 194:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=38.1]train epoch: 194:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.31it/s, loss=38.1]train epoch: 194:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.31it/s, loss=19.9]train epoch: 194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.19it/s, loss=19.9]train epoch: 194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.19it/s, loss=19.9]
[[032m2021-11-26 10:35:15,122[0m INFO] trainer.training_epoch Training epoch 194, num_steps 1560,  avg_loss: 29.0281, total_loss: 232.2247
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.58it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.63it/s]
[[032m2021-11-26 10:35:15,616[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:15,616[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:16,052[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 195:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 195:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.7]train epoch: 195:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.64it/s, loss=28.7]train epoch: 195:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.64it/s, loss=26.6]train epoch: 195:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.96it/s, loss=26.6]train epoch: 195:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.96it/s, loss=25.1]train epoch: 195:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s, loss=25.1]train epoch: 195:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s, loss=36.9]train epoch: 195:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.39it/s, loss=36.9]train epoch: 195:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.39it/s, loss=26.9]train epoch: 195:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=26.9]train epoch: 195:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=34.2]train epoch: 195:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.07it/s, loss=34.2]train epoch: 195:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.07it/s, loss=27.6]train epoch: 195:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.23it/s, loss=27.6]train epoch: 195:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.23it/s, loss=32.3]train epoch: 195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.25it/s, loss=32.3]train epoch: 195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.21it/s, loss=32.3]
[[032m2021-11-26 10:35:17,964[0m INFO] trainer.training_epoch Training epoch 195, num_steps 1568,  avg_loss: 29.7855, total_loss: 238.2837
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.44it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.86it/s]
[[032m2021-11-26 10:35:18,387[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:35:18,387[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:18,638[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 196:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 196:   0%|          | 0/8 [00:00<?, ?it/s, loss=22]train epoch: 196:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.76it/s, loss=22]train epoch: 196:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.76it/s, loss=28.8]train epoch: 196:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.76it/s, loss=28.8]train epoch: 196:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.76it/s, loss=27.4]train epoch: 196:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.04it/s, loss=27.4]train epoch: 196:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.04it/s, loss=24.4]train epoch: 196:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=24.4]train epoch: 196:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=24.4]train epoch: 196:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.81it/s, loss=24.4]train epoch: 196:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.81it/s, loss=29.6]train epoch: 196:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.88it/s, loss=29.6]train epoch: 196:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.88it/s, loss=29.8]train epoch: 196:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.87it/s, loss=29.8]train epoch: 196:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.87it/s, loss=24.8]train epoch: 196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=24.8]train epoch: 196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.79it/s, loss=24.8]
[[032m2021-11-26 10:35:20,757[0m INFO] trainer.training_epoch Training epoch 196, num_steps 1576,  avg_loss: 26.3842, total_loss: 211.0738
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]
[[032m2021-11-26 10:35:21,178[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:35:21,178[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:21,464[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 197:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 197:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 197:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=27.9]train epoch: 197:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=22.5]train epoch: 197:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=22.5]train epoch: 197:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=30.9]train epoch: 197:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=30.9]train epoch: 197:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=28.2]train epoch: 197:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=28.2]train epoch: 197:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=28.1]train epoch: 197:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=28.1]train epoch: 197:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.55it/s, loss=23.9]train epoch: 197:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=23.9]train epoch: 197:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=30.1]train epoch: 197:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.93it/s, loss=30.1]train epoch: 197:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.93it/s, loss=23.5]train epoch: 197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.04it/s, loss=23.5]train epoch: 197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=23.5]
[[032m2021-11-26 10:35:23,598[0m INFO] trainer.training_epoch Training epoch 197, num_steps 1584,  avg_loss: 26.8896, total_loss: 215.1170
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.23it/s]
[[032m2021-11-26 10:35:23,975[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:35:23,976[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:24,194[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 198:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 198:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 198:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=25.5]train epoch: 198:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=29.8]train epoch: 198:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.43it/s, loss=29.8]train epoch: 198:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.43it/s, loss=26.6]train epoch: 198:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.89it/s, loss=26.6]train epoch: 198:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.89it/s, loss=31.2]train epoch: 198:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.80it/s, loss=31.2]train epoch: 198:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.80it/s, loss=29.3]train epoch: 198:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.81it/s, loss=29.3]train epoch: 198:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.81it/s, loss=22.6]train epoch: 198:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.69it/s, loss=22.6]train epoch: 198:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.69it/s, loss=24.7]train epoch: 198:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.75it/s, loss=24.7]train epoch: 198:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.75it/s, loss=26.9]train epoch: 198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.91it/s, loss=26.9]train epoch: 198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s, loss=26.9]
[[032m2021-11-26 10:35:26,294[0m INFO] trainer.training_epoch Training epoch 198, num_steps 1592,  avg_loss: 27.0748, total_loss: 216.5986
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.31it/s]
[[032m2021-11-26 10:35:26,744[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:26,744[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:26,957[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 199:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 199:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 199:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.80it/s, loss=24.9]train epoch: 199:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.80it/s, loss=22.5]train epoch: 199:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.13it/s, loss=22.5]train epoch: 199:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.13it/s, loss=27.9]train epoch: 199:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.63it/s, loss=27.9]train epoch: 199:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.63it/s, loss=22.7]train epoch: 199:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s, loss=22.7]train epoch: 199:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s, loss=29.1]train epoch: 199:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=29.1]train epoch: 199:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=28]  train epoch: 199:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.00it/s, loss=28]train epoch: 199:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.00it/s, loss=28.4]train epoch: 199:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.31it/s, loss=28.4]train epoch: 199:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.31it/s, loss=31.2]train epoch: 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=31.2]train epoch: 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.54it/s, loss=31.2]
[[032m2021-11-26 10:35:29,223[0m INFO] trainer.training_epoch Training epoch 199, num_steps 1600,  avg_loss: 26.8162, total_loss: 214.5295
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.74it/s]
[[032m2021-11-26 10:35:29,652[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:29,652[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:29,878[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 200:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3884, 0.6116],
        [0.7036, 0.2964],
        [0.4383, 0.5617],
        [0.7103, 0.2897],
        [0.6493, 0.3507],
        [0.3806, 0.6194],
        [0.5443, 0.4557],
        [0.3744, 0.6256]], device='cuda:0')

prompt tensor([[0.6567, 0.3433],
        [0.7374, 0.2626],
        [0.4877, 0.5123],
        [0.6582, 0.3418],
        [0.7311, 0.2689],
        [0.5061, 0.4939],
        [0.6926, 0.3074],
        [0.7859, 0.2141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 200:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 200:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.12it/s, loss=23.6]train epoch: 200:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.12it/s, loss=24.2]train epoch: 200:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.68it/s, loss=24.2]train epoch: 200:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.68it/s, loss=27.1]train epoch: 200:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.43it/s, loss=27.1]train epoch: 200:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.43it/s, loss=22.6]train epoch: 200:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.17it/s, loss=22.6]train epoch: 200:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.17it/s, loss=22.5]train epoch: 200:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=22.5]train epoch: 200:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=25.2]train epoch: 200:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.88it/s, loss=25.2]train epoch: 200:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.88it/s, loss=29.1]train epoch: 200:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.21it/s, loss=29.1]train epoch: 200:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=33.4]train epoch: 200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=33.4]train epoch: 200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.61it/s, loss=33.4]
[[032m2021-11-26 10:35:32,103[0m INFO] trainer.training_epoch Training epoch 200, num_steps 1608,  avg_loss: 25.9521, total_loss: 207.6166
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.55it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.66it/s]
[[032m2021-11-26 10:35:32,582[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:35:32,582[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:32,805[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 201:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 201:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.1]train epoch: 201:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.28it/s, loss=24.1]train epoch: 201:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.28it/s, loss=20.3]train epoch: 201:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=20.3]train epoch: 201:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=26.9]train epoch: 201:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s, loss=26.9]train epoch: 201:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s, loss=24.1]train epoch: 201:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.37it/s, loss=24.1]train epoch: 201:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.37it/s, loss=20.1]train epoch: 201:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=20.1]train epoch: 201:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=25.8]train epoch: 201:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.25it/s, loss=25.8]train epoch: 201:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.25it/s, loss=30.4]train epoch: 201:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.40it/s, loss=30.4]train epoch: 201:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.40it/s, loss=22.7]train epoch: 201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=22.7]train epoch: 201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=22.7]
[[032m2021-11-26 10:35:35,006[0m INFO] trainer.training_epoch Training epoch 201, num_steps 1616,  avg_loss: 24.2887, total_loss: 194.3095
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.77it/s]
[[032m2021-11-26 10:35:35,485[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:35:35,485[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:35,699[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 202:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 202:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.4]train epoch: 202:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=35.4]train epoch: 202:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=34.1]train epoch: 202:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.64it/s, loss=34.1]train epoch: 202:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.64it/s, loss=28.6]train epoch: 202:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s, loss=28.6]train epoch: 202:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s, loss=28.1]train epoch: 202:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.40it/s, loss=28.1]train epoch: 202:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.40it/s, loss=19.3]train epoch: 202:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.42it/s, loss=19.3]train epoch: 202:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.42it/s, loss=27]  train epoch: 202:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=27]train epoch: 202:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=28.5]train epoch: 202:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.99it/s, loss=28.5]train epoch: 202:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.99it/s, loss=26.3]train epoch: 202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.69it/s, loss=26.3]train epoch: 202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.07it/s, loss=26.3]
[[032m2021-11-26 10:35:37,670[0m INFO] trainer.training_epoch Training epoch 202, num_steps 1624,  avg_loss: 28.4058, total_loss: 227.2466
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.67it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.50it/s]
[[032m2021-11-26 10:35:38,184[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:38,185[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:38,518[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 203:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 203:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.4]train epoch: 203:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.44it/s, loss=23.4]train epoch: 203:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.44it/s, loss=21.9]train epoch: 203:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=21.9]train epoch: 203:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=33.4]train epoch: 203:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.11it/s, loss=33.4]train epoch: 203:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.11it/s, loss=29]  train epoch: 203:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.95it/s, loss=29]train epoch: 203:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s, loss=21.8]train epoch: 203:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=21.8]train epoch: 203:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=27]  train epoch: 203:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.31it/s, loss=27]train epoch: 203:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.31it/s, loss=31.4]train epoch: 203:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=31.4]train epoch: 203:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.17it/s, loss=34.5]train epoch: 203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s, loss=34.5]train epoch: 203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.69it/s, loss=34.5]
[[032m2021-11-26 10:35:40,689[0m INFO] trainer.training_epoch Training epoch 203, num_steps 1632,  avg_loss: 27.8034, total_loss: 222.4271
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.57it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.13it/s]
[[032m2021-11-26 10:35:41,148[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:35:41,148[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:41,444[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 204:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 204:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 204:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.16it/s, loss=29.3]train epoch: 204:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.16it/s, loss=31.3]train epoch: 204:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=31.3]train epoch: 204:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=26.2]train epoch: 204:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.31it/s, loss=26.2]train epoch: 204:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.31it/s, loss=24.2]train epoch: 204:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.19it/s, loss=24.2]train epoch: 204:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.19it/s, loss=21.5]train epoch: 204:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.32it/s, loss=21.5]train epoch: 204:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.32it/s, loss=21]  train epoch: 204:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.35it/s, loss=21]train epoch: 204:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.35it/s, loss=25.1]train epoch: 204:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.89it/s, loss=25.1]train epoch: 204:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.89it/s, loss=23.1]train epoch: 204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=23.1]train epoch: 204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.89it/s, loss=23.1]
[[032m2021-11-26 10:35:43,512[0m INFO] trainer.training_epoch Training epoch 204, num_steps 1640,  avg_loss: 25.1994, total_loss: 201.5952
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.27it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.76it/s]
[[032m2021-11-26 10:35:43,999[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:35:44,004[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:44,233[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 205:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 205:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.4]train epoch: 205:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=31.4]train epoch: 205:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=31.2]train epoch: 205:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.39it/s, loss=31.2]train epoch: 205:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.39it/s, loss=25]  train epoch: 205:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.18it/s, loss=25]train epoch: 205:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.18it/s, loss=26.7]train epoch: 205:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.14it/s, loss=26.7]train epoch: 205:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.14it/s, loss=31.4]train epoch: 205:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.99it/s, loss=31.4]train epoch: 205:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.99it/s, loss=28.2]train epoch: 205:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.12it/s, loss=28.2]train epoch: 205:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.12it/s, loss=36.8]train epoch: 205:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.71it/s, loss=36.8]train epoch: 205:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.71it/s, loss=17]  train epoch: 205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=17]train epoch: 205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=17]
[[032m2021-11-26 10:35:46,439[0m INFO] trainer.training_epoch Training epoch 205, num_steps 1648,  avg_loss: 28.4634, total_loss: 227.7075
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.53it/s]
[[032m2021-11-26 10:35:46,929[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:35:46,930[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:47,206[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 206:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 206:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.8]train epoch: 206:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=37.8]train epoch: 206:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=27.3]train epoch: 206:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.76it/s, loss=27.3]train epoch: 206:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.76it/s, loss=36.2]train epoch: 206:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=36.2]train epoch: 206:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=24.4]train epoch: 206:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.31it/s, loss=24.4]train epoch: 206:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.31it/s, loss=33.3]train epoch: 206:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.43it/s, loss=33.3]train epoch: 206:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.43it/s, loss=38.1]train epoch: 206:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.51it/s, loss=38.1]train epoch: 206:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.51it/s, loss=20.7]train epoch: 206:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.37it/s, loss=20.7]train epoch: 206:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.37it/s, loss=31.7]train epoch: 206: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.70it/s, loss=31.7]train epoch: 206: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.14it/s, loss=31.7]
[[032m2021-11-26 10:35:49,146[0m INFO] trainer.training_epoch Training epoch 206, num_steps 1656,  avg_loss: 31.2068, total_loss: 249.6547
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.78it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.87it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.49it/s]
[[032m2021-11-26 10:35:49,704[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:35:49,705[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:50,011[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 207:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 207:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.8]train epoch: 207:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=26.8]train epoch: 207:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=32.6]train epoch: 207:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.39it/s, loss=32.6]train epoch: 207:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.39it/s, loss=34.6]train epoch: 207:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=34.6]train epoch: 207:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=27.1]train epoch: 207:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.48it/s, loss=27.1]train epoch: 207:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.48it/s, loss=27]  train epoch: 207:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=27]train epoch: 207:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=25.8]train epoch: 207:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.30it/s, loss=25.8]train epoch: 207:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.30it/s, loss=27.1]train epoch: 207:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.08it/s, loss=27.1]train epoch: 207:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.08it/s, loss=25.6]train epoch: 207: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.82it/s, loss=25.6]train epoch: 207: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.10it/s, loss=25.6]
[[032m2021-11-26 10:35:51,967[0m INFO] trainer.training_epoch Training epoch 207, num_steps 1664,  avg_loss: 28.3197, total_loss: 226.5577
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.60it/s]
[[032m2021-11-26 10:35:52,476[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:52,476[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:52,968[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 208:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 208:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.7]train epoch: 208:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=35.7]train epoch: 208:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=31.3]train epoch: 208:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.45it/s, loss=31.3]train epoch: 208:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.45it/s, loss=39]  train epoch: 208:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.42it/s, loss=39]train epoch: 208:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.42it/s, loss=23.4]train epoch: 208:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.42it/s, loss=23.4]train epoch: 208:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.42it/s, loss=26.6]train epoch: 208:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=26.6]train epoch: 208:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=22.3]train epoch: 208:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=22.3]train epoch: 208:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=31]  train epoch: 208:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.13it/s, loss=31]train epoch: 208:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.13it/s, loss=29.3]train epoch: 208: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.07it/s, loss=29.3]train epoch: 208: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.20it/s, loss=29.3]
[[032m2021-11-26 10:35:54,877[0m INFO] trainer.training_epoch Training epoch 208, num_steps 1672,  avg_loss: 29.8248, total_loss: 238.5984
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.01it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.11it/s]
[[032m2021-11-26 10:35:55,468[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:35:55,469[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:55,841[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 209:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 209:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.6]train epoch: 209:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.96it/s, loss=33.6]train epoch: 209:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.96it/s, loss=30.3]train epoch: 209:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=30.3]train epoch: 209:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=27]  train epoch: 209:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.35it/s, loss=27]train epoch: 209:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.35it/s, loss=24.9]train epoch: 209:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.25it/s, loss=24.9]train epoch: 209:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.25it/s, loss=33.2]train epoch: 209:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.02it/s, loss=33.2]train epoch: 209:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.02it/s, loss=30.2]train epoch: 209:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.26it/s, loss=30.2]train epoch: 209:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.26it/s, loss=29.1]train epoch: 209:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.41it/s, loss=29.1]train epoch: 209:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.41it/s, loss=28.2]train epoch: 209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.48it/s, loss=28.2]train epoch: 209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.39it/s, loss=28.2]
[[032m2021-11-26 10:35:57,676[0m INFO] trainer.training_epoch Training epoch 209, num_steps 1680,  avg_loss: 29.5692, total_loss: 236.5534
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.32it/s]
[[032m2021-11-26 10:35:58,086[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:35:58,086[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:35:58,489[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 210:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 210:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.8]train epoch: 210:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=22.8]train epoch: 210:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=22.6]train epoch: 210:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.68it/s, loss=22.6]train epoch: 210:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.68it/s, loss=20.5]train epoch: 210:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.12it/s, loss=20.5]train epoch: 210:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.12it/s, loss=19.2]train epoch: 210:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=19.2]train epoch: 210:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=38.6]train epoch: 210:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.69it/s, loss=38.6]train epoch: 210:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.69it/s, loss=27]  train epoch: 210:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.98it/s, loss=27]train epoch: 210:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.98it/s, loss=30.6]train epoch: 210:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.15it/s, loss=30.6]train epoch: 210:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.15it/s, loss=24.3]train epoch: 210: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.18it/s, loss=24.3]train epoch: 210: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.80it/s, loss=24.3]
[[032m2021-11-26 10:36:00,606[0m INFO] trainer.training_epoch Training epoch 210, num_steps 1688,  avg_loss: 25.6970, total_loss: 205.5759
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.26it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.83it/s]
[[032m2021-11-26 10:36:01,135[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:01,135[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:01,762[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 211:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 211:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.1]train epoch: 211:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.20it/s, loss=19.1]train epoch: 211:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.20it/s, loss=22.5]train epoch: 211:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.60it/s, loss=22.5]train epoch: 211:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.60it/s, loss=25.4]train epoch: 211:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.68it/s, loss=25.4]train epoch: 211:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.68it/s, loss=24.6]train epoch: 211:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.01it/s, loss=24.6]train epoch: 211:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.01it/s, loss=26.4]train epoch: 211:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.11it/s, loss=26.4]train epoch: 211:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.11it/s, loss=27.2]train epoch: 211:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.05it/s, loss=27.2]train epoch: 211:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.05it/s, loss=22]  train epoch: 211:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.27it/s, loss=22]train epoch: 211:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.27it/s, loss=29.6]train epoch: 211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.14it/s, loss=29.6]train epoch: 211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.01it/s, loss=29.6]
[[032m2021-11-26 10:36:03,764[0m INFO] trainer.training_epoch Training epoch 211, num_steps 1696,  avg_loss: 24.5894, total_loss: 196.7152
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.89it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.24it/s]
[[032m2021-11-26 10:36:04,265[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:36:04,266[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:04,810[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 212:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 212:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.1]train epoch: 212:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.23it/s, loss=26.1]train epoch: 212:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.23it/s, loss=27.3]train epoch: 212:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.50it/s, loss=27.3]train epoch: 212:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.50it/s, loss=30.4]train epoch: 212:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=30.4]train epoch: 212:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=34.5]train epoch: 212:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.27it/s, loss=34.5]
model tensor([[0.6717, 0.3283],
        [0.4988, 0.5012],
        [0.7953, 0.2047],
        [0.3049, 0.6951],
        [0.3184, 0.6816],
        [0.3498, 0.6502],
        [0.4667, 0.5333],
        [0.5439, 0.4561]], device='cuda:0')

prompt tensor([[0.6935, 0.3065],
        [0.6839, 0.3161],
        [0.9588, 0.0412],
        [0.7612, 0.2388],
        [0.6472, 0.3528],
        [0.5326, 0.4674],
        [0.5812, 0.4188],
        [0.8337, 0.1663]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 212:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.27it/s, loss=30.7]train epoch: 212:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.33it/s, loss=30.7]train epoch: 212:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.33it/s, loss=28.7]train epoch: 212:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=28.7]train epoch: 212:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=24.6]train epoch: 212:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.30it/s, loss=24.6]train epoch: 212:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.30it/s, loss=22.7]train epoch: 212: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.27it/s, loss=22.7]train epoch: 212: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.16it/s, loss=22.7]
[[032m2021-11-26 10:36:06,752[0m INFO] trainer.training_epoch Training epoch 212, num_steps 1704,  avg_loss: 28.1325, total_loss: 225.0598
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]
[[032m2021-11-26 10:36:07,126[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:36:07,126[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:07,746[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 213:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 213:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.3]train epoch: 213:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=23.3]train epoch: 213:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=28.7]train epoch: 213:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=28.7]train epoch: 213:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=25.8]train epoch: 213:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.50it/s, loss=25.8]train epoch: 213:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.50it/s, loss=30.4]train epoch: 213:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=30.4]train epoch: 213:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=28.5]train epoch: 213:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=28.5]train epoch: 213:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=26.8]train epoch: 213:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.13it/s, loss=26.8]train epoch: 213:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.13it/s, loss=40.6]train epoch: 213:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.30it/s, loss=40.6]train epoch: 213:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.30it/s, loss=32]  train epoch: 213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.25it/s, loss=32]train epoch: 213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=32]
[[032m2021-11-26 10:36:09,803[0m INFO] trainer.training_epoch Training epoch 213, num_steps 1712,  avg_loss: 29.5029, total_loss: 236.0235
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.12it/s]
[[032m2021-11-26 10:36:10,278[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:36:10,279[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:10,804[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 214:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 214:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.9]train epoch: 214:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.34it/s, loss=26.9]train epoch: 214:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.34it/s, loss=29.9]train epoch: 214:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.06it/s, loss=29.9]train epoch: 214:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.06it/s, loss=24.2]train epoch: 214:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.59it/s, loss=24.2]train epoch: 214:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.59it/s, loss=31.1]train epoch: 214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s, loss=31.1]train epoch: 214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s, loss=24]  train epoch: 214:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.15it/s, loss=24]train epoch: 214:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.15it/s, loss=19.5]train epoch: 214:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.33it/s, loss=19.5]train epoch: 214:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.33it/s, loss=31.3]train epoch: 214:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.25it/s, loss=31.3]train epoch: 214:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.25it/s, loss=30.9]train epoch: 214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.33it/s, loss=30.9]train epoch: 214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=30.9]
[[032m2021-11-26 10:36:12,846[0m INFO] trainer.training_epoch Training epoch 214, num_steps 1720,  avg_loss: 27.2264, total_loss: 217.8109
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.60it/s]
[[032m2021-11-26 10:36:13,240[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:13,240[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:13,615[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 215:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 215:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.1]train epoch: 215:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=32.1]train epoch: 215:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=27]  train epoch: 215:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.13it/s, loss=27]train epoch: 215:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.13it/s, loss=30.4]train epoch: 215:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.74it/s, loss=30.4]train epoch: 215:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.74it/s, loss=26.1]train epoch: 215:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=26.1]train epoch: 215:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=24.5]train epoch: 215:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=24.5]train epoch: 215:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=27.7]train epoch: 215:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.14it/s, loss=27.7]train epoch: 215:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.14it/s, loss=28.6]train epoch: 215:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.24it/s, loss=28.6]train epoch: 215:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.24it/s, loss=32.4]train epoch: 215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=32.4]train epoch: 215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=32.4]
[[032m2021-11-26 10:36:15,625[0m INFO] trainer.training_epoch Training epoch 215, num_steps 1728,  avg_loss: 28.6029, total_loss: 228.8232
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.52it/s]
[[032m2021-11-26 10:36:16,067[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:36:16,067[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:16,515[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 216:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 216:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.3]train epoch: 216:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.31it/s, loss=30.3]train epoch: 216:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.31it/s, loss=24.6]train epoch: 216:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=24.6]train epoch: 216:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=28.5]train epoch: 216:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.35it/s, loss=28.5]train epoch: 216:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.35it/s, loss=25.4]train epoch: 216:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.65it/s, loss=25.4]train epoch: 216:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.65it/s, loss=29.4]train epoch: 216:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.88it/s, loss=29.4]train epoch: 216:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.88it/s, loss=33.4]train epoch: 216:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.95it/s, loss=33.4]train epoch: 216:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.95it/s, loss=32.5]train epoch: 216:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.88it/s, loss=32.5]train epoch: 216:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.88it/s, loss=26.9]train epoch: 216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.90it/s, loss=26.9]train epoch: 216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.73it/s, loss=26.9]
[[032m2021-11-26 10:36:18,668[0m INFO] trainer.training_epoch Training epoch 216, num_steps 1736,  avg_loss: 28.8804, total_loss: 231.0433
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.45it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.33it/s]
[[032m2021-11-26 10:36:19,208[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:36:19,209[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:19,906[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 217:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 217:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 217:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.38it/s, loss=23.6]train epoch: 217:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.38it/s, loss=24.2]train epoch: 217:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.61it/s, loss=24.2]train epoch: 217:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.61it/s, loss=23.9]train epoch: 217:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.86it/s, loss=23.9]train epoch: 217:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.86it/s, loss=22.2]train epoch: 217:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.98it/s, loss=22.2]train epoch: 217:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.98it/s, loss=29.6]train epoch: 217:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=29.6]train epoch: 217:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=26.7]train epoch: 217:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.31it/s, loss=26.7]train epoch: 217:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.31it/s, loss=22.4]train epoch: 217:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.23it/s, loss=22.4]train epoch: 217:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.23it/s, loss=26.7]train epoch: 217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.32it/s, loss=26.7]train epoch: 217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.13it/s, loss=26.7]
[[032m2021-11-26 10:36:21,862[0m INFO] trainer.training_epoch Training epoch 217, num_steps 1744,  avg_loss: 24.9256, total_loss: 199.4048
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.02it/s]
[[032m2021-11-26 10:36:22,287[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:36:22,287[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:22,904[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 218:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 218:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.8]train epoch: 218:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=28.8]train epoch: 218:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=29.8]train epoch: 218:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.89it/s, loss=29.8]train epoch: 218:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.89it/s, loss=26.2]train epoch: 218:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=26.2]train epoch: 218:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=31.3]train epoch: 218:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.61it/s, loss=31.3]train epoch: 218:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.61it/s, loss=24.4]train epoch: 218:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=24.4]train epoch: 218:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.89it/s, loss=27.6]train epoch: 218:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.94it/s, loss=27.6]train epoch: 218:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.94it/s, loss=26.1]train epoch: 218:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.64it/s, loss=26.1]train epoch: 218:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.64it/s, loss=23.3]train epoch: 218: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=23.3]train epoch: 218: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=23.3]
[[032m2021-11-26 10:36:25,165[0m INFO] trainer.training_epoch Training epoch 218, num_steps 1752,  avg_loss: 27.1879, total_loss: 217.5034
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.35it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.01it/s]
[[032m2021-11-26 10:36:25,886[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:25,886[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:26,305[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 219:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 219:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.6]train epoch: 219:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=30.6]train epoch: 219:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=31.8]train epoch: 219:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.20it/s, loss=31.8]train epoch: 219:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.20it/s, loss=34.7]train epoch: 219:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=34.7]train epoch: 219:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=18.5]train epoch: 219:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.34it/s, loss=18.5]train epoch: 219:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.34it/s, loss=35.7]train epoch: 219:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.39it/s, loss=35.7]train epoch: 219:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.39it/s, loss=24.4]train epoch: 219:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.46it/s, loss=24.4]train epoch: 219:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.46it/s, loss=25.7]train epoch: 219:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=25.7]train epoch: 219:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=26.5]train epoch: 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.86it/s, loss=26.5]train epoch: 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.13it/s, loss=26.5]
[[032m2021-11-26 10:36:28,250[0m INFO] trainer.training_epoch Training epoch 219, num_steps 1760,  avg_loss: 28.4805, total_loss: 227.8438
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.15it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.22it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.94it/s]
[[032m2021-11-26 10:36:28,848[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:36:28,855[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:29,226[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 220:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 220:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.1]train epoch: 220:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.38it/s, loss=30.1]train epoch: 220:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.38it/s, loss=26.9]train epoch: 220:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.38it/s, loss=26.9]train epoch: 220:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.38it/s, loss=29.7]train epoch: 220:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.47it/s, loss=29.7]train epoch: 220:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.47it/s, loss=30.4]train epoch: 220:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.35it/s, loss=30.4]train epoch: 220:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.35it/s, loss=28.2]train epoch: 220:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.51it/s, loss=28.2]train epoch: 220:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.51it/s, loss=21.8]train epoch: 220:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=21.8]train epoch: 220:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=31]  train epoch: 220:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.42it/s, loss=31]train epoch: 220:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.42it/s, loss=26.8]train epoch: 220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.93it/s, loss=26.8]train epoch: 220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.21it/s, loss=26.8]
[[032m2021-11-26 10:36:31,133[0m INFO] trainer.training_epoch Training epoch 220, num_steps 1768,  avg_loss: 28.1102, total_loss: 224.8817
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.32it/s]
[[032m2021-11-26 10:36:31,553[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:31,553[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:31,864[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 221:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 221:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.7]train epoch: 221:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=35.7]train epoch: 221:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=28.9]train epoch: 221:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=28.9]train epoch: 221:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=17.6]train epoch: 221:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.06it/s, loss=17.6]train epoch: 221:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.06it/s, loss=28.4]train epoch: 221:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.34it/s, loss=28.4]train epoch: 221:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.34it/s, loss=30.8]train epoch: 221:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=30.8]train epoch: 221:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=28.3]train epoch: 221:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.55it/s, loss=28.3]train epoch: 221:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.55it/s, loss=35.4]train epoch: 221:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.48it/s, loss=35.4]train epoch: 221:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.48it/s, loss=33.5]train epoch: 221: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=33.5]train epoch: 221: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.79it/s, loss=33.5]
[[032m2021-11-26 10:36:33,982[0m INFO] trainer.training_epoch Training epoch 221, num_steps 1776,  avg_loss: 29.8292, total_loss: 238.6340
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.40it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.96it/s]
[[032m2021-11-26 10:36:34,578[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:36:34,579[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:34,912[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 222:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 222:   0%|          | 0/8 [00:00<?, ?it/s, loss=31]train epoch: 222:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=31]train epoch: 222:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=29.2]train epoch: 222:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.65it/s, loss=29.2]train epoch: 222:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.65it/s, loss=27.6]train epoch: 222:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.04it/s, loss=27.6]train epoch: 222:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.04it/s, loss=27.3]train epoch: 222:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.30it/s, loss=27.3]train epoch: 222:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.30it/s, loss=30.5]train epoch: 222:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.39it/s, loss=30.5]train epoch: 222:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.39it/s, loss=32.9]train epoch: 222:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.38it/s, loss=32.9]train epoch: 222:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.38it/s, loss=28]  train epoch: 222:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.31it/s, loss=28]train epoch: 222:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.31it/s, loss=39.8]train epoch: 222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.26it/s, loss=39.8]train epoch: 222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.22it/s, loss=39.8]
[[032m2021-11-26 10:36:36,813[0m INFO] trainer.training_epoch Training epoch 222, num_steps 1784,  avg_loss: 30.7891, total_loss: 246.3130
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.88it/s]
[[032m2021-11-26 10:36:37,181[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:37,181[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:37,559[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 223:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 223:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 223:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.23it/s, loss=27.9]train epoch: 223:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.23it/s, loss=33.9]train epoch: 223:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.82it/s, loss=33.9]train epoch: 223:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.82it/s, loss=22.6]train epoch: 223:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=22.6]train epoch: 223:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=26.6]train epoch: 223:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.48it/s, loss=26.6]train epoch: 223:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.48it/s, loss=27.6]train epoch: 223:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.67it/s, loss=27.6]train epoch: 223:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.67it/s, loss=29.7]train epoch: 223:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.82it/s, loss=29.7]train epoch: 223:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.82it/s, loss=25.2]train epoch: 223:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.97it/s, loss=25.2]train epoch: 223:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.97it/s, loss=32.8]train epoch: 223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.09it/s, loss=32.8]train epoch: 223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=32.8]
[[032m2021-11-26 10:36:39,648[0m INFO] trainer.training_epoch Training epoch 223, num_steps 1792,  avg_loss: 28.2895, total_loss: 226.3164
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.11it/s]
[[032m2021-11-26 10:36:40,022[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:40,022[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:40,254[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 224:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 224:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.4]train epoch: 224:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.63it/s, loss=29.4]train epoch: 224:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.63it/s, loss=27.1]train epoch: 224:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.09it/s, loss=27.1]train epoch: 224:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.09it/s, loss=31]  train epoch: 224:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.69it/s, loss=31]train epoch: 224:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.69it/s, loss=19.6]train epoch: 224:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=19.6]train epoch: 224:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=26.5]train epoch: 224:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=26.5]train epoch: 224:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.28it/s, loss=27.9]train epoch: 224:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.65it/s, loss=27.9]train epoch: 224:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.65it/s, loss=20.2]train epoch: 224:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.80it/s, loss=20.2]train epoch: 224:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.80it/s, loss=26.1]train epoch: 224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.91it/s, loss=26.1]train epoch: 224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.68it/s, loss=26.1]
[[032m2021-11-26 10:36:42,436[0m INFO] trainer.training_epoch Training epoch 224, num_steps 1800,  avg_loss: 25.9725, total_loss: 207.7803
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.94it/s]
[[032m2021-11-26 10:36:42,860[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:36:42,860[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:43,071[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 225:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.4587, 0.5413],
        [0.6761, 0.3239],
        [0.4988, 0.5012],
        [0.4305, 0.5695],
        [0.3806, 0.6194],
        [0.5443, 0.4557],
        [0.3391, 0.6609],
        [0.2477, 0.7523]], device='cuda:0')

prompt tensor([[0.5587, 0.4413],
        [0.5962, 0.4038],
        [0.5105, 0.4895],
        [0.6834, 0.3166],
        [0.8111, 0.1889],
        [0.6262, 0.3738],
        [0.3730, 0.6270],
        [0.5134, 0.4866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 225:   0%|          | 0/8 [00:00<?, ?it/s, loss=40]train epoch: 225:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.37it/s, loss=40]train epoch: 225:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.37it/s, loss=32.7]train epoch: 225:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=32.7]train epoch: 225:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=34.1]train epoch: 225:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.01it/s, loss=34.1]train epoch: 225:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.01it/s, loss=26.2]train epoch: 225:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.56it/s, loss=26.2]train epoch: 225:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.56it/s, loss=33.8]train epoch: 225:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.80it/s, loss=33.8]train epoch: 225:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.80it/s, loss=25.5]train epoch: 225:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.13it/s, loss=25.5]train epoch: 225:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.13it/s, loss=27.2]train epoch: 225:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.49it/s, loss=27.2]train epoch: 225:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.49it/s, loss=28.2]train epoch: 225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.23it/s, loss=28.2]train epoch: 225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=28.2]
[[032m2021-11-26 10:36:45,654[0m INFO] trainer.training_epoch Training epoch 225, num_steps 1808,  avg_loss: 30.9741, total_loss: 247.7926
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.52it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.47it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.26it/s]
[[032m2021-11-26 10:36:46,236[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:46,237[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:46,501[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 226:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 226:   0%|          | 0/8 [00:00<?, ?it/s, loss=18.2]train epoch: 226:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=18.2]train epoch: 226:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=25.9]train epoch: 226:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=25.9]train epoch: 226:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=29.1]train epoch: 226:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.37it/s, loss=29.1]train epoch: 226:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.37it/s, loss=28.8]train epoch: 226:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.79it/s, loss=28.8]train epoch: 226:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.79it/s, loss=18.7]train epoch: 226:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.68it/s, loss=18.7]train epoch: 226:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.68it/s, loss=29]  train epoch: 226:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.05it/s, loss=29]train epoch: 226:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.05it/s, loss=20.5]train epoch: 226:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=20.5]train epoch: 226:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=39.5]train epoch: 226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.42it/s, loss=39.5]train epoch: 226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=39.5]
[[032m2021-11-26 10:36:48,970[0m INFO] trainer.training_epoch Training epoch 226, num_steps 1816,  avg_loss: 26.2089, total_loss: 209.6716
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.59it/s]
[[032m2021-11-26 10:36:49,375[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:36:49,375[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:49,583[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 227:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 227:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.1]train epoch: 227:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=22.1]train epoch: 227:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=25]  train epoch: 227:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.47it/s, loss=25]train epoch: 227:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.47it/s, loss=41.8]train epoch: 227:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.38it/s, loss=41.8]train epoch: 227:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.38it/s, loss=32.8]train epoch: 227:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=32.8]train epoch: 227:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=25.6]train epoch: 227:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=25.6]train epoch: 227:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=32.4]train epoch: 227:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.84it/s, loss=32.4]train epoch: 227:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.84it/s, loss=24.4]train epoch: 227:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=24.4]train epoch: 227:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=31.7]train epoch: 227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.92it/s, loss=31.7]train epoch: 227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.08it/s, loss=31.7]
[[032m2021-11-26 10:36:52,188[0m INFO] trainer.training_epoch Training epoch 227, num_steps 1824,  avg_loss: 29.4736, total_loss: 235.7886
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.49it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.03it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.54it/s]
[[032m2021-11-26 10:36:52,671[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:36:52,671[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:52,876[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 228:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 228:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.1]train epoch: 228:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.11it/s, loss=25.1]train epoch: 228:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.11it/s, loss=25.4]train epoch: 228:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.82it/s, loss=25.4]train epoch: 228:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.82it/s, loss=26]  train epoch: 228:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.43it/s, loss=26]train epoch: 228:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.43it/s, loss=27.9]train epoch: 228:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.61it/s, loss=27.9]train epoch: 228:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.61it/s, loss=24.2]train epoch: 228:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=24.2]train epoch: 228:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=22.2]train epoch: 228:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.56it/s, loss=22.2]train epoch: 228:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=27.1]train epoch: 228:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.88it/s, loss=27.1]train epoch: 228:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.88it/s, loss=34.6]train epoch: 228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=34.6]train epoch: 228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=34.6]
[[032m2021-11-26 10:36:55,320[0m INFO] trainer.training_epoch Training epoch 228, num_steps 1832,  avg_loss: 26.5717, total_loss: 212.5737
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.01it/s]
[[032m2021-11-26 10:36:55,704[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:36:55,705[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:55,925[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 229:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 229:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.1]train epoch: 229:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=24.1]train epoch: 229:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=31.3]train epoch: 229:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.76it/s, loss=31.3]train epoch: 229:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.76it/s, loss=22.4]train epoch: 229:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.90it/s, loss=22.4]train epoch: 229:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.90it/s, loss=27.4]train epoch: 229:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=27.4]train epoch: 229:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=25.5]train epoch: 229:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=25.5]train epoch: 229:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=25.5]train epoch: 229:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.95it/s, loss=25.5]train epoch: 229:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=24.2]train epoch: 229:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=24.2]train epoch: 229:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=30.3]train epoch: 229: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=30.3]train epoch: 229: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.20it/s, loss=30.3]
[[032m2021-11-26 10:36:58,428[0m INFO] trainer.training_epoch Training epoch 229, num_steps 1840,  avg_loss: 26.3311, total_loss: 210.6492
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.68it/s]
[[032m2021-11-26 10:36:58,818[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:36:58,819[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:36:59,034[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 230:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 230:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.5]train epoch: 230:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.44it/s, loss=31.5]train epoch: 230:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.44it/s, loss=22.1]train epoch: 230:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=22.1]train epoch: 230:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=26.1]train epoch: 230:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.72it/s, loss=26.1]train epoch: 230:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.72it/s, loss=25.9]train epoch: 230:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.02it/s, loss=25.9]train epoch: 230:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.02it/s, loss=27.8]train epoch: 230:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=27.8]train epoch: 230:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=22.4]train epoch: 230:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s, loss=22.4]train epoch: 230:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.30it/s, loss=29.2]train epoch: 230:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=29.2]train epoch: 230:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=32.5]train epoch: 230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.07it/s, loss=32.5]train epoch: 230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.36it/s, loss=32.5]
[[032m2021-11-26 10:37:01,421[0m INFO] trainer.training_epoch Training epoch 230, num_steps 1848,  avg_loss: 27.1983, total_loss: 217.5862
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.18it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.57it/s]
[[032m2021-11-26 10:37:01,853[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:37:01,853[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:02,074[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 231:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 231:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.9]train epoch: 231:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=23.9]train epoch: 231:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.09it/s, loss=22.9]train epoch: 231:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.81it/s, loss=22.9]train epoch: 231:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.81it/s, loss=26.9]train epoch: 231:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.28it/s, loss=26.9]train epoch: 231:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.28it/s, loss=28]  train epoch: 231:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.17it/s, loss=28]train epoch: 231:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.17it/s, loss=24.1]train epoch: 231:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.50it/s, loss=24.1]train epoch: 231:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.50it/s, loss=24.4]train epoch: 231:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.93it/s, loss=24.4]train epoch: 231:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.93it/s, loss=27.6]train epoch: 231:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=27.6]train epoch: 231:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=27.1]train epoch: 231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=27.1]train epoch: 231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=27.1]
[[032m2021-11-26 10:37:04,394[0m INFO] trainer.training_epoch Training epoch 231, num_steps 1856,  avg_loss: 25.6181, total_loss: 204.9444
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.45it/s]
[[032m2021-11-26 10:37:04,796[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:37:04,796[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:05,023[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 232:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 232:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.1]train epoch: 232:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=35.1]train epoch: 232:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=18.2]train epoch: 232:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.62it/s, loss=18.2]train epoch: 232:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.62it/s, loss=28]  train epoch: 232:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.88it/s, loss=28]train epoch: 232:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.88it/s, loss=33.6]train epoch: 232:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.99it/s, loss=33.6]train epoch: 232:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.99it/s, loss=19.8]train epoch: 232:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.67it/s, loss=19.8]train epoch: 232:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.67it/s, loss=23.1]train epoch: 232:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.73it/s, loss=23.1]train epoch: 232:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.73it/s, loss=31.9]train epoch: 232:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.17it/s, loss=31.9]train epoch: 232:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.17it/s, loss=19.2]train epoch: 232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.41it/s, loss=19.2]train epoch: 232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.05it/s, loss=19.2]
[[032m2021-11-26 10:37:07,648[0m INFO] trainer.training_epoch Training epoch 232, num_steps 1864,  avg_loss: 26.1184, total_loss: 208.9470
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.16it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.23it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.82it/s]
[[032m2021-11-26 10:37:08,129[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:37:08,129[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:08,542[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 233:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 233:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.2]train epoch: 233:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.10it/s, loss=23.2]train epoch: 233:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.10it/s, loss=22.3]train epoch: 233:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.24it/s, loss=22.3]train epoch: 233:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.24it/s, loss=31.1]train epoch: 233:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.71it/s, loss=31.1]train epoch: 233:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.71it/s, loss=20.4]train epoch: 233:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=20.4]train epoch: 233:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=32.4]train epoch: 233:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.68it/s, loss=32.4]train epoch: 233:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.68it/s, loss=24.8]train epoch: 233:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.25it/s, loss=24.8]train epoch: 233:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.25it/s, loss=27.1]train epoch: 233:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.90it/s, loss=27.1]train epoch: 233:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.90it/s, loss=21.6]train epoch: 233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=21.6]train epoch: 233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=21.6]
[[032m2021-11-26 10:37:12,179[0m INFO] trainer.training_epoch Training epoch 233, num_steps 1872,  avg_loss: 25.3735, total_loss: 202.9877
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.67it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.88it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.98it/s]
[[032m2021-11-26 10:37:12,773[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:37:12,774[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:13,199[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 234:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 234:   0%|          | 0/8 [00:00<?, ?it/s, loss=27]train epoch: 234:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=27]train epoch: 234:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=34.5]train epoch: 234:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.89it/s, loss=34.5]train epoch: 234:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.89it/s, loss=25.3]train epoch: 234:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.20it/s, loss=25.3]train epoch: 234:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.20it/s, loss=24.5]train epoch: 234:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=24.5]train epoch: 234:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=37.9]train epoch: 234:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.46it/s, loss=37.9]train epoch: 234:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.46it/s, loss=30.5]train epoch: 234:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=30.5]train epoch: 234:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=28.8]train epoch: 234:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.13it/s, loss=28.8]train epoch: 234:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.13it/s, loss=24.2]train epoch: 234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=24.2]train epoch: 234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s, loss=24.2]
[[032m2021-11-26 10:37:16,711[0m INFO] trainer.training_epoch Training epoch 234, num_steps 1880,  avg_loss: 29.0857, total_loss: 232.6858
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.28it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.57it/s]
[[032m2021-11-26 10:37:17,197[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:37:17,197[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:17,722[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 235:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 235:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 235:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=25.5]train epoch: 235:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=27.8]train epoch: 235:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.05it/s, loss=27.8]train epoch: 235:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.05it/s, loss=39]  train epoch: 235:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.17it/s, loss=39]train epoch: 235:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.17it/s, loss=23.5]train epoch: 235:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.18it/s, loss=23.5]train epoch: 235:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.18it/s, loss=26.9]train epoch: 235:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.34it/s, loss=26.9]train epoch: 235:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.34it/s, loss=25.8]train epoch: 235:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.48it/s, loss=25.8]train epoch: 235:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.48it/s, loss=28.7]train epoch: 235:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.01it/s, loss=28.7]train epoch: 235:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.01it/s, loss=31.2]train epoch: 235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s, loss=31.2]train epoch: 235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=31.2]
[[032m2021-11-26 10:37:20,431[0m INFO] trainer.training_epoch Training epoch 235, num_steps 1888,  avg_loss: 28.5458, total_loss: 228.3660
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.47it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.34it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.00it/s]
[[032m2021-11-26 10:37:21,270[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:37:21,270[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:22,068[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 236:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 236:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.6]train epoch: 236:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.24it/s, loss=32.6]train epoch: 236:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.24it/s, loss=29.2]train epoch: 236:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.15it/s, loss=29.2]train epoch: 236:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.15it/s, loss=32.8]train epoch: 236:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.24it/s, loss=32.8]train epoch: 236:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.24it/s, loss=32]  train epoch: 236:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=32]train epoch: 236:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.75it/s, loss=33.6]train epoch: 236:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.31it/s, loss=33.6]train epoch: 236:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.31it/s, loss=33.1]train epoch: 236:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.58it/s, loss=33.1]train epoch: 236:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.58it/s, loss=29]  train epoch: 236:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.33it/s, loss=29]train epoch: 236:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.33it/s, loss=21.9]train epoch: 236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.30it/s, loss=21.9]train epoch: 236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=21.9]
[[032m2021-11-26 10:37:25,482[0m INFO] trainer.training_epoch Training epoch 236, num_steps 1896,  avg_loss: 30.5268, total_loss: 244.2143
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.78it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.28it/s]
[[032m2021-11-26 10:37:26,080[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:37:26,081[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:26,723[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 237:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 237:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.6]train epoch: 237:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.74it/s, loss=24.6]train epoch: 237:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.74it/s, loss=25.7]train epoch: 237:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.77it/s, loss=25.7]train epoch: 237:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.77it/s, loss=26.8]train epoch: 237:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=26.8]train epoch: 237:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=28]  train epoch: 237:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.10it/s, loss=28]
model tensor([[0.5702, 0.4298],
        [0.6493, 0.3507],
        [0.3498, 0.6502],
        [0.5951, 0.4049],
        [0.2873, 0.7127],
        [0.5650, 0.4350],
        [0.6310, 0.3690],
        [0.4013, 0.5987]], device='cuda:0')

prompt tensor([[0.6547, 0.3453],
        [0.7354, 0.2646],
        [0.5375, 0.4625],
        [0.7251, 0.2749],
        [0.5059, 0.4941],
        [0.5731, 0.4269],
        [0.7474, 0.2526],
        [0.4070, 0.5930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 237:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.10it/s, loss=24.4]train epoch: 237:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.30it/s, loss=24.4]train epoch: 237:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.30it/s, loss=26.4]train epoch: 237:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.48it/s, loss=26.4]train epoch: 237:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.48it/s, loss=20.2]train epoch: 237:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.82it/s, loss=20.2]train epoch: 237:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.82it/s, loss=20]  train epoch: 237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.75it/s, loss=20]train epoch: 237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.41it/s, loss=20]
[[032m2021-11-26 10:37:30,049[0m INFO] trainer.training_epoch Training epoch 237, num_steps 1904,  avg_loss: 24.5215, total_loss: 196.1717
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.37it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.77it/s]
[[032m2021-11-26 10:37:30,799[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:37:30,800[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:31,639[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 238:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 238:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.8]train epoch: 238:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=33.8]train epoch: 238:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=24.5]train epoch: 238:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.45it/s, loss=24.5]train epoch: 238:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.45it/s, loss=20.4]train epoch: 238:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=20.4]train epoch: 238:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=31.5]train epoch: 238:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.44it/s, loss=31.5]train epoch: 238:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.44it/s, loss=17.1]train epoch: 238:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.76it/s, loss=17.1]train epoch: 238:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.76it/s, loss=21.9]train epoch: 238:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=21.9]train epoch: 238:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=24.1]train epoch: 238:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=24.1]train epoch: 238:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=32.3]train epoch: 238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=32.3]train epoch: 238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.83it/s, loss=32.3]
[[032m2021-11-26 10:37:34,467[0m INFO] trainer.training_epoch Training epoch 238, num_steps 1912,  avg_loss: 25.7271, total_loss: 205.8170
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.64it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.52it/s]
[[032m2021-11-26 10:37:34,961[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:37:34,961[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:35,397[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 239:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 239:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 239:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.90it/s, loss=30.2]train epoch: 239:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.90it/s, loss=24]  train epoch: 239:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.73it/s, loss=24]train epoch: 239:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.73it/s, loss=27.5]train epoch: 239:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.24it/s, loss=27.5]train epoch: 239:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.24it/s, loss=22]  train epoch: 239:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.31it/s, loss=22]train epoch: 239:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.31it/s, loss=26.6]train epoch: 239:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.45it/s, loss=26.6]train epoch: 239:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.45it/s, loss=31.2]train epoch: 239:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.47it/s, loss=31.2]train epoch: 239:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.47it/s, loss=26.5]train epoch: 239:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.61it/s, loss=26.5]train epoch: 239:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.61it/s, loss=32.4]train epoch: 239: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.60it/s, loss=32.4]train epoch: 239: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=32.4]
[[032m2021-11-26 10:37:38,575[0m INFO] trainer.training_epoch Training epoch 239, num_steps 1920,  avg_loss: 27.5521, total_loss: 220.4170
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.76it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.84it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.27it/s]
[[032m2021-11-26 10:37:39,187[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:37:39,203[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:40,102[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 240:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 240:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.8]train epoch: 240:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.55it/s, loss=24.8]train epoch: 240:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.55it/s, loss=25]  train epoch: 240:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.02it/s, loss=25]train epoch: 240:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.02it/s, loss=26.4]train epoch: 240:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.70it/s, loss=26.4]train epoch: 240:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.70it/s, loss=31.6]train epoch: 240:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=31.6]train epoch: 240:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=25.5]train epoch: 240:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.13it/s, loss=25.5]train epoch: 240:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.13it/s, loss=30.7]train epoch: 240:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=30.7]train epoch: 240:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=22.5]train epoch: 240:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=22.5]train epoch: 240:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.81it/s, loss=21.9]train epoch: 240: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  3.04it/s, loss=21.9]train epoch: 240: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=21.9]
[[032m2021-11-26 10:37:43,339[0m INFO] trainer.training_epoch Training epoch 240, num_steps 1928,  avg_loss: 26.0515, total_loss: 208.4120
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.66it/s]
[[032m2021-11-26 10:37:43,731[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:37:43,731[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:44,060[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 241:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 241:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.5]train epoch: 241:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.95it/s, loss=27.5]train epoch: 241:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:02,  2.95it/s, loss=25.7]train epoch: 241:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.84it/s, loss=25.7]train epoch: 241:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.84it/s, loss=21.7]train epoch: 241:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=21.7]train epoch: 241:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=18.1]train epoch: 241:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.17it/s, loss=18.1]train epoch: 241:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.17it/s, loss=30.9]train epoch: 241:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.54it/s, loss=30.9]train epoch: 241:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.54it/s, loss=26.1]train epoch: 241:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.97it/s, loss=26.1]train epoch: 241:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.97it/s, loss=25.4]train epoch: 241:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.05it/s, loss=25.4]train epoch: 241:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.05it/s, loss=34.4]train epoch: 241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.38it/s, loss=34.4]train epoch: 241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.26it/s, loss=34.4]
[[032m2021-11-26 10:37:47,604[0m INFO] trainer.training_epoch Training epoch 241, num_steps 1936,  avg_loss: 26.2347, total_loss: 209.8774
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.12it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.23it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.83it/s]
[[032m2021-11-26 10:37:48,086[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:37:48,087[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:48,626[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 242:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 242:   0%|          | 0/8 [00:00<?, ?it/s, loss=29]train epoch: 242:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.09it/s, loss=29]train epoch: 242:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  2.09it/s, loss=27.1]train epoch: 242:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.76it/s, loss=27.1]train epoch: 242:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.76it/s, loss=24]  train epoch: 242:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=24]train epoch: 242:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=25.8]train epoch: 242:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=25.8]train epoch: 242:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.45it/s, loss=38.4]train epoch: 242:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=38.4]train epoch: 242:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=28]  train epoch: 242:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.07it/s, loss=28]train epoch: 242:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.07it/s, loss=17.6]train epoch: 242:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=17.6]train epoch: 242:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=27.3]train epoch: 242: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s, loss=27.3]train epoch: 242: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.31it/s, loss=27.3]
[[032m2021-11-26 10:37:52,114[0m INFO] trainer.training_epoch Training epoch 242, num_steps 1944,  avg_loss: 27.1602, total_loss: 217.2812
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.99it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.16it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.44it/s]
[[032m2021-11-26 10:37:52,882[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:37:52,882[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:53,379[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 243:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 243:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.8]train epoch: 243:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.00it/s, loss=27.8]train epoch: 243:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.00it/s, loss=22.7]train epoch: 243:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.82it/s, loss=22.7]train epoch: 243:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.82it/s, loss=28.7]train epoch: 243:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.72it/s, loss=28.7]train epoch: 243:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.72it/s, loss=29.2]train epoch: 243:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.85it/s, loss=29.2]train epoch: 243:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.85it/s, loss=32]  train epoch: 243:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=32]train epoch: 243:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s, loss=24.1]train epoch: 243:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.21it/s, loss=24.1]train epoch: 243:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.21it/s, loss=25.1]train epoch: 243:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.87it/s, loss=25.1]train epoch: 243:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.87it/s, loss=27.8]train epoch: 243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=27.8]train epoch: 243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.20it/s, loss=27.8]
[[032m2021-11-26 10:37:57,027[0m INFO] trainer.training_epoch Training epoch 243, num_steps 1952,  avg_loss: 27.1875, total_loss: 217.5002
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.07it/s]
[[032m2021-11-26 10:37:57,738[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:37:57,739[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:37:58,059[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 244:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 244:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.4]train epoch: 244:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.97it/s, loss=25.4]train epoch: 244:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.97it/s, loss=25]  train epoch: 244:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=25]train epoch: 244:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.99it/s, loss=35.7]train epoch: 244:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.66it/s, loss=35.7]train epoch: 244:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.66it/s, loss=27.2]train epoch: 244:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=27.2]train epoch: 244:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=37.9]train epoch: 244:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=37.9]train epoch: 244:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=29.1]train epoch: 244:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.20it/s, loss=29.1]train epoch: 244:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.20it/s, loss=21.8]train epoch: 244:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=21.8]train epoch: 244:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=28.8]train epoch: 244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.70it/s, loss=28.8]train epoch: 244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.89it/s, loss=28.8]
[[032m2021-11-26 10:38:00,836[0m INFO] trainer.training_epoch Training epoch 244, num_steps 1960,  avg_loss: 28.8615, total_loss: 230.8916
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.44it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.28it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.54it/s]
[[032m2021-11-26 10:38:01,586[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:38:01,587[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:02,160[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 245:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 245:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.3]train epoch: 245:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.12it/s, loss=25.3]train epoch: 245:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.12it/s, loss=30.8]train epoch: 245:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.49it/s, loss=30.8]train epoch: 245:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.49it/s, loss=21.2]train epoch: 245:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.70it/s, loss=21.2]train epoch: 245:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.70it/s, loss=25.5]train epoch: 245:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=25.5]train epoch: 245:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=27.7]train epoch: 245:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=27.7]train epoch: 245:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=29.4]train epoch: 245:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s, loss=29.4]train epoch: 245:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.30it/s, loss=32]  train epoch: 245:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=32]train epoch: 245:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=23.9]train epoch: 245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.70it/s, loss=23.9]train epoch: 245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=23.9]
[[032m2021-11-26 10:38:05,046[0m INFO] trainer.training_epoch Training epoch 245, num_steps 1968,  avg_loss: 26.9811, total_loss: 215.8486
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.21it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.04it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.38it/s]
[[032m2021-11-26 10:38:05,700[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:38:05,701[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:06,347[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 246:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 246:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 246:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=29.3]train epoch: 246:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=24]  train epoch: 246:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.63it/s, loss=24]train epoch: 246:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.63it/s, loss=28.6]train epoch: 246:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.08it/s, loss=28.6]train epoch: 246:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.08it/s, loss=27]  train epoch: 246:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=27]train epoch: 246:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=19.8]train epoch: 246:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=19.8]train epoch: 246:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.89it/s, loss=32]  train epoch: 246:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.10it/s, loss=32]train epoch: 246:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.10it/s, loss=29.7]train epoch: 246:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=29.7]train epoch: 246:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=25.8]train epoch: 246: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.55it/s, loss=25.8]train epoch: 246: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.76it/s, loss=25.8]
[[032m2021-11-26 10:38:09,264[0m INFO] trainer.training_epoch Training epoch 246, num_steps 1976,  avg_loss: 27.0145, total_loss: 216.1158
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.28it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.69it/s]
[[032m2021-11-26 10:38:10,158[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:38:10,158[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:10,742[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 247:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 247:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.8]train epoch: 247:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.70it/s, loss=26.8]train epoch: 247:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.70it/s, loss=31.9]train epoch: 247:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.41it/s, loss=31.9]train epoch: 247:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.41it/s, loss=24.8]train epoch: 247:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.31it/s, loss=24.8]train epoch: 247:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.31it/s, loss=28.4]train epoch: 247:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=28.4]train epoch: 247:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=20.3]train epoch: 247:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=20.3]train epoch: 247:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=32.9]train epoch: 247:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.26it/s, loss=32.9]train epoch: 247:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.26it/s, loss=29.6]train epoch: 247:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=29.6]train epoch: 247:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=28]  train epoch: 247: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.47it/s, loss=28]train epoch: 247: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.80it/s, loss=28]
[[032m2021-11-26 10:38:13,609[0m INFO] trainer.training_epoch Training epoch 247, num_steps 1984,  avg_loss: 27.8528, total_loss: 222.8225
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.10it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.58it/s]
[[032m2021-11-26 10:38:14,258[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:38:14,258[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:14,667[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 248:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 248:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.9]train epoch: 248:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.66it/s, loss=26.9]train epoch: 248:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:02,  2.66it/s, loss=29.7]train epoch: 248:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.66it/s, loss=29.7]train epoch: 248:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.66it/s, loss=35.6]train epoch: 248:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.16it/s, loss=35.6]train epoch: 248:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.16it/s, loss=22.2]train epoch: 248:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.28it/s, loss=22.2]train epoch: 248:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.28it/s, loss=34.9]train epoch: 248:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.57it/s, loss=34.9]train epoch: 248:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.57it/s, loss=22.1]train epoch: 248:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.91it/s, loss=22.1]train epoch: 248:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.91it/s, loss=17.8]train epoch: 248:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=17.8]train epoch: 248:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=25.7]train epoch: 248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=25.7]train epoch: 248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.72it/s, loss=25.7]
[[032m2021-11-26 10:38:17,616[0m INFO] trainer.training_epoch Training epoch 248, num_steps 1992,  avg_loss: 26.8519, total_loss: 214.8153
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.69it/s]
[[032m2021-11-26 10:38:18,065[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:38:18,065[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:18,466[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 249:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 249:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.1]train epoch: 249:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=25.1]train epoch: 249:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.62it/s, loss=27.2]train epoch: 249:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.93it/s, loss=27.2]train epoch: 249:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.93it/s, loss=30]  train epoch: 249:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.90it/s, loss=30]train epoch: 249:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.90it/s, loss=30.3]train epoch: 249:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.98it/s, loss=30.3]train epoch: 249:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.98it/s, loss=30.1]train epoch: 249:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.16it/s, loss=30.1]train epoch: 249:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.16it/s, loss=29.2]train epoch: 249:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=29.2]train epoch: 249:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=23.5]train epoch: 249:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.67it/s, loss=23.5]train epoch: 249:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.67it/s, loss=23.9]train epoch: 249: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.97it/s, loss=23.9]train epoch: 249: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=23.9]
[[032m2021-11-26 10:38:21,622[0m INFO] trainer.training_epoch Training epoch 249, num_steps 2000,  avg_loss: 27.4317, total_loss: 219.4536
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.59it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.42it/s]
[[032m2021-11-26 10:38:22,068[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:38:22,068[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:22,683[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 250:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.5418, 0.4582],
        [0.8361, 0.1639],
        [0.6054, 0.3946],
        [0.2828, 0.7172],
        [0.3184, 0.6816],
        [0.6717, 0.3283],
        [0.6761, 0.3239],
        [0.3884, 0.6116]], device='cuda:0')

prompt tensor([[0.6596, 0.3404],
        [0.7649, 0.2351],
        [0.7079, 0.2921],
        [0.6932, 0.3068],
        [0.5164, 0.4836],
        [0.7531, 0.2469],
        [0.7552, 0.2448],
        [0.4372, 0.5628]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 250:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.3]train epoch: 250:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.83it/s, loss=34.3]train epoch: 250:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.83it/s, loss=26.7]train epoch: 250:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=26.7]train epoch: 250:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.84it/s, loss=26.5]train epoch: 250:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.24it/s, loss=26.5]train epoch: 250:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.24it/s, loss=28.5]train epoch: 250:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.20it/s, loss=28.5]train epoch: 250:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.20it/s, loss=27.1]train epoch: 250:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.84it/s, loss=27.1]train epoch: 250:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.84it/s, loss=24.2]train epoch: 250:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.98it/s, loss=24.2]train epoch: 250:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.98it/s, loss=27.7]train epoch: 250:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.26it/s, loss=27.7]train epoch: 250:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.26it/s, loss=29.2]train epoch: 250: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s, loss=29.2]train epoch: 250: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.19it/s, loss=29.2]
[[032m2021-11-26 10:38:26,354[0m INFO] trainer.training_epoch Training epoch 250, num_steps 2008,  avg_loss: 28.0361, total_loss: 224.2889
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.97it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.61it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.38it/s]
[[032m2021-11-26 10:38:27,132[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:38:27,133[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:27,849[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 251:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 251:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.6]train epoch: 251:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.47it/s, loss=33.6]train epoch: 251:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.47it/s, loss=19.2]train epoch: 251:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:03,  1.96it/s, loss=19.2]train epoch: 251:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.96it/s, loss=23.3]train epoch: 251:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.54it/s, loss=23.3]train epoch: 251:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.54it/s, loss=38.5]train epoch: 251:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.97it/s, loss=38.5]train epoch: 251:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.97it/s, loss=28.6]train epoch: 251:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=28.6]train epoch: 251:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.21it/s, loss=22.6]train epoch: 251:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.16it/s, loss=22.6]train epoch: 251:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.16it/s, loss=23.2]train epoch: 251:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=23.2]train epoch: 251:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=29.1]train epoch: 251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=29.1]train epoch: 251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.17it/s, loss=29.1]
[[032m2021-11-26 10:38:31,538[0m INFO] trainer.training_epoch Training epoch 251, num_steps 2016,  avg_loss: 27.2522, total_loss: 218.0177
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.98it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.38it/s]
[[032m2021-11-26 10:38:32,471[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:38:32,471[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:33,209[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 252:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 252:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.2]train epoch: 252:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=25.2]train epoch: 252:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=25.3]train epoch: 252:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.54it/s, loss=25.3]train epoch: 252:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.54it/s, loss=25.8]train epoch: 252:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=25.8]train epoch: 252:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=34]  train epoch: 252:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.66it/s, loss=34]train epoch: 252:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.66it/s, loss=28.6]train epoch: 252:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.48it/s, loss=28.6]train epoch: 252:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.48it/s, loss=27.6]train epoch: 252:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.82it/s, loss=27.6]train epoch: 252:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.82it/s, loss=29.7]train epoch: 252:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.87it/s, loss=29.7]train epoch: 252:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.87it/s, loss=42.7]train epoch: 252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.66it/s, loss=42.7]train epoch: 252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.60it/s, loss=42.7]
[[032m2021-11-26 10:38:36,287[0m INFO] trainer.training_epoch Training epoch 252, num_steps 2024,  avg_loss: 29.8583, total_loss: 238.8663
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.29it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.03it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.30it/s]
[[032m2021-11-26 10:38:37,298[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:38:37,299[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:37,560[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 253:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 253:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.7]train epoch: 253:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.06it/s, loss=33.7]train epoch: 253:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.06it/s, loss=27.4]train epoch: 253:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.06it/s, loss=27.4]train epoch: 253:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.06it/s, loss=19.2]train epoch: 253:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.93it/s, loss=19.2]train epoch: 253:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.93it/s, loss=27.4]train epoch: 253:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.91it/s, loss=27.4]train epoch: 253:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.91it/s, loss=21.7]train epoch: 253:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.97it/s, loss=21.7]train epoch: 253:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.97it/s, loss=28.5]train epoch: 253:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.43it/s, loss=28.5]train epoch: 253:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.43it/s, loss=28.2]train epoch: 253:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.79it/s, loss=28.2]train epoch: 253:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.79it/s, loss=32.4]train epoch: 253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.88it/s, loss=32.4]train epoch: 253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=32.4]
[[032m2021-11-26 10:38:40,910[0m INFO] trainer.training_epoch Training epoch 253, num_steps 2032,  avg_loss: 27.3239, total_loss: 218.5913
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.17it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.07it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.44it/s]
[[032m2021-11-26 10:38:41,490[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.46875)])
[[032m2021-11-26 10:38:41,491[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:42,364[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 254:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 254:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.1]train epoch: 254:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.30it/s, loss=28.1]train epoch: 254:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.30it/s, loss=26.3]train epoch: 254:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=26.3]train epoch: 254:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=21.7]train epoch: 254:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=21.7]train epoch: 254:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=25.5]train epoch: 254:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=25.5]train epoch: 254:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=36.5]train epoch: 254:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.67it/s, loss=36.5]train epoch: 254:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.67it/s, loss=23]  train epoch: 254:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.59it/s, loss=23]train epoch: 254:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.59it/s, loss=27.2]train epoch: 254:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=27.2]train epoch: 254:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=26.2]train epoch: 254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.66it/s, loss=26.2]train epoch: 254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.76it/s, loss=26.2]
[[032m2021-11-26 10:38:45,277[0m INFO] trainer.training_epoch Training epoch 254, num_steps 2040,  avg_loss: 26.7986, total_loss: 214.3891
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.25it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.95it/s]
[[032m2021-11-26 10:38:45,697[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:38:45,697[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:45,988[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 255:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 255:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 255:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.38it/s, loss=27.9]train epoch: 255:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.38it/s, loss=22.8]train epoch: 255:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.15it/s, loss=22.8]train epoch: 255:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.15it/s, loss=23.1]train epoch: 255:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=23.1]train epoch: 255:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=19.6]train epoch: 255:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=19.6]train epoch: 255:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=23]  train epoch: 255:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.02it/s, loss=23]train epoch: 255:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.02it/s, loss=18.5]train epoch: 255:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=18.5]train epoch: 255:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=28.7]train epoch: 255:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=28.7]train epoch: 255:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=29.2]train epoch: 255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=29.2]train epoch: 255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s, loss=29.2]
[[032m2021-11-26 10:38:48,683[0m INFO] trainer.training_epoch Training epoch 255, num_steps 2048,  avg_loss: 24.1092, total_loss: 192.8736
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.73it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.18it/s]
[[032m2021-11-26 10:38:49,359[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:38:49,360[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:49,620[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 256:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 256:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 256:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.66it/s, loss=23.6]train epoch: 256:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.66it/s, loss=26.1]train epoch: 256:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.34it/s, loss=26.1]train epoch: 256:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.34it/s, loss=25.5]train epoch: 256:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.86it/s, loss=25.5]train epoch: 256:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.86it/s, loss=31.2]train epoch: 256:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=31.2]train epoch: 256:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=32]  train epoch: 256:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=32]train epoch: 256:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.81it/s, loss=28.1]train epoch: 256:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.59it/s, loss=28.1]train epoch: 256:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.59it/s, loss=25.8]train epoch: 256:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.40it/s, loss=25.8]train epoch: 256:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.40it/s, loss=23.8]train epoch: 256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s, loss=23.8]train epoch: 256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=23.8]
[[032m2021-11-26 10:38:52,777[0m INFO] trainer.training_epoch Training epoch 256, num_steps 2056,  avg_loss: 27.0159, total_loss: 216.1270
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.80it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.19it/s]
[[032m2021-11-26 10:38:53,456[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:38:53,456[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:53,752[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 257:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 257:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.6]train epoch: 257:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.54it/s, loss=28.6]train epoch: 257:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.54it/s, loss=21.8]train epoch: 257:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.90it/s, loss=21.8]train epoch: 257:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.90it/s, loss=27.2]train epoch: 257:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.44it/s, loss=27.2]train epoch: 257:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.44it/s, loss=27.8]train epoch: 257:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=27.8]train epoch: 257:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=23.7]train epoch: 257:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.88it/s, loss=23.7]train epoch: 257:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.88it/s, loss=23.5]train epoch: 257:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.18it/s, loss=23.5]train epoch: 257:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.18it/s, loss=28.2]train epoch: 257:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.06it/s, loss=28.2]train epoch: 257:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.06it/s, loss=20.8]train epoch: 257: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=20.8]train epoch: 257: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.30it/s, loss=20.8]
[[032m2021-11-26 10:38:57,235[0m INFO] trainer.training_epoch Training epoch 257, num_steps 2064,  avg_loss: 25.2074, total_loss: 201.6595
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.27it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.05it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.63it/s]
[[032m2021-11-26 10:38:58,013[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:38:58,013[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:38:58,317[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 258:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 258:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.9]train epoch: 258:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.47it/s, loss=29.9]train epoch: 258:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.47it/s, loss=18.4]train epoch: 258:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.47it/s, loss=18.4]train epoch: 258:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.47it/s, loss=36]  train epoch: 258:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.10it/s, loss=36]train epoch: 258:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.10it/s, loss=28.8]train epoch: 258:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=28.8]train epoch: 258:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=27.8]train epoch: 258:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=27.8]train epoch: 258:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=28]  train epoch: 258:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.01it/s, loss=28]train epoch: 258:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.01it/s, loss=27.8]train epoch: 258:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.45it/s, loss=27.8]train epoch: 258:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.45it/s, loss=34.6]train epoch: 258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.06it/s, loss=34.6]train epoch: 258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=34.6]
[[032m2021-11-26 10:39:01,498[0m INFO] trainer.training_epoch Training epoch 258, num_steps 2072,  avg_loss: 28.9071, total_loss: 231.2568
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.69it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.34it/s]
[[032m2021-11-26 10:39:02,434[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:39:02,435[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:02,958[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 259:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 259:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.7]train epoch: 259:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.64it/s, loss=24.7]train epoch: 259:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.64it/s, loss=34.8]train epoch: 259:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.71it/s, loss=34.8]train epoch: 259:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.71it/s, loss=30.7]train epoch: 259:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=30.7]train epoch: 259:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=31.2]train epoch: 259:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=31.2]train epoch: 259:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=28]  train epoch: 259:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.51it/s, loss=28]train epoch: 259:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.51it/s, loss=32.3]train epoch: 259:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.65it/s, loss=32.3]train epoch: 259:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.65it/s, loss=24.3]train epoch: 259:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=24.3]train epoch: 259:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=32.9]train epoch: 259: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=32.9]train epoch: 259: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s, loss=32.9]
[[032m2021-11-26 10:39:05,684[0m INFO] trainer.training_epoch Training epoch 259, num_steps 2080,  avg_loss: 29.8692, total_loss: 238.9534
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.43it/s]
[[032m2021-11-26 10:39:06,356[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:39:06,357[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:06,942[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 260:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 260:   0%|          | 0/8 [00:00<?, ?it/s, loss=29]train epoch: 260:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.31it/s, loss=29]train epoch: 260:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.31it/s, loss=26.8]train epoch: 260:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.17it/s, loss=26.8]train epoch: 260:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.17it/s, loss=23.3]train epoch: 260:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.93it/s, loss=23.3]train epoch: 260:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.93it/s, loss=31.7]train epoch: 260:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.46it/s, loss=31.7]train epoch: 260:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.46it/s, loss=30.9]train epoch: 260:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.47it/s, loss=30.9]train epoch: 260:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.47it/s, loss=25.7]train epoch: 260:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.59it/s, loss=25.7]train epoch: 260:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.59it/s, loss=26.1]train epoch: 260:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.62it/s, loss=26.1]train epoch: 260:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.62it/s, loss=26.1]train epoch: 260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=26.1]train epoch: 260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.37it/s, loss=26.1]
[[032m2021-11-26 10:39:10,327[0m INFO] trainer.training_epoch Training epoch 260, num_steps 2088,  avg_loss: 27.4480, total_loss: 219.5842
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.82it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.56it/s]
[[032m2021-11-26 10:39:10,820[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:39:10,821[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:11,266[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 261:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 261:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.9]train epoch: 261:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.24it/s, loss=25.9]train epoch: 261:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  2.24it/s, loss=28]  train epoch: 261:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.90it/s, loss=28]train epoch: 261:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.90it/s, loss=27.4]train epoch: 261:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.08it/s, loss=27.4]train epoch: 261:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  2.08it/s, loss=30.1]train epoch: 261:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.37it/s, loss=30.1]train epoch: 261:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.37it/s, loss=32.2]train epoch: 261:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.77it/s, loss=32.2]train epoch: 261:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.77it/s, loss=30]  train epoch: 261:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.80it/s, loss=30]train epoch: 261:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.80it/s, loss=28.9]train epoch: 261:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.05it/s, loss=28.9]train epoch: 261:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  2.05it/s, loss=18.4]train epoch: 261: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.25it/s, loss=18.4]train epoch: 261: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.96it/s, loss=18.4]
[[032m2021-11-26 10:39:15,372[0m INFO] trainer.training_epoch Training epoch 261, num_steps 2096,  avg_loss: 27.6115, total_loss: 220.8924
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.92it/s]
[[032m2021-11-26 10:39:15,804[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:39:15,804[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:16,549[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 262:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 262:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.6]train epoch: 262:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.98it/s, loss=32.6]train epoch: 262:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.98it/s, loss=31]  train epoch: 262:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.25it/s, loss=31]train epoch: 262:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.25it/s, loss=23.8]train epoch: 262:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.45it/s, loss=23.8]train epoch: 262:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.45it/s, loss=25.1]train epoch: 262:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=25.1]
model tensor([[0.5951, 0.4049],
        [0.3489, 0.6511],
        [0.3690, 0.6310],
        [0.6493, 0.3507],
        [0.4305, 0.5695],
        [0.4404, 0.5596],
        [0.4383, 0.5617],
        [0.4201, 0.5799]], device='cuda:0')

prompt tensor([[0.6404, 0.3596],
        [0.5254, 0.4746],
        [0.6159, 0.3841],
        [0.6439, 0.3561],
        [0.5103, 0.4897],
        [0.6293, 0.3707],
        [0.8320, 0.1680],
        [0.3989, 0.6011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 262:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=28.3]train epoch: 262:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=28.3]train epoch: 262:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.82it/s, loss=24.9]train epoch: 262:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=24.9]train epoch: 262:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=29.8]train epoch: 262:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=29.8]train epoch: 262:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=27.8]train epoch: 262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s, loss=27.8]train epoch: 262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=27.8]
[[032m2021-11-26 10:39:19,431[0m INFO] trainer.training_epoch Training epoch 262, num_steps 2104,  avg_loss: 27.9097, total_loss: 223.2778
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.58it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.93it/s]
[[032m2021-11-26 10:39:19,961[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:39:19,961[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:20,357[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 263:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 263:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 263:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=25.5]train epoch: 263:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=27.8]train epoch: 263:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.77it/s, loss=27.8]train epoch: 263:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.77it/s, loss=27.5]train epoch: 263:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=27.5]train epoch: 263:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=26.9]train epoch: 263:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=26.9]train epoch: 263:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=23.8]train epoch: 263:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=23.8]train epoch: 263:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.91it/s, loss=26.8]train epoch: 263:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.05it/s, loss=26.8]train epoch: 263:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.05it/s, loss=26.1]train epoch: 263:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.17it/s, loss=26.1]train epoch: 263:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.17it/s, loss=29.3]train epoch: 263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=29.3]train epoch: 263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.06it/s, loss=29.3]
[[032m2021-11-26 10:39:22,989[0m INFO] trainer.training_epoch Training epoch 263, num_steps 2112,  avg_loss: 26.7103, total_loss: 213.6824
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.09it/s]
[[032m2021-11-26 10:39:23,400[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:39:23,400[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:23,644[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 264:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 264:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.4]train epoch: 264:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=25.4]train epoch: 264:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=27.1]train epoch: 264:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=27.1]train epoch: 264:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=17.2]train epoch: 264:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.41it/s, loss=17.2]train epoch: 264:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.41it/s, loss=28.4]train epoch: 264:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.53it/s, loss=28.4]train epoch: 264:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.53it/s, loss=23]  train epoch: 264:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s, loss=23]train epoch: 264:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s, loss=31.2]train epoch: 264:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.22it/s, loss=31.2]train epoch: 264:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=36.3]train epoch: 264:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=36.3]train epoch: 264:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=27.3]train epoch: 264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=27.3]train epoch: 264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=27.3]
[[032m2021-11-26 10:39:26,052[0m INFO] trainer.training_epoch Training epoch 264, num_steps 2120,  avg_loss: 26.9773, total_loss: 215.8187
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.38it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.70it/s]
[[032m2021-11-26 10:39:26,786[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:26,786[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:27,367[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 265:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 265:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.6]train epoch: 265:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.84it/s, loss=34.6]train epoch: 265:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.84it/s, loss=25.4]train epoch: 265:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.32it/s, loss=25.4]train epoch: 265:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.32it/s, loss=27.2]train epoch: 265:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.29it/s, loss=27.2]train epoch: 265:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.29it/s, loss=30.7]train epoch: 265:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  2.00it/s, loss=30.7]train epoch: 265:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  2.00it/s, loss=23.8]train epoch: 265:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.29it/s, loss=23.8]train epoch: 265:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.29it/s, loss=31.3]train epoch: 265:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.23it/s, loss=31.3]train epoch: 265:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.23it/s, loss=24.1]train epoch: 265:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.26it/s, loss=24.1]train epoch: 265:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.26it/s, loss=29.7]train epoch: 265: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=29.7]train epoch: 265: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=29.7]
[[032m2021-11-26 10:39:30,775[0m INFO] trainer.training_epoch Training epoch 265, num_steps 2128,  avg_loss: 28.3434, total_loss: 226.7472
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.26it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.77it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.24it/s]
[[032m2021-11-26 10:39:31,596[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:31,596[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:33,006[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 266:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 266:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.1]train epoch: 266:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.54it/s, loss=25.1]train epoch: 266:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.54it/s, loss=27.5]train epoch: 266:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.25it/s, loss=27.5]train epoch: 266:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.25it/s, loss=34.5]train epoch: 266:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.35it/s, loss=34.5]train epoch: 266:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.35it/s, loss=21.8]train epoch: 266:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=21.8]train epoch: 266:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.65it/s, loss=28.7]train epoch: 266:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=28.7]train epoch: 266:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.81it/s, loss=27.9]train epoch: 266:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.69it/s, loss=27.9]train epoch: 266:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.69it/s, loss=25]  train epoch: 266:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.62it/s, loss=25]train epoch: 266:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.62it/s, loss=35.1]train epoch: 266: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.53it/s, loss=35.1]train epoch: 266: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.56it/s, loss=35.1]
[[032m2021-11-26 10:39:36,171[0m INFO] trainer.training_epoch Training epoch 266, num_steps 2136,  avg_loss: 28.1971, total_loss: 225.5765
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.19it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.91it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.49it/s]
[[032m2021-11-26 10:39:36,947[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:36,948[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:37,387[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 267:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 267:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.6]train epoch: 267:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.82it/s, loss=30.6]train epoch: 267:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.82it/s, loss=28.5]train epoch: 267:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.49it/s, loss=28.5]train epoch: 267:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.49it/s, loss=24.6]train epoch: 267:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=24.6]train epoch: 267:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=21.8]train epoch: 267:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=21.8]train epoch: 267:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=27.8]train epoch: 267:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=27.8]train epoch: 267:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=24.3]train epoch: 267:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.27it/s, loss=24.3]train epoch: 267:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.27it/s, loss=30.6]train epoch: 267:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.93it/s, loss=30.6]train epoch: 267:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.93it/s, loss=20.9]train epoch: 267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.09it/s, loss=20.9]train epoch: 267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s, loss=20.9]
[[032m2021-11-26 10:39:39,901[0m INFO] trainer.training_epoch Training epoch 267, num_steps 2144,  avg_loss: 26.1464, total_loss: 209.1710
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.50it/s]
[[032m2021-11-26 10:39:40,661[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:40,671[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:41,456[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 268:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 268:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 268:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.82it/s, loss=23.6]train epoch: 268:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.82it/s, loss=23]  train epoch: 268:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.29it/s, loss=23]train epoch: 268:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.29it/s, loss=28.8]train epoch: 268:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.55it/s, loss=28.8]train epoch: 268:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.55it/s, loss=27.8]train epoch: 268:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.76it/s, loss=27.8]train epoch: 268:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.76it/s, loss=23.1]train epoch: 268:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=23.1]train epoch: 268:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.01it/s, loss=23]  train epoch: 268:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=23]train epoch: 268:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=29.3]train epoch: 268:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=29.3]train epoch: 268:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=29.3]train epoch: 268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=29.3]train epoch: 268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=29.3]
[[032m2021-11-26 10:39:44,202[0m INFO] trainer.training_epoch Training epoch 268, num_steps 2152,  avg_loss: 25.9927, total_loss: 207.9417
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.38it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.75it/s]
[[032m2021-11-26 10:39:44,812[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:44,813[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:45,480[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 269:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 269:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.1]train epoch: 269:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.31it/s, loss=24.1]train epoch: 269:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.31it/s, loss=26.3]train epoch: 269:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.65it/s, loss=26.3]train epoch: 269:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.65it/s, loss=40]  train epoch: 269:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.27it/s, loss=40]train epoch: 269:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.27it/s, loss=29.4]train epoch: 269:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.29it/s, loss=29.4]train epoch: 269:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.29it/s, loss=24.7]train epoch: 269:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.28it/s, loss=24.7]train epoch: 269:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.28it/s, loss=35.4]train epoch: 269:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.21it/s, loss=35.4]train epoch: 269:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.21it/s, loss=33.2]train epoch: 269:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.27it/s, loss=33.2]train epoch: 269:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.27it/s, loss=23.8]train epoch: 269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.60it/s, loss=23.8]train epoch: 269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.41it/s, loss=23.8]
[[032m2021-11-26 10:39:48,815[0m INFO] trainer.training_epoch Training epoch 269, num_steps 2160,  avg_loss: 29.6053, total_loss: 236.8427
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.52it/s]
[[032m2021-11-26 10:39:49,578[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:49,578[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:50,562[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 270:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 270:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.3]train epoch: 270:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.69it/s, loss=33.3]train epoch: 270:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.69it/s, loss=28]  train epoch: 270:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.20it/s, loss=28]train epoch: 270:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.20it/s, loss=29.8]train epoch: 270:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=29.8]train epoch: 270:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=17]  train epoch: 270:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=17]train epoch: 270:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.80it/s, loss=27.6]train epoch: 270:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=27.6]train epoch: 270:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=29.2]train epoch: 270:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.52it/s, loss=29.2]train epoch: 270:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.52it/s, loss=20.6]train epoch: 270:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=20.6]train epoch: 270:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=24.9]train epoch: 270: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=24.9]train epoch: 270: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s, loss=24.9]
[[032m2021-11-26 10:39:53,560[0m INFO] trainer.training_epoch Training epoch 270, num_steps 2168,  avg_loss: 26.2881, total_loss: 210.3049
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.58it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.79it/s]
[[032m2021-11-26 10:39:54,296[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:54,296[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:55,194[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 271:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 271:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.7]train epoch: 271:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:05,  1.40it/s, loss=24.7]train epoch: 271:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:05,  1.40it/s, loss=30.1]train epoch: 271:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:05,  1.17it/s, loss=30.1]train epoch: 271:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:05,  1.17it/s, loss=27.4]train epoch: 271:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.65it/s, loss=27.4]train epoch: 271:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.65it/s, loss=33.7]train epoch: 271:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.13it/s, loss=33.7]train epoch: 271:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.13it/s, loss=21.8]train epoch: 271:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.28it/s, loss=21.8]train epoch: 271:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.28it/s, loss=22.1]train epoch: 271:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=22.1]train epoch: 271:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.67it/s, loss=35.8]train epoch: 271:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  3.08it/s, loss=35.8]train epoch: 271:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  3.08it/s, loss=27.5]train epoch: 271: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  3.04it/s, loss=27.5]train epoch: 271: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.33it/s, loss=27.5]
[[032m2021-11-26 10:39:58,633[0m INFO] trainer.training_epoch Training epoch 271, num_steps 2176,  avg_loss: 27.8864, total_loss: 223.0913
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.28it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.64it/s]
[[032m2021-11-26 10:39:59,065[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:39:59,065[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:39:59,409[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 272:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 272:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.8]train epoch: 272:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=26.8]train epoch: 272:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=25.1]train epoch: 272:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.04it/s, loss=25.1]train epoch: 272:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.04it/s, loss=27.8]train epoch: 272:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=27.8]train epoch: 272:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=29.7]train epoch: 272:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=29.7]train epoch: 272:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=29.3]train epoch: 272:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.96it/s, loss=29.3]train epoch: 272:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.96it/s, loss=27.8]train epoch: 272:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=27.8]train epoch: 272:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=33.5]train epoch: 272:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.59it/s, loss=33.5]train epoch: 272:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.59it/s, loss=21.7]train epoch: 272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=21.7]train epoch: 272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.84it/s, loss=21.7]
[[032m2021-11-26 10:40:02,228[0m INFO] trainer.training_epoch Training epoch 272, num_steps 2184,  avg_loss: 27.7023, total_loss: 221.6187
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.65it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.67it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.21it/s]
[[032m2021-11-26 10:40:02,696[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:02,696[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:03,209[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 273:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 273:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.2]train epoch: 273:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.93it/s, loss=28.2]train epoch: 273:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.93it/s, loss=23.3]train epoch: 273:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.32it/s, loss=23.3]train epoch: 273:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.32it/s, loss=24.9]train epoch: 273:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.96it/s, loss=24.9]train epoch: 273:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.96it/s, loss=25.7]train epoch: 273:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.37it/s, loss=25.7]train epoch: 273:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.37it/s, loss=28.7]train epoch: 273:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.99it/s, loss=28.7]train epoch: 273:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.99it/s, loss=34]  train epoch: 273:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.90it/s, loss=34]train epoch: 273:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.90it/s, loss=22.8]train epoch: 273:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.98it/s, loss=22.8]train epoch: 273:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.98it/s, loss=30.7]train epoch: 273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.17it/s, loss=30.7]train epoch: 273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.19it/s, loss=30.7]
[[032m2021-11-26 10:40:06,892[0m INFO] trainer.training_epoch Training epoch 273, num_steps 2192,  avg_loss: 27.2997, total_loss: 218.3974
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.05it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.74it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.23it/s]
[[032m2021-11-26 10:40:07,490[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:07,490[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:07,884[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 274:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 274:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.3]train epoch: 274:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.31it/s, loss=26.3]train epoch: 274:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.31it/s, loss=30.4]train epoch: 274:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.57it/s, loss=30.4]train epoch: 274:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.57it/s, loss=24.1]train epoch: 274:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=24.1]train epoch: 274:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=27.4]train epoch: 274:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.69it/s, loss=27.4]train epoch: 274:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.69it/s, loss=22.7]train epoch: 274:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.88it/s, loss=22.7]train epoch: 274:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.88it/s, loss=27.9]train epoch: 274:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.85it/s, loss=27.9]train epoch: 274:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.85it/s, loss=31]  train epoch: 274:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.82it/s, loss=31]train epoch: 274:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.82it/s, loss=24.3]train epoch: 274: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.68it/s, loss=24.3]train epoch: 274: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.03it/s, loss=24.3]
[[032m2021-11-26 10:40:11,835[0m INFO] trainer.training_epoch Training epoch 274, num_steps 2200,  avg_loss: 26.7426, total_loss: 213.9404
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.72it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.91it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.06it/s]
[[032m2021-11-26 10:40:12,360[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:12,361[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:12,587[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 275:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3806, 0.6194],
        [0.3489, 0.6511],
        [0.2477, 0.7523],
        [0.4988, 0.5012],
        [0.3391, 0.6609],
        [0.7953, 0.2047],
        [0.5715, 0.4285],
        [0.6310, 0.3690]], device='cuda:0')

prompt tensor([[0.5549, 0.4451],
        [0.5711, 0.4289],
        [0.2676, 0.7324],
        [0.5650, 0.4350],
        [0.6695, 0.3305],
        [0.9105, 0.0895],
        [0.6458, 0.3542],
        [0.3004, 0.6996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 275:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.3]train epoch: 275:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.56it/s, loss=26.3]train epoch: 275:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.56it/s, loss=23.3]train epoch: 275:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=23.3]train epoch: 275:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.19it/s, loss=28.7]train epoch: 275:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.04it/s, loss=28.7]train epoch: 275:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.04it/s, loss=23.8]train epoch: 275:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.76it/s, loss=23.8]train epoch: 275:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.76it/s, loss=36.7]train epoch: 275:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s, loss=36.7]train epoch: 275:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s, loss=31.3]train epoch: 275:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=31.3]train epoch: 275:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=26.7]train epoch: 275:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.46it/s, loss=26.7]train epoch: 275:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.46it/s, loss=32.7]train epoch: 275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.85it/s, loss=32.7]train epoch: 275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=32.7]
[[032m2021-11-26 10:40:14,983[0m INFO] trainer.training_epoch Training epoch 275, num_steps 2208,  avg_loss: 28.6906, total_loss: 229.5252
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.46it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.02it/s]
[[032m2021-11-26 10:40:15,716[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:15,727[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:16,243[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 276:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 276:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.4]train epoch: 276:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=21.4]train epoch: 276:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=35.9]train epoch: 276:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=35.9]train epoch: 276:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=29.4]train epoch: 276:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.45it/s, loss=29.4]train epoch: 276:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.45it/s, loss=35.9]train epoch: 276:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=35.9]train epoch: 276:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=24.8]train epoch: 276:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.76it/s, loss=24.8]train epoch: 276:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.76it/s, loss=28.7]train epoch: 276:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.06it/s, loss=28.7]train epoch: 276:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.06it/s, loss=24.1]train epoch: 276:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=24.1]train epoch: 276:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=29.3]train epoch: 276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.81it/s, loss=29.3]train epoch: 276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=29.3]
[[032m2021-11-26 10:40:18,974[0m INFO] trainer.training_epoch Training epoch 276, num_steps 2216,  avg_loss: 28.6985, total_loss: 229.5880
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.63it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.06it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.17it/s]
[[032m2021-11-26 10:40:19,779[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:19,779[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:20,094[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 277:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 277:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.1]train epoch: 277:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.44it/s, loss=24.1]train epoch: 277:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.44it/s, loss=31.3]train epoch: 277:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.18it/s, loss=31.3]train epoch: 277:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.18it/s, loss=31]  train epoch: 277:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=31]train epoch: 277:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=29.3]train epoch: 277:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=29.3]train epoch: 277:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.16it/s, loss=33.8]train epoch: 277:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.39it/s, loss=33.8]train epoch: 277:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.39it/s, loss=32]  train epoch: 277:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.39it/s, loss=32]train epoch: 277:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.39it/s, loss=27.8]train epoch: 277:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.45it/s, loss=27.8]train epoch: 277:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.45it/s, loss=27.1]train epoch: 277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.18it/s, loss=27.1]train epoch: 277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s, loss=27.1]
[[032m2021-11-26 10:40:23,616[0m INFO] trainer.training_epoch Training epoch 277, num_steps 2224,  avg_loss: 29.5405, total_loss: 236.3237
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.39it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.54it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  4.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.95it/s]
[[032m2021-11-26 10:40:24,650[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:24,650[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:24,973[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 278:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 278:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 278:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=27.9]train epoch: 278:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=30.1]train epoch: 278:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.27it/s, loss=30.1]train epoch: 278:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.27it/s, loss=37.4]train epoch: 278:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.94it/s, loss=37.4]train epoch: 278:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.94it/s, loss=26.5]train epoch: 278:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.36it/s, loss=26.5]train epoch: 278:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.36it/s, loss=27.5]train epoch: 278:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=27.5]train epoch: 278:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=23.3]train epoch: 278:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.58it/s, loss=23.3]train epoch: 278:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.58it/s, loss=28.4]train epoch: 278:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.75it/s, loss=28.4]train epoch: 278:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.75it/s, loss=34.8]train epoch: 278: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.77it/s, loss=34.8]train epoch: 278: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=34.8]
[[032m2021-11-26 10:40:27,238[0m INFO] trainer.training_epoch Training epoch 278, num_steps 2232,  avg_loss: 29.4718, total_loss: 235.7742
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.96it/s]
[[032m2021-11-26 10:40:27,656[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:27,657[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:28,186[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 279:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 279:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.6]train epoch: 279:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=27.6]train epoch: 279:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=28.7]train epoch: 279:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.94it/s, loss=28.7]train epoch: 279:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.94it/s, loss=29.8]train epoch: 279:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=29.8]train epoch: 279:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=32.5]train epoch: 279:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.26it/s, loss=32.5]train epoch: 279:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.26it/s, loss=27.9]train epoch: 279:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=27.9]train epoch: 279:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=32.6]train epoch: 279:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.31it/s, loss=32.6]train epoch: 279:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.31it/s, loss=26.1]train epoch: 279:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.34it/s, loss=26.1]train epoch: 279:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.34it/s, loss=29]  train epoch: 279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s, loss=29]train epoch: 279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.50it/s, loss=29]
[[032m2021-11-26 10:40:31,400[0m INFO] trainer.training_epoch Training epoch 279, num_steps 2240,  avg_loss: 29.2630, total_loss: 234.1041
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.51it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.47it/s]
[[032m2021-11-26 10:40:32,056[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:32,057[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:32,634[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 280:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 280:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.2]train epoch: 280:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.69it/s, loss=26.2]train epoch: 280:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.69it/s, loss=22.2]train epoch: 280:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.10it/s, loss=22.2]train epoch: 280:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.10it/s, loss=24]  train epoch: 280:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.72it/s, loss=24]train epoch: 280:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.72it/s, loss=38.1]train epoch: 280:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.95it/s, loss=38.1]train epoch: 280:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.95it/s, loss=30.4]train epoch: 280:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=30.4]train epoch: 280:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.36it/s, loss=28.4]train epoch: 280:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.68it/s, loss=28.4]train epoch: 280:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.68it/s, loss=31.8]train epoch: 280:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.80it/s, loss=31.8]train epoch: 280:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.80it/s, loss=30.8]train epoch: 280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.83it/s, loss=30.8]train epoch: 280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.47it/s, loss=30.8]
[[032m2021-11-26 10:40:35,884[0m INFO] trainer.training_epoch Training epoch 280, num_steps 2248,  avg_loss: 28.9996, total_loss: 231.9968
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.66it/s]
[[032m2021-11-26 10:40:36,381[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:40:36,381[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:37,212[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 281:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 281:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.3]train epoch: 281:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=23.3]train epoch: 281:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.12it/s, loss=28.4]train epoch: 281:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.04it/s, loss=28.4]train epoch: 281:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.04it/s, loss=31.5]train epoch: 281:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.25it/s, loss=31.5]train epoch: 281:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.25it/s, loss=29.9]train epoch: 281:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.29it/s, loss=29.9]train epoch: 281:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.29it/s, loss=25.9]train epoch: 281:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.73it/s, loss=25.9]train epoch: 281:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.73it/s, loss=21.3]train epoch: 281:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.68it/s, loss=21.3]train epoch: 281:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.68it/s, loss=22.1]train epoch: 281:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.44it/s, loss=22.1]train epoch: 281:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.44it/s, loss=32.8]train epoch: 281: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.30it/s, loss=32.8]train epoch: 281: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.60it/s, loss=32.8]
[[032m2021-11-26 10:40:40,302[0m INFO] trainer.training_epoch Training epoch 281, num_steps 2256,  avg_loss: 26.9004, total_loss: 215.2029
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.68it/s]
[[032m2021-11-26 10:40:40,765[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:40:40,765[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:41,050[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 282:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 282:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 282:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=24.9]train epoch: 282:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=28]  train epoch: 282:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.40it/s, loss=28]train epoch: 282:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.40it/s, loss=20.9]train epoch: 282:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.58it/s, loss=20.9]train epoch: 282:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.58it/s, loss=25.6]train epoch: 282:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=25.6]train epoch: 282:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.70it/s, loss=22]  train epoch: 282:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.19it/s, loss=22]train epoch: 282:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.19it/s, loss=29.5]train epoch: 282:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.04it/s, loss=29.5]train epoch: 282:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.04it/s, loss=28.6]train epoch: 282:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.12it/s, loss=28.6]train epoch: 282:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.12it/s, loss=20]  train epoch: 282: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.16it/s, loss=20]train epoch: 282: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.24it/s, loss=20]
[[032m2021-11-26 10:40:44,634[0m INFO] trainer.training_epoch Training epoch 282, num_steps 2264,  avg_loss: 24.9331, total_loss: 199.4645
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.59it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.71it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.06it/s]
[[032m2021-11-26 10:40:45,218[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:40:45,218[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:45,457[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 283:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 283:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.9]train epoch: 283:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=26.9]train epoch: 283:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=25.8]train epoch: 283:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.38it/s, loss=25.8]train epoch: 283:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.38it/s, loss=35.3]train epoch: 283:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.62it/s, loss=35.3]train epoch: 283:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.62it/s, loss=22.2]train epoch: 283:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.14it/s, loss=22.2]train epoch: 283:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.14it/s, loss=29.5]train epoch: 283:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.40it/s, loss=29.5]train epoch: 283:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.40it/s, loss=32.6]train epoch: 283:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.22it/s, loss=32.6]train epoch: 283:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.22it/s, loss=31.4]train epoch: 283:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.28it/s, loss=31.4]train epoch: 283:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.28it/s, loss=29.6]train epoch: 283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.51it/s, loss=29.6]train epoch: 283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.32it/s, loss=29.6]
[[032m2021-11-26 10:40:48,911[0m INFO] trainer.training_epoch Training epoch 283, num_steps 2272,  avg_loss: 29.1746, total_loss: 233.3966
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.22it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.83it/s]
[[032m2021-11-26 10:40:49,618[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:49,619[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:50,201[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 284:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 284:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.1]train epoch: 284:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=26.1]train epoch: 284:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=28.8]train epoch: 284:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.74it/s, loss=28.8]train epoch: 284:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.74it/s, loss=34.8]train epoch: 284:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.19it/s, loss=34.8]train epoch: 284:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.19it/s, loss=24]  train epoch: 284:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.93it/s, loss=24]train epoch: 284:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.93it/s, loss=27.5]train epoch: 284:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.11it/s, loss=27.5]train epoch: 284:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.11it/s, loss=31.9]train epoch: 284:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.93it/s, loss=31.9]train epoch: 284:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.93it/s, loss=34.3]train epoch: 284:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.91it/s, loss=34.3]train epoch: 284:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.91it/s, loss=20.9]train epoch: 284: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.22it/s, loss=20.9]train epoch: 284: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.25it/s, loss=20.9]
[[032m2021-11-26 10:40:53,765[0m INFO] trainer.training_epoch Training epoch 284, num_steps 2280,  avg_loss: 28.5377, total_loss: 228.3016
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.11it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.02it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.47it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.02it/s]
[[032m2021-11-26 10:40:54,369[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:54,369[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:54,898[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 285:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 285:   0%|          | 0/8 [00:00<?, ?it/s, loss=40.6]train epoch: 285:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=40.6]train epoch: 285:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=27.6]train epoch: 285:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=27.6]train epoch: 285:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=35.6]train epoch: 285:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.25it/s, loss=35.6]train epoch: 285:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.25it/s, loss=29]  train epoch: 285:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.51it/s, loss=29]train epoch: 285:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.51it/s, loss=28.9]train epoch: 285:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.24it/s, loss=28.9]train epoch: 285:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.24it/s, loss=26.5]train epoch: 285:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.92it/s, loss=26.5]train epoch: 285:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.92it/s, loss=27.2]train epoch: 285:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.10it/s, loss=27.2]train epoch: 285:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.10it/s, loss=29.5]train epoch: 285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=29.5]train epoch: 285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.24it/s, loss=29.5]
[[032m2021-11-26 10:40:58,468[0m INFO] trainer.training_epoch Training epoch 285, num_steps 2288,  avg_loss: 30.6180, total_loss: 244.9444
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.33it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.85it/s]
[[032m2021-11-26 10:40:59,172[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:40:59,172[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:40:59,665[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 286:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 286:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.3]train epoch: 286:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.90it/s, loss=33.3]train epoch: 286:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.90it/s, loss=27.5]train epoch: 286:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.58it/s, loss=27.5]train epoch: 286:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.58it/s, loss=27.2]train epoch: 286:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.40it/s, loss=27.2]train epoch: 286:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.40it/s, loss=30.3]train epoch: 286:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.44it/s, loss=30.3]train epoch: 286:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.44it/s, loss=25.6]train epoch: 286:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.44it/s, loss=25.6]train epoch: 286:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.44it/s, loss=25.9]train epoch: 286:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.20it/s, loss=25.9]train epoch: 286:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.20it/s, loss=27.3]train epoch: 286:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.32it/s, loss=27.3]train epoch: 286:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=27.5]train epoch: 286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.41it/s, loss=27.5]train epoch: 286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=27.5]
[[032m2021-11-26 10:41:03,001[0m INFO] trainer.training_epoch Training epoch 286, num_steps 2296,  avg_loss: 28.0608, total_loss: 224.4868
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.12it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.00it/s]
[[032m2021-11-26 10:41:03,518[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:41:03,519[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:03,947[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 287:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 287:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.7]train epoch: 287:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.33it/s, loss=22.7]train epoch: 287:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.33it/s, loss=26.9]train epoch: 287:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.38it/s, loss=26.9]train epoch: 287:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.38it/s, loss=30.3]train epoch: 287:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.74it/s, loss=30.3]train epoch: 287:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.74it/s, loss=27.3]train epoch: 287:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.06it/s, loss=27.3]
model tensor([[0.2873, 0.7127],
        [0.6493, 0.3507],
        [0.4305, 0.5695],
        [0.3806, 0.6194],
        [0.4593, 0.5407],
        [0.3690, 0.6310],
        [0.8361, 0.1639],
        [0.3049, 0.6951]], device='cuda:0')

prompt tensor([[0.4885, 0.5115],
        [0.5373, 0.4627],
        [0.4371, 0.5629],
        [0.6641, 0.3359],
        [0.5384, 0.4616],
        [0.4966, 0.5034],
        [0.8406, 0.1594],
        [0.4494, 0.5506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 287:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.06it/s, loss=21.6]train epoch: 287:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=21.6]train epoch: 287:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.98it/s, loss=35.3]train epoch: 287:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=35.3]train epoch: 287:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=26.6]train epoch: 287:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.52it/s, loss=26.6]train epoch: 287:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.52it/s, loss=24.4]train epoch: 287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=24.4]train epoch: 287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.64it/s, loss=24.4]
[[032m2021-11-26 10:41:07,001[0m INFO] trainer.training_epoch Training epoch 287, num_steps 2304,  avg_loss: 26.8877, total_loss: 215.1019
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.54it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.67it/s]
[[032m2021-11-26 10:41:07,721[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:41:07,721[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:08,217[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 288:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 288:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.2]train epoch: 288:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.94it/s, loss=29.2]train epoch: 288:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.94it/s, loss=23.5]train epoch: 288:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.40it/s, loss=23.5]train epoch: 288:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.40it/s, loss=28.1]train epoch: 288:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=28.1]train epoch: 288:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=39.3]train epoch: 288:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=39.3]train epoch: 288:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=23.5]train epoch: 288:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=23.5]train epoch: 288:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.04it/s, loss=28.4]train epoch: 288:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=28.4]train epoch: 288:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=27.5]train epoch: 288:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s, loss=27.5]train epoch: 288:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s, loss=20.5]train epoch: 288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=20.5]train epoch: 288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s, loss=20.5]
[[032m2021-11-26 10:41:10,861[0m INFO] trainer.training_epoch Training epoch 288, num_steps 2312,  avg_loss: 27.4827, total_loss: 219.8618
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.11it/s]
[[032m2021-11-26 10:41:11,542[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:11,542[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:12,119[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 289:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 289:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.3]train epoch: 289:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.02it/s, loss=24.3]train epoch: 289:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.02it/s, loss=27.3]train epoch: 289:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.67it/s, loss=27.3]train epoch: 289:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.67it/s, loss=33]  train epoch: 289:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.88it/s, loss=33]train epoch: 289:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.88it/s, loss=26]train epoch: 289:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.10it/s, loss=26]train epoch: 289:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.10it/s, loss=29.2]train epoch: 289:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.23it/s, loss=29.2]train epoch: 289:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.23it/s, loss=32.3]train epoch: 289:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=32.3]train epoch: 289:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=25.7]train epoch: 289:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.95it/s, loss=25.7]train epoch: 289:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.95it/s, loss=28.4]train epoch: 289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.81it/s, loss=28.4]train epoch: 289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=28.4]
[[032m2021-11-26 10:41:15,294[0m INFO] trainer.training_epoch Training epoch 289, num_steps 2320,  avg_loss: 28.2753, total_loss: 226.2022
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.06it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.59it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.16it/s]
[[032m2021-11-26 10:41:15,802[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:15,803[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:16,073[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 290:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 290:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.5]train epoch: 290:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=36.5]train epoch: 290:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=30.2]train epoch: 290:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.44it/s, loss=30.2]train epoch: 290:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.44it/s, loss=30.2]train epoch: 290:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=30.2]train epoch: 290:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=33.5]train epoch: 290:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=33.5]train epoch: 290:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=36.3]train epoch: 290:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.07it/s, loss=36.3]train epoch: 290:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.07it/s, loss=24.6]train epoch: 290:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.26it/s, loss=24.6]train epoch: 290:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.26it/s, loss=19.9]train epoch: 290:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=19.9]train epoch: 290:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=31.1]train epoch: 290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=31.1]train epoch: 290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=31.1]
[[032m2021-11-26 10:41:18,625[0m INFO] trainer.training_epoch Training epoch 290, num_steps 2328,  avg_loss: 30.2784, total_loss: 242.2271
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.16it/s]
[[032m2021-11-26 10:41:19,086[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:19,087[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:19,380[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 291:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 291:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.2]train epoch: 291:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.20it/s, loss=27.2]train epoch: 291:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.20it/s, loss=31.2]train epoch: 291:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.92it/s, loss=31.2]train epoch: 291:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.92it/s, loss=26.6]train epoch: 291:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.06it/s, loss=26.6]train epoch: 291:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.06it/s, loss=26.3]train epoch: 291:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.19it/s, loss=26.3]train epoch: 291:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.19it/s, loss=24.2]train epoch: 291:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.26it/s, loss=24.2]train epoch: 291:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.26it/s, loss=28.7]train epoch: 291:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.27it/s, loss=28.7]train epoch: 291:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.27it/s, loss=34]  train epoch: 291:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.22it/s, loss=34]train epoch: 291:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.22it/s, loss=21.9]train epoch: 291: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.06it/s, loss=21.9]train epoch: 291: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.62it/s, loss=21.9]
[[032m2021-11-26 10:41:22,435[0m INFO] trainer.training_epoch Training epoch 291, num_steps 2336,  avg_loss: 27.5105, total_loss: 220.0838
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.04it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.40it/s]
[[032m2021-11-26 10:41:22,876[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:22,876[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:23,427[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 292:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 292:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.2]train epoch: 292:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=31.2]train epoch: 292:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=19.7]train epoch: 292:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.93it/s, loss=19.7]train epoch: 292:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.93it/s, loss=36.7]train epoch: 292:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.97it/s, loss=36.7]train epoch: 292:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.97it/s, loss=25.8]train epoch: 292:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=25.8]train epoch: 292:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=29.5]train epoch: 292:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.93it/s, loss=29.5]train epoch: 292:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.93it/s, loss=36]  train epoch: 292:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=36]train epoch: 292:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=29.1]train epoch: 292:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=29.1]train epoch: 292:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=22.4]train epoch: 292: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s, loss=22.4]train epoch: 292: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s, loss=22.4]
[[032m2021-11-26 10:41:26,194[0m INFO] trainer.training_epoch Training epoch 292, num_steps 2344,  avg_loss: 28.7976, total_loss: 230.3807
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.64it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.77it/s]
[[032m2021-11-26 10:41:26,697[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:26,697[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:27,335[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 293:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 293:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.1]train epoch: 293:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:05,  1.28it/s, loss=37.1]train epoch: 293:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:05,  1.28it/s, loss=32.1]train epoch: 293:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=32.1]train epoch: 293:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=29.8]train epoch: 293:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.07it/s, loss=29.8]train epoch: 293:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.07it/s, loss=27.8]train epoch: 293:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=27.8]train epoch: 293:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.16it/s, loss=32.3]train epoch: 293:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.37it/s, loss=32.3]train epoch: 293:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.37it/s, loss=30.1]train epoch: 293:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.63it/s, loss=30.1]train epoch: 293:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.63it/s, loss=28.8]train epoch: 293:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=28.8]train epoch: 293:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.77it/s, loss=28.9]train epoch: 293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.75it/s, loss=28.9]train epoch: 293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=28.9]
[[032m2021-11-26 10:41:30,688[0m INFO] trainer.training_epoch Training epoch 293, num_steps 2352,  avg_loss: 30.8624, total_loss: 246.8989
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.17it/s]
[[032m2021-11-26 10:41:31,075[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:41:31,075[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:31,486[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 294:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 294:   0%|          | 0/8 [00:00<?, ?it/s, loss=18.9]train epoch: 294:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.57it/s, loss=18.9]train epoch: 294:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.57it/s, loss=29.8]train epoch: 294:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:03,  1.95it/s, loss=29.8]train epoch: 294:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.95it/s, loss=22.4]train epoch: 294:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=22.4]train epoch: 294:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=27.7]train epoch: 294:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.96it/s, loss=27.7]train epoch: 294:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.96it/s, loss=29.8]train epoch: 294:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.26it/s, loss=29.8]train epoch: 294:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.26it/s, loss=30.2]train epoch: 294:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.49it/s, loss=30.2]train epoch: 294:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.49it/s, loss=31]  train epoch: 294:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.53it/s, loss=31]train epoch: 294:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.53it/s, loss=33.6]train epoch: 294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=33.6]train epoch: 294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.34it/s, loss=33.6]
[[032m2021-11-26 10:41:34,911[0m INFO] trainer.training_epoch Training epoch 294, num_steps 2360,  avg_loss: 27.9184, total_loss: 223.3470
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.62it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.32it/s]
[[032m2021-11-26 10:41:35,483[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:35,484[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:35,827[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 295:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 295:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.3]train epoch: 295:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.71it/s, loss=28.3]train epoch: 295:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.71it/s, loss=21.5]train epoch: 295:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.13it/s, loss=21.5]train epoch: 295:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.13it/s, loss=27.8]train epoch: 295:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=27.8]train epoch: 295:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=22.6]train epoch: 295:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.30it/s, loss=22.6]train epoch: 295:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.30it/s, loss=19.5]train epoch: 295:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.08it/s, loss=19.5]train epoch: 295:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.08it/s, loss=25]  train epoch: 295:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.19it/s, loss=25]train epoch: 295:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.19it/s, loss=29.3]train epoch: 295:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.24it/s, loss=29.3]train epoch: 295:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.24it/s, loss=32.7]train epoch: 295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.20it/s, loss=32.7]train epoch: 295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=32.7]
[[032m2021-11-26 10:41:39,461[0m INFO] trainer.training_epoch Training epoch 295, num_steps 2368,  avg_loss: 25.8563, total_loss: 206.8507
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.83it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.02it/s]
[[032m2021-11-26 10:41:40,049[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:40,049[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:40,635[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 296:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 296:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.4]train epoch: 296:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:05,  1.21it/s, loss=25.4]train epoch: 296:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:05,  1.21it/s, loss=26.9]train epoch: 296:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.82it/s, loss=26.9]train epoch: 296:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.82it/s, loss=22.7]train epoch: 296:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.98it/s, loss=22.7]train epoch: 296:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.98it/s, loss=33]  train epoch: 296:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=33]train epoch: 296:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.01it/s, loss=23.9]train epoch: 296:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.80it/s, loss=23.9]train epoch: 296:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.80it/s, loss=33.9]train epoch: 296:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.15it/s, loss=33.9]train epoch: 296:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.15it/s, loss=24.7]train epoch: 296:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.03it/s, loss=24.7]train epoch: 296:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.03it/s, loss=19.4]train epoch: 296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.22it/s, loss=19.4]train epoch: 296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.01it/s, loss=19.4]
[[032m2021-11-26 10:41:44,638[0m INFO] trainer.training_epoch Training epoch 296, num_steps 2376,  avg_loss: 26.2300, total_loss: 209.8404
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.39it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.76it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.34it/s]
[[032m2021-11-26 10:41:45,099[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:41:45,100[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:45,564[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 297:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 297:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.7]train epoch: 297:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.49it/s, loss=25.7]train epoch: 297:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.49it/s, loss=34.2]train epoch: 297:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:03,  2.00it/s, loss=34.2]train epoch: 297:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  2.00it/s, loss=26.8]train epoch: 297:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=26.8]train epoch: 297:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=27.1]train epoch: 297:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.13it/s, loss=27.1]train epoch: 297:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.13it/s, loss=22.4]train epoch: 297:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.90it/s, loss=22.4]train epoch: 297:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.90it/s, loss=23.5]train epoch: 297:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.67it/s, loss=23.5]train epoch: 297:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.67it/s, loss=33.5]train epoch: 297:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.02it/s, loss=33.5]train epoch: 297:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.02it/s, loss=30.9]train epoch: 297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.15it/s, loss=30.9]train epoch: 297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.05it/s, loss=30.9]
[[032m2021-11-26 10:41:49,484[0m INFO] trainer.training_epoch Training epoch 297, num_steps 2384,  avg_loss: 28.0006, total_loss: 224.0049
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.93it/s]
[[032m2021-11-26 10:41:49,956[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:49,957[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:50,267[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 298:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 298:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.8]train epoch: 298:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.06it/s, loss=30.8]train epoch: 298:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.06it/s, loss=26]  train epoch: 298:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.77it/s, loss=26]train epoch: 298:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.77it/s, loss=21.9]train epoch: 298:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.55it/s, loss=21.9]train epoch: 298:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.55it/s, loss=27.3]train epoch: 298:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.99it/s, loss=27.3]train epoch: 298:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.99it/s, loss=21]  train epoch: 298:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.12it/s, loss=21]train epoch: 298:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.12it/s, loss=28.2]train epoch: 298:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.28it/s, loss=28.2]train epoch: 298:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.28it/s, loss=24.3]train epoch: 298:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.11it/s, loss=24.3]train epoch: 298:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.11it/s, loss=33.2]train epoch: 298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.46it/s, loss=33.2]train epoch: 298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.53it/s, loss=33.2]
[[032m2021-11-26 10:41:53,443[0m INFO] trainer.training_epoch Training epoch 298, num_steps 2392,  avg_loss: 26.6032, total_loss: 212.8252
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.10it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.18it/s]
[[032m2021-11-26 10:41:54,230[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:41:54,230[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:54,807[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 299:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 299:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.7]train epoch: 299:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.14it/s, loss=24.7]train epoch: 299:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.14it/s, loss=35.6]train epoch: 299:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.61it/s, loss=35.6]train epoch: 299:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.61it/s, loss=26.9]train epoch: 299:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.83it/s, loss=26.9]train epoch: 299:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.83it/s, loss=26.3]train epoch: 299:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.05it/s, loss=26.3]train epoch: 299:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.05it/s, loss=28.3]train epoch: 299:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.93it/s, loss=28.3]train epoch: 299:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.93it/s, loss=23.9]train epoch: 299:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.90it/s, loss=23.9]train epoch: 299:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.90it/s, loss=28.6]train epoch: 299:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=28.6]train epoch: 299:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=23.3]train epoch: 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.77it/s, loss=23.3]train epoch: 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s, loss=23.3]
[[032m2021-11-26 10:41:57,562[0m INFO] trainer.training_epoch Training epoch 299, num_steps 2400,  avg_loss: 27.1961, total_loss: 217.5689
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.55it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.95it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.19it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.58it/s]
[[032m2021-11-26 10:41:58,306[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:41:58,307[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:41:58,650[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 300:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3141, 0.6859],
        [0.4988, 0.5012],
        [0.4469, 0.5531],
        [0.2534, 0.7466],
        [0.2156, 0.7844],
        [0.7036, 0.2964],
        [0.5715, 0.4285],
        [0.6731, 0.3269]], device='cuda:0')

prompt tensor([[0.5842, 0.4158],
        [0.7275, 0.2725],
        [0.6626, 0.3374],
        [0.5268, 0.4732],
        [0.2684, 0.7316],
        [0.6838, 0.3162],
        [0.6582, 0.3418],
        [0.4575, 0.5425]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 300:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.6]train epoch: 300:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.95it/s, loss=26.6]train epoch: 300:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.95it/s, loss=24.3]train epoch: 300:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.54it/s, loss=24.3]train epoch: 300:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.54it/s, loss=28.1]train epoch: 300:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.61it/s, loss=28.1]train epoch: 300:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.61it/s, loss=26.5]train epoch: 300:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=26.5]train epoch: 300:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=24.7]train epoch: 300:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.68it/s, loss=24.7]train epoch: 300:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.68it/s, loss=30.6]train epoch: 300:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.69it/s, loss=30.6]train epoch: 300:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.69it/s, loss=28.9]train epoch: 300:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.15it/s, loss=28.9]train epoch: 300:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.15it/s, loss=30.5]train epoch: 300: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.89it/s, loss=30.5]train epoch: 300: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.22it/s, loss=30.5]
[[032m2021-11-26 10:42:02,258[0m INFO] trainer.training_epoch Training epoch 300, num_steps 2408,  avg_loss: 27.5315, total_loss: 220.2523
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.06it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.35it/s]
[[032m2021-11-26 10:42:03,205[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:03,205[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:03,606[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 301:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 301:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.3]train epoch: 301:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=20.3]train epoch: 301:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=29.6]train epoch: 301:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=29.6]train epoch: 301:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.84it/s, loss=28.4]train epoch: 301:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.68it/s, loss=28.4]train epoch: 301:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.68it/s, loss=26.4]train epoch: 301:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=26.4]train epoch: 301:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=29.8]train epoch: 301:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.62it/s, loss=29.8]train epoch: 301:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.62it/s, loss=30.3]train epoch: 301:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.93it/s, loss=30.3]train epoch: 301:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.93it/s, loss=30.9]train epoch: 301:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.90it/s, loss=30.9]train epoch: 301:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.90it/s, loss=27.4]train epoch: 301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=27.4]train epoch: 301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s, loss=27.4]
[[032m2021-11-26 10:42:06,357[0m INFO] trainer.training_epoch Training epoch 301, num_steps 2416,  avg_loss: 27.8880, total_loss: 223.1038
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.21it/s]
[[032m2021-11-26 10:42:06,934[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:06,935[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:07,665[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 302:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 302:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.6]train epoch: 302:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.13it/s, loss=31.6]train epoch: 302:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.13it/s, loss=22]  train epoch: 302:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.66it/s, loss=22]train epoch: 302:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.66it/s, loss=16]train epoch: 302:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=16]train epoch: 302:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.10it/s, loss=27]train epoch: 302:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.02it/s, loss=27]train epoch: 302:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.02it/s, loss=36.4]train epoch: 302:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.32it/s, loss=36.4]train epoch: 302:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.32it/s, loss=25.8]train epoch: 302:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=25.8]train epoch: 302:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=31.4]train epoch: 302:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.58it/s, loss=31.4]train epoch: 302:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.58it/s, loss=20.5]train epoch: 302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.32it/s, loss=20.5]train epoch: 302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.36it/s, loss=20.5]
[[032m2021-11-26 10:42:11,085[0m INFO] trainer.training_epoch Training epoch 302, num_steps 2424,  avg_loss: 26.3359, total_loss: 210.6869
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.28it/s]
[[032m2021-11-26 10:42:11,665[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:11,665[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:12,034[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 303:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 303:   0%|          | 0/8 [00:00<?, ?it/s, loss=18.7]train epoch: 303:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.36it/s, loss=18.7]train epoch: 303:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.36it/s, loss=23.3]train epoch: 303:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.66it/s, loss=23.3]train epoch: 303:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.66it/s, loss=35.7]train epoch: 303:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.37it/s, loss=35.7]train epoch: 303:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.37it/s, loss=33.6]train epoch: 303:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.81it/s, loss=33.6]train epoch: 303:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.81it/s, loss=21.6]train epoch: 303:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.01it/s, loss=21.6]train epoch: 303:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.01it/s, loss=28.9]train epoch: 303:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.26it/s, loss=28.9]train epoch: 303:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.26it/s, loss=19.9]train epoch: 303:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.38it/s, loss=19.9]train epoch: 303:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.38it/s, loss=31.6]train epoch: 303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.38it/s, loss=31.6]train epoch: 303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.33it/s, loss=31.6]
[[032m2021-11-26 10:42:15,496[0m INFO] trainer.training_epoch Training epoch 303, num_steps 2432,  avg_loss: 26.6639, total_loss: 213.3113
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.01it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.06it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.04it/s]
[[032m2021-11-26 10:42:16,080[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:16,080[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:16,336[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 304:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 304:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.4]train epoch: 304:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.48it/s, loss=36.4]train epoch: 304:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.48it/s, loss=28.6]train epoch: 304:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.55it/s, loss=28.6]train epoch: 304:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.55it/s, loss=32.5]train epoch: 304:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.92it/s, loss=32.5]train epoch: 304:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.92it/s, loss=23.8]train epoch: 304:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.15it/s, loss=23.8]train epoch: 304:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.15it/s, loss=26.2]train epoch: 304:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.00it/s, loss=26.2]train epoch: 304:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  2.00it/s, loss=20.1]train epoch: 304:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.11it/s, loss=20.1]train epoch: 304:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.11it/s, loss=23.7]train epoch: 304:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.44it/s, loss=23.7]train epoch: 304:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.44it/s, loss=23.8]train epoch: 304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.60it/s, loss=23.8]train epoch: 304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.19it/s, loss=23.8]
[[032m2021-11-26 10:42:19,986[0m INFO] trainer.training_epoch Training epoch 304, num_steps 2440,  avg_loss: 26.8814, total_loss: 215.0514
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.53it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.31it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.77it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.66it/s]
[[032m2021-11-26 10:42:20,524[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:20,524[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:20,975[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 305:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 305:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.7]train epoch: 305:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.60it/s, loss=24.7]train epoch: 305:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.60it/s, loss=29.8]train epoch: 305:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.32it/s, loss=29.8]train epoch: 305:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:02<00:04,  1.32it/s, loss=25.5]train epoch: 305:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.40it/s, loss=25.5]train epoch: 305:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.40it/s, loss=30.6]train epoch: 305:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.68it/s, loss=30.6]train epoch: 305:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.68it/s, loss=26.5]train epoch: 305:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.07it/s, loss=26.5]train epoch: 305:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  2.07it/s, loss=27.4]train epoch: 305:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.14it/s, loss=27.4]train epoch: 305:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.14it/s, loss=31.2]train epoch: 305:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.41it/s, loss=31.2]train epoch: 305:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.41it/s, loss=24]  train epoch: 305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.56it/s, loss=24]train epoch: 305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=24]
[[032m2021-11-26 10:42:24,918[0m INFO] trainer.training_epoch Training epoch 305, num_steps 2448,  avg_loss: 27.4532, total_loss: 219.6254
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.12it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.19it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.43it/s]
[[032m2021-11-26 10:42:25,568[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:25,568[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:26,175[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 306:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 306:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.1]train epoch: 306:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.69it/s, loss=37.1]train epoch: 306:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.69it/s, loss=20.5]train epoch: 306:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.14it/s, loss=20.5]train epoch: 306:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.14it/s, loss=22.7]train epoch: 306:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.70it/s, loss=22.7]train epoch: 306:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.70it/s, loss=32]  train epoch: 306:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.33it/s, loss=32]train epoch: 306:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.33it/s, loss=24.2]train epoch: 306:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.61it/s, loss=24.2]train epoch: 306:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.61it/s, loss=26.8]train epoch: 306:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=26.8]train epoch: 306:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=26.4]train epoch: 306:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.46it/s, loss=26.4]train epoch: 306:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.46it/s, loss=24.2]train epoch: 306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.53it/s, loss=24.2]train epoch: 306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.45it/s, loss=24.2]
[[032m2021-11-26 10:42:29,468[0m INFO] trainer.training_epoch Training epoch 306, num_steps 2456,  avg_loss: 26.7238, total_loss: 213.7903
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.31it/s]
[[032m2021-11-26 10:42:30,155[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:30,156[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:30,994[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 307:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 307:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.1]train epoch: 307:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.01it/s, loss=25.1]train epoch: 307:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  2.01it/s, loss=31.9]train epoch: 307:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.80it/s, loss=31.9]train epoch: 307:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.80it/s, loss=21]  train epoch: 307:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.13it/s, loss=21]train epoch: 307:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.13it/s, loss=31.9]train epoch: 307:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.64it/s, loss=31.9]train epoch: 307:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.64it/s, loss=22.9]train epoch: 307:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.78it/s, loss=22.9]train epoch: 307:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.78it/s, loss=37.2]train epoch: 307:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.64it/s, loss=37.2]train epoch: 307:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.64it/s, loss=31.2]train epoch: 307:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.22it/s, loss=31.2]train epoch: 307:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.22it/s, loss=33.5]train epoch: 307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.55it/s, loss=33.5]train epoch: 307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.42it/s, loss=33.5]
[[032m2021-11-26 10:42:34,304[0m INFO] trainer.training_epoch Training epoch 307, num_steps 2464,  avg_loss: 29.3381, total_loss: 234.7052
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.72it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.57it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.63it/s]
[[032m2021-11-26 10:42:35,487[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:42:35,487[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:36,163[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 308:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 308:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.9]train epoch: 308:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.79it/s, loss=31.9]train epoch: 308:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  1.79it/s, loss=24.8]train epoch: 308:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.79it/s, loss=24.8]train epoch: 308:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.79it/s, loss=27.8]train epoch: 308:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.69it/s, loss=27.8]train epoch: 308:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.69it/s, loss=27.2]train epoch: 308:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.88it/s, loss=27.2]train epoch: 308:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.88it/s, loss=27.6]train epoch: 308:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.73it/s, loss=27.6]train epoch: 308:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.73it/s, loss=24.4]train epoch: 308:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.73it/s, loss=24.4]train epoch: 308:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:04<00:01,  1.73it/s, loss=22]  train epoch: 308:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.70it/s, loss=22]train epoch: 308:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.70it/s, loss=28.3]train epoch: 308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.91it/s, loss=28.3]train epoch: 308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.81it/s, loss=28.3]
[[032m2021-11-26 10:42:40,589[0m INFO] trainer.training_epoch Training epoch 308, num_steps 2472,  avg_loss: 26.7501, total_loss: 214.0009
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.54it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.17it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.67it/s]
[[032m2021-11-26 10:42:41,479[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:42:41,480[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:41,759[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 309:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 309:   0%|          | 0/8 [00:00<?, ?it/s, loss=37]train epoch: 309:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=37]train epoch: 309:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=25.8]train epoch: 309:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.24it/s, loss=25.8]train epoch: 309:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.24it/s, loss=29.1]train epoch: 309:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.41it/s, loss=29.1]train epoch: 309:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.41it/s, loss=30.4]train epoch: 309:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=30.4]train epoch: 309:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.95it/s, loss=18.3]train epoch: 309:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.77it/s, loss=18.3]train epoch: 309:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.77it/s, loss=27.8]train epoch: 309:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.63it/s, loss=27.8]train epoch: 309:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.63it/s, loss=30.2]train epoch: 309:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=30.2]train epoch: 309:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.63it/s, loss=20.9]train epoch: 309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.02it/s, loss=20.9]train epoch: 309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.49it/s, loss=20.9]
[[032m2021-11-26 10:42:44,990[0m INFO] trainer.training_epoch Training epoch 309, num_steps 2480,  avg_loss: 27.4304, total_loss: 219.4434
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.42it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.70it/s]
[[032m2021-11-26 10:42:45,615[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:42:45,615[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:45,977[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 310:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 310:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.8]train epoch: 310:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.39it/s, loss=20.8]train epoch: 310:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.39it/s, loss=23.1]train epoch: 310:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.64it/s, loss=23.1]train epoch: 310:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.64it/s, loss=30.5]train epoch: 310:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.51it/s, loss=30.5]train epoch: 310:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.51it/s, loss=24.3]train epoch: 310:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.61it/s, loss=24.3]train epoch: 310:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.61it/s, loss=27.8]train epoch: 310:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=27.8]train epoch: 310:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.78it/s, loss=27.1]train epoch: 310:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.00it/s, loss=27.1]train epoch: 310:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.00it/s, loss=23.3]train epoch: 310:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=23.3]train epoch: 310:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=23.4]train epoch: 310: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.63it/s, loss=23.4]train epoch: 310: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.74it/s, loss=23.4]
[[032m2021-11-26 10:42:48,902[0m INFO] trainer.training_epoch Training epoch 310, num_steps 2488,  avg_loss: 25.0376, total_loss: 200.3007
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.30it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.13it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.29it/s]
[[032m2021-11-26 10:42:49,487[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:42:49,487[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:50,518[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 311:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 311:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.3]train epoch: 311:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.21it/s, loss=20.3]train epoch: 311:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.21it/s, loss=30.6]train epoch: 311:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.05it/s, loss=30.6]train epoch: 311:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.05it/s, loss=30]  train epoch: 311:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.07it/s, loss=30]train epoch: 311:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.07it/s, loss=30.7]train epoch: 311:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.54it/s, loss=30.7]train epoch: 311:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.54it/s, loss=29.5]train epoch: 311:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.76it/s, loss=29.5]train epoch: 311:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.76it/s, loss=29.1]train epoch: 311:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=29.1]train epoch: 311:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=23.1]train epoch: 311:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.41it/s, loss=23.1]train epoch: 311:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.41it/s, loss=25.7]train epoch: 311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.66it/s, loss=25.7]train epoch: 311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.77it/s, loss=25.7]
[[032m2021-11-26 10:42:53,416[0m INFO] trainer.training_epoch Training epoch 311, num_steps 2496,  avg_loss: 27.3702, total_loss: 218.9618
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.38it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.98it/s]
[[032m2021-11-26 10:42:53,877[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:42:53,877[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:54,275[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 312:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 312:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.8]train epoch: 312:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.31it/s, loss=32.8]train epoch: 312:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.31it/s, loss=28.4]train epoch: 312:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.10it/s, loss=28.4]train epoch: 312:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.10it/s, loss=27.7]train epoch: 312:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.56it/s, loss=27.7]train epoch: 312:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.56it/s, loss=28.2]train epoch: 312:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.61it/s, loss=28.2]
model tensor([[0.5501, 0.4499],
        [0.3053, 0.6947],
        [0.6493, 0.3507],
        [0.4667, 0.5333],
        [0.8361, 0.1639],
        [0.3690, 0.6310],
        [0.7103, 0.2897],
        [0.2156, 0.7844]], device='cuda:0')

prompt tensor([[0.6948, 0.3052],
        [0.7090, 0.2910],
        [0.5321, 0.4679],
        [0.4568, 0.5432],
        [0.9782, 0.0218],
        [0.4613, 0.5387],
        [0.5327, 0.4673],
        [0.5308, 0.4692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 312:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.61it/s, loss=40.2]train epoch: 312:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.95it/s, loss=40.2]train epoch: 312:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.95it/s, loss=27.5]train epoch: 312:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.91it/s, loss=27.5]train epoch: 312:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.91it/s, loss=26.2]train epoch: 312:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.09it/s, loss=26.2]train epoch: 312:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.09it/s, loss=24.4]train epoch: 312: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.43it/s, loss=24.4]train epoch: 312: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.06it/s, loss=24.4]
[[032m2021-11-26 10:42:58,182[0m INFO] trainer.training_epoch Training epoch 312, num_steps 2504,  avg_loss: 29.4101, total_loss: 235.2810
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.56it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.15it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.11it/s]
[[032m2021-11-26 10:42:59,018[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:42:59,018[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:42:59,873[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 313:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 313:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.5]train epoch: 313:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.68it/s, loss=33.5]train epoch: 313:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.68it/s, loss=27.1]train epoch: 313:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.83it/s, loss=27.1]train epoch: 313:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.83it/s, loss=28.4]train epoch: 313:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.93it/s, loss=28.4]train epoch: 313:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.93it/s, loss=35.8]train epoch: 313:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.24it/s, loss=35.8]train epoch: 313:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.24it/s, loss=26.1]train epoch: 313:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.48it/s, loss=26.1]train epoch: 313:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.48it/s, loss=28.8]train epoch: 313:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=28.8]train epoch: 313:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.44it/s, loss=25.6]train epoch: 313:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.42it/s, loss=25.6]train epoch: 313:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.42it/s, loss=27.4]train epoch: 313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.85it/s, loss=27.4]train epoch: 313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.41it/s, loss=27.4]
[[032m2021-11-26 10:43:03,194[0m INFO] trainer.training_epoch Training epoch 313, num_steps 2512,  avg_loss: 29.0894, total_loss: 232.7152
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.73it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.19it/s]
[[032m2021-11-26 10:43:03,709[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:43:03,709[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:04,275[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 314:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 314:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.9]train epoch: 314:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.25it/s, loss=25.9]train epoch: 314:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.25it/s, loss=30.3]train epoch: 314:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.16it/s, loss=30.3]train epoch: 314:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.16it/s, loss=23.6]train epoch: 314:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.88it/s, loss=23.6]train epoch: 314:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.88it/s, loss=23.8]train epoch: 314:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.85it/s, loss=23.8]train epoch: 314:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.85it/s, loss=22.1]train epoch: 314:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.91it/s, loss=22.1]train epoch: 314:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.91it/s, loss=26.6]train epoch: 314:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.14it/s, loss=26.6]train epoch: 314:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.14it/s, loss=20.1]train epoch: 314:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.40it/s, loss=20.1]train epoch: 314:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.40it/s, loss=28.2]train epoch: 314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.36it/s, loss=28.2]train epoch: 314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.19it/s, loss=28.2]
[[032m2021-11-26 10:43:07,931[0m INFO] trainer.training_epoch Training epoch 314, num_steps 2520,  avg_loss: 25.0824, total_loss: 200.6590
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.83it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.99it/s]
[[032m2021-11-26 10:43:08,451[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:08,451[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:09,035[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 315:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 315:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 315:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.79it/s, loss=24.9]train epoch: 315:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:02,  2.79it/s, loss=30.9]train epoch: 315:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.72it/s, loss=30.9]train epoch: 315:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.72it/s, loss=21.9]train epoch: 315:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.60it/s, loss=21.9]train epoch: 315:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.60it/s, loss=27.1]train epoch: 315:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.89it/s, loss=27.1]train epoch: 315:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.89it/s, loss=26.4]train epoch: 315:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=26.4]train epoch: 315:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=24.4]train epoch: 315:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.78it/s, loss=24.4]train epoch: 315:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.78it/s, loss=29.9]train epoch: 315:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.48it/s, loss=29.9]train epoch: 315:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.48it/s, loss=27.1]train epoch: 315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.53it/s, loss=27.1]train epoch: 315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.29it/s, loss=27.1]
[[032m2021-11-26 10:43:12,547[0m INFO] trainer.training_epoch Training epoch 315, num_steps 2528,  avg_loss: 26.5679, total_loss: 212.5433
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.96it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.87it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.08it/s]
[[032m2021-11-26 10:43:13,071[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:13,071[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:13,422[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 316:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 316:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.9]train epoch: 316:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.13it/s, loss=26.9]train epoch: 316:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.13it/s, loss=27.5]train epoch: 316:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.74it/s, loss=27.5]train epoch: 316:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.74it/s, loss=25.7]train epoch: 316:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.72it/s, loss=25.7]train epoch: 316:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.72it/s, loss=32.3]train epoch: 316:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.52it/s, loss=32.3]train epoch: 316:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.52it/s, loss=24.9]train epoch: 316:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=24.9]train epoch: 316:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.87it/s, loss=27.3]train epoch: 316:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.01it/s, loss=27.3]train epoch: 316:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.01it/s, loss=23.1]train epoch: 316:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.85it/s, loss=23.1]train epoch: 316:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.85it/s, loss=22.3]train epoch: 316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.05it/s, loss=22.3]train epoch: 316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.25it/s, loss=22.3]
[[032m2021-11-26 10:43:16,984[0m INFO] trainer.training_epoch Training epoch 316, num_steps 2536,  avg_loss: 26.2415, total_loss: 209.9319
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.85it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.30it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.84it/s]
[[032m2021-11-26 10:43:17,693[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:17,693[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:18,073[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 317:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 317:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 317:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.67it/s, loss=27.9]train epoch: 317:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.67it/s, loss=22.1]train epoch: 317:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.13it/s, loss=22.1]train epoch: 317:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.13it/s, loss=18.1]train epoch: 317:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.37it/s, loss=18.1]train epoch: 317:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.37it/s, loss=25.1]train epoch: 317:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=25.1]train epoch: 317:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=29.3]train epoch: 317:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.45it/s, loss=29.3]train epoch: 317:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.45it/s, loss=28.9]train epoch: 317:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=28.9]train epoch: 317:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=29]  train epoch: 317:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.35it/s, loss=29]train epoch: 317:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=37]train epoch: 317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=37]train epoch: 317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.36it/s, loss=37]
[[032m2021-11-26 10:43:21,476[0m INFO] trainer.training_epoch Training epoch 317, num_steps 2544,  avg_loss: 27.1790, total_loss: 217.4323
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.35it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.12it/s]
[[032m2021-11-26 10:43:22,275[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:22,275[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:22,705[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 318:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 318:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.4]train epoch: 318:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.53it/s, loss=30.4]train epoch: 318:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.53it/s, loss=19.2]train epoch: 318:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.67it/s, loss=19.2]train epoch: 318:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.67it/s, loss=21]  train epoch: 318:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=21]train epoch: 318:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=31.8]train epoch: 318:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=31.8]train epoch: 318:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=24.7]train epoch: 318:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.40it/s, loss=24.7]train epoch: 318:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.40it/s, loss=18.6]train epoch: 318:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.60it/s, loss=18.6]train epoch: 318:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.60it/s, loss=35.1]train epoch: 318:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.62it/s, loss=35.1]train epoch: 318:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.62it/s, loss=29.3]train epoch: 318: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.83it/s, loss=29.3]train epoch: 318: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.21it/s, loss=29.3]
[[032m2021-11-26 10:43:26,328[0m INFO] trainer.training_epoch Training epoch 318, num_steps 2552,  avg_loss: 26.2713, total_loss: 210.1707
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.96it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.42it/s]
[[032m2021-11-26 10:43:26,774[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:26,775[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:27,403[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 319:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 319:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 319:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.73it/s, loss=30.2]train epoch: 319:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.73it/s, loss=24.6]train epoch: 319:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.15it/s, loss=24.6]train epoch: 319:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.15it/s, loss=27]  train epoch: 319:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=27]train epoch: 319:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=25.6]train epoch: 319:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.41it/s, loss=25.6]train epoch: 319:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.41it/s, loss=28.5]train epoch: 319:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.51it/s, loss=28.5]train epoch: 319:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.51it/s, loss=26.8]train epoch: 319:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=26.8]train epoch: 319:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=25]  train epoch: 319:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=25]train epoch: 319:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=26.6]train epoch: 319: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=26.6]train epoch: 319: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=26.6]
[[032m2021-11-26 10:43:30,276[0m INFO] trainer.training_epoch Training epoch 319, num_steps 2560,  avg_loss: 26.7985, total_loss: 214.3877
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.12it/s]
[[032m2021-11-26 10:43:30,749[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:30,750[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:31,070[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 320:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 320:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.6]train epoch: 320:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.67it/s, loss=27.6]train epoch: 320:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.67it/s, loss=35.8]train epoch: 320:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.23it/s, loss=35.8]train epoch: 320:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.23it/s, loss=30]  train epoch: 320:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=30]train epoch: 320:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=36.7]train epoch: 320:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=36.7]train epoch: 320:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.17it/s, loss=23.9]train epoch: 320:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=23.9]train epoch: 320:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.27it/s, loss=37.9]train epoch: 320:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=37.9]train epoch: 320:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=27.7]train epoch: 320:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.41it/s, loss=27.7]train epoch: 320:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.41it/s, loss=28.9]train epoch: 320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.65it/s, loss=28.9]train epoch: 320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.62it/s, loss=28.9]
[[032m2021-11-26 10:43:34,135[0m INFO] trainer.training_epoch Training epoch 320, num_steps 2568,  avg_loss: 31.0660, total_loss: 248.5281
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.05it/s]
[[032m2021-11-26 10:43:34,564[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:34,564[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:35,180[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 321:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 321:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.5]train epoch: 321:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.59it/s, loss=30.5]train epoch: 321:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.59it/s, loss=25.4]train epoch: 321:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.32it/s, loss=25.4]train epoch: 321:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.32it/s, loss=29.2]train epoch: 321:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.50it/s, loss=29.2]train epoch: 321:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.50it/s, loss=27]  train epoch: 321:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.46it/s, loss=27]train epoch: 321:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.46it/s, loss=24.3]train epoch: 321:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.19it/s, loss=24.3]train epoch: 321:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.19it/s, loss=23.5]train epoch: 321:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=23.5]train epoch: 321:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=28.7]train epoch: 321:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=28.7]train epoch: 321:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=34]  train epoch: 321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s, loss=34]train epoch: 321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s, loss=34]
[[032m2021-11-26 10:43:37,915[0m INFO] trainer.training_epoch Training epoch 321, num_steps 2576,  avg_loss: 27.8337, total_loss: 222.6694
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.86it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.75it/s]
[[032m2021-11-26 10:43:38,684[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:38,684[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:38,998[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 322:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 322:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.4]train epoch: 322:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.60it/s, loss=34.4]train epoch: 322:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.60it/s, loss=24.2]train epoch: 322:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.68it/s, loss=24.2]train epoch: 322:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.68it/s, loss=25.7]train epoch: 322:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.83it/s, loss=25.7]train epoch: 322:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.83it/s, loss=26.1]train epoch: 322:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.88it/s, loss=26.1]train epoch: 322:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.88it/s, loss=25.6]train epoch: 322:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=25.6]train epoch: 322:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=35.2]train epoch: 322:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.69it/s, loss=35.2]train epoch: 322:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.69it/s, loss=26]  train epoch: 322:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.40it/s, loss=26]train epoch: 322:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.40it/s, loss=29.2]train epoch: 322: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=29.2]train epoch: 322: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=29.2]
[[032m2021-11-26 10:43:41,289[0m INFO] trainer.training_epoch Training epoch 322, num_steps 2584,  avg_loss: 28.2872, total_loss: 226.2974
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.30it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.50it/s]
[[032m2021-11-26 10:43:41,777[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:41,777[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:42,118[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 323:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 323:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 323:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.53it/s, loss=25]train epoch: 323:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.53it/s, loss=28.1]train epoch: 323:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.05it/s, loss=28.1]train epoch: 323:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.05it/s, loss=18.9]train epoch: 323:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.05it/s, loss=18.9]train epoch: 323:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.05it/s, loss=23.1]train epoch: 323:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.09it/s, loss=23.1]train epoch: 323:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.09it/s, loss=18.9]train epoch: 323:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.80it/s, loss=18.9]train epoch: 323:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.80it/s, loss=23.9]train epoch: 323:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=23.9]train epoch: 323:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.56it/s, loss=29.7]train epoch: 323:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.76it/s, loss=29.7]train epoch: 323:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.76it/s, loss=25.2]train epoch: 323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.74it/s, loss=25.2]train epoch: 323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=25.2]
[[032m2021-11-26 10:43:44,992[0m INFO] trainer.training_epoch Training epoch 323, num_steps 2592,  avg_loss: 24.1161, total_loss: 192.9290
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.84it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.69it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.00it/s]
[[032m2021-11-26 10:43:45,520[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:45,521[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:46,205[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 324:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 324:   0%|          | 0/8 [00:00<?, ?it/s, loss=17.6]train epoch: 324:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.82it/s, loss=17.6]train epoch: 324:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:02,  2.82it/s, loss=33.3]train epoch: 324:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.46it/s, loss=33.3]train epoch: 324:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:04,  1.46it/s, loss=26.2]train epoch: 324:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.66it/s, loss=26.2]train epoch: 324:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:03,  1.66it/s, loss=30.5]train epoch: 324:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.90it/s, loss=30.5]train epoch: 324:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.90it/s, loss=25.6]train epoch: 324:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.14it/s, loss=25.6]train epoch: 324:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.14it/s, loss=33]  train epoch: 324:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.21it/s, loss=33]train epoch: 324:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.21it/s, loss=24.2]train epoch: 324:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.34it/s, loss=24.2]train epoch: 324:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.34it/s, loss=29.5]train epoch: 324: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=29.5]train epoch: 324: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.18it/s, loss=29.5]
[[032m2021-11-26 10:43:49,902[0m INFO] trainer.training_epoch Training epoch 324, num_steps 2600,  avg_loss: 27.4859, total_loss: 219.8870
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.50it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.30it/s]
[[032m2021-11-26 10:43:50,469[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:50,469[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:50,742[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 325:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.5951, 0.4049],
        [0.6054, 0.3946],
        [0.4201, 0.5799],
        [0.3248, 0.6752],
        [0.4404, 0.5596],
        [0.5557, 0.4443],
        [0.6349, 0.3651],
        [0.5650, 0.4350]], device='cuda:0')

prompt tensor([[0.5374, 0.4626],
        [0.6679, 0.3321],
        [0.4358, 0.5642],
        [0.4457, 0.5543],
        [0.4905, 0.5095],
        [0.9239, 0.0761],
        [0.6042, 0.3958],
        [0.7802, 0.2198]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 325:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 325:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.92it/s, loss=30.2]train epoch: 325:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.92it/s, loss=23.4]train epoch: 325:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.14it/s, loss=23.4]train epoch: 325:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.14it/s, loss=25.6]train epoch: 325:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=25.6]train epoch: 325:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=19.4]train epoch: 325:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.48it/s, loss=19.4]train epoch: 325:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.48it/s, loss=29.4]train epoch: 325:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.64it/s, loss=29.4]train epoch: 325:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.64it/s, loss=26.5]train epoch: 325:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=26.5]train epoch: 325:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=25.5]train epoch: 325:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.97it/s, loss=25.5]train epoch: 325:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.97it/s, loss=32.3]train epoch: 325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.63it/s, loss=32.3]train epoch: 325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s, loss=32.3]
[[032m2021-11-26 10:43:53,858[0m INFO] trainer.training_epoch Training epoch 325, num_steps 2608,  avg_loss: 26.5452, total_loss: 212.3614
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.32it/s]
[[032m2021-11-26 10:43:54,431[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:54,431[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:54,731[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 326:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 326:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.5]train epoch: 326:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.03it/s, loss=29.5]train epoch: 326:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.03it/s, loss=27.4]train epoch: 326:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.97it/s, loss=27.4]train epoch: 326:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.97it/s, loss=27.2]train epoch: 326:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=27.2]train epoch: 326:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=28.7]train epoch: 326:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.13it/s, loss=28.7]train epoch: 326:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.13it/s, loss=25.9]train epoch: 326:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.19it/s, loss=25.9]train epoch: 326:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.19it/s, loss=21.8]train epoch: 326:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.40it/s, loss=21.8]train epoch: 326:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.40it/s, loss=31.2]train epoch: 326:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.83it/s, loss=31.2]train epoch: 326:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.83it/s, loss=34.4]train epoch: 326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.94it/s, loss=34.4]train epoch: 326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=34.4]
[[032m2021-11-26 10:43:58,482[0m INFO] trainer.training_epoch Training epoch 326, num_steps 2616,  avg_loss: 28.2560, total_loss: 226.0479
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.70it/s]
[[032m2021-11-26 10:43:59,048[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:43:59,049[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:43:59,413[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 327:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 327:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 327:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.03it/s, loss=27.9]train epoch: 327:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.03it/s, loss=29.6]train epoch: 327:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.76it/s, loss=29.6]train epoch: 327:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.76it/s, loss=23]  train epoch: 327:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=23]train epoch: 327:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.17it/s, loss=24.3]train epoch: 327:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:02,  1.85it/s, loss=24.3]train epoch: 327:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.85it/s, loss=29.6]train epoch: 327:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.82it/s, loss=29.6]train epoch: 327:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.82it/s, loss=32.2]train epoch: 327:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.15it/s, loss=32.2]train epoch: 327:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.15it/s, loss=29]  train epoch: 327:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=29]train epoch: 327:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.07it/s, loss=25.8]train epoch: 327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=25.8]train epoch: 327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.20it/s, loss=25.8]
[[032m2021-11-26 10:44:03,068[0m INFO] trainer.training_epoch Training epoch 327, num_steps 2624,  avg_loss: 27.6754, total_loss: 221.4034
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.28it/s]
[[032m2021-11-26 10:44:03,732[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:44:03,733[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:04,057[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 328:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 328:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.5]train epoch: 328:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.02it/s, loss=27.5]train epoch: 328:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:03,  2.02it/s, loss=20.2]train epoch: 328:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=20.2]train epoch: 328:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=28.8]train epoch: 328:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  1.90it/s, loss=28.8]train epoch: 328:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:02,  1.90it/s, loss=23.4]train epoch: 328:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.80it/s, loss=23.4]train epoch: 328:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.80it/s, loss=25.9]train epoch: 328:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  1.93it/s, loss=25.9]train epoch: 328:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:03<00:01,  1.93it/s, loss=29.3]train epoch: 328:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.04it/s, loss=29.3]train epoch: 328:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.04it/s, loss=28]  train epoch: 328:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.28it/s, loss=28]train epoch: 328:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.28it/s, loss=26.5]train epoch: 328: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.46it/s, loss=26.5]train epoch: 328: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.15it/s, loss=26.5]
[[032m2021-11-26 10:44:07,792[0m INFO] trainer.training_epoch Training epoch 328, num_steps 2632,  avg_loss: 26.2021, total_loss: 209.6167
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.33it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.61it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.22it/s]
[[032m2021-11-26 10:44:08,453[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:44:08,453[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:09,064[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 329:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 329:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.9]train epoch: 329:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=28.9]train epoch: 329:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.28it/s, loss=23.1]train epoch: 329:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.06it/s, loss=23.1]train epoch: 329:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.06it/s, loss=22.8]train epoch: 329:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.03it/s, loss=22.8]train epoch: 329:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.03it/s, loss=26.8]train epoch: 329:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.07it/s, loss=26.8]train epoch: 329:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.07it/s, loss=31.6]train epoch: 329:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=31.6]train epoch: 329:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.34it/s, loss=21.4]train epoch: 329:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.41it/s, loss=21.4]train epoch: 329:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.41it/s, loss=28.2]train epoch: 329:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.78it/s, loss=28.2]train epoch: 329:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.78it/s, loss=28]  train epoch: 329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  3.01it/s, loss=28]train epoch: 329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.65it/s, loss=28]
[[032m2021-11-26 10:44:12,102[0m INFO] trainer.training_epoch Training epoch 329, num_steps 2640,  avg_loss: 26.3362, total_loss: 210.6899
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.79it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.99it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.30it/s]
[[032m2021-11-26 10:44:12,669[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:12,669[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:13,247[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 330:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 330:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.4]train epoch: 330:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.43it/s, loss=21.4]train epoch: 330:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.43it/s, loss=23.7]train epoch: 330:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.93it/s, loss=23.7]train epoch: 330:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.93it/s, loss=26.1]train epoch: 330:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.08it/s, loss=26.1]train epoch: 330:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.08it/s, loss=26.1]train epoch: 330:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.35it/s, loss=26.1]train epoch: 330:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.35it/s, loss=23.3]train epoch: 330:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.27it/s, loss=23.3]train epoch: 330:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.27it/s, loss=29.2]train epoch: 330:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.47it/s, loss=29.2]train epoch: 330:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.47it/s, loss=19.3]train epoch: 330:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.37it/s, loss=19.3]train epoch: 330:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.37it/s, loss=28]  train epoch: 330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.55it/s, loss=28]train epoch: 330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.37it/s, loss=28]
[[032m2021-11-26 10:44:16,625[0m INFO] trainer.training_epoch Training epoch 330, num_steps 2648,  avg_loss: 24.6366, total_loss: 197.0929
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.25it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.19it/s]
[[032m2021-11-26 10:44:17,202[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:17,202[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:17,518[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 331:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 331:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.7]train epoch: 331:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=27.7]train epoch: 331:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.09it/s, loss=23]  train epoch: 331:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.04it/s, loss=23]train epoch: 331:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.04it/s, loss=21.6]train epoch: 331:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.78it/s, loss=21.6]train epoch: 331:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.78it/s, loss=23.8]train epoch: 331:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.61it/s, loss=23.8]train epoch: 331:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.61it/s, loss=23.7]train epoch: 331:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.50it/s, loss=23.7]train epoch: 331:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.50it/s, loss=28.5]train epoch: 331:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.79it/s, loss=28.5]train epoch: 331:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.79it/s, loss=23.2]train epoch: 331:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.29it/s, loss=23.2]train epoch: 331:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.29it/s, loss=28.7]train epoch: 331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.51it/s, loss=28.7]train epoch: 331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.59it/s, loss=28.7]
[[032m2021-11-26 10:44:20,618[0m INFO] trainer.training_epoch Training epoch 331, num_steps 2656,  avg_loss: 25.0345, total_loss: 200.2759
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.01it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.27it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.90it/s]
[[032m2021-11-26 10:44:21,350[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:21,351[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:21,715[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 332:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 332:   0%|          | 0/8 [00:00<?, ?it/s, loss=36]train epoch: 332:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=36]train epoch: 332:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=24.3]train epoch: 332:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=24.3]train epoch: 332:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=22.7]train epoch: 332:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.29it/s, loss=22.7]train epoch: 332:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.29it/s, loss=20.4]train epoch: 332:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.61it/s, loss=20.4]train epoch: 332:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.61it/s, loss=26.8]train epoch: 332:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=26.8]train epoch: 332:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=30.8]train epoch: 332:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.64it/s, loss=30.8]train epoch: 332:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.64it/s, loss=32.5]train epoch: 332:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.48it/s, loss=32.5]train epoch: 332:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.48it/s, loss=36.7]train epoch: 332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s, loss=36.7]train epoch: 332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.49it/s, loss=36.7]
[[032m2021-11-26 10:44:24,929[0m INFO] trainer.training_epoch Training epoch 332, num_steps 2664,  avg_loss: 28.7798, total_loss: 230.2386
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.74it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.82it/s]
[[032m2021-11-26 10:44:25,420[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:25,420[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:26,095[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 333:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 333:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.3]train epoch: 333:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.18it/s, loss=31.3]train epoch: 333:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.18it/s, loss=29.4]train epoch: 333:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.87it/s, loss=29.4]train epoch: 333:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.87it/s, loss=28.2]train epoch: 333:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.98it/s, loss=28.2]train epoch: 333:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.98it/s, loss=23.9]train epoch: 333:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=23.9]train epoch: 333:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.96it/s, loss=26.9]train epoch: 333:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=26.9]train epoch: 333:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.89it/s, loss=30]  train epoch: 333:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=30]train epoch: 333:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=23.1]train epoch: 333:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=23.1]train epoch: 333:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=26.2]train epoch: 333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.06it/s, loss=26.2]train epoch: 333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=26.2]
[[032m2021-11-26 10:44:28,838[0m INFO] trainer.training_epoch Training epoch 333, num_steps 2672,  avg_loss: 27.3807, total_loss: 219.0459
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.80it/s]
[[032m2021-11-26 10:44:29,470[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:29,471[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:30,069[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 334:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 334:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.1]train epoch: 334:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.50it/s, loss=29.1]train epoch: 334:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.50it/s, loss=29.3]train epoch: 334:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.95it/s, loss=29.3]train epoch: 334:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.95it/s, loss=22.4]train epoch: 334:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.09it/s, loss=22.4]train epoch: 334:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.09it/s, loss=21]  train epoch: 334:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=21]train epoch: 334:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=29.4]train epoch: 334:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.31it/s, loss=29.4]train epoch: 334:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.31it/s, loss=22]  train epoch: 334:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.08it/s, loss=22]train epoch: 334:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.08it/s, loss=29.6]train epoch: 334:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.90it/s, loss=29.6]train epoch: 334:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.90it/s, loss=24]  train epoch: 334: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s, loss=24]train epoch: 334: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=24]
[[032m2021-11-26 10:44:32,762[0m INFO] trainer.training_epoch Training epoch 334, num_steps 2680,  avg_loss: 25.8587, total_loss: 206.8695
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.22it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.41it/s]
[[032m2021-11-26 10:44:33,258[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:33,258[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:33,693[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 335:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 335:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.6]train epoch: 335:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.70it/s, loss=27.6]train epoch: 335:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.70it/s, loss=26.2]train epoch: 335:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.19it/s, loss=26.2]train epoch: 335:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.19it/s, loss=21.1]train epoch: 335:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.34it/s, loss=21.1]train epoch: 335:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.34it/s, loss=25.4]train epoch: 335:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.62it/s, loss=25.4]train epoch: 335:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.62it/s, loss=34.5]train epoch: 335:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.43it/s, loss=34.5]train epoch: 335:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.43it/s, loss=28.3]train epoch: 335:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.94it/s, loss=28.3]train epoch: 335:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.94it/s, loss=41.9]train epoch: 335:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.31it/s, loss=41.9]train epoch: 335:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.31it/s, loss=28.2]train epoch: 335: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.41it/s, loss=28.2]train epoch: 335: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s, loss=28.2]
[[032m2021-11-26 10:44:37,113[0m INFO] trainer.training_epoch Training epoch 335, num_steps 2688,  avg_loss: 29.1449, total_loss: 233.1592
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.41it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.91it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.25it/s]
[[032m2021-11-26 10:44:37,940[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:37,941[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:38,425[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 336:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 336:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.9]train epoch: 336:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.24it/s, loss=31.9]train epoch: 336:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.24it/s, loss=24.5]train epoch: 336:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.53it/s, loss=24.5]train epoch: 336:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.53it/s, loss=26.2]train epoch: 336:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.02it/s, loss=26.2]train epoch: 336:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.02it/s, loss=30.3]train epoch: 336:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=30.3]train epoch: 336:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=28.2]train epoch: 336:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.64it/s, loss=28.2]train epoch: 336:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.64it/s, loss=20.2]train epoch: 336:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=20.2]train epoch: 336:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=27.4]train epoch: 336:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.62it/s, loss=27.4]train epoch: 336:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.62it/s, loss=26.6]train epoch: 336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.62it/s, loss=26.6]train epoch: 336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.73it/s, loss=26.6]
[[032m2021-11-26 10:44:41,379[0m INFO] trainer.training_epoch Training epoch 336, num_steps 2696,  avg_loss: 26.9075, total_loss: 215.2601
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.92it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.11it/s]
[[032m2021-11-26 10:44:42,061[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:42,061[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:42,371[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 337:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 337:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.8]train epoch: 337:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.10it/s, loss=26.8]train epoch: 337:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.10it/s, loss=26.3]train epoch: 337:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.07it/s, loss=26.3]train epoch: 337:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.07it/s, loss=27.5]train epoch: 337:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.64it/s, loss=27.5]train epoch: 337:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.64it/s, loss=25.8]train epoch: 337:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.46it/s, loss=25.8]
model tensor([[0.5418, 0.4582],
        [0.3884, 0.6116],
        [0.3141, 0.6859],
        [0.4593, 0.5407],
        [0.7103, 0.2897],
        [0.3806, 0.6194],
        [0.7342, 0.2658],
        [0.5702, 0.4298]], device='cuda:0')

prompt tensor([[0.5040, 0.4960],
        [0.3622, 0.6378],
        [0.5308, 0.4692],
        [0.5601, 0.4399],
        [0.7441, 0.2559],
        [0.4719, 0.5281],
        [0.7924, 0.2076],
        [0.6689, 0.3311]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 337:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.46it/s, loss=22.9]train epoch: 337:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=22.9]train epoch: 337:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.91it/s, loss=21.8]train epoch: 337:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.98it/s, loss=21.8]train epoch: 337:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:01,  1.98it/s, loss=25.2]train epoch: 337:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.35it/s, loss=25.2]train epoch: 337:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.35it/s, loss=26.6]train epoch: 337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.25it/s, loss=26.6]train epoch: 337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s, loss=26.6]
[[032m2021-11-26 10:44:45,491[0m INFO] trainer.training_epoch Training epoch 337, num_steps 2704,  avg_loss: 25.3510, total_loss: 202.8078
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.48it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.13it/s]
[[032m2021-11-26 10:44:46,519[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:44:46,520[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:46,782[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 338:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 338:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.1]train epoch: 338:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=26.1]train epoch: 338:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=23.1]train epoch: 338:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=23.1]train epoch: 338:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.31it/s, loss=25.6]train epoch: 338:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.81it/s, loss=25.6]train epoch: 338:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.81it/s, loss=33.4]train epoch: 338:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=33.4]train epoch: 338:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=29.6]train epoch: 338:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.51it/s, loss=29.6]train epoch: 338:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.51it/s, loss=27.3]train epoch: 338:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.13it/s, loss=27.3]train epoch: 338:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.13it/s, loss=25.8]train epoch: 338:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.02it/s, loss=25.8]train epoch: 338:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.02it/s, loss=34.7]train epoch: 338: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.07it/s, loss=34.7]train epoch: 338: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.31it/s, loss=34.7]
[[032m2021-11-26 10:44:50,247[0m INFO] trainer.training_epoch Training epoch 338, num_steps 2712,  avg_loss: 28.2057, total_loss: 225.6452
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.40it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.84it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.44it/s]
[[032m2021-11-26 10:44:51,006[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:44:51,011[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:51,336[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 339:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 339:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.7]train epoch: 339:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=27.7]train epoch: 339:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=20.8]train epoch: 339:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.11it/s, loss=20.8]train epoch: 339:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.11it/s, loss=28.1]train epoch: 339:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.66it/s, loss=28.1]train epoch: 339:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.66it/s, loss=26.3]train epoch: 339:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.20it/s, loss=26.3]train epoch: 339:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.20it/s, loss=21.6]train epoch: 339:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=21.6]train epoch: 339:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.91it/s, loss=27.4]train epoch: 339:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=27.4]train epoch: 339:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=31]  train epoch: 339:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.14it/s, loss=31]train epoch: 339:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.14it/s, loss=24.3]train epoch: 339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.97it/s, loss=24.3]train epoch: 339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.29it/s, loss=24.3]
[[032m2021-11-26 10:44:54,847[0m INFO] trainer.training_epoch Training epoch 339, num_steps 2720,  avg_loss: 25.9012, total_loss: 207.2097
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.29it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.45it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.63it/s]
[[032m2021-11-26 10:44:55,743[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:44:55,744[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:44:56,105[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 340:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 340:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.7]train epoch: 340:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.94it/s, loss=21.7]train epoch: 340:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.94it/s, loss=35.9]train epoch: 340:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=35.9]train epoch: 340:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=30]  train epoch: 340:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=30]train epoch: 340:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=25.2]train epoch: 340:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.31it/s, loss=25.2]train epoch: 340:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.31it/s, loss=25.7]train epoch: 340:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.23it/s, loss=25.7]train epoch: 340:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.23it/s, loss=30]  train epoch: 340:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.18it/s, loss=30]train epoch: 340:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.18it/s, loss=27.9]train epoch: 340:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.03it/s, loss=27.9]train epoch: 340:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.03it/s, loss=31.3]train epoch: 340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.11it/s, loss=31.3]train epoch: 340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.27it/s, loss=31.3]
[[032m2021-11-26 10:44:59,636[0m INFO] trainer.training_epoch Training epoch 340, num_steps 2728,  avg_loss: 28.4543, total_loss: 227.6343
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.35it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.17it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.54it/s]
[[032m2021-11-26 10:45:00,180[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:00,180[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:00,839[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 341:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 341:   0%|          | 0/8 [00:00<?, ?it/s, loss=18.3]train epoch: 341:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=18.3]train epoch: 341:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=38.2]train epoch: 341:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.62it/s, loss=38.2]train epoch: 341:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.62it/s, loss=27.8]train epoch: 341:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.30it/s, loss=27.8]train epoch: 341:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.30it/s, loss=36.7]train epoch: 341:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.52it/s, loss=36.7]train epoch: 341:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.52it/s, loss=34.9]train epoch: 341:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.86it/s, loss=34.9]train epoch: 341:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.86it/s, loss=30.4]train epoch: 341:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.99it/s, loss=30.4]train epoch: 341:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.99it/s, loss=23.7]train epoch: 341:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=23.7]train epoch: 341:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=34]  train epoch: 341: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=34]train epoch: 341: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=34]
[[032m2021-11-26 10:45:03,553[0m INFO] trainer.training_epoch Training epoch 341, num_steps 2736,  avg_loss: 30.5150, total_loss: 244.1201
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.46it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.47it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.56it/s]
[[032m2021-11-26 10:45:04,051[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:45:04,056[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:04,402[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:45:04,533[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 342:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 342:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.3]train epoch: 342:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.39it/s, loss=30.3]train epoch: 342:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.39it/s, loss=22.4]train epoch: 342:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.73it/s, loss=22.4]train epoch: 342:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.73it/s, loss=20.1]train epoch: 342:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.70it/s, loss=20.1]train epoch: 342:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.70it/s, loss=29.2]train epoch: 342:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s, loss=29.2]train epoch: 342:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s, loss=25.4]train epoch: 342:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=25.4]train epoch: 342:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=38.9]train epoch: 342:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.49it/s, loss=38.9]train epoch: 342:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.49it/s, loss=21.7]train epoch: 342:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=21.7]train epoch: 342:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=31.7]train epoch: 342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=31.7]train epoch: 342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=31.7]
[[032m2021-11-26 10:45:06,858[0m INFO] trainer.training_epoch Training epoch 342, num_steps 2744,  avg_loss: 27.4589, total_loss: 219.6710
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.02it/s]
[[032m2021-11-26 10:45:07,397[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:07,397[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:08,080[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 343:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 343:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.7]train epoch: 343:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.94it/s, loss=26.7]train epoch: 343:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.94it/s, loss=25.7]train epoch: 343:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.81it/s, loss=25.7]train epoch: 343:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.81it/s, loss=31]  train epoch: 343:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.87it/s, loss=31]train epoch: 343:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.87it/s, loss=30.8]train epoch: 343:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.76it/s, loss=30.8]train epoch: 343:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.76it/s, loss=26.2]train epoch: 343:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.35it/s, loss=26.2]train epoch: 343:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.35it/s, loss=29.5]train epoch: 343:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.29it/s, loss=29.5]train epoch: 343:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.29it/s, loss=25.6]train epoch: 343:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  1.97it/s, loss=25.6]train epoch: 343:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.97it/s, loss=27.4]train epoch: 343: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.82it/s, loss=27.4]train epoch: 343: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.20it/s, loss=27.4]
[[032m2021-11-26 10:45:11,719[0m INFO] trainer.training_epoch Training epoch 343, num_steps 2752,  avg_loss: 27.8448, total_loss: 222.7580
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.07it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.08it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.99it/s]
[[032m2021-11-26 10:45:12,771[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:12,772[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:13,901[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 344:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 344:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.2]train epoch: 344:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=25.2]train epoch: 344:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=34.4]train epoch: 344:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.25it/s, loss=34.4]train epoch: 344:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.25it/s, loss=19.2]train epoch: 344:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=19.2]train epoch: 344:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s, loss=24.8]train epoch: 344:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.69it/s, loss=24.8]train epoch: 344:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.69it/s, loss=32.8]train epoch: 344:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=32.8]train epoch: 344:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.66it/s, loss=27.6]train epoch: 344:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.14it/s, loss=27.6]train epoch: 344:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:00,  2.14it/s, loss=21.3]train epoch: 344:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.66it/s, loss=21.3]train epoch: 344:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  1.66it/s, loss=19.7]train epoch: 344: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.82it/s, loss=19.7]train epoch: 344: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.02it/s, loss=19.7]
[[032m2021-11-26 10:45:17,892[0m INFO] trainer.training_epoch Training epoch 344, num_steps 2760,  avg_loss: 25.6147, total_loss: 204.9178
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.81it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.81it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.82it/s]
[[032m2021-11-26 10:45:18,525[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:45:18,525[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:19,078[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 345:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 345:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.5]train epoch: 345:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=33.5]train epoch: 345:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s, loss=27.7]train epoch: 345:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.53it/s, loss=27.7]train epoch: 345:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.53it/s, loss=30.7]train epoch: 345:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.10it/s, loss=30.7]train epoch: 345:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.10it/s, loss=31.1]train epoch: 345:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.98it/s, loss=31.1]train epoch: 345:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.98it/s, loss=24.9]train epoch: 345:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=24.9]train epoch: 345:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.78it/s, loss=27.1]train epoch: 345:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.46it/s, loss=27.1]train epoch: 345:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.46it/s, loss=20.3]train epoch: 345:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.30it/s, loss=20.3]train epoch: 345:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.30it/s, loss=22]  train epoch: 345: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.43it/s, loss=22]train epoch: 345: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=22]
[[032m2021-11-26 10:45:22,256[0m INFO] trainer.training_epoch Training epoch 345, num_steps 2768,  avg_loss: 27.1710, total_loss: 217.3676
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.14it/s]
[[032m2021-11-26 10:45:22,855[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:22,856[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:23,234[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 346:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 346:   0%|          | 0/8 [00:00<?, ?it/s, loss=30]train epoch: 346:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.00it/s, loss=30]train epoch: 346:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.00it/s, loss=24.1]train epoch: 346:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.29it/s, loss=24.1]train epoch: 346:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.29it/s, loss=25.4]train epoch: 346:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.44it/s, loss=25.4]train epoch: 346:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.44it/s, loss=37.5]train epoch: 346:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.49it/s, loss=37.5]train epoch: 346:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.49it/s, loss=19]  train epoch: 346:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.39it/s, loss=19]train epoch: 346:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.39it/s, loss=24]train epoch: 346:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=24]train epoch: 346:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=29.1]train epoch: 346:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.06it/s, loss=29.1]train epoch: 346:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  3.06it/s, loss=21.1]train epoch: 346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.04it/s, loss=21.1]train epoch: 346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.32it/s, loss=21.1]
[[032m2021-11-26 10:45:26,684[0m INFO] trainer.training_epoch Training epoch 346, num_steps 2776,  avg_loss: 26.2640, total_loss: 210.1119
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.27it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.05it/s]
[[032m2021-11-26 10:45:27,394[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:27,394[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:28,191[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 347:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 347:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.1]train epoch: 347:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.49it/s, loss=25.1]train epoch: 347:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.49it/s, loss=38.6]train epoch: 347:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.36it/s, loss=38.6]train epoch: 347:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.36it/s, loss=28.5]train epoch: 347:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.89it/s, loss=28.5]train epoch: 347:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.89it/s, loss=26.7]train epoch: 347:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=26.7]train epoch: 347:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=32]  train epoch: 347:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.32it/s, loss=32]train epoch: 347:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.32it/s, loss=26.7]train epoch: 347:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=26.7]train epoch: 347:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=29.7]train epoch: 347:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.51it/s, loss=29.7]train epoch: 347:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.51it/s, loss=23.8]train epoch: 347: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.07it/s, loss=23.8]train epoch: 347: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.49it/s, loss=23.8]
[[032m2021-11-26 10:45:31,417[0m INFO] trainer.training_epoch Training epoch 347, num_steps 2784,  avg_loss: 28.8970, total_loss: 231.1763
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.53it/s]
[[032m2021-11-26 10:45:32,068[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:32,069[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:32,433[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 348:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 348:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.4]train epoch: 348:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=26.4]train epoch: 348:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.99it/s, loss=26.1]train epoch: 348:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.49it/s, loss=26.1]train epoch: 348:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.49it/s, loss=29]  train epoch: 348:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=29]train epoch: 348:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.43it/s, loss=26.3]train epoch: 348:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.64it/s, loss=26.3]train epoch: 348:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.64it/s, loss=34.2]train epoch: 348:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.51it/s, loss=34.2]train epoch: 348:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.51it/s, loss=29]  train epoch: 348:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=29]train epoch: 348:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=34.8]train epoch: 348:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.32it/s, loss=34.8]train epoch: 348:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=31.7]train epoch: 348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  1.99it/s, loss=31.7]train epoch: 348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.26it/s, loss=31.7]
[[032m2021-11-26 10:45:35,989[0m INFO] trainer.training_epoch Training epoch 348, num_steps 2792,  avg_loss: 29.6858, total_loss: 237.4863
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.42it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.90it/s]
[[032m2021-11-26 10:45:36,842[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:36,843[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:37,167[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 349:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 349:   0%|          | 0/8 [00:00<?, ?it/s, loss=24]train epoch: 349:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.10it/s, loss=24]train epoch: 349:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.10it/s, loss=27.6]train epoch: 349:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=27.6]train epoch: 349:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=28.6]train epoch: 349:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.57it/s, loss=28.6]train epoch: 349:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.57it/s, loss=24.6]train epoch: 349:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=24.6]train epoch: 349:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=38.2]train epoch: 349:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=38.2]train epoch: 349:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=26.6]train epoch: 349:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.06it/s, loss=26.6]train epoch: 349:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.06it/s, loss=22.9]train epoch: 349:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=22.9]train epoch: 349:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=24]  train epoch: 349: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.44it/s, loss=24]train epoch: 349: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s, loss=24]
[[032m2021-11-26 10:45:40,081[0m INFO] trainer.training_epoch Training epoch 349, num_steps 2800,  avg_loss: 27.0590, total_loss: 216.4721
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.73it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.59it/s]
[[032m2021-11-26 10:45:40,516[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:40,516[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:40,758[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 350:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3295, 0.6705],
        [0.3053, 0.6947],
        [0.3690, 0.6310],
        [0.5964, 0.4036],
        [0.5715, 0.4285],
        [0.4383, 0.5617],
        [0.4587, 0.5413],
        [0.5560, 0.4440]], device='cuda:0')

prompt tensor([[0.4461, 0.5539],
        [0.5174, 0.4826],
        [0.7509, 0.2491],
        [0.6265, 0.3735],
        [0.7228, 0.2772],
        [0.6448, 0.3552],
        [0.7145, 0.2855],
        [0.5450, 0.4550]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 350:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.2]train epoch: 350:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.63it/s, loss=27.2]train epoch: 350:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.63it/s, loss=39.9]train epoch: 350:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.75it/s, loss=39.9]train epoch: 350:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.75it/s, loss=29.7]train epoch: 350:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.39it/s, loss=29.7]train epoch: 350:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.39it/s, loss=24.9]train epoch: 350:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=24.9]train epoch: 350:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=37.7]train epoch: 350:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.76it/s, loss=37.7]train epoch: 350:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.76it/s, loss=30.5]train epoch: 350:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.95it/s, loss=30.5]train epoch: 350:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.95it/s, loss=30.6]train epoch: 350:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=30.6]train epoch: 350:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.17it/s, loss=21.8]train epoch: 350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.26it/s, loss=21.8]train epoch: 350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.89it/s, loss=21.8]
[[032m2021-11-26 10:45:42,820[0m INFO] trainer.training_epoch Training epoch 350, num_steps 2808,  avg_loss: 30.2792, total_loss: 242.2335
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00, 10.00it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.94it/s]
[[032m2021-11-26 10:45:43,201[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:43,201[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:43,423[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 351:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 351:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.4]train epoch: 351:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=28.4]train epoch: 351:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=21.4]train epoch: 351:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.64it/s, loss=21.4]train epoch: 351:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.64it/s, loss=28.1]train epoch: 351:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=28.1]train epoch: 351:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=32.6]train epoch: 351:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=32.6]train epoch: 351:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=28.8]train epoch: 351:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=28.8]train epoch: 351:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=33.6]train epoch: 351:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.11it/s, loss=33.6]train epoch: 351:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.11it/s, loss=22.4]train epoch: 351:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=22.4]train epoch: 351:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=31.1]train epoch: 351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=31.1]train epoch: 351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=31.1]
[[032m2021-11-26 10:45:45,922[0m INFO] trainer.training_epoch Training epoch 351, num_steps 2816,  avg_loss: 28.2994, total_loss: 226.3952
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.22it/s]
[[032m2021-11-26 10:45:46,330[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:46,331[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:46,544[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 352:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 352:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 352:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=25]train epoch: 352:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=18.2]train epoch: 352:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.85it/s, loss=18.2]train epoch: 352:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.85it/s, loss=31]  train epoch: 352:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=31]train epoch: 352:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.01it/s, loss=36.1]train epoch: 352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.21it/s, loss=36.1]train epoch: 352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.21it/s, loss=32.1]train epoch: 352:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=32.1]train epoch: 352:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=20.9]train epoch: 352:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.89it/s, loss=20.9]train epoch: 352:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.89it/s, loss=29.1]train epoch: 352:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=29.1]train epoch: 352:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=39.9]train epoch: 352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=39.9]train epoch: 352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=39.9]
[[032m2021-11-26 10:45:48,954[0m INFO] trainer.training_epoch Training epoch 352, num_steps 2824,  avg_loss: 29.0457, total_loss: 232.3652
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.45it/s]
[[032m2021-11-26 10:45:49,319[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:49,319[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:49,541[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 353:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 353:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.2]train epoch: 353:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.72it/s, loss=27.2]train epoch: 353:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.72it/s, loss=36.4]train epoch: 353:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=36.4]train epoch: 353:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=35.8]train epoch: 353:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.46it/s, loss=35.8]train epoch: 353:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.46it/s, loss=26.7]train epoch: 353:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=26.7]train epoch: 353:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=24.6]train epoch: 353:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=24.6]train epoch: 353:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=30.3]train epoch: 353:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.85it/s, loss=30.3]train epoch: 353:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=28.6]train epoch: 353:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=28.6]train epoch: 353:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=29.6]train epoch: 353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=29.6]train epoch: 353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=29.6]
[[032m2021-11-26 10:45:51,962[0m INFO] trainer.training_epoch Training epoch 353, num_steps 2832,  avg_loss: 29.8983, total_loss: 239.1866
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.32it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.03it/s]
[[032m2021-11-26 10:45:52,376[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:52,377[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:52,591[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 354:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 354:   0%|          | 0/8 [00:00<?, ?it/s, loss=34]train epoch: 354:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=34]train epoch: 354:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=34.7]train epoch: 354:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.04it/s, loss=34.7]train epoch: 354:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.04it/s, loss=21.7]train epoch: 354:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.85it/s, loss=21.7]train epoch: 354:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.85it/s, loss=22.9]train epoch: 354:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.03it/s, loss=22.9]train epoch: 354:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.03it/s, loss=22.7]train epoch: 354:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.29it/s, loss=22.7]train epoch: 354:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.29it/s, loss=28.6]train epoch: 354:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.27it/s, loss=28.6]train epoch: 354:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.27it/s, loss=32.6]train epoch: 354:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.52it/s, loss=32.6]train epoch: 354:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.52it/s, loss=28.6]train epoch: 354: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.67it/s, loss=28.6]train epoch: 354: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.67it/s, loss=28.6]
[[032m2021-11-26 10:45:54,779[0m INFO] trainer.training_epoch Training epoch 354, num_steps 2840,  avg_loss: 28.2257, total_loss: 225.8053
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.29it/s]
[[032m2021-11-26 10:45:55,152[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:55,152[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:55,385[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 355:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 355:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.9]train epoch: 355:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.17it/s, loss=22.9]train epoch: 355:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.17it/s, loss=27.4]train epoch: 355:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=27.4]train epoch: 355:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=30.4]train epoch: 355:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.04it/s, loss=30.4]train epoch: 355:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.04it/s, loss=24]  train epoch: 355:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.97it/s, loss=24]train epoch: 355:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.97it/s, loss=24.9]train epoch: 355:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=24.9]train epoch: 355:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=24.5]train epoch: 355:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.34it/s, loss=24.5]train epoch: 355:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.34it/s, loss=19.3]train epoch: 355:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.67it/s, loss=19.3]train epoch: 355:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.67it/s, loss=28.5]train epoch: 355: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.87it/s, loss=28.5]train epoch: 355: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.48it/s, loss=28.5]
[[032m2021-11-26 10:45:57,690[0m INFO] trainer.training_epoch Training epoch 355, num_steps 2848,  avg_loss: 25.2233, total_loss: 201.7864
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.08it/s]
[[032m2021-11-26 10:45:58,068[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:45:58,068[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:45:58,283[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 356:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 356:   0%|          | 0/8 [00:00<?, ?it/s, loss=34]train epoch: 356:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=34]train epoch: 356:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=24]train epoch: 356:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=24]train epoch: 356:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=29.2]train epoch: 356:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=29.2]train epoch: 356:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=26.6]train epoch: 356:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.00it/s, loss=26.6]train epoch: 356:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.00it/s, loss=22.6]train epoch: 356:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=22.6]train epoch: 356:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=20.1]train epoch: 356:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.49it/s, loss=20.1]train epoch: 356:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.49it/s, loss=22.9]train epoch: 356:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.69it/s, loss=22.9]train epoch: 356:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=30.1]train epoch: 356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=30.1]train epoch: 356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.87it/s, loss=30.1]
[[032m2021-11-26 10:46:00,356[0m INFO] trainer.training_epoch Training epoch 356, num_steps 2856,  avg_loss: 26.2029, total_loss: 209.6235
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.71it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.50it/s]
[[032m2021-11-26 10:46:00,751[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:00,751[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:00,961[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 357:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 357:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 357:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=23.6]train epoch: 357:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=28.5]train epoch: 357:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=28.5]train epoch: 357:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=29.9]train epoch: 357:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.53it/s, loss=29.9]train epoch: 357:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.53it/s, loss=27.9]train epoch: 357:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.51it/s, loss=27.9]train epoch: 357:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.51it/s, loss=34.2]train epoch: 357:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.91it/s, loss=34.2]train epoch: 357:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.91it/s, loss=25.4]train epoch: 357:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=25.4]train epoch: 357:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=27.5]train epoch: 357:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.62it/s, loss=27.5]train epoch: 357:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.62it/s, loss=16.6]train epoch: 357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=16.6]train epoch: 357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.86it/s, loss=16.6]
[[032m2021-11-26 10:46:03,041[0m INFO] trainer.training_epoch Training epoch 357, num_steps 2864,  avg_loss: 26.6971, total_loss: 213.5768
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.75it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.12it/s]
[[032m2021-11-26 10:46:03,460[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:03,460[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:03,679[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 358:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 358:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.2]train epoch: 358:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=28.2]train epoch: 358:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=24.5]train epoch: 358:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.81it/s, loss=24.5]train epoch: 358:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.81it/s, loss=26.9]train epoch: 358:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=26.9]train epoch: 358:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=21]  train epoch: 358:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.22it/s, loss=21]train epoch: 358:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.22it/s, loss=27.8]train epoch: 358:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.11it/s, loss=27.8]train epoch: 358:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.11it/s, loss=26.5]train epoch: 358:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.62it/s, loss=26.5]train epoch: 358:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.62it/s, loss=27.5]train epoch: 358:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=27.5]train epoch: 358:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=19]  train epoch: 358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s, loss=19]train epoch: 358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s, loss=19]
[[032m2021-11-26 10:46:06,006[0m INFO] trainer.training_epoch Training epoch 358, num_steps 2872,  avg_loss: 25.1737, total_loss: 201.3893
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.37it/s]
[[032m2021-11-26 10:46:06,411[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:06,411[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:06,623[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 359:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 359:   0%|          | 0/8 [00:00<?, ?it/s, loss=17.7]train epoch: 359:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=17.7]train epoch: 359:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.88it/s, loss=19.9]train epoch: 359:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.71it/s, loss=19.9]train epoch: 359:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.71it/s, loss=29.4]train epoch: 359:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=29.4]train epoch: 359:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.26it/s, loss=30]  train epoch: 359:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=30]train epoch: 359:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=26.2]train epoch: 359:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=26.2]train epoch: 359:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=30.6]train epoch: 359:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.98it/s, loss=30.6]train epoch: 359:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=21.4]train epoch: 359:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s, loss=21.4]train epoch: 359:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s, loss=34]  train epoch: 359: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=34]train epoch: 359: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=34]
[[032m2021-11-26 10:46:09,006[0m INFO] trainer.training_epoch Training epoch 359, num_steps 2880,  avg_loss: 26.1481, total_loss: 209.1848
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.91it/s]
[[032m2021-11-26 10:46:09,396[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:46:09,397[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:09,613[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:46:09,709[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 360:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 360:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.7]train epoch: 360:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.21it/s, loss=25.7]train epoch: 360:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.21it/s, loss=33.8]train epoch: 360:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.46it/s, loss=33.8]train epoch: 360:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.46it/s, loss=31.6]train epoch: 360:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.47it/s, loss=31.6]train epoch: 360:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.47it/s, loss=22.3]train epoch: 360:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.53it/s, loss=22.3]train epoch: 360:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.53it/s, loss=29.2]train epoch: 360:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=29.2]train epoch: 360:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=24.2]train epoch: 360:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s, loss=24.2]train epoch: 360:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.38it/s, loss=33]  train epoch: 360:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=33]train epoch: 360:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=26.5]train epoch: 360: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.00it/s, loss=26.5]train epoch: 360: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=26.5]
[[032m2021-11-26 10:46:12,118[0m INFO] trainer.training_epoch Training epoch 360, num_steps 2888,  avg_loss: 28.2839, total_loss: 226.2708
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.84it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.76it/s]
[[032m2021-11-26 10:46:12,545[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:12,546[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:12,774[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 361:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 361:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.5]train epoch: 361:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.77it/s, loss=21.5]train epoch: 361:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.77it/s, loss=29.8]train epoch: 361:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.41it/s, loss=29.8]train epoch: 361:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.41it/s, loss=28.5]train epoch: 361:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=28.5]train epoch: 361:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=33.7]train epoch: 361:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.48it/s, loss=33.7]train epoch: 361:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.48it/s, loss=27.5]train epoch: 361:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=27.5]train epoch: 361:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.87it/s, loss=31.3]train epoch: 361:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=31.3]train epoch: 361:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=25.1]train epoch: 361:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=25.1]train epoch: 361:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=21.9]train epoch: 361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.73it/s, loss=21.9]train epoch: 361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.06it/s, loss=21.9]
[[032m2021-11-26 10:46:15,396[0m INFO] trainer.training_epoch Training epoch 361, num_steps 2896,  avg_loss: 27.4124, total_loss: 219.2992
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.75it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.35it/s]
[[032m2021-11-26 10:46:15,839[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:15,839[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:16,764[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 362:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 362:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.7]train epoch: 362:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.46it/s, loss=33.7]train epoch: 362:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.46it/s, loss=24.9]train epoch: 362:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.85it/s, loss=24.9]train epoch: 362:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.85it/s, loss=24.3]train epoch: 362:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.22it/s, loss=24.3]train epoch: 362:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.22it/s, loss=25.4]train epoch: 362:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=25.4]
model tensor([[0.3806, 0.6194],
        [0.4305, 0.5695],
        [0.7454, 0.2546],
        [0.3744, 0.6256],
        [0.5439, 0.4561],
        [0.5501, 0.4499],
        [0.5964, 0.4036],
        [0.6349, 0.3651]], device='cuda:0')

prompt tensor([[0.4900, 0.5100],
        [0.5647, 0.4353],
        [0.6460, 0.3540],
        [0.4335, 0.5665],
        [0.5826, 0.4174],
        [0.5876, 0.4124],
        [0.4841, 0.5159],
        [0.7353, 0.2647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 362:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=26.6]train epoch: 362:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.72it/s, loss=26.6]train epoch: 362:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.72it/s, loss=26.3]train epoch: 362:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=26.3]train epoch: 362:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=34.9]train epoch: 362:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=34.9]train epoch: 362:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.95it/s, loss=37.7]train epoch: 362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.06it/s, loss=37.7]train epoch: 362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.67it/s, loss=37.7]
[[032m2021-11-26 10:46:18,964[0m INFO] trainer.training_epoch Training epoch 362, num_steps 2904,  avg_loss: 29.2173, total_loss: 233.7382
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.84it/s]
[[032m2021-11-26 10:46:19,500[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:19,501[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:20,176[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 363:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 363:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 363:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.04it/s, loss=29.8]train epoch: 363:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.04it/s, loss=32]  train epoch: 363:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=32]train epoch: 363:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=23.8]train epoch: 363:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.78it/s, loss=23.8]train epoch: 363:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.78it/s, loss=28.7]train epoch: 363:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.13it/s, loss=28.7]train epoch: 363:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.13it/s, loss=28.5]train epoch: 363:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=28.5]train epoch: 363:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=27.8]train epoch: 363:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.37it/s, loss=27.8]train epoch: 363:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.37it/s, loss=24.1]train epoch: 363:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.33it/s, loss=24.1]train epoch: 363:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.33it/s, loss=20.3]train epoch: 363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.35it/s, loss=20.3]train epoch: 363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.13it/s, loss=20.3]
[[032m2021-11-26 10:46:22,120[0m INFO] trainer.training_epoch Training epoch 363, num_steps 2912,  avg_loss: 26.8711, total_loss: 214.9685
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.54it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.58it/s]
[[032m2021-11-26 10:46:22,678[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:22,679[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:23,427[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 364:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 364:   0%|          | 0/8 [00:00<?, ?it/s, loss=28]train epoch: 364:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.95it/s, loss=28]train epoch: 364:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.95it/s, loss=23.8]train epoch: 364:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.28it/s, loss=23.8]train epoch: 364:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.28it/s, loss=33.5]train epoch: 364:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.62it/s, loss=33.5]train epoch: 364:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.62it/s, loss=26.9]train epoch: 364:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.89it/s, loss=26.9]train epoch: 364:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.89it/s, loss=25.4]train epoch: 364:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=25.4]train epoch: 364:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=26.6]train epoch: 364:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=26.6]train epoch: 364:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=41.9]train epoch: 364:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.68it/s, loss=41.9]train epoch: 364:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.68it/s, loss=23.5]train epoch: 364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.66it/s, loss=23.5]train epoch: 364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=23.5]
[[032m2021-11-26 10:46:25,933[0m INFO] trainer.training_epoch Training epoch 364, num_steps 2920,  avg_loss: 28.7049, total_loss: 229.6395
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.04it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.01it/s]
[[032m2021-11-26 10:46:26,467[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:26,467[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:26,677[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 365:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 365:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.3]train epoch: 365:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.20it/s, loss=26.3]train epoch: 365:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.20it/s, loss=19.6]train epoch: 365:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.77it/s, loss=19.6]train epoch: 365:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.77it/s, loss=30.6]train epoch: 365:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.69it/s, loss=30.6]train epoch: 365:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.69it/s, loss=23.2]train epoch: 365:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.44it/s, loss=23.2]train epoch: 365:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.44it/s, loss=21.7]train epoch: 365:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=21.7]train epoch: 365:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=31.8]train epoch: 365:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.15it/s, loss=31.8]train epoch: 365:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.15it/s, loss=29]  train epoch: 365:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.18it/s, loss=29]train epoch: 365:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.18it/s, loss=31.6]train epoch: 365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.94it/s, loss=31.6]train epoch: 365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.18it/s, loss=31.6]
[[032m2021-11-26 10:46:28,605[0m INFO] trainer.training_epoch Training epoch 365, num_steps 2928,  avg_loss: 26.7369, total_loss: 213.8956
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.31it/s]
[[032m2021-11-26 10:46:29,289[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:29,289[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:29,583[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 366:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 366:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.2]train epoch: 366:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=28.2]train epoch: 366:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=26.7]train epoch: 366:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=26.7]train epoch: 366:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=21.9]train epoch: 366:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.06it/s, loss=21.9]train epoch: 366:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.06it/s, loss=24.1]train epoch: 366:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.06it/s, loss=24.1]train epoch: 366:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.06it/s, loss=34.5]train epoch: 366:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=34.5]train epoch: 366:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=30.2]train epoch: 366:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.41it/s, loss=30.2]train epoch: 366:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.41it/s, loss=26.9]train epoch: 366:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=26.9]train epoch: 366:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.17it/s, loss=37.2]train epoch: 366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.51it/s, loss=37.2]train epoch: 366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.90it/s, loss=37.2]
[[032m2021-11-26 10:46:31,640[0m INFO] trainer.training_epoch Training epoch 366, num_steps 2936,  avg_loss: 28.7054, total_loss: 229.6429
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.04it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.04it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.77it/s]
[[032m2021-11-26 10:46:32,254[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:32,254[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:32,574[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 367:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 367:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.8]train epoch: 367:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=28.8]train epoch: 367:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=30.4]train epoch: 367:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=30.4]train epoch: 367:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=22.2]train epoch: 367:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=22.2]train epoch: 367:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=24.8]train epoch: 367:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.54it/s, loss=24.8]train epoch: 367:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.54it/s, loss=34.5]train epoch: 367:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.47it/s, loss=34.5]train epoch: 367:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.47it/s, loss=26.8]train epoch: 367:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.39it/s, loss=26.8]train epoch: 367:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.39it/s, loss=28.7]train epoch: 367:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.23it/s, loss=28.7]train epoch: 367:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.23it/s, loss=27]  train epoch: 367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.32it/s, loss=27]train epoch: 367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.39it/s, loss=27]
[[032m2021-11-26 10:46:34,402[0m INFO] trainer.training_epoch Training epoch 367, num_steps 2944,  avg_loss: 27.9008, total_loss: 223.2062
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.63it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.70it/s]
[[032m2021-11-26 10:46:35,284[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:35,284[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:35,673[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 368:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 368:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.8]train epoch: 368:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=23.8]train epoch: 368:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=32.7]train epoch: 368:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=32.7]train epoch: 368:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=32.6]train epoch: 368:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=32.6]train epoch: 368:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=33.2]train epoch: 368:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.49it/s, loss=33.2]train epoch: 368:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.49it/s, loss=29.8]train epoch: 368:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=29.8]train epoch: 368:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=29.3]train epoch: 368:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.83it/s, loss=29.3]train epoch: 368:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.83it/s, loss=24.3]train epoch: 368:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=24.3]train epoch: 368:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=23.2]train epoch: 368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.99it/s, loss=23.2]train epoch: 368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.10it/s, loss=23.2]
[[032m2021-11-26 10:46:37,641[0m INFO] trainer.training_epoch Training epoch 368, num_steps 2952,  avg_loss: 28.5999, total_loss: 228.7991
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.36it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.03it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.27it/s]
[[032m2021-11-26 10:46:38,252[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:38,253[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:38,641[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 369:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 369:   0%|          | 0/8 [00:00<?, ?it/s, loss=26]train epoch: 369:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.41it/s, loss=26]train epoch: 369:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.41it/s, loss=35]train epoch: 369:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=35]train epoch: 369:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=22.3]train epoch: 369:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=22.3]train epoch: 369:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=25.7]train epoch: 369:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.24it/s, loss=25.7]train epoch: 369:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.24it/s, loss=24.2]train epoch: 369:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=24.2]train epoch: 369:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=30.5]train epoch: 369:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.23it/s, loss=30.5]train epoch: 369:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.23it/s, loss=21.4]train epoch: 369:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.13it/s, loss=21.4]train epoch: 369:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.13it/s, loss=33.7]train epoch: 369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.98it/s, loss=33.7]train epoch: 369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.05it/s, loss=33.7]
[[032m2021-11-26 10:46:40,624[0m INFO] trainer.training_epoch Training epoch 369, num_steps 2960,  avg_loss: 27.3475, total_loss: 218.7798
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.33it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.27it/s]
[[032m2021-11-26 10:46:41,399[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:41,399[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:41,875[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 370:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 370:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.8]train epoch: 370:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.64it/s, loss=24.8]train epoch: 370:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.64it/s, loss=23.4]train epoch: 370:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=23.4]train epoch: 370:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=27.9]train epoch: 370:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.14it/s, loss=27.9]train epoch: 370:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.14it/s, loss=25.8]train epoch: 370:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.29it/s, loss=25.8]train epoch: 370:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.29it/s, loss=28]  train epoch: 370:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=28]train epoch: 370:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=18.9]train epoch: 370:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.04it/s, loss=18.9]train epoch: 370:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.04it/s, loss=27.2]train epoch: 370:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=27.2]train epoch: 370:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=26.9]train epoch: 370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.96it/s, loss=26.9]train epoch: 370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.05it/s, loss=26.9]
[[032m2021-11-26 10:46:43,857[0m INFO] trainer.training_epoch Training epoch 370, num_steps 2968,  avg_loss: 25.3540, total_loss: 202.8320
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.88it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.89it/s]
[[032m2021-11-26 10:46:44,558[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:44,558[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:44,822[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 371:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 371:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.4]train epoch: 371:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.24it/s, loss=24.4]train epoch: 371:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.24it/s, loss=28.6]train epoch: 371:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.56it/s, loss=28.6]train epoch: 371:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.56it/s, loss=28.8]train epoch: 371:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.19it/s, loss=28.8]train epoch: 371:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.19it/s, loss=22.9]train epoch: 371:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.13it/s, loss=22.9]train epoch: 371:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.13it/s, loss=27.3]train epoch: 371:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.11it/s, loss=27.3]train epoch: 371:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.11it/s, loss=30.7]train epoch: 371:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=30.7]train epoch: 371:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=31.1]train epoch: 371:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.27it/s, loss=31.1]train epoch: 371:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.27it/s, loss=23.9]train epoch: 371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=23.9]train epoch: 371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.86it/s, loss=23.9]
[[032m2021-11-26 10:46:46,900[0m INFO] trainer.training_epoch Training epoch 371, num_steps 2976,  avg_loss: 27.1877, total_loss: 217.5015
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.90it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.77it/s]
[[032m2021-11-26 10:46:47,433[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:46:47,434[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:47,779[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 372:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 372:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.3]train epoch: 372:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=23.3]train epoch: 372:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=24.6]train epoch: 372:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.86it/s, loss=24.6]train epoch: 372:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.86it/s, loss=34.1]train epoch: 372:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.12it/s, loss=34.1]train epoch: 372:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.12it/s, loss=25.9]train epoch: 372:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.04it/s, loss=25.9]train epoch: 372:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.04it/s, loss=26]  train epoch: 372:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=26]train epoch: 372:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=24.7]train epoch: 372:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=24.7]train epoch: 372:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=28.5]train epoch: 372:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.92it/s, loss=28.5]train epoch: 372:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.92it/s, loss=27.6]train epoch: 372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=27.6]train epoch: 372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.79it/s, loss=27.6]
[[032m2021-11-26 10:46:49,905[0m INFO] trainer.training_epoch Training epoch 372, num_steps 2984,  avg_loss: 26.8601, total_loss: 214.8808
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.27it/s]
[[032m2021-11-26 10:46:50,523[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:46:50,523[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:50,751[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:46:50,894[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 373:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 373:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 373:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.77it/s, loss=29.8]train epoch: 373:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.77it/s, loss=27.7]train epoch: 373:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=27.7]train epoch: 373:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=30]  train epoch: 373:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s, loss=30]train epoch: 373:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s, loss=29.5]train epoch: 373:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.28it/s, loss=29.5]train epoch: 373:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.28it/s, loss=29.5]train epoch: 373:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.37it/s, loss=29.5]train epoch: 373:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.37it/s, loss=22.5]train epoch: 373:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.21it/s, loss=22.5]train epoch: 373:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.21it/s, loss=25.4]train epoch: 373:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.51it/s, loss=25.4]train epoch: 373:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=27.9]train epoch: 373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s, loss=27.9]train epoch: 373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.66it/s, loss=27.9]
[[032m2021-11-26 10:46:53,089[0m INFO] trainer.training_epoch Training epoch 373, num_steps 2992,  avg_loss: 27.7999, total_loss: 222.3995
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.36it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.28it/s]
[[032m2021-11-26 10:46:53,742[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:46:53,742[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:54,004[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:46:54,102[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 374:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 374:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.1]train epoch: 374:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=26.1]train epoch: 374:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=30]  train epoch: 374:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.51it/s, loss=30]train epoch: 374:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.51it/s, loss=21.8]train epoch: 374:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.74it/s, loss=21.8]train epoch: 374:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.74it/s, loss=26.5]train epoch: 374:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.65it/s, loss=26.5]train epoch: 374:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.65it/s, loss=27.4]train epoch: 374:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=27.4]train epoch: 374:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.19it/s, loss=30.9]train epoch: 374:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=30.9]train epoch: 374:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=27.7]train epoch: 374:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.61it/s, loss=27.7]train epoch: 374:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.61it/s, loss=28]  train epoch: 374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.84it/s, loss=28]train epoch: 374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.01it/s, loss=28]
[[032m2021-11-26 10:46:56,101[0m INFO] trainer.training_epoch Training epoch 374, num_steps 3000,  avg_loss: 27.3041, total_loss: 218.4330
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.98it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.77it/s]
[[032m2021-11-26 10:46:56,571[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:46:56,572[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:56,824[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:46:56,920[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 375:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.2534, 0.7466],
        [0.8361, 0.1639],
        [0.4013, 0.5987],
        [0.2477, 0.7523],
        [0.3391, 0.6609],
        [0.6717, 0.3283],
        [0.4587, 0.5413],
        [0.5557, 0.4443]], device='cuda:0')

prompt tensor([[0.6743, 0.3257],
        [0.8432, 0.1568],
        [0.6984, 0.3016],
        [0.4183, 0.5817],
        [0.6362, 0.3638],
        [0.6125, 0.3875],
        [0.6207, 0.3793],
        [0.7497, 0.2503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 375:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.9]train epoch: 375:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.31it/s, loss=23.9]train epoch: 375:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.31it/s, loss=21.6]train epoch: 375:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=21.6]train epoch: 375:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=28.1]train epoch: 375:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=28.1]train epoch: 375:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=26.4]train epoch: 375:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.58it/s, loss=26.4]train epoch: 375:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.58it/s, loss=37.4]train epoch: 375:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.57it/s, loss=37.4]train epoch: 375:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.57it/s, loss=30.6]train epoch: 375:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.32it/s, loss=30.6]train epoch: 375:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.32it/s, loss=25.7]train epoch: 375:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=25.7]train epoch: 375:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=24.4]train epoch: 375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.31it/s, loss=24.4]train epoch: 375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.38it/s, loss=24.4]
[[032m2021-11-26 10:46:58,753[0m INFO] trainer.training_epoch Training epoch 375, num_steps 3008,  avg_loss: 27.2649, total_loss: 218.1192
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.34it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.66it/s]
[[032m2021-11-26 10:46:59,290[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:46:59,290[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:46:59,817[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:47:00,036[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 376:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 376:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.5]train epoch: 376:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=23.5]train epoch: 376:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=30]  train epoch: 376:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.07it/s, loss=30]train epoch: 376:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.07it/s, loss=34]train epoch: 376:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.98it/s, loss=34]train epoch: 376:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.98it/s, loss=19.4]train epoch: 376:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.15it/s, loss=19.4]train epoch: 376:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.15it/s, loss=22]  train epoch: 376:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.00it/s, loss=22]train epoch: 376:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.00it/s, loss=29.5]train epoch: 376:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.11it/s, loss=29.5]train epoch: 376:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.11it/s, loss=24.5]train epoch: 376:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.31it/s, loss=24.5]train epoch: 376:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.31it/s, loss=26.7]train epoch: 376: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.88it/s, loss=26.7]train epoch: 376: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=26.7]
[[032m2021-11-26 10:47:02,031[0m INFO] trainer.training_epoch Training epoch 376, num_steps 3016,  avg_loss: 26.2018, total_loss: 209.6145
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.19it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.94it/s]
[[032m2021-11-26 10:47:02,769[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:47:02,769[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:03,222[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 377:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 377:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.8]train epoch: 377:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.41it/s, loss=24.8]train epoch: 377:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.41it/s, loss=27.8]train epoch: 377:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.24it/s, loss=27.8]train epoch: 377:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.24it/s, loss=23.8]train epoch: 377:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.40it/s, loss=23.8]train epoch: 377:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.40it/s, loss=30.6]train epoch: 377:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.92it/s, loss=30.6]train epoch: 377:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s, loss=28.7]train epoch: 377:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=28.7]train epoch: 377:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=29.9]train epoch: 377:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.98it/s, loss=29.9]train epoch: 377:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.98it/s, loss=26.6]train epoch: 377:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.34it/s, loss=26.6]train epoch: 377:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.34it/s, loss=22.7]train epoch: 377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.59it/s, loss=22.7]train epoch: 377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=22.7]
[[032m2021-11-26 10:47:05,668[0m INFO] trainer.training_epoch Training epoch 377, num_steps 3024,  avg_loss: 26.8690, total_loss: 214.9516
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.81it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.92it/s]
[[032m2021-11-26 10:47:06,189[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:47:06,189[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:06,436[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 378:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 378:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.1]train epoch: 378:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.69it/s, loss=32.1]train epoch: 378:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.69it/s, loss=27.6]train epoch: 378:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=27.6]train epoch: 378:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=27]  train epoch: 378:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=27]train epoch: 378:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=32.9]train epoch: 378:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.06it/s, loss=32.9]train epoch: 378:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.06it/s, loss=25.6]train epoch: 378:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.13it/s, loss=25.6]train epoch: 378:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.13it/s, loss=29.9]train epoch: 378:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.33it/s, loss=29.9]train epoch: 378:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.33it/s, loss=41.1]train epoch: 378:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  2.95it/s, loss=41.1]train epoch: 378:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.95it/s, loss=28.3]train epoch: 378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.63it/s, loss=28.3]train epoch: 378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.30it/s, loss=28.3]
[[032m2021-11-26 10:47:08,868[0m INFO] trainer.training_epoch Training epoch 378, num_steps 3032,  avg_loss: 30.5795, total_loss: 244.6363
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.34it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.71it/s]
[[032m2021-11-26 10:47:09,479[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:47:09,479[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:09,714[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 379:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 379:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.7]train epoch: 379:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=25.7]train epoch: 379:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=34.4]train epoch: 379:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=34.4]train epoch: 379:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=29.7]train epoch: 379:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.35it/s, loss=29.7]train epoch: 379:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.35it/s, loss=19]  train epoch: 379:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.28it/s, loss=19]train epoch: 379:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.28it/s, loss=24.3]train epoch: 379:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=24.3]train epoch: 379:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=30.8]train epoch: 379:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=30.8]train epoch: 379:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=28.7]train epoch: 379:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.85it/s, loss=28.7]train epoch: 379:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.85it/s, loss=33.2]train epoch: 379: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s, loss=33.2]train epoch: 379: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.70it/s, loss=33.2]
[[032m2021-11-26 10:47:11,880[0m INFO] trainer.training_epoch Training epoch 379, num_steps 3040,  avg_loss: 28.2336, total_loss: 225.8688
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.29it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.38it/s]
[[032m2021-11-26 10:47:12,397[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:47:12,397[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:12,658[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 380:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 380:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.3]train epoch: 380:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.59it/s, loss=28.3]train epoch: 380:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.59it/s, loss=30.1]train epoch: 380:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.38it/s, loss=30.1]train epoch: 380:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.38it/s, loss=24]  train epoch: 380:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.12it/s, loss=24]train epoch: 380:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.12it/s, loss=29]train epoch: 380:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.18it/s, loss=29]train epoch: 380:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.18it/s, loss=28.4]train epoch: 380:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=28.4]train epoch: 380:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.25it/s, loss=24.4]train epoch: 380:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.15it/s, loss=24.4]train epoch: 380:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.15it/s, loss=25.3]train epoch: 380:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.39it/s, loss=25.3]train epoch: 380:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=32.1]train epoch: 380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=32.1]train epoch: 380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=32.1]
[[032m2021-11-26 10:47:14,872[0m INFO] trainer.training_epoch Training epoch 380, num_steps 3048,  avg_loss: 27.6960, total_loss: 221.5682
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.77it/s]
[[032m2021-11-26 10:47:15,364[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:15,365[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:15,586[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 381:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 381:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.4]train epoch: 381:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.12it/s, loss=33.4]train epoch: 381:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.12it/s, loss=27.9]train epoch: 381:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=27.9]train epoch: 381:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=31]  train epoch: 381:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=31]train epoch: 381:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=26.8]train epoch: 381:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.32it/s, loss=26.8]train epoch: 381:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.32it/s, loss=26.7]train epoch: 381:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=26.7]train epoch: 381:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=25.9]train epoch: 381:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.04it/s, loss=25.9]train epoch: 381:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  4.04it/s, loss=30.8]train epoch: 381:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.59it/s, loss=30.8]train epoch: 381:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.59it/s, loss=32.6]train epoch: 381: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.57it/s, loss=32.6]train epoch: 381: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s, loss=32.6]
[[032m2021-11-26 10:47:18,102[0m INFO] trainer.training_epoch Training epoch 381, num_steps 3056,  avg_loss: 29.3794, total_loss: 235.0352
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.75it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.64it/s]
[[032m2021-11-26 10:47:18,595[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:18,596[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:18,857[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 382:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 382:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.8]train epoch: 382:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.01it/s, loss=32.8]train epoch: 382:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.01it/s, loss=35.5]train epoch: 382:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=35.5]train epoch: 382:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=26.6]train epoch: 382:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s, loss=26.6]train epoch: 382:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s, loss=27.9]train epoch: 382:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.16it/s, loss=27.9]train epoch: 382:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.16it/s, loss=25.8]train epoch: 382:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=25.8]train epoch: 382:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.30it/s, loss=27.3]train epoch: 382:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.67it/s, loss=27.3]train epoch: 382:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=32.8]train epoch: 382:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.60it/s, loss=32.8]train epoch: 382:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.60it/s, loss=31]  train epoch: 382: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s, loss=31]train epoch: 382: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s, loss=31]
[[032m2021-11-26 10:47:21,438[0m INFO] trainer.training_epoch Training epoch 382, num_steps 3064,  avg_loss: 29.9622, total_loss: 239.6976
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.52it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.73it/s]
[[032m2021-11-26 10:47:21,866[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:47:21,867[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:22,086[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 383:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 383:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.2]train epoch: 383:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=32.2]train epoch: 383:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=29]  train epoch: 383:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=29]train epoch: 383:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=38.2]train epoch: 383:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.25it/s, loss=38.2]train epoch: 383:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.25it/s, loss=34.3]train epoch: 383:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.72it/s, loss=34.3]train epoch: 383:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.72it/s, loss=23.1]train epoch: 383:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.16it/s, loss=23.1]train epoch: 383:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.16it/s, loss=34.3]train epoch: 383:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=34.3]train epoch: 383:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=21.1]train epoch: 383:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.83it/s, loss=21.1]train epoch: 383:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.83it/s, loss=23]  train epoch: 383: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s, loss=23]train epoch: 383: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=23]
[[032m2021-11-26 10:47:24,611[0m INFO] trainer.training_epoch Training epoch 383, num_steps 3072,  avg_loss: 29.3933, total_loss: 235.1464
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.06it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.96it/s]
[[032m2021-11-26 10:47:25,076[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:47:25,076[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:25,285[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 384:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 384:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.2]train epoch: 384:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.02it/s, loss=26.2]train epoch: 384:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.02it/s, loss=28.1]train epoch: 384:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=28.1]train epoch: 384:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=29.3]train epoch: 384:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.09it/s, loss=29.3]train epoch: 384:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.09it/s, loss=25.4]train epoch: 384:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=25.4]train epoch: 384:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=30]  train epoch: 384:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.56it/s, loss=30]train epoch: 384:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.56it/s, loss=21.3]train epoch: 384:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=21.3]train epoch: 384:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=34.8]train epoch: 384:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=34.8]train epoch: 384:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=28]  train epoch: 384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=28]train epoch: 384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=28]
[[032m2021-11-26 10:47:27,777[0m INFO] trainer.training_epoch Training epoch 384, num_steps 3080,  avg_loss: 27.9035, total_loss: 223.2278
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.61it/s]
[[032m2021-11-26 10:47:28,137[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:28,137[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:28,351[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 385:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 385:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.7]train epoch: 385:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.89it/s, loss=30.7]train epoch: 385:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.89it/s, loss=24.1]train epoch: 385:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.13it/s, loss=24.1]train epoch: 385:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.13it/s, loss=34.1]train epoch: 385:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.07it/s, loss=34.1]train epoch: 385:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.07it/s, loss=24.2]train epoch: 385:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=24.2]train epoch: 385:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=31.1]train epoch: 385:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.23it/s, loss=31.1]train epoch: 385:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.23it/s, loss=32.3]train epoch: 385:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s, loss=32.3]train epoch: 385:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.37it/s, loss=22.1]train epoch: 385:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=22.1]train epoch: 385:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=25.6]train epoch: 385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=25.6]train epoch: 385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=25.6]
[[032m2021-11-26 10:47:30,810[0m INFO] trainer.training_epoch Training epoch 385, num_steps 3088,  avg_loss: 28.0299, total_loss: 224.2395
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.57it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.43it/s]
[[032m2021-11-26 10:47:31,207[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:31,207[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:31,420[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 386:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 386:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.8]train epoch: 386:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=24.8]train epoch: 386:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=32.9]train epoch: 386:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.45it/s, loss=32.9]train epoch: 386:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.45it/s, loss=33.1]train epoch: 386:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s, loss=33.1]train epoch: 386:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s, loss=23.5]train epoch: 386:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.63it/s, loss=23.5]train epoch: 386:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.63it/s, loss=25]  train epoch: 386:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.43it/s, loss=25]train epoch: 386:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.43it/s, loss=20.7]train epoch: 386:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.71it/s, loss=20.7]train epoch: 386:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.71it/s, loss=27.6]train epoch: 386:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.03it/s, loss=27.6]train epoch: 386:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=29.1]train epoch: 386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=29.1]train epoch: 386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.66it/s, loss=29.1]
[[032m2021-11-26 10:47:33,613[0m INFO] trainer.training_epoch Training epoch 386, num_steps 3096,  avg_loss: 27.0777, total_loss: 216.6212
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.96it/s]
[[032m2021-11-26 10:47:33,993[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:33,994[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:34,228[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 387:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 387:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 387:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.94it/s, loss=29.3]train epoch: 387:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.94it/s, loss=23.8]train epoch: 387:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=23.8]train epoch: 387:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=21]  train epoch: 387:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=21]train epoch: 387:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.99it/s, loss=35.7]train epoch: 387:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.64it/s, loss=35.7]
model tensor([[0.5951, 0.4049],
        [0.3473, 0.6527],
        [0.5964, 0.4036],
        [0.4305, 0.5695],
        [0.2828, 0.7172],
        [0.6054, 0.3946],
        [0.5443, 0.4557],
        [0.5702, 0.4298]], device='cuda:0')

prompt tensor([[0.6274, 0.3726],
        [0.6359, 0.3641],
        [0.5239, 0.4761],
        [0.5516, 0.4484],
        [0.3705, 0.6295],
        [0.7759, 0.2241],
        [0.5237, 0.4763],
        [0.8173, 0.1827]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 387:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.64it/s, loss=25.9]train epoch: 387:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.83it/s, loss=25.9]train epoch: 387:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.83it/s, loss=24]  train epoch: 387:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=24]train epoch: 387:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=21.4]train epoch: 387:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=21.4]train epoch: 387:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=28.5]train epoch: 387: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.74it/s, loss=28.5]train epoch: 387: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.59it/s, loss=28.5]
[[032m2021-11-26 10:47:36,462[0m INFO] trainer.training_epoch Training epoch 387, num_steps 3104,  avg_loss: 26.1843, total_loss: 209.4745
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.93it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.93it/s]
[[032m2021-11-26 10:47:36,846[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:36,846[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:37,068[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 388:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 388:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.2]train epoch: 388:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.76it/s, loss=29.2]train epoch: 388:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.76it/s, loss=27.8]train epoch: 388:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=27.8]train epoch: 388:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=25.1]train epoch: 388:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=25.1]train epoch: 388:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=24.7]train epoch: 388:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.27it/s, loss=24.7]train epoch: 388:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.27it/s, loss=21.9]train epoch: 388:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=21.9]train epoch: 388:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=24.6]train epoch: 388:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.35it/s, loss=24.6]train epoch: 388:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.35it/s, loss=27.5]train epoch: 388:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.11it/s, loss=27.5]train epoch: 388:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.11it/s, loss=25.7]train epoch: 388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.74it/s, loss=25.7]train epoch: 388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=25.7]
[[032m2021-11-26 10:47:39,063[0m INFO] trainer.training_epoch Training epoch 388, num_steps 3112,  avg_loss: 25.8131, total_loss: 206.5047
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.44it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.06it/s]
[[032m2021-11-26 10:47:39,665[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:39,666[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:40,157[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 389:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 389:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.9]train epoch: 389:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=32.9]train epoch: 389:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=32.9]train epoch: 389:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=32.9]train epoch: 389:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=28.5]train epoch: 389:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=28.5]train epoch: 389:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=21.6]train epoch: 389:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.31it/s, loss=21.6]train epoch: 389:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.31it/s, loss=25.9]train epoch: 389:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.13it/s, loss=25.9]train epoch: 389:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.13it/s, loss=26.7]train epoch: 389:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=26.7]train epoch: 389:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=29.6]train epoch: 389:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.74it/s, loss=29.6]train epoch: 389:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.74it/s, loss=23.6]train epoch: 389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.61it/s, loss=23.6]train epoch: 389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=23.6]
[[032m2021-11-26 10:47:42,244[0m INFO] trainer.training_epoch Training epoch 389, num_steps 3120,  avg_loss: 27.7115, total_loss: 221.6917
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.95it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.17it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.81it/s]
[[032m2021-11-26 10:47:42,875[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:42,875[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:43,282[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 390:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 390:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.5]train epoch: 390:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=29.5]train epoch: 390:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=30.5]train epoch: 390:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=30.5]train epoch: 390:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=22.2]train epoch: 390:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=22.2]train epoch: 390:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=29.8]train epoch: 390:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.01it/s, loss=29.8]train epoch: 390:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.01it/s, loss=28.8]train epoch: 390:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.22it/s, loss=28.8]train epoch: 390:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.22it/s, loss=31.9]train epoch: 390:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=31.9]train epoch: 390:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.25it/s, loss=27]  train epoch: 390:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.36it/s, loss=27]train epoch: 390:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.36it/s, loss=26.9]train epoch: 390: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.15it/s, loss=26.9]train epoch: 390: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.19it/s, loss=26.9]
[[032m2021-11-26 10:47:45,199[0m INFO] trainer.training_epoch Training epoch 390, num_steps 3128,  avg_loss: 28.3209, total_loss: 226.5669
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.97it/s]
[[032m2021-11-26 10:47:45,736[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:45,737[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:46,045[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 391:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 391:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.6]train epoch: 391:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=25.6]train epoch: 391:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=35.3]train epoch: 391:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.04it/s, loss=35.3]train epoch: 391:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.04it/s, loss=30.6]train epoch: 391:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s, loss=30.6]train epoch: 391:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s, loss=28.8]train epoch: 391:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.34it/s, loss=28.8]train epoch: 391:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.34it/s, loss=29.5]train epoch: 391:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=29.5]train epoch: 391:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=36.5]train epoch: 391:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=36.5]train epoch: 391:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=29.6]train epoch: 391:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=29.6]train epoch: 391:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.95it/s, loss=26.2]train epoch: 391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=26.2]train epoch: 391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s, loss=26.2]
[[032m2021-11-26 10:47:48,183[0m INFO] trainer.training_epoch Training epoch 391, num_steps 3136,  avg_loss: 30.2566, total_loss: 242.0525
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.48it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.30it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.66it/s]
[[032m2021-11-26 10:47:48,930[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:47:48,931[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:49,444[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 392:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 392:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.3]train epoch: 392:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.67it/s, loss=24.3]train epoch: 392:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.67it/s, loss=19.9]train epoch: 392:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.70it/s, loss=19.9]train epoch: 392:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.70it/s, loss=16.5]train epoch: 392:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.80it/s, loss=16.5]train epoch: 392:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.80it/s, loss=31.2]train epoch: 392:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.73it/s, loss=31.2]train epoch: 392:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.73it/s, loss=18.9]train epoch: 392:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.00it/s, loss=18.9]train epoch: 392:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.00it/s, loss=28]  train epoch: 392:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=28]train epoch: 392:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=30.1]train epoch: 392:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.50it/s, loss=30.1]train epoch: 392:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=24.7]train epoch: 392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.68it/s, loss=24.7]train epoch: 392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=24.7]
[[032m2021-11-26 10:47:51,915[0m INFO] trainer.training_epoch Training epoch 392, num_steps 3144,  avg_loss: 24.2068, total_loss: 193.6543
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.75it/s]
[[032m2021-11-26 10:47:52,450[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:47:52,450[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:52,701[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 393:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 393:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.2]train epoch: 393:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=34.2]train epoch: 393:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=26.6]train epoch: 393:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.43it/s, loss=26.6]train epoch: 393:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.43it/s, loss=27]  train epoch: 393:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=27]train epoch: 393:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=32.7]train epoch: 393:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.39it/s, loss=32.7]train epoch: 393:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.39it/s, loss=25.1]train epoch: 393:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=25.1]train epoch: 393:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=37.4]train epoch: 393:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=37.4]train epoch: 393:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.34it/s, loss=29.8]train epoch: 393:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.53it/s, loss=29.8]train epoch: 393:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.53it/s, loss=32.4]train epoch: 393: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=32.4]train epoch: 393: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s, loss=32.4]
[[032m2021-11-26 10:47:54,803[0m INFO] trainer.training_epoch Training epoch 393, num_steps 3152,  avg_loss: 30.6653, total_loss: 245.3223
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.46it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.91it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.96it/s]
[[032m2021-11-26 10:47:55,651[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:47:55,652[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:55,889[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 394:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 394:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.3]train epoch: 394:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.06it/s, loss=21.3]train epoch: 394:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.06it/s, loss=26.3]train epoch: 394:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.84it/s, loss=26.3]train epoch: 394:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.84it/s, loss=26.9]train epoch: 394:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=26.9]train epoch: 394:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=33.5]train epoch: 394:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.07it/s, loss=33.5]train epoch: 394:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.07it/s, loss=32.4]train epoch: 394:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.15it/s, loss=32.4]train epoch: 394:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.15it/s, loss=27.9]train epoch: 394:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=27.9]train epoch: 394:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.72it/s, loss=26.6]train epoch: 394:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.79it/s, loss=26.6]train epoch: 394:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.79it/s, loss=26.8]train epoch: 394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.62it/s, loss=26.8]train epoch: 394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=26.8]
[[032m2021-11-26 10:47:58,366[0m INFO] trainer.training_epoch Training epoch 394, num_steps 3160,  avg_loss: 27.7136, total_loss: 221.7089
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.12it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.20it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.01it/s]
[[032m2021-11-26 10:47:58,953[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:47:58,953[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:47:59,215[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 395:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 395:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.1]train epoch: 395:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=36.1]train epoch: 395:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=24]  train epoch: 395:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=24]train epoch: 395:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=26.6]train epoch: 395:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=26.6]train epoch: 395:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=21.6]train epoch: 395:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.49it/s, loss=21.6]train epoch: 395:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.49it/s, loss=25.8]train epoch: 395:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=25.8]train epoch: 395:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=26.6]train epoch: 395:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.38it/s, loss=26.6]train epoch: 395:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.38it/s, loss=27.6]train epoch: 395:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.06it/s, loss=27.6]train epoch: 395:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.06it/s, loss=28.3]train epoch: 395: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.62it/s, loss=28.3]train epoch: 395: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=28.3]
[[032m2021-11-26 10:48:01,606[0m INFO] trainer.training_epoch Training epoch 395, num_steps 3168,  avg_loss: 27.0881, total_loss: 216.7045
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.23it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.49it/s]
[[032m2021-11-26 10:48:02,101[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:48:02,101[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:02,357[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 396:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 396:   0%|          | 0/8 [00:00<?, ?it/s, loss=22]train epoch: 396:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=22]train epoch: 396:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=24.1]train epoch: 396:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=24.1]train epoch: 396:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=22.6]train epoch: 396:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=22.6]train epoch: 396:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=27.5]train epoch: 396:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.32it/s, loss=27.5]train epoch: 396:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.32it/s, loss=28.8]train epoch: 396:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.44it/s, loss=28.8]train epoch: 396:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.44it/s, loss=29.5]train epoch: 396:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.36it/s, loss=29.5]train epoch: 396:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.36it/s, loss=26.5]train epoch: 396:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.10it/s, loss=26.5]train epoch: 396:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.10it/s, loss=23.5]train epoch: 396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=23.5]train epoch: 396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.80it/s, loss=23.5]
[[032m2021-11-26 10:48:04,468[0m INFO] trainer.training_epoch Training epoch 396, num_steps 3176,  avg_loss: 25.5613, total_loss: 204.4903
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.69it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.03it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.09it/s]
[[032m2021-11-26 10:48:05,054[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:48:05,055[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:05,364[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 397:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 397:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.9]train epoch: 397:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=28.9]train epoch: 397:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.90it/s, loss=33.3]train epoch: 397:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=33.3]train epoch: 397:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.74it/s, loss=30.4]train epoch: 397:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=30.4]train epoch: 397:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=29.3]train epoch: 397:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.53it/s, loss=29.3]train epoch: 397:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.53it/s, loss=27.5]train epoch: 397:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=27.5]train epoch: 397:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.14it/s, loss=26.3]train epoch: 397:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.86it/s, loss=26.3]train epoch: 397:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=20]  train epoch: 397:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.44it/s, loss=20]train epoch: 397:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.44it/s, loss=32.2]train epoch: 397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.72it/s, loss=32.2]train epoch: 397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=32.2]
[[032m2021-11-26 10:48:07,889[0m INFO] trainer.training_epoch Training epoch 397, num_steps 3184,  avg_loss: 28.4718, total_loss: 227.7742
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.71it/s]
[[032m2021-11-26 10:48:08,292[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:48:08,292[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:08,520[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 398:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 398:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 398:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=24.9]train epoch: 398:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=24.2]train epoch: 398:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=24.2]train epoch: 398:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=29.6]train epoch: 398:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.45it/s, loss=29.6]train epoch: 398:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.45it/s, loss=28.5]train epoch: 398:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.30it/s, loss=28.5]train epoch: 398:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.30it/s, loss=26.6]train epoch: 398:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.36it/s, loss=26.6]train epoch: 398:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.36it/s, loss=25.9]train epoch: 398:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.71it/s, loss=25.9]train epoch: 398:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=24.2]train epoch: 398:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.64it/s, loss=24.2]train epoch: 398:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.64it/s, loss=36.2]train epoch: 398: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.69it/s, loss=36.2]train epoch: 398: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s, loss=36.2]
[[032m2021-11-26 10:48:11,170[0m INFO] trainer.training_epoch Training epoch 398, num_steps 3192,  avg_loss: 27.5070, total_loss: 220.0559
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.88it/s]
[[032m2021-11-26 10:48:11,554[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:48:11,555[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:11,764[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 399:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 399:   0%|          | 0/8 [00:00<?, ?it/s, loss=38.8]train epoch: 399:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=38.8]train epoch: 399:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=26.7]train epoch: 399:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=26.7]train epoch: 399:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=25.5]train epoch: 399:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=25.5]train epoch: 399:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.50it/s, loss=36.1]train epoch: 399:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.95it/s, loss=36.1]train epoch: 399:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s, loss=24.1]train epoch: 399:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=24.1]train epoch: 399:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=23.8]train epoch: 399:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.98it/s, loss=23.8]train epoch: 399:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=22.3]train epoch: 399:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s, loss=22.3]train epoch: 399:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s, loss=23.4]train epoch: 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=23.4]train epoch: 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=23.4]
[[032m2021-11-26 10:48:14,013[0m INFO] trainer.training_epoch Training epoch 399, num_steps 3200,  avg_loss: 27.5862, total_loss: 220.6894
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.44it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.78it/s]
[[032m2021-11-26 10:48:14,438[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:48:14,438[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:14,652[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 400:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.5445, 0.4555],
        [0.6761, 0.3239],
        [0.3690, 0.6310],
        [0.4469, 0.5531],
        [0.5951, 0.4049],
        [0.3295, 0.6705],
        [0.5650, 0.4350],
        [0.4013, 0.5987]], device='cuda:0')

prompt tensor([[0.4363, 0.5637],
        [0.7364, 0.2636],
        [0.3394, 0.6606],
        [0.6782, 0.3218],
        [0.7311, 0.2689],
        [0.4126, 0.5874],
        [0.7114, 0.2886],
        [0.3940, 0.6060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 400:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.3]train epoch: 400:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.68it/s, loss=28.3]train epoch: 400:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.68it/s, loss=25.4]train epoch: 400:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.44it/s, loss=25.4]train epoch: 400:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.44it/s, loss=37]  train epoch: 400:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.52it/s, loss=37]train epoch: 400:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.52it/s, loss=27.2]train epoch: 400:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=27.2]train epoch: 400:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=28.1]train epoch: 400:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=28.1]train epoch: 400:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.95it/s, loss=24]  train epoch: 400:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=24]train epoch: 400:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=31.8]train epoch: 400:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=31.8]train epoch: 400:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.77it/s, loss=19]  train epoch: 400: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=19]train epoch: 400: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s, loss=19]
[[032m2021-11-26 10:48:17,232[0m INFO] trainer.training_epoch Training epoch 400, num_steps 3208,  avg_loss: 27.6071, total_loss: 220.8564
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.30it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.97it/s]
[[032m2021-11-26 10:48:17,652[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:48:17,652[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:17,869[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 401:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 401:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.7]train epoch: 401:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=32.7]train epoch: 401:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.40it/s, loss=24.3]train epoch: 401:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=24.3]train epoch: 401:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=29.4]train epoch: 401:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=29.4]train epoch: 401:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=27.8]train epoch: 401:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.13it/s, loss=27.8]train epoch: 401:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.13it/s, loss=34]  train epoch: 401:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.49it/s, loss=34]train epoch: 401:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.49it/s, loss=28.3]train epoch: 401:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.93it/s, loss=28.3]train epoch: 401:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.93it/s, loss=24]  train epoch: 401:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.60it/s, loss=24]train epoch: 401:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.60it/s, loss=23.9]train epoch: 401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s, loss=23.9]train epoch: 401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.23it/s, loss=23.9]
[[032m2021-11-26 10:48:20,353[0m INFO] trainer.training_epoch Training epoch 401, num_steps 3216,  avg_loss: 28.0561, total_loss: 224.4490
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.97it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.27it/s]
[[032m2021-11-26 10:48:20,808[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:48:20,809[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:21,048[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 402:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 402:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.9]train epoch: 402:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=28.9]train epoch: 402:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=22.6]train epoch: 402:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.59it/s, loss=22.6]train epoch: 402:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.59it/s, loss=33.3]train epoch: 402:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=33.3]train epoch: 402:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.42it/s, loss=34.4]train epoch: 402:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.25it/s, loss=34.4]train epoch: 402:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.25it/s, loss=32.4]train epoch: 402:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=32.4]train epoch: 402:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.66it/s, loss=27.1]train epoch: 402:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.10it/s, loss=27.1]train epoch: 402:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.10it/s, loss=36.1]train epoch: 402:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=36.1]train epoch: 402:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=32.2]train epoch: 402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=32.2]train epoch: 402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=32.2]
[[032m2021-11-26 10:48:23,639[0m INFO] trainer.training_epoch Training epoch 402, num_steps 3224,  avg_loss: 30.8835, total_loss: 247.0679
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.31it/s]
[[032m2021-11-26 10:48:24,047[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:48:24,048[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:24,269[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 403:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 403:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 403:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.44it/s, loss=27.9]train epoch: 403:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.44it/s, loss=25.3]train epoch: 403:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.77it/s, loss=25.3]train epoch: 403:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.77it/s, loss=27.5]train epoch: 403:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.40it/s, loss=27.5]train epoch: 403:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.40it/s, loss=34.7]train epoch: 403:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.97it/s, loss=34.7]train epoch: 403:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.97it/s, loss=21.7]train epoch: 403:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=21.7]train epoch: 403:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=27.4]train epoch: 403:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.15it/s, loss=27.4]train epoch: 403:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.15it/s, loss=27.2]train epoch: 403:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=27.2]train epoch: 403:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=24.8]train epoch: 403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.36it/s, loss=24.8]train epoch: 403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=24.8]
[[032m2021-11-26 10:48:26,739[0m INFO] trainer.training_epoch Training epoch 403, num_steps 3232,  avg_loss: 27.0456, total_loss: 216.3651
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.11it/s]
[[032m2021-11-26 10:48:27,154[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:48:27,155[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:27,383[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 404:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 404:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.8]train epoch: 404:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.65it/s, loss=22.8]train epoch: 404:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.65it/s, loss=29.2]train epoch: 404:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.68it/s, loss=29.2]train epoch: 404:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.68it/s, loss=27.8]train epoch: 404:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=27.8]train epoch: 404:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.44it/s, loss=27.1]train epoch: 404:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.39it/s, loss=27.1]train epoch: 404:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.39it/s, loss=31]  train epoch: 404:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.21it/s, loss=31]train epoch: 404:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.21it/s, loss=37.1]train epoch: 404:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=37.1]train epoch: 404:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.72it/s, loss=25.4]train epoch: 404:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  2.96it/s, loss=25.4]train epoch: 404:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=25.1]train epoch: 404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.61it/s, loss=25.1]train epoch: 404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=25.1]
[[032m2021-11-26 10:48:29,829[0m INFO] trainer.training_epoch Training epoch 404, num_steps 3240,  avg_loss: 28.1892, total_loss: 225.5134
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.49it/s]
[[032m2021-11-26 10:48:30,226[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:48:30,227[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:30,460[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 405:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 405:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.4]train epoch: 405:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=32.4]train epoch: 405:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=19.8]train epoch: 405:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=19.8]train epoch: 405:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.53it/s, loss=32.2]train epoch: 405:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.36it/s, loss=32.2]train epoch: 405:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.36it/s, loss=29.3]train epoch: 405:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.41it/s, loss=29.3]train epoch: 405:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.41it/s, loss=26.7]train epoch: 405:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=26.7]train epoch: 405:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=22]  train epoch: 405:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.78it/s, loss=22]train epoch: 405:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.78it/s, loss=27.8]train epoch: 405:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=27.8]train epoch: 405:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=23]  train epoch: 405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s, loss=23]train epoch: 405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=23]
[[032m2021-11-26 10:48:32,929[0m INFO] trainer.training_epoch Training epoch 405, num_steps 3248,  avg_loss: 26.6523, total_loss: 213.2180
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.60it/s]
[[032m2021-11-26 10:48:33,325[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:48:33,326[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:33,533[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 406:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 406:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 406:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=23.6]train epoch: 406:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.66it/s, loss=19.3]train epoch: 406:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=19.3]train epoch: 406:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=31.3]train epoch: 406:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.25it/s, loss=31.3]train epoch: 406:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.25it/s, loss=28.2]train epoch: 406:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=28.2]train epoch: 406:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=29.2]train epoch: 406:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.19it/s, loss=29.2]train epoch: 406:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.19it/s, loss=31.2]train epoch: 406:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=31.2]train epoch: 406:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.16it/s, loss=17.4]train epoch: 406:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=17.4]train epoch: 406:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=29.8]train epoch: 406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=29.8]train epoch: 406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=29.8]
[[032m2021-11-26 10:48:35,915[0m INFO] trainer.training_epoch Training epoch 406, num_steps 3256,  avg_loss: 26.2479, total_loss: 209.9829
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.20it/s]
[[032m2021-11-26 10:48:36,322[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:48:36,323[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:36,533[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 407:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 407:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.4]train epoch: 407:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.91it/s, loss=21.4]train epoch: 407:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.91it/s, loss=32.5]train epoch: 407:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.50it/s, loss=32.5]train epoch: 407:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.50it/s, loss=23.3]train epoch: 407:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.51it/s, loss=23.3]train epoch: 407:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.51it/s, loss=26.1]train epoch: 407:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.35it/s, loss=26.1]train epoch: 407:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.35it/s, loss=26]  train epoch: 407:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=26]train epoch: 407:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=22.3]train epoch: 407:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.92it/s, loss=22.3]train epoch: 407:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=23.2]train epoch: 407:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.55it/s, loss=23.2]train epoch: 407:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.55it/s, loss=27]  train epoch: 407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.87it/s, loss=27]train epoch: 407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=27]
[[032m2021-11-26 10:48:39,053[0m INFO] trainer.training_epoch Training epoch 407, num_steps 3264,  avg_loss: 25.2279, total_loss: 201.8233
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.10it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.18it/s]
[[032m2021-11-26 10:48:39,510[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:48:39,510[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:39,724[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 408:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 408:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.5]train epoch: 408:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=27.5]train epoch: 408:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=32.1]train epoch: 408:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=32.1]train epoch: 408:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=20.9]train epoch: 408:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=20.9]train epoch: 408:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=24.8]train epoch: 408:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.48it/s, loss=24.8]train epoch: 408:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.48it/s, loss=25.4]train epoch: 408:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.15it/s, loss=25.4]train epoch: 408:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.15it/s, loss=22.5]train epoch: 408:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s, loss=22.5]train epoch: 408:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s, loss=19.5]train epoch: 408:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=19.5]train epoch: 408:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=23.6]train epoch: 408: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.35it/s, loss=23.6]train epoch: 408: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.07it/s, loss=23.6]
[[032m2021-11-26 10:48:42,338[0m INFO] trainer.training_epoch Training epoch 408, num_steps 3272,  avg_loss: 24.5385, total_loss: 196.3078
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.14it/s]
[[032m2021-11-26 10:48:42,790[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:48:42,791[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:43,005[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 409:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 409:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.1]train epoch: 409:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.95it/s, loss=32.1]train epoch: 409:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.95it/s, loss=22.2]train epoch: 409:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.80it/s, loss=22.2]train epoch: 409:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.80it/s, loss=26.6]train epoch: 409:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.09it/s, loss=26.6]train epoch: 409:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.09it/s, loss=23]  train epoch: 409:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.18it/s, loss=23]train epoch: 409:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.18it/s, loss=25.8]train epoch: 409:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s, loss=25.8]train epoch: 409:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s, loss=32.7]train epoch: 409:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.99it/s, loss=32.7]train epoch: 409:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.99it/s, loss=30.8]train epoch: 409:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=30.8]train epoch: 409:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=25.5]train epoch: 409: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s, loss=25.5]train epoch: 409: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=25.5]
[[032m2021-11-26 10:48:45,561[0m INFO] trainer.training_epoch Training epoch 409, num_steps 3280,  avg_loss: 27.3386, total_loss: 218.7085
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.74it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.65it/s]
[[032m2021-11-26 10:48:45,998[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:48:45,999[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:46,216[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 410:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 410:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 410:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.92it/s, loss=29.8]train epoch: 410:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.92it/s, loss=24.9]train epoch: 410:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=24.9]train epoch: 410:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=22.5]train epoch: 410:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.53it/s, loss=22.5]train epoch: 410:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.53it/s, loss=25.5]train epoch: 410:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.48it/s, loss=25.5]train epoch: 410:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.48it/s, loss=32.3]train epoch: 410:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=32.3]train epoch: 410:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=33]  train epoch: 410:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.81it/s, loss=33]train epoch: 410:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.81it/s, loss=30.8]train epoch: 410:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.26it/s, loss=30.8]train epoch: 410:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s, loss=20.2]train epoch: 410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.84it/s, loss=20.2]train epoch: 410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=20.2]
[[032m2021-11-26 10:48:48,525[0m INFO] trainer.training_epoch Training epoch 410, num_steps 3288,  avg_loss: 27.3690, total_loss: 218.9518
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.81it/s]
[[032m2021-11-26 10:48:48,980[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:48:48,980[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:49,208[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 411:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 411:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.2]train epoch: 411:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=21.2]train epoch: 411:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.29it/s, loss=31.4]train epoch: 411:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=31.4]train epoch: 411:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=26.4]train epoch: 411:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=26.4]train epoch: 411:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=28.9]train epoch: 411:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.32it/s, loss=28.9]train epoch: 411:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.32it/s, loss=23.4]train epoch: 411:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.56it/s, loss=23.4]train epoch: 411:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.56it/s, loss=29.6]train epoch: 411:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.45it/s, loss=29.6]train epoch: 411:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.45it/s, loss=26.7]train epoch: 411:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.58it/s, loss=26.7]train epoch: 411:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=31.3]train epoch: 411: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=31.3]train epoch: 411: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.63it/s, loss=31.3]
[[032m2021-11-26 10:48:51,417[0m INFO] trainer.training_epoch Training epoch 411, num_steps 3296,  avg_loss: 27.3597, total_loss: 218.8779
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.12it/s]
[[032m2021-11-26 10:48:51,827[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:48:51,827[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:52,064[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 412:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 412:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.8]train epoch: 412:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.98it/s, loss=19.8]train epoch: 412:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.98it/s, loss=28.2]train epoch: 412:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=28.2]train epoch: 412:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=21.5]train epoch: 412:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=21.5]train epoch: 412:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=30]  train epoch: 412:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.22it/s, loss=30]
model tensor([[0.3049, 0.6951],
        [0.5951, 0.4049],
        [0.3498, 0.6502],
        [0.3884, 0.6116],
        [0.8361, 0.1639],
        [0.2534, 0.7466],
        [0.5951, 0.4049],
        [0.4808, 0.5192]], device='cuda:0')

prompt tensor([[0.6736, 0.3264],
        [0.7170, 0.2830],
        [0.6738, 0.3262],
        [0.4052, 0.5948],
        [0.9345, 0.0655],
        [0.7348, 0.2652],
        [0.4117, 0.5883],
        [0.4730, 0.5270]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 412:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.22it/s, loss=25.6]train epoch: 412:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=25.6]train epoch: 412:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.32it/s, loss=21.4]train epoch: 412:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.26it/s, loss=21.4]train epoch: 412:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.26it/s, loss=30.4]train epoch: 412:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.53it/s, loss=30.4]train epoch: 412:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.53it/s, loss=24.1]train epoch: 412: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.64it/s, loss=24.1]train epoch: 412: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.92it/s, loss=24.1]
[[032m2021-11-26 10:48:54,807[0m INFO] trainer.training_epoch Training epoch 412, num_steps 3304,  avg_loss: 25.1165, total_loss: 200.9318
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.72it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.72it/s]
[[032m2021-11-26 10:48:55,233[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:48:55,234[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:55,444[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 413:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 413:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 413:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.45it/s, loss=25.5]train epoch: 413:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.45it/s, loss=28.5]train epoch: 413:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=28.5]train epoch: 413:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.63it/s, loss=34.3]train epoch: 413:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.57it/s, loss=34.3]train epoch: 413:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.57it/s, loss=33.4]train epoch: 413:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.42it/s, loss=33.4]train epoch: 413:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.42it/s, loss=27.7]train epoch: 413:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=27.7]train epoch: 413:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.10it/s, loss=37]  train epoch: 413:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=37]train epoch: 413:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=36.9]train epoch: 413:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.59it/s, loss=36.9]train epoch: 413:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.59it/s, loss=28.9]train epoch: 413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=28.9]train epoch: 413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.68it/s, loss=28.9]
[[032m2021-11-26 10:48:57,626[0m INFO] trainer.training_epoch Training epoch 413, num_steps 3312,  avg_loss: 31.5279, total_loss: 252.2233
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.16it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.77it/s]
[[032m2021-11-26 10:48:58,231[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:48:58,231[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:48:58,518[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 414:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 414:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.9]train epoch: 414:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=30.9]train epoch: 414:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=26.2]train epoch: 414:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=26.2]train epoch: 414:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=27.3]train epoch: 414:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=27.3]train epoch: 414:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.55it/s, loss=25.8]train epoch: 414:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.48it/s, loss=25.8]train epoch: 414:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.48it/s, loss=34.7]train epoch: 414:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.50it/s, loss=34.7]train epoch: 414:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.50it/s, loss=22.6]train epoch: 414:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=22.6]train epoch: 414:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=16.4]train epoch: 414:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.43it/s, loss=16.4]train epoch: 414:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.43it/s, loss=25]  train epoch: 414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.89it/s, loss=25]train epoch: 414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.23it/s, loss=25]
[[032m2021-11-26 10:49:00,414[0m INFO] trainer.training_epoch Training epoch 414, num_steps 3320,  avg_loss: 26.1301, total_loss: 209.0410
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.35it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.18it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.06it/s]
[[032m2021-11-26 10:49:01,228[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:01,228[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:01,764[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 415:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 415:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.6]train epoch: 415:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=26.6]train epoch: 415:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=33.6]train epoch: 415:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=33.6]train epoch: 415:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=27.6]train epoch: 415:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.37it/s, loss=27.6]train epoch: 415:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.37it/s, loss=26.5]train epoch: 415:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.38it/s, loss=26.5]train epoch: 415:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.38it/s, loss=30.5]train epoch: 415:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=30.5]train epoch: 415:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=28]  train epoch: 415:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.13it/s, loss=28]train epoch: 415:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.13it/s, loss=20.1]train epoch: 415:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.61it/s, loss=20.1]train epoch: 415:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.61it/s, loss=19.1]train epoch: 415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s, loss=19.1]train epoch: 415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=19.1]
[[032m2021-11-26 10:49:04,038[0m INFO] trainer.training_epoch Training epoch 415, num_steps 3328,  avg_loss: 26.4933, total_loss: 211.9466
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.17it/s]
[[032m2021-11-26 10:49:04,569[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:04,569[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:05,001[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 416:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 416:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.6]train epoch: 416:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=33.6]train epoch: 416:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=26.8]train epoch: 416:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=26.8]train epoch: 416:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=37.2]train epoch: 416:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.19it/s, loss=37.2]train epoch: 416:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.19it/s, loss=25.2]train epoch: 416:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.88it/s, loss=25.2]train epoch: 416:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.88it/s, loss=19.8]train epoch: 416:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.09it/s, loss=19.8]train epoch: 416:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.09it/s, loss=24.8]train epoch: 416:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.21it/s, loss=24.8]train epoch: 416:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.21it/s, loss=36.6]train epoch: 416:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.92it/s, loss=36.6]train epoch: 416:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.92it/s, loss=26.8]train epoch: 416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.71it/s, loss=26.8]train epoch: 416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s, loss=26.8]
[[032m2021-11-26 10:49:07,036[0m INFO] trainer.training_epoch Training epoch 416, num_steps 3336,  avg_loss: 28.8395, total_loss: 230.7164
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.61it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.83it/s]
[[032m2021-11-26 10:49:07,575[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:07,575[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:07,901[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 417:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 417:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.1]train epoch: 417:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.74it/s, loss=22.1]train epoch: 417:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.74it/s, loss=29.8]train epoch: 417:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.11it/s, loss=29.8]train epoch: 417:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.11it/s, loss=29.4]train epoch: 417:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s, loss=29.4]train epoch: 417:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s, loss=35.2]train epoch: 417:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.29it/s, loss=35.2]train epoch: 417:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.29it/s, loss=21.3]train epoch: 417:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.16it/s, loss=21.3]train epoch: 417:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.16it/s, loss=25.6]train epoch: 417:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.26it/s, loss=25.6]train epoch: 417:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.26it/s, loss=29.2]train epoch: 417:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.43it/s, loss=29.2]train epoch: 417:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.43it/s, loss=23.1]train epoch: 417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.41it/s, loss=23.1]train epoch: 417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.29it/s, loss=23.1]
[[032m2021-11-26 10:49:09,771[0m INFO] trainer.training_epoch Training epoch 417, num_steps 3344,  avg_loss: 26.9553, total_loss: 215.6427
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.36it/s]
[[032m2021-11-26 10:49:10,189[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:10,189[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:10,919[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 418:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 418:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.6]train epoch: 418:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=25.6]train epoch: 418:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=24.5]train epoch: 418:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.33it/s, loss=24.5]train epoch: 418:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.33it/s, loss=26.4]train epoch: 418:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.09it/s, loss=26.4]train epoch: 418:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.09it/s, loss=30.2]train epoch: 418:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.28it/s, loss=30.2]train epoch: 418:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.28it/s, loss=24.8]train epoch: 418:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.71it/s, loss=24.8]train epoch: 418:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.71it/s, loss=30.1]train epoch: 418:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=30.1]train epoch: 418:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=24.2]train epoch: 418:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=24.2]train epoch: 418:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.12it/s, loss=35.2]train epoch: 418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.19it/s, loss=35.2]train epoch: 418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.78it/s, loss=35.2]
[[032m2021-11-26 10:49:13,054[0m INFO] trainer.training_epoch Training epoch 418, num_steps 3352,  avg_loss: 27.6208, total_loss: 220.9664
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.81it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.92it/s]
[[032m2021-11-26 10:49:13,580[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:13,581[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:13,791[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 419:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 419:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.3]train epoch: 419:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.13it/s, loss=33.3]train epoch: 419:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.13it/s, loss=31.5]train epoch: 419:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=31.5]train epoch: 419:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=28.3]train epoch: 419:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.36it/s, loss=28.3]train epoch: 419:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.36it/s, loss=28.3]train epoch: 419:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=28.3]train epoch: 419:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.50it/s, loss=26]  train epoch: 419:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.88it/s, loss=26]train epoch: 419:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.88it/s, loss=26.1]train epoch: 419:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=26.1]train epoch: 419:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=26.5]train epoch: 419:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.02it/s, loss=26.5]train epoch: 419:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.02it/s, loss=23.3]train epoch: 419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.16it/s, loss=23.3]train epoch: 419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.72it/s, loss=23.3]
[[032m2021-11-26 10:49:15,949[0m INFO] trainer.training_epoch Training epoch 419, num_steps 3360,  avg_loss: 27.9156, total_loss: 223.3251
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.28it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.97it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.13it/s]
[[032m2021-11-26 10:49:16,612[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:16,612[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:17,205[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 420:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 420:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.7]train epoch: 420:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.94it/s, loss=29.7]train epoch: 420:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.94it/s, loss=26.1]train epoch: 420:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.96it/s, loss=26.1]train epoch: 420:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.96it/s, loss=20.3]train epoch: 420:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.73it/s, loss=20.3]train epoch: 420:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.73it/s, loss=27.8]train epoch: 420:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=27.8]train epoch: 420:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=36.2]train epoch: 420:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.05it/s, loss=36.2]train epoch: 420:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.05it/s, loss=24.1]train epoch: 420:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=24.1]train epoch: 420:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=26.3]train epoch: 420:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.69it/s, loss=26.3]train epoch: 420:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=24]  train epoch: 420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.85it/s, loss=24]train epoch: 420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=24]
[[032m2021-11-26 10:49:19,558[0m INFO] trainer.training_epoch Training epoch 420, num_steps 3368,  avg_loss: 26.8057, total_loss: 214.4458
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.15it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.67it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.30it/s]
[[032m2021-11-26 10:49:20,320[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:20,321[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:20,580[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 421:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 421:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.1]train epoch: 421:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.77it/s, loss=29.1]train epoch: 421:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.77it/s, loss=24.3]train epoch: 421:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=24.3]train epoch: 421:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=26.5]train epoch: 421:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.04it/s, loss=26.5]train epoch: 421:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.04it/s, loss=25.2]train epoch: 421:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.19it/s, loss=25.2]train epoch: 421:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.19it/s, loss=30.3]train epoch: 421:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=30.3]train epoch: 421:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=27.8]train epoch: 421:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.67it/s, loss=27.8]train epoch: 421:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.67it/s, loss=30.9]train epoch: 421:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.84it/s, loss=30.9]train epoch: 421:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.84it/s, loss=25]  train epoch: 421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=25]train epoch: 421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=25]
[[032m2021-11-26 10:49:22,576[0m INFO] trainer.training_epoch Training epoch 421, num_steps 3376,  avg_loss: 27.3764, total_loss: 219.0114
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.99it/s]
[[032m2021-11-26 10:49:23,009[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:23,009[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:23,244[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 422:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 422:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.3]train epoch: 422:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=30.3]train epoch: 422:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=25.9]train epoch: 422:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=25.9]train epoch: 422:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=22.3]train epoch: 422:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.52it/s, loss=22.3]train epoch: 422:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.52it/s, loss=37.4]train epoch: 422:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.36it/s, loss=37.4]train epoch: 422:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.36it/s, loss=25.3]train epoch: 422:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=25.3]train epoch: 422:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=36.9]train epoch: 422:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.13it/s, loss=36.9]train epoch: 422:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.13it/s, loss=22.9]train epoch: 422:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.10it/s, loss=22.9]train epoch: 422:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.10it/s, loss=30.7]train epoch: 422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=30.7]train epoch: 422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s, loss=30.7]
[[032m2021-11-26 10:49:25,524[0m INFO] trainer.training_epoch Training epoch 422, num_steps 3384,  avg_loss: 28.9524, total_loss: 231.6190
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.89it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.79it/s]
[[032m2021-11-26 10:49:26,076[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:26,077[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:26,291[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 423:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 423:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.3]train epoch: 423:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=30.3]train epoch: 423:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=26.4]train epoch: 423:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.26it/s, loss=26.4]train epoch: 423:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.26it/s, loss=22.6]train epoch: 423:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.42it/s, loss=22.6]train epoch: 423:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.42it/s, loss=30.6]train epoch: 423:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.44it/s, loss=30.6]train epoch: 423:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.44it/s, loss=30.2]train epoch: 423:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.45it/s, loss=30.2]train epoch: 423:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.45it/s, loss=25.5]train epoch: 423:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.94it/s, loss=25.5]train epoch: 423:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.94it/s, loss=28.6]train epoch: 423:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.63it/s, loss=28.6]train epoch: 423:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.63it/s, loss=29.2]train epoch: 423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.56it/s, loss=29.2]train epoch: 423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.89it/s, loss=29.2]
[[032m2021-11-26 10:49:28,358[0m INFO] trainer.training_epoch Training epoch 423, num_steps 3392,  avg_loss: 27.9358, total_loss: 223.4864
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.44it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.72it/s]
[[032m2021-11-26 10:49:29,073[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:29,074[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:29,281[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 424:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 424:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.1]train epoch: 424:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=32.1]train epoch: 424:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=30.6]train epoch: 424:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.46it/s, loss=30.6]train epoch: 424:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.46it/s, loss=26.7]train epoch: 424:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s, loss=26.7]train epoch: 424:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s, loss=21.7]train epoch: 424:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.46it/s, loss=21.7]train epoch: 424:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.46it/s, loss=35.4]train epoch: 424:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=35.4]train epoch: 424:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=32.2]train epoch: 424:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.71it/s, loss=32.2]train epoch: 424:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=24.4]train epoch: 424:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=24.4]train epoch: 424:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=26.4]train epoch: 424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.08it/s, loss=26.4]train epoch: 424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.42it/s, loss=26.4]
[[032m2021-11-26 10:49:31,626[0m INFO] trainer.training_epoch Training epoch 424, num_steps 3400,  avg_loss: 28.6760, total_loss: 229.4079
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.19it/s]
[[032m2021-11-26 10:49:32,009[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:32,010[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:32,245[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 425:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.2477, 0.7523],
        [0.3806, 0.6194],
        [0.4383, 0.5617],
        [0.7454, 0.2546],
        [0.2828, 0.7172],
        [0.5560, 0.4440],
        [0.5418, 0.4582],
        [0.4587, 0.5413]], device='cuda:0')

prompt tensor([[0.4865, 0.5135],
        [0.3954, 0.6046],
        [0.6436, 0.3564],
        [0.8681, 0.1319],
        [0.6169, 0.3831],
        [0.6544, 0.3456],
        [0.5470, 0.4530],
        [0.6103, 0.3897]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 425:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.4]train epoch: 425:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=28.4]train epoch: 425:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.46it/s, loss=27.4]train epoch: 425:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=27.4]train epoch: 425:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=22.1]train epoch: 425:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=22.1]train epoch: 425:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=23.3]train epoch: 425:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.05it/s, loss=23.3]train epoch: 425:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=28.9]train epoch: 425:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=28.9]train epoch: 425:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=21.9]train epoch: 425:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=21.9]train epoch: 425:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=20.7]train epoch: 425:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.85it/s, loss=20.7]train epoch: 425:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.85it/s, loss=35.5]train epoch: 425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.86it/s, loss=35.5]train epoch: 425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.96it/s, loss=35.5]
[[032m2021-11-26 10:49:34,269[0m INFO] trainer.training_epoch Training epoch 425, num_steps 3408,  avg_loss: 26.0345, total_loss: 208.2757
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.14it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.57it/s]
[[032m2021-11-26 10:49:34,827[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:49:34,827[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:35,135[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 426:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 426:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.7]train epoch: 426:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=34.7]train epoch: 426:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.17it/s, loss=26.3]train epoch: 426:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.93it/s, loss=26.3]train epoch: 426:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.93it/s, loss=26]  train epoch: 426:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.43it/s, loss=26]train epoch: 426:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.43it/s, loss=31.1]train epoch: 426:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.75it/s, loss=31.1]train epoch: 426:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.75it/s, loss=23.3]train epoch: 426:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=23.3]train epoch: 426:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.98it/s, loss=36.8]train epoch: 426:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.22it/s, loss=36.8]train epoch: 426:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.22it/s, loss=31.6]train epoch: 426:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.19it/s, loss=31.6]train epoch: 426:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.19it/s, loss=32.1]train epoch: 426: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.73it/s, loss=32.1]train epoch: 426: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.66it/s, loss=32.1]
[[032m2021-11-26 10:49:37,335[0m INFO] trainer.training_epoch Training epoch 426, num_steps 3416,  avg_loss: 30.2215, total_loss: 241.7723
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.46it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.01it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.14it/s]
[[032m2021-11-26 10:49:37,881[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:49:37,881[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:38,379[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 427:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 427:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.5]train epoch: 427:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.50it/s, loss=24.5]train epoch: 427:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.50it/s, loss=21.7]train epoch: 427:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=21.7]train epoch: 427:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=23.2]train epoch: 427:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=23.2]train epoch: 427:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.21it/s, loss=31.6]train epoch: 427:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=31.6]train epoch: 427:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s, loss=26.2]train epoch: 427:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=26.2]train epoch: 427:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.94it/s, loss=29]  train epoch: 427:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=29]train epoch: 427:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.00it/s, loss=33.1]train epoch: 427:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.38it/s, loss=33.1]train epoch: 427:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=34.2]train epoch: 427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.58it/s, loss=34.2]train epoch: 427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.73it/s, loss=34.2]
[[032m2021-11-26 10:49:40,532[0m INFO] trainer.training_epoch Training epoch 427, num_steps 3424,  avg_loss: 27.9382, total_loss: 223.5059
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.50it/s]
[[032m2021-11-26 10:49:41,181[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:49:41,181[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:41,553[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 428:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 428:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.4]train epoch: 428:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.86it/s, loss=28.4]train epoch: 428:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.86it/s, loss=23.2]train epoch: 428:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=23.2]train epoch: 428:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=27.5]train epoch: 428:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=27.5]train epoch: 428:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=29.4]train epoch: 428:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.25it/s, loss=29.4]train epoch: 428:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.25it/s, loss=19.6]train epoch: 428:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=19.6]train epoch: 428:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=24]  train epoch: 428:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.27it/s, loss=24]train epoch: 428:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.27it/s, loss=33.6]train epoch: 428:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.30it/s, loss=33.6]train epoch: 428:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.30it/s, loss=32.1]train epoch: 428: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.28it/s, loss=32.1]train epoch: 428: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.23it/s, loss=32.1]
[[032m2021-11-26 10:49:43,451[0m INFO] trainer.training_epoch Training epoch 428, num_steps 3432,  avg_loss: 27.2285, total_loss: 217.8278
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.19it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.54it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.74it/s]
[[032m2021-11-26 10:49:44,145[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.484375)])
[[032m2021-11-26 10:49:44,145[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:44,499[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 429:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 429:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.8]train epoch: 429:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.64it/s, loss=20.8]train epoch: 429:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.64it/s, loss=22.4]train epoch: 429:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.46it/s, loss=22.4]train epoch: 429:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.46it/s, loss=31.5]train epoch: 429:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.89it/s, loss=31.5]train epoch: 429:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.89it/s, loss=31.9]train epoch: 429:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.85it/s, loss=31.9]train epoch: 429:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.85it/s, loss=24]  train epoch: 429:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=24]train epoch: 429:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=34.1]train epoch: 429:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.94it/s, loss=34.1]train epoch: 429:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.94it/s, loss=26.9]train epoch: 429:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.18it/s, loss=26.9]train epoch: 429:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.18it/s, loss=24.4]train epoch: 429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.24it/s, loss=24.4]train epoch: 429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s, loss=24.4]
[[032m2021-11-26 10:49:46,544[0m INFO] trainer.training_epoch Training epoch 429, num_steps 3440,  avg_loss: 26.9930, total_loss: 215.9443
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.59it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.33it/s]
[[032m2021-11-26 10:49:47,331[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:49:47,331[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:47,690[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 430:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 430:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 430:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.89it/s, loss=27.9]train epoch: 430:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.89it/s, loss=41.2]train epoch: 430:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.17it/s, loss=41.2]train epoch: 430:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.17it/s, loss=25.1]train epoch: 430:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.47it/s, loss=25.1]train epoch: 430:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.47it/s, loss=29.5]train epoch: 430:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.65it/s, loss=29.5]train epoch: 430:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.65it/s, loss=24]  train epoch: 430:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.84it/s, loss=24]train epoch: 430:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.84it/s, loss=30.9]train epoch: 430:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.09it/s, loss=30.9]train epoch: 430:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.09it/s, loss=32]  train epoch: 430:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.20it/s, loss=32]train epoch: 430:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.20it/s, loss=31.6]train epoch: 430: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=31.6]train epoch: 430: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=31.6]
[[032m2021-11-26 10:49:49,934[0m INFO] trainer.training_epoch Training epoch 430, num_steps 3448,  avg_loss: 30.2945, total_loss: 242.3557
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.34it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.80it/s]
[[032m2021-11-26 10:49:50,497[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:49:50,497[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:50,899[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 431:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 431:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.7]train epoch: 431:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=26.7]train epoch: 431:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.61it/s, loss=24.4]train epoch: 431:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=24.4]train epoch: 431:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.55it/s, loss=25.6]train epoch: 431:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s, loss=25.6]train epoch: 431:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s, loss=23.1]train epoch: 431:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.45it/s, loss=23.1]train epoch: 431:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.45it/s, loss=24.1]train epoch: 431:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=24.1]train epoch: 431:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.29it/s, loss=39.2]train epoch: 431:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.41it/s, loss=39.2]train epoch: 431:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.41it/s, loss=29.9]train epoch: 431:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=29.9]train epoch: 431:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=28.7]train epoch: 431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.59it/s, loss=28.7]train epoch: 431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=28.7]
[[032m2021-11-26 10:49:52,896[0m INFO] trainer.training_epoch Training epoch 431, num_steps 3456,  avg_loss: 27.7127, total_loss: 221.7019
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.40it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.25it/s]
[[032m2021-11-26 10:49:53,386[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:49:53,388[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:53,820[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:49:53,997[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 432:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 432:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.6]train epoch: 432:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=29.6]train epoch: 432:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=21.4]train epoch: 432:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=21.4]train epoch: 432:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=26.3]train epoch: 432:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=26.3]train epoch: 432:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=18.8]train epoch: 432:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.17it/s, loss=18.8]train epoch: 432:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.17it/s, loss=20.4]train epoch: 432:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=20.4]train epoch: 432:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.18it/s, loss=27.9]train epoch: 432:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.28it/s, loss=27.9]train epoch: 432:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.28it/s, loss=19.7]train epoch: 432:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.51it/s, loss=19.7]train epoch: 432:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=27.5]train epoch: 432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s, loss=27.5]train epoch: 432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=27.5]
[[032m2021-11-26 10:49:56,224[0m INFO] trainer.training_epoch Training epoch 432, num_steps 3464,  avg_loss: 23.9447, total_loss: 191.5580
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.65it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.69it/s]
[[032m2021-11-26 10:49:57,019[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:49:57,019[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:49:57,289[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 433:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 433:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.2]train epoch: 433:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.94it/s, loss=25.2]train epoch: 433:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.94it/s, loss=34.4]train epoch: 433:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.24it/s, loss=34.4]train epoch: 433:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.24it/s, loss=26.9]train epoch: 433:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=26.9]train epoch: 433:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=30.1]train epoch: 433:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s, loss=30.1]train epoch: 433:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s, loss=23.3]train epoch: 433:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=23.3]train epoch: 433:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=30.4]train epoch: 433:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.14it/s, loss=30.4]train epoch: 433:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.14it/s, loss=25.4]train epoch: 433:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.81it/s, loss=25.4]train epoch: 433:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.81it/s, loss=31.5]train epoch: 433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s, loss=31.5]train epoch: 433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.54it/s, loss=31.5]
[[032m2021-11-26 10:49:59,552[0m INFO] trainer.training_epoch Training epoch 433, num_steps 3472,  avg_loss: 28.3863, total_loss: 227.0905
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.55it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.82it/s]
[[032m2021-11-26 10:50:00,051[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:00,054[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:00,577[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 434:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 434:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.6]train epoch: 434:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.99it/s, loss=33.6]train epoch: 434:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.99it/s, loss=23.4]train epoch: 434:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=23.4]train epoch: 434:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=30]  train epoch: 434:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.70it/s, loss=30]train epoch: 434:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.70it/s, loss=23.8]train epoch: 434:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.02it/s, loss=23.8]train epoch: 434:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.02it/s, loss=36.2]train epoch: 434:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=36.2]train epoch: 434:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=18.3]train epoch: 434:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=18.3]train epoch: 434:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=27.7]train epoch: 434:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.21it/s, loss=27.7]train epoch: 434:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=19.5]train epoch: 434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s, loss=19.5]train epoch: 434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.56it/s, loss=19.5]
[[032m2021-11-26 10:50:02,832[0m INFO] trainer.training_epoch Training epoch 434, num_steps 3480,  avg_loss: 26.5662, total_loss: 212.5297
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.79it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.42it/s]
[[032m2021-11-26 10:50:03,497[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:50:03,497[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:03,789[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 435:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 435:   0%|          | 0/8 [00:00<?, ?it/s, loss=44.1]train epoch: 435:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=44.1]train epoch: 435:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=24.2]train epoch: 435:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=24.2]train epoch: 435:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=31.9]train epoch: 435:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.52it/s, loss=31.9]train epoch: 435:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.52it/s, loss=36.3]train epoch: 435:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.24it/s, loss=36.3]train epoch: 435:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.24it/s, loss=23]  train epoch: 435:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=23]train epoch: 435:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.36it/s, loss=29.1]train epoch: 435:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.02it/s, loss=29.1]train epoch: 435:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.02it/s, loss=29.2]train epoch: 435:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.70it/s, loss=29.2]train epoch: 435:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.70it/s, loss=23.1]train epoch: 435: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s, loss=23.1]train epoch: 435: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s, loss=23.1]
[[032m2021-11-26 10:50:06,303[0m INFO] trainer.training_epoch Training epoch 435, num_steps 3488,  avg_loss: 30.0909, total_loss: 240.7272
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.05it/s]
[[032m2021-11-26 10:50:06,800[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:50:06,801[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:07,025[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 436:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 436:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.5]train epoch: 436:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=32.5]train epoch: 436:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=25.6]train epoch: 436:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.58it/s, loss=25.6]train epoch: 436:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.58it/s, loss=23.7]train epoch: 436:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.19it/s, loss=23.7]train epoch: 436:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.19it/s, loss=23.9]train epoch: 436:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.31it/s, loss=23.9]train epoch: 436:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.31it/s, loss=29.8]train epoch: 436:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.39it/s, loss=29.8]train epoch: 436:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.39it/s, loss=34.3]train epoch: 436:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.61it/s, loss=34.3]train epoch: 436:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.61it/s, loss=22.4]train epoch: 436:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.39it/s, loss=22.4]train epoch: 436:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.39it/s, loss=24.5]train epoch: 436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.48it/s, loss=24.5]train epoch: 436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.76it/s, loss=24.5]
[[032m2021-11-26 10:50:09,927[0m INFO] trainer.training_epoch Training epoch 436, num_steps 3496,  avg_loss: 27.0858, total_loss: 216.6862
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.95it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.96it/s]
[[032m2021-11-26 10:50:10,438[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:10,438[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:10,709[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 437:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 437:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.6]train epoch: 437:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.90it/s, loss=30.6]train epoch: 437:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.90it/s, loss=28.2]train epoch: 437:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.25it/s, loss=28.2]train epoch: 437:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.25it/s, loss=45.4]train epoch: 437:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.17it/s, loss=45.4]train epoch: 437:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.17it/s, loss=32.7]train epoch: 437:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.26it/s, loss=32.7]
model tensor([[0.3295, 0.6705],
        [0.3498, 0.6502],
        [0.5964, 0.4036],
        [0.3206, 0.6794],
        [0.2873, 0.7127],
        [0.5560, 0.4440],
        [0.5557, 0.4443],
        [0.3053, 0.6947]], device='cuda:0')

prompt tensor([[0.4261, 0.5739],
        [0.5913, 0.4087],
        [0.4657, 0.5343],
        [0.5187, 0.4813],
        [0.3894, 0.6106],
        [0.7254, 0.2746],
        [0.6249, 0.3751],
        [0.5375, 0.4625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 437:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.26it/s, loss=30.4]train epoch: 437:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.83it/s, loss=30.4]train epoch: 437:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.83it/s, loss=24.7]train epoch: 437:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.65it/s, loss=24.7]train epoch: 437:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.65it/s, loss=33.2]train epoch: 437:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=33.2]train epoch: 437:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=23.2]train epoch: 437: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.57it/s, loss=23.2]train epoch: 437: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=23.2]
[[032m2021-11-26 10:50:13,449[0m INFO] trainer.training_epoch Training epoch 437, num_steps 3504,  avg_loss: 31.0346, total_loss: 248.2772
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.03it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.44it/s]
[[032m2021-11-26 10:50:14,065[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:50:14,065[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:14,309[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 438:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 438:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.3]train epoch: 438:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=25.3]train epoch: 438:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.05it/s, loss=29.1]train epoch: 438:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=29.1]train epoch: 438:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.70it/s, loss=19.5]train epoch: 438:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.14it/s, loss=19.5]train epoch: 438:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.14it/s, loss=29.2]train epoch: 438:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.09it/s, loss=29.2]train epoch: 438:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.09it/s, loss=31.5]train epoch: 438:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=31.5]train epoch: 438:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=23.1]train epoch: 438:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.63it/s, loss=23.1]train epoch: 438:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.63it/s, loss=22.6]train epoch: 438:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.97it/s, loss=22.6]train epoch: 438:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.97it/s, loss=27.6]train epoch: 438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.62it/s, loss=27.6]train epoch: 438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=27.6]
[[032m2021-11-26 10:50:16,796[0m INFO] trainer.training_epoch Training epoch 438, num_steps 3512,  avg_loss: 25.9911, total_loss: 207.9285
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.30it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.17it/s]
[[032m2021-11-26 10:50:17,357[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:50:17,357[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:17,588[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 439:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 439:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.3]train epoch: 439:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.96it/s, loss=24.3]train epoch: 439:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.96it/s, loss=25.2]train epoch: 439:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=25.2]train epoch: 439:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.65it/s, loss=20.2]train epoch: 439:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.60it/s, loss=20.2]train epoch: 439:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.60it/s, loss=28]  train epoch: 439:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=28]train epoch: 439:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=30.5]train epoch: 439:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.80it/s, loss=30.5]train epoch: 439:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.80it/s, loss=25.8]train epoch: 439:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.69it/s, loss=25.8]train epoch: 439:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.69it/s, loss=31.3]train epoch: 439:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.85it/s, loss=31.3]train epoch: 439:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.85it/s, loss=25]  train epoch: 439: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s, loss=25]train epoch: 439: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=25]
[[032m2021-11-26 10:50:20,085[0m INFO] trainer.training_epoch Training epoch 439, num_steps 3520,  avg_loss: 26.2786, total_loss: 210.2285
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.19it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.12it/s]
[[032m2021-11-26 10:50:20,568[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:50:20,569[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:20,814[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 440:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 440:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 440:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=23.6]train epoch: 440:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=21.4]train epoch: 440:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.03it/s, loss=21.4]train epoch: 440:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.03it/s, loss=30.3]train epoch: 440:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.31it/s, loss=30.3]train epoch: 440:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.31it/s, loss=30.4]train epoch: 440:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.39it/s, loss=30.4]train epoch: 440:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.39it/s, loss=23.4]train epoch: 440:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=23.4]train epoch: 440:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=20.3]train epoch: 440:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.08it/s, loss=20.3]train epoch: 440:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.08it/s, loss=23.4]train epoch: 440:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=23.4]train epoch: 440:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=23.7]train epoch: 440: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s, loss=23.7]train epoch: 440: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=23.7]
[[032m2021-11-26 10:50:23,255[0m INFO] trainer.training_epoch Training epoch 440, num_steps 3528,  avg_loss: 24.5876, total_loss: 196.7010
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]
[[032m2021-11-26 10:50:23,639[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:50:23,639[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:23,851[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 441:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 441:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.6]train epoch: 441:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=30.6]train epoch: 441:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=30.9]train epoch: 441:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.28it/s, loss=30.9]train epoch: 441:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.28it/s, loss=26.2]train epoch: 441:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.37it/s, loss=26.2]train epoch: 441:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.37it/s, loss=22.9]train epoch: 441:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.37it/s, loss=22.9]train epoch: 441:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.37it/s, loss=22.3]train epoch: 441:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=22.3]train epoch: 441:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=24.2]train epoch: 441:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=24.2]train epoch: 441:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.16it/s, loss=26.6]train epoch: 441:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=26.6]train epoch: 441:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=25.5]train epoch: 441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=25.5]train epoch: 441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=25.5]
[[032m2021-11-26 10:50:26,212[0m INFO] trainer.training_epoch Training epoch 441, num_steps 3536,  avg_loss: 26.1418, total_loss: 209.1348
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.83it/s]
[[032m2021-11-26 10:50:26,617[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:50:26,617[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:26,836[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 442:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 442:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.2]train epoch: 442:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.10it/s, loss=28.2]train epoch: 442:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.10it/s, loss=29.5]train epoch: 442:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.48it/s, loss=29.5]train epoch: 442:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.48it/s, loss=28.2]train epoch: 442:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=28.2]train epoch: 442:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=31.5]train epoch: 442:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=31.5]train epoch: 442:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=25.1]train epoch: 442:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=25.1]train epoch: 442:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=29.6]train epoch: 442:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s, loss=29.6]train epoch: 442:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.37it/s, loss=26.9]train epoch: 442:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=26.9]train epoch: 442:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=24.9]train epoch: 442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=24.9]train epoch: 442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=24.9]
[[032m2021-11-26 10:50:29,324[0m INFO] trainer.training_epoch Training epoch 442, num_steps 3544,  avg_loss: 27.9807, total_loss: 223.8458
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.39it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.13it/s]
[[032m2021-11-26 10:50:29,780[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:29,780[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:30,004[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 443:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 443:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.1]train epoch: 443:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.16it/s, loss=21.1]train epoch: 443:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.16it/s, loss=30]  train epoch: 443:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=30]train epoch: 443:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=26.5]train epoch: 443:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.78it/s, loss=26.5]train epoch: 443:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.78it/s, loss=34.3]train epoch: 443:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.60it/s, loss=34.3]train epoch: 443:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.60it/s, loss=32.8]train epoch: 443:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.12it/s, loss=32.8]train epoch: 443:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.12it/s, loss=32.9]train epoch: 443:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.07it/s, loss=32.9]train epoch: 443:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.07it/s, loss=29.5]train epoch: 443:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=29.5]train epoch: 443:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=33.5]train epoch: 443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=33.5]train epoch: 443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=33.5]
[[032m2021-11-26 10:50:32,382[0m INFO] trainer.training_epoch Training epoch 443, num_steps 3552,  avg_loss: 30.0699, total_loss: 240.5592
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.87it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.93it/s]
[[032m2021-11-26 10:50:32,799[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:50:32,799[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:33,011[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 444:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 444:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.1]train epoch: 444:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=37.1]train epoch: 444:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=27.5]train epoch: 444:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=27.5]train epoch: 444:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.79it/s, loss=18.7]train epoch: 444:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.74it/s, loss=18.7]train epoch: 444:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.74it/s, loss=28.1]train epoch: 444:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=28.1]train epoch: 444:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=29.4]train epoch: 444:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.65it/s, loss=29.4]train epoch: 444:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.65it/s, loss=27.2]train epoch: 444:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.90it/s, loss=27.2]train epoch: 444:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.90it/s, loss=29.8]train epoch: 444:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=29.8]train epoch: 444:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=28.7]train epoch: 444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=28.7]train epoch: 444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=28.7]
[[032m2021-11-26 10:50:35,511[0m INFO] trainer.training_epoch Training epoch 444, num_steps 3560,  avg_loss: 28.3143, total_loss: 226.5141
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.77it/s]
[[032m2021-11-26 10:50:35,877[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5)])
[[032m2021-11-26 10:50:35,877[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:36,091[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 445:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 445:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.7]train epoch: 445:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.38it/s, loss=29.7]train epoch: 445:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.38it/s, loss=24.2]train epoch: 445:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.07it/s, loss=24.2]train epoch: 445:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.07it/s, loss=33.5]train epoch: 445:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.68it/s, loss=33.5]train epoch: 445:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.68it/s, loss=20.2]train epoch: 445:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.97it/s, loss=20.2]train epoch: 445:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.97it/s, loss=23.4]train epoch: 445:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.02it/s, loss=23.4]train epoch: 445:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.02it/s, loss=27.3]train epoch: 445:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.94it/s, loss=27.3]train epoch: 445:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.94it/s, loss=24.2]train epoch: 445:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=24.2]train epoch: 445:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=29]  train epoch: 445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=29]train epoch: 445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=29]
[[032m2021-11-26 10:50:38,675[0m INFO] trainer.training_epoch Training epoch 445, num_steps 3568,  avg_loss: 26.4528, total_loss: 211.6226
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.18it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.63it/s]
[[032m2021-11-26 10:50:39,141[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:39,142[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:39,385[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 446:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 446:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.5]train epoch: 446:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.91it/s, loss=32.5]train epoch: 446:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.91it/s, loss=25.8]train epoch: 446:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.66it/s, loss=25.8]train epoch: 446:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.66it/s, loss=22]  train epoch: 446:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.73it/s, loss=22]train epoch: 446:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.73it/s, loss=30.3]train epoch: 446:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=30.3]train epoch: 446:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=29.8]train epoch: 446:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.70it/s, loss=29.8]train epoch: 446:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.70it/s, loss=34.2]train epoch: 446:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.85it/s, loss=34.2]train epoch: 446:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=22.5]train epoch: 446:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=22.5]train epoch: 446:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=23.5]train epoch: 446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=23.5]train epoch: 446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=23.5]
[[032m2021-11-26 10:50:41,878[0m INFO] trainer.training_epoch Training epoch 446, num_steps 3576,  avg_loss: 27.5797, total_loss: 220.6377
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.17it/s]
[[032m2021-11-26 10:50:42,354[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:42,354[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:42,591[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 447:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 447:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.8]train epoch: 447:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.32it/s, loss=32.8]train epoch: 447:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.32it/s, loss=19.2]train epoch: 447:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.26it/s, loss=19.2]train epoch: 447:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.26it/s, loss=24.7]train epoch: 447:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.62it/s, loss=24.7]train epoch: 447:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.62it/s, loss=26.9]train epoch: 447:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=26.9]train epoch: 447:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=22.8]train epoch: 447:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.76it/s, loss=22.8]train epoch: 447:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.76it/s, loss=30.5]train epoch: 447:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.07it/s, loss=30.5]train epoch: 447:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.07it/s, loss=41.1]train epoch: 447:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.41it/s, loss=41.1]train epoch: 447:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.41it/s, loss=27.7]train epoch: 447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.58it/s, loss=27.7]train epoch: 447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=27.7]
[[032m2021-11-26 10:50:45,011[0m INFO] trainer.training_epoch Training epoch 447, num_steps 3584,  avg_loss: 28.2070, total_loss: 225.6562
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.07it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.75it/s]
[[032m2021-11-26 10:50:45,510[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:50:45,510[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:45,758[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 448:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 448:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 448:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.02it/s, loss=29.8]train epoch: 448:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.02it/s, loss=23.4]train epoch: 448:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=23.4]train epoch: 448:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=22.4]train epoch: 448:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.54it/s, loss=22.4]train epoch: 448:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.54it/s, loss=24.5]train epoch: 448:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=24.5]train epoch: 448:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=30.1]train epoch: 448:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.03it/s, loss=30.1]train epoch: 448:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.03it/s, loss=25.4]train epoch: 448:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.21it/s, loss=25.4]train epoch: 448:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.21it/s, loss=28.9]train epoch: 448:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.33it/s, loss=28.9]train epoch: 448:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.33it/s, loss=25.6]train epoch: 448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=25.6]train epoch: 448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=25.6]
[[032m2021-11-26 10:50:48,194[0m INFO] trainer.training_epoch Training epoch 448, num_steps 3592,  avg_loss: 26.2558, total_loss: 210.0462
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.39it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.27it/s]
[[032m2021-11-26 10:50:48,817[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:50:48,817[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:49,422[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 449:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 449:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.4]train epoch: 449:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.10it/s, loss=27.4]train epoch: 449:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.10it/s, loss=22.7]train epoch: 449:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.23it/s, loss=22.7]train epoch: 449:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.23it/s, loss=20.7]train epoch: 449:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.77it/s, loss=20.7]train epoch: 449:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.77it/s, loss=28.1]train epoch: 449:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s, loss=28.1]train epoch: 449:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s, loss=27.1]train epoch: 449:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=27.1]train epoch: 449:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=27.4]train epoch: 449:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=27.4]train epoch: 449:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=30.6]train epoch: 449:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.42it/s, loss=30.6]train epoch: 449:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.42it/s, loss=31.2]train epoch: 449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s, loss=31.2]train epoch: 449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=31.2]
[[032m2021-11-26 10:50:51,680[0m INFO] trainer.training_epoch Training epoch 449, num_steps 3600,  avg_loss: 26.8989, total_loss: 215.1911
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.82it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.27it/s]
[[032m2021-11-26 10:50:52,183[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:52,183[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:52,538[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 450:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.2873, 0.7127],
        [0.4305, 0.5695],
        [0.7645, 0.2355],
        [0.4716, 0.5284],
        [0.3953, 0.6047],
        [0.5439, 0.4561],
        [0.3248, 0.6752],
        [0.3391, 0.6609]], device='cuda:0')

prompt tensor([[0.2858, 0.7142],
        [0.6308, 0.3692],
        [0.6530, 0.3470],
        [0.4976, 0.5024],
        [0.7322, 0.2678],
        [0.5645, 0.4355],
        [0.4726, 0.5274],
        [0.5991, 0.4009]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 450:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.1]train epoch: 450:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.95it/s, loss=25.1]train epoch: 450:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.95it/s, loss=23.3]train epoch: 450:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=23.3]train epoch: 450:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.84it/s, loss=28.2]train epoch: 450:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.27it/s, loss=28.2]train epoch: 450:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.27it/s, loss=27.1]train epoch: 450:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.48it/s, loss=27.1]train epoch: 450:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.48it/s, loss=32.8]train epoch: 450:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.29it/s, loss=32.8]train epoch: 450:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.29it/s, loss=28.7]train epoch: 450:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=28.7]train epoch: 450:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=24.3]train epoch: 450:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.67it/s, loss=24.3]train epoch: 450:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.67it/s, loss=22.9]train epoch: 450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.56it/s, loss=22.9]train epoch: 450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.81it/s, loss=22.9]
[[032m2021-11-26 10:50:55,389[0m INFO] trainer.training_epoch Training epoch 450, num_steps 3608,  avg_loss: 26.5534, total_loss: 212.4268
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.43it/s]
[[032m2021-11-26 10:50:55,884[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:55,884[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:50:56,564[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 451:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 451:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.3]train epoch: 451:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=21.3]train epoch: 451:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.87it/s, loss=28.7]train epoch: 451:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.46it/s, loss=28.7]train epoch: 451:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.46it/s, loss=21.7]train epoch: 451:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.88it/s, loss=21.7]train epoch: 451:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.88it/s, loss=24.3]train epoch: 451:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=24.3]train epoch: 451:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=23]  train epoch: 451:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=23]train epoch: 451:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=26.6]train epoch: 451:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=26.6]train epoch: 451:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=23.7]train epoch: 451:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=23.7]train epoch: 451:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=20.6]train epoch: 451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.87it/s, loss=20.6]train epoch: 451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=20.6]
[[032m2021-11-26 10:50:59,426[0m INFO] trainer.training_epoch Training epoch 451, num_steps 3616,  avg_loss: 23.7253, total_loss: 189.8020
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.24it/s]
[[032m2021-11-26 10:50:59,902[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:50:59,902[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:00,618[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 452:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 452:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.5]train epoch: 452:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.11it/s, loss=21.5]train epoch: 452:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.11it/s, loss=26.8]train epoch: 452:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:03,  2.00it/s, loss=26.8]train epoch: 452:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  2.00it/s, loss=34.3]train epoch: 452:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=34.3]train epoch: 452:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=29.2]train epoch: 452:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.63it/s, loss=29.2]train epoch: 452:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.63it/s, loss=25.1]train epoch: 452:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=25.1]train epoch: 452:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=23.1]train epoch: 452:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.43it/s, loss=23.1]train epoch: 452:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.43it/s, loss=24.6]train epoch: 452:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.61it/s, loss=24.6]train epoch: 452:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.61it/s, loss=21.6]train epoch: 452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.97it/s, loss=21.6]train epoch: 452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s, loss=21.6]
[[032m2021-11-26 10:51:03,693[0m INFO] trainer.training_epoch Training epoch 452, num_steps 3624,  avg_loss: 25.7915, total_loss: 206.3318
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.61it/s]
[[032m2021-11-26 10:51:04,256[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:51:04,257[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:04,888[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 453:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 453:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.1]train epoch: 453:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.01it/s, loss=22.1]train epoch: 453:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.01it/s, loss=31]  train epoch: 453:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.71it/s, loss=31]train epoch: 453:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.71it/s, loss=34.8]train epoch: 453:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.93it/s, loss=34.8]train epoch: 453:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.93it/s, loss=23.2]train epoch: 453:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=23.2]train epoch: 453:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=27.8]train epoch: 453:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.30it/s, loss=27.8]train epoch: 453:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.30it/s, loss=33.3]train epoch: 453:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.20it/s, loss=33.3]train epoch: 453:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.20it/s, loss=25.1]train epoch: 453:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.04it/s, loss=25.1]train epoch: 453:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.04it/s, loss=23.1]train epoch: 453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.64it/s, loss=23.1]train epoch: 453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.83it/s, loss=23.1]
[[032m2021-11-26 10:51:07,744[0m INFO] trainer.training_epoch Training epoch 453, num_steps 3632,  avg_loss: 27.5525, total_loss: 220.4201
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.88it/s]
[[032m2021-11-26 10:51:08,239[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:51:08,240[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:08,853[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 454:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 454:   0%|          | 0/8 [00:00<?, ?it/s, loss=27]train epoch: 454:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.59it/s, loss=27]train epoch: 454:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.59it/s, loss=26.6]train epoch: 454:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.96it/s, loss=26.6]train epoch: 454:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.96it/s, loss=30.3]train epoch: 454:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.56it/s, loss=30.3]train epoch: 454:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.56it/s, loss=21.5]train epoch: 454:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.15it/s, loss=21.5]train epoch: 454:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.15it/s, loss=35.3]train epoch: 454:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=35.3]train epoch: 454:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.24it/s, loss=27.6]train epoch: 454:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.31it/s, loss=27.6]train epoch: 454:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.31it/s, loss=27.7]train epoch: 454:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=27.7]train epoch: 454:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=24.6]train epoch: 454: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s, loss=24.6]train epoch: 454: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s, loss=24.6]
[[032m2021-11-26 10:51:11,663[0m INFO] trainer.training_epoch Training epoch 454, num_steps 3640,  avg_loss: 27.5900, total_loss: 220.7202
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.51it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.43it/s]
[[032m2021-11-26 10:51:12,159[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:12,159[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:12,394[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:12,686[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 455:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 455:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.4]train epoch: 455:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.42it/s, loss=26.4]train epoch: 455:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.42it/s, loss=30.6]train epoch: 455:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.17it/s, loss=30.6]train epoch: 455:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.17it/s, loss=34.1]train epoch: 455:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.31it/s, loss=34.1]train epoch: 455:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.31it/s, loss=22.8]train epoch: 455:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=22.8]train epoch: 455:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=24.7]train epoch: 455:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.88it/s, loss=24.7]train epoch: 455:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.88it/s, loss=32.7]train epoch: 455:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=32.7]train epoch: 455:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.42it/s, loss=23.7]train epoch: 455:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.21it/s, loss=23.7]train epoch: 455:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.21it/s, loss=22.6]train epoch: 455: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s, loss=22.6]train epoch: 455: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=22.6]
[[032m2021-11-26 10:51:15,913[0m INFO] trainer.training_epoch Training epoch 455, num_steps 3648,  avg_loss: 27.1962, total_loss: 217.5695
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.08it/s]
[[032m2021-11-26 10:51:16,348[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:51:16,349[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:16,565[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 456:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 456:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.8]train epoch: 456:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=34.8]train epoch: 456:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.19it/s, loss=30.2]train epoch: 456:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=30.2]train epoch: 456:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.89it/s, loss=30.7]train epoch: 456:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.42it/s, loss=30.7]train epoch: 456:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.42it/s, loss=26.8]train epoch: 456:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=26.8]train epoch: 456:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=25.4]train epoch: 456:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=25.4]train epoch: 456:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.27it/s, loss=30.7]train epoch: 456:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.24it/s, loss=30.7]train epoch: 456:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.24it/s, loss=25.3]train epoch: 456:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=25.3]train epoch: 456:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=33.9]train epoch: 456: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=33.9]train epoch: 456: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=33.9]
[[032m2021-11-26 10:51:19,116[0m INFO] trainer.training_epoch Training epoch 456, num_steps 3656,  avg_loss: 29.7218, total_loss: 237.7746
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.33it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.26it/s]
[[032m2021-11-26 10:51:19,812[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:19,813[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:20,090[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:20,198[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 457:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 457:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.7]train epoch: 457:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.23it/s, loss=24.7]train epoch: 457:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.23it/s, loss=24.8]train epoch: 457:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.06it/s, loss=24.8]train epoch: 457:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.06it/s, loss=29.2]train epoch: 457:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.50it/s, loss=29.2]train epoch: 457:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.50it/s, loss=37.2]train epoch: 457:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=37.2]train epoch: 457:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.42it/s, loss=31.6]train epoch: 457:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.73it/s, loss=31.6]train epoch: 457:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.73it/s, loss=19.9]train epoch: 457:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.94it/s, loss=19.9]train epoch: 457:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.94it/s, loss=27.8]train epoch: 457:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.76it/s, loss=27.8]train epoch: 457:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.76it/s, loss=23.2]train epoch: 457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=23.2]train epoch: 457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.56it/s, loss=23.2]
[[032m2021-11-26 10:51:23,325[0m INFO] trainer.training_epoch Training epoch 457, num_steps 3664,  avg_loss: 27.2838, total_loss: 218.2701
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.79it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.22it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.94it/s]
[[032m2021-11-26 10:51:23,955[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:23,956[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:24,170[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:24,289[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 458:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 458:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.2]train epoch: 458:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.16it/s, loss=24.2]train epoch: 458:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.16it/s, loss=22.8]train epoch: 458:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.54it/s, loss=22.8]train epoch: 458:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.54it/s, loss=21.6]train epoch: 458:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.26it/s, loss=21.6]train epoch: 458:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.26it/s, loss=30.7]train epoch: 458:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.53it/s, loss=30.7]train epoch: 458:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.53it/s, loss=27.6]train epoch: 458:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=27.6]train epoch: 458:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.33it/s, loss=27.9]train epoch: 458:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.53it/s, loss=27.9]train epoch: 458:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.53it/s, loss=27.4]train epoch: 458:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.54it/s, loss=27.4]train epoch: 458:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.54it/s, loss=30.8]train epoch: 458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s, loss=30.8]train epoch: 458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s, loss=30.8]
[[032m2021-11-26 10:51:27,413[0m INFO] trainer.training_epoch Training epoch 458, num_steps 3672,  avg_loss: 26.6033, total_loss: 212.8263
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.36it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.05it/s]
[[032m2021-11-26 10:51:27,909[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:51:27,909[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:28,387[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 459:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 459:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 459:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=25.5]train epoch: 459:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.14it/s, loss=24.5]train epoch: 459:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.62it/s, loss=24.5]train epoch: 459:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.62it/s, loss=29.6]train epoch: 459:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.11it/s, loss=29.6]train epoch: 459:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.11it/s, loss=39.1]train epoch: 459:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.52it/s, loss=39.1]train epoch: 459:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.52it/s, loss=24.1]train epoch: 459:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.79it/s, loss=24.1]train epoch: 459:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.79it/s, loss=30]  train epoch: 459:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.47it/s, loss=30]train epoch: 459:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.47it/s, loss=17.7]train epoch: 459:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=17.7]train epoch: 459:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=22.3]train epoch: 459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.92it/s, loss=22.3]train epoch: 459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=22.3]
[[032m2021-11-26 10:51:30,859[0m INFO] trainer.training_epoch Training epoch 459, num_steps 3680,  avg_loss: 26.5969, total_loss: 212.7750
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.35it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]
[[032m2021-11-26 10:51:31,299[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:51:31,300[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:31,542[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 460:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 460:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.1]train epoch: 460:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.05it/s, loss=29.1]train epoch: 460:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.05it/s, loss=31.4]train epoch: 460:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.68it/s, loss=31.4]train epoch: 460:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.68it/s, loss=19.9]train epoch: 460:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.65it/s, loss=19.9]train epoch: 460:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.65it/s, loss=28]  train epoch: 460:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=28]train epoch: 460:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=27.5]train epoch: 460:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.96it/s, loss=27.5]train epoch: 460:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.96it/s, loss=23.9]train epoch: 460:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.12it/s, loss=23.9]train epoch: 460:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.12it/s, loss=26.5]train epoch: 460:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.43it/s, loss=26.5]train epoch: 460:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.43it/s, loss=19.3]train epoch: 460: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=19.3]train epoch: 460: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.20it/s, loss=19.3]
[[032m2021-11-26 10:51:34,051[0m INFO] trainer.training_epoch Training epoch 460, num_steps 3688,  avg_loss: 25.7020, total_loss: 205.6163
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.30it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.19it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.84it/s]
[[032m2021-11-26 10:51:34,635[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:34,635[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:35,017[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:35,152[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 461:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 461:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.1]train epoch: 461:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.80it/s, loss=27.1]train epoch: 461:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.80it/s, loss=26.7]train epoch: 461:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.40it/s, loss=26.7]train epoch: 461:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.40it/s, loss=22.6]train epoch: 461:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.28it/s, loss=22.6]train epoch: 461:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.28it/s, loss=24]  train epoch: 461:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.46it/s, loss=24]train epoch: 461:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.46it/s, loss=30.9]train epoch: 461:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.79it/s, loss=30.9]train epoch: 461:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.79it/s, loss=28.6]train epoch: 461:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.24it/s, loss=28.6]train epoch: 461:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.24it/s, loss=18.1]train epoch: 461:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=18.1]train epoch: 461:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=25.6]train epoch: 461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=25.6]train epoch: 461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=25.6]
[[032m2021-11-26 10:51:37,650[0m INFO] trainer.training_epoch Training epoch 461, num_steps 3696,  avg_loss: 25.4646, total_loss: 203.7165
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.70it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.71it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.62it/s]
[[032m2021-11-26 10:51:38,248[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:38,248[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:38,863[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:39,070[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 462:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 462:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.8]train epoch: 462:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=28.8]train epoch: 462:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=38.7]train epoch: 462:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=38.7]train epoch: 462:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.14it/s, loss=26.4]train epoch: 462:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.24it/s, loss=26.4]train epoch: 462:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.24it/s, loss=26.1]train epoch: 462:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.67it/s, loss=26.1]
model tensor([[0.4469, 0.5531],
        [0.5418, 0.4582],
        [0.3184, 0.6816],
        [0.7342, 0.2658],
        [0.3049, 0.6951],
        [0.7103, 0.2897],
        [0.3489, 0.6511],
        [0.6269, 0.3731]], device='cuda:0')

prompt tensor([[0.6812, 0.3188],
        [0.5273, 0.4727],
        [0.5406, 0.4594],
        [0.7271, 0.2729],
        [0.6398, 0.3602],
        [0.4643, 0.5357],
        [0.7476, 0.2524],
        [0.7871, 0.2129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 462:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.67it/s, loss=19.8]train epoch: 462:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.23it/s, loss=19.8]train epoch: 462:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.23it/s, loss=19.7]train epoch: 462:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.29it/s, loss=19.7]train epoch: 462:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.29it/s, loss=18.7]train epoch: 462:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s, loss=18.7]train epoch: 462:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s, loss=31.5]train epoch: 462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=31.5]train epoch: 462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=31.5]
[[032m2021-11-26 10:51:41,489[0m INFO] trainer.training_epoch Training epoch 462, num_steps 3704,  avg_loss: 26.2123, total_loss: 209.6988
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.26it/s]
[[032m2021-11-26 10:51:42,075[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:42,075[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:42,347[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:42,439[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 463:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 463:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.7]train epoch: 463:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.91it/s, loss=26.7]train epoch: 463:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.91it/s, loss=27.3]train epoch: 463:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.85it/s, loss=27.3]train epoch: 463:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.85it/s, loss=31.5]train epoch: 463:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=31.5]train epoch: 463:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=24.5]train epoch: 463:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=24.5]train epoch: 463:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=30.5]train epoch: 463:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=30.5]train epoch: 463:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=30.2]train epoch: 463:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.06it/s, loss=30.2]train epoch: 463:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.06it/s, loss=22.6]train epoch: 463:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=22.6]train epoch: 463:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=31.4]train epoch: 463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=31.4]train epoch: 463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.05it/s, loss=31.4]
[[032m2021-11-26 10:51:45,071[0m INFO] trainer.training_epoch Training epoch 463, num_steps 3712,  avg_loss: 28.0820, total_loss: 224.6560
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.12it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.69it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.57it/s]
[[032m2021-11-26 10:51:45,578[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:45,578[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:46,117[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:46,256[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 464:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 464:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.1]train epoch: 464:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.80it/s, loss=32.1]train epoch: 464:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.80it/s, loss=26]  train epoch: 464:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.93it/s, loss=26]train epoch: 464:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.93it/s, loss=26.1]train epoch: 464:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.58it/s, loss=26.1]train epoch: 464:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.58it/s, loss=27.5]train epoch: 464:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=27.5]train epoch: 464:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=34.3]train epoch: 464:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.62it/s, loss=34.3]train epoch: 464:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.62it/s, loss=26.3]train epoch: 464:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=26.3]train epoch: 464:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.86it/s, loss=31]  train epoch: 464:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.12it/s, loss=31]train epoch: 464:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.12it/s, loss=25.4]train epoch: 464: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.86it/s, loss=25.4]train epoch: 464: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.86it/s, loss=25.4]
[[032m2021-11-26 10:51:49,054[0m INFO] trainer.training_epoch Training epoch 464, num_steps 3720,  avg_loss: 28.6016, total_loss: 228.8131
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.68it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.21it/s]
[[032m2021-11-26 10:51:50,017[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:50,017[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:50,309[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:50,454[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 465:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 465:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.1]train epoch: 465:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=22.1]train epoch: 465:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=28.9]train epoch: 465:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.06it/s, loss=28.9]train epoch: 465:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.06it/s, loss=25.6]train epoch: 465:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.22it/s, loss=25.6]train epoch: 465:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.22it/s, loss=27.5]train epoch: 465:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.43it/s, loss=27.5]train epoch: 465:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.43it/s, loss=34.5]train epoch: 465:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=34.5]train epoch: 465:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.55it/s, loss=27.1]train epoch: 465:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=27.1]train epoch: 465:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.95it/s, loss=24.3]train epoch: 465:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=24.3]train epoch: 465:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.96it/s, loss=26.7]train epoch: 465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.70it/s, loss=26.7]train epoch: 465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.64it/s, loss=26.7]
[[032m2021-11-26 10:51:53,495[0m INFO] trainer.training_epoch Training epoch 465, num_steps 3728,  avg_loss: 27.0855, total_loss: 216.6842
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.01it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.85it/s]
[[032m2021-11-26 10:51:54,266[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:54,266[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:54,498[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:54,631[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 466:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 466:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.9]train epoch: 466:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.39it/s, loss=28.9]train epoch: 466:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.39it/s, loss=20.5]train epoch: 466:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.45it/s, loss=20.5]train epoch: 466:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.45it/s, loss=31.6]train epoch: 466:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.65it/s, loss=31.6]train epoch: 466:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.65it/s, loss=21.6]train epoch: 466:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.56it/s, loss=21.6]train epoch: 466:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.56it/s, loss=36.5]train epoch: 466:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=36.5]train epoch: 466:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.95it/s, loss=24.7]train epoch: 466:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.13it/s, loss=24.7]train epoch: 466:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.13it/s, loss=25.5]train epoch: 466:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.79it/s, loss=25.5]train epoch: 466:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.79it/s, loss=32.3]train epoch: 466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.42it/s, loss=32.3]train epoch: 466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.64it/s, loss=32.3]
[[032m2021-11-26 10:51:57,668[0m INFO] trainer.training_epoch Training epoch 466, num_steps 3736,  avg_loss: 27.6818, total_loss: 221.4546
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.01it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.35it/s]
[[032m2021-11-26 10:51:58,408[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:51:58,408[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:51:58,673[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:51:58,786[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 467:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 467:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 467:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.70it/s, loss=25.5]train epoch: 467:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.70it/s, loss=33.3]train epoch: 467:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.24it/s, loss=33.3]train epoch: 467:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.24it/s, loss=20.9]train epoch: 467:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=20.9]train epoch: 467:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.01it/s, loss=31.7]train epoch: 467:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.25it/s, loss=31.7]train epoch: 467:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.25it/s, loss=27]  train epoch: 467:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=27]train epoch: 467:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=23.3]train epoch: 467:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=23.3]train epoch: 467:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=31.7]train epoch: 467:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.88it/s, loss=31.7]train epoch: 467:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.88it/s, loss=24]  train epoch: 467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.70it/s, loss=24]train epoch: 467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s, loss=24]
[[032m2021-11-26 10:52:01,862[0m INFO] trainer.training_epoch Training epoch 467, num_steps 3744,  avg_loss: 27.1626, total_loss: 217.3005
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.47it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.12it/s]
[[032m2021-11-26 10:52:02,442[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:02,443[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:02,690[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:02,803[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 468:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 468:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 468:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=24.9]train epoch: 468:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=28]  train epoch: 468:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.65it/s, loss=28]train epoch: 468:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.65it/s, loss=34.9]train epoch: 468:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=34.9]train epoch: 468:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.48it/s, loss=27.9]train epoch: 468:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.32it/s, loss=27.9]train epoch: 468:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.32it/s, loss=25.9]train epoch: 468:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.71it/s, loss=25.9]train epoch: 468:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.71it/s, loss=28.8]train epoch: 468:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=28.8]train epoch: 468:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=31.1]train epoch: 468:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.45it/s, loss=31.1]train epoch: 468:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.45it/s, loss=33.8]train epoch: 468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.33it/s, loss=33.8]train epoch: 468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.50it/s, loss=33.8]
[[032m2021-11-26 10:52:06,014[0m INFO] trainer.training_epoch Training epoch 468, num_steps 3752,  avg_loss: 29.4036, total_loss: 235.2284
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.40it/s]
[[032m2021-11-26 10:52:06,532[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:06,532[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:07,077[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:07,266[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 469:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 469:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.5]train epoch: 469:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.92it/s, loss=28.5]train epoch: 469:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.92it/s, loss=27.8]train epoch: 469:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.63it/s, loss=27.8]train epoch: 469:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.63it/s, loss=26.3]train epoch: 469:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.02it/s, loss=26.3]train epoch: 469:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.02it/s, loss=30.3]train epoch: 469:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.19it/s, loss=30.3]train epoch: 469:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.19it/s, loss=22.1]train epoch: 469:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=22.1]train epoch: 469:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=25.2]train epoch: 469:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s, loss=25.2]train epoch: 469:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.33it/s, loss=32.1]train epoch: 469:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.01it/s, loss=32.1]train epoch: 469:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.01it/s, loss=28.9]train epoch: 469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.74it/s, loss=28.9]train epoch: 469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=28.9]
[[032m2021-11-26 10:52:09,984[0m INFO] trainer.training_epoch Training epoch 469, num_steps 3760,  avg_loss: 27.6443, total_loss: 221.1540
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.81it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.33it/s]
[[032m2021-11-26 10:52:10,497[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:52:10,497[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:11,233[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 470:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 470:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.8]train epoch: 470:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.72it/s, loss=25.8]train epoch: 470:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.72it/s, loss=26.4]train epoch: 470:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.53it/s, loss=26.4]train epoch: 470:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.53it/s, loss=22]  train epoch: 470:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.52it/s, loss=22]train epoch: 470:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.52it/s, loss=39.7]train epoch: 470:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.66it/s, loss=39.7]train epoch: 470:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.66it/s, loss=26.7]train epoch: 470:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=26.7]train epoch: 470:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=21.7]train epoch: 470:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.62it/s, loss=21.7]train epoch: 470:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.62it/s, loss=20.4]train epoch: 470:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=20.4]train epoch: 470:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=34.2]train epoch: 470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=34.2]train epoch: 470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.44it/s, loss=34.2]
[[032m2021-11-26 10:52:13,595[0m INFO] trainer.training_epoch Training epoch 470, num_steps 3768,  avg_loss: 27.1144, total_loss: 216.9150
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.45it/s]
[[032m2021-11-26 10:52:14,081[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:52:14,081[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:14,431[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 471:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 471:   0%|          | 0/8 [00:00<?, ?it/s, loss=19.2]train epoch: 471:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.65it/s, loss=19.2]train epoch: 471:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.65it/s, loss=23]  train epoch: 471:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.85it/s, loss=23]train epoch: 471:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.85it/s, loss=21.7]train epoch: 471:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.58it/s, loss=21.7]train epoch: 471:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.58it/s, loss=25.3]train epoch: 471:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=25.3]train epoch: 471:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=22.3]train epoch: 471:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=22.3]train epoch: 471:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s, loss=26.8]train epoch: 471:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.44it/s, loss=26.8]train epoch: 471:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.44it/s, loss=28.1]train epoch: 471:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.45it/s, loss=28.1]train epoch: 471:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.45it/s, loss=22.8]train epoch: 471: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.27it/s, loss=22.8]train epoch: 471: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.80it/s, loss=22.8]
[[032m2021-11-26 10:52:17,298[0m INFO] trainer.training_epoch Training epoch 471, num_steps 3776,  avg_loss: 23.6666, total_loss: 189.3330
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.22it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.93it/s]
[[032m2021-11-26 10:52:17,995[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:52:17,995[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:18,233[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 472:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 472:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.2]train epoch: 472:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.74it/s, loss=24.2]train epoch: 472:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.74it/s, loss=33.7]train epoch: 472:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.16it/s, loss=33.7]train epoch: 472:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.16it/s, loss=35.7]train epoch: 472:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.10it/s, loss=35.7]train epoch: 472:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.10it/s, loss=32.1]train epoch: 472:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.59it/s, loss=32.1]train epoch: 472:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.59it/s, loss=33.5]train epoch: 472:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.46it/s, loss=33.5]train epoch: 472:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.46it/s, loss=24.6]train epoch: 472:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.53it/s, loss=24.6]train epoch: 472:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.53it/s, loss=25.8]train epoch: 472:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.82it/s, loss=25.8]train epoch: 472:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.82it/s, loss=25.8]train epoch: 472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.02it/s, loss=25.8]train epoch: 472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.63it/s, loss=25.8]
[[032m2021-11-26 10:52:20,445[0m INFO] trainer.training_epoch Training epoch 472, num_steps 3784,  avg_loss: 29.4306, total_loss: 235.4448
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.35it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.10it/s]
[[032m2021-11-26 10:52:20,988[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.515625)])
[[032m2021-11-26 10:52:20,988[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:21,400[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 473:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 473:   0%|          | 0/8 [00:00<?, ?it/s, loss=20]train epoch: 473:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.69it/s, loss=20]train epoch: 473:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.69it/s, loss=32.8]train epoch: 473:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.83it/s, loss=32.8]train epoch: 473:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.83it/s, loss=24.1]train epoch: 473:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.68it/s, loss=24.1]train epoch: 473:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.68it/s, loss=21.3]train epoch: 473:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=21.3]train epoch: 473:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=26.9]train epoch: 473:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=26.9]train epoch: 473:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=29]  train epoch: 473:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.18it/s, loss=29]train epoch: 473:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.18it/s, loss=32.1]train epoch: 473:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=32.1]train epoch: 473:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=26.1]train epoch: 473: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.56it/s, loss=26.1]train epoch: 473: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=26.1]
[[032m2021-11-26 10:52:23,812[0m INFO] trainer.training_epoch Training epoch 473, num_steps 3792,  avg_loss: 26.5318, total_loss: 212.2542
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.88it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.93it/s]
[[032m2021-11-26 10:52:24,508[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:52:24,509[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:25,057[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 474:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 474:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.2]train epoch: 474:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.95it/s, loss=23.2]train epoch: 474:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.95it/s, loss=23.3]train epoch: 474:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.01it/s, loss=23.3]train epoch: 474:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.01it/s, loss=29.3]train epoch: 474:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.18it/s, loss=29.3]train epoch: 474:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.18it/s, loss=29.8]train epoch: 474:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.44it/s, loss=29.8]train epoch: 474:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.44it/s, loss=28.2]train epoch: 474:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.51it/s, loss=28.2]train epoch: 474:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.51it/s, loss=22.9]train epoch: 474:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.40it/s, loss=22.9]train epoch: 474:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.40it/s, loss=33.5]train epoch: 474:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.82it/s, loss=33.5]train epoch: 474:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.82it/s, loss=25.7]train epoch: 474: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=25.7]train epoch: 474: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.06it/s, loss=25.7]
[[032m2021-11-26 10:52:27,688[0m INFO] trainer.training_epoch Training epoch 474, num_steps 3800,  avg_loss: 26.9912, total_loss: 215.9294
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.52it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.40it/s]
[[032m2021-11-26 10:52:28,469[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:52:28,469[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:28,972[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 475:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.4593, 0.5407],
        [0.7342, 0.2658],
        [0.4404, 0.5596],
        [0.3184, 0.6816],
        [0.5557, 0.4443],
        [0.5443, 0.4557],
        [0.5715, 0.4285],
        [0.5445, 0.4555]], device='cuda:0')

prompt tensor([[0.6556, 0.3444],
        [0.8995, 0.1005],
        [0.7437, 0.2563],
        [0.5830, 0.4170],
        [0.7549, 0.2451],
        [0.4979, 0.5021],
        [0.6362, 0.3638],
        [0.7901, 0.2099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 475:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.3]train epoch: 475:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.68it/s, loss=22.3]train epoch: 475:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.68it/s, loss=25.8]train epoch: 475:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.00it/s, loss=25.8]train epoch: 475:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.00it/s, loss=22.6]train epoch: 475:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.26it/s, loss=22.6]train epoch: 475:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.26it/s, loss=29]  train epoch: 475:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.14it/s, loss=29]train epoch: 475:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.14it/s, loss=25.9]train epoch: 475:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.06it/s, loss=25.9]train epoch: 475:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.06it/s, loss=28.2]train epoch: 475:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.29it/s, loss=28.2]train epoch: 475:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.29it/s, loss=26.1]train epoch: 475:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=26.1]train epoch: 475:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=22.3]train epoch: 475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=22.3]train epoch: 475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=22.3]
[[032m2021-11-26 10:52:31,389[0m INFO] trainer.training_epoch Training epoch 475, num_steps 3808,  avg_loss: 25.2732, total_loss: 202.1859
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.29it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.01it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.64it/s]
[[032m2021-11-26 10:52:32,031[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:52:32,031[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:32,435[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 476:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 476:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.6]train epoch: 476:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.64it/s, loss=21.6]train epoch: 476:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.64it/s, loss=26.6]train epoch: 476:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.10it/s, loss=26.6]train epoch: 476:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.10it/s, loss=29.4]train epoch: 476:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.36it/s, loss=29.4]train epoch: 476:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.36it/s, loss=24.2]train epoch: 476:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.05it/s, loss=24.2]train epoch: 476:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=24]  train epoch: 476:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=24]train epoch: 476:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=28.7]train epoch: 476:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.90it/s, loss=28.7]train epoch: 476:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.90it/s, loss=46.3]train epoch: 476:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.06it/s, loss=46.3]train epoch: 476:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.06it/s, loss=21.2]train epoch: 476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=21.2]train epoch: 476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=21.2]
[[032m2021-11-26 10:52:34,851[0m INFO] trainer.training_epoch Training epoch 476, num_steps 3816,  avg_loss: 27.7464, total_loss: 221.9709
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.14it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.99it/s]
[[032m2021-11-26 10:52:35,474[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:35,474[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:36,085[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:36,304[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 477:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 477:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.1]train epoch: 477:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.39it/s, loss=23.1]train epoch: 477:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.39it/s, loss=24.9]train epoch: 477:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=24.9]train epoch: 477:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.98it/s, loss=29.4]train epoch: 477:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.36it/s, loss=29.4]train epoch: 477:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.36it/s, loss=30.3]train epoch: 477:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.41it/s, loss=30.3]train epoch: 477:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.41it/s, loss=22.2]train epoch: 477:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.66it/s, loss=22.2]train epoch: 477:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.66it/s, loss=29.6]train epoch: 477:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=29.6]train epoch: 477:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.57it/s, loss=29.3]train epoch: 477:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.90it/s, loss=29.3]train epoch: 477:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.90it/s, loss=25.1]train epoch: 477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=25.1]train epoch: 477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.89it/s, loss=25.1]
[[032m2021-11-26 10:52:39,100[0m INFO] trainer.training_epoch Training epoch 477, num_steps 3824,  avg_loss: 26.7408, total_loss: 213.9261
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.67it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.96it/s]
[[032m2021-11-26 10:52:39,787[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:39,788[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:40,058[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:40,259[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 478:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 478:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.4]train epoch: 478:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.04it/s, loss=23.4]train epoch: 478:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.04it/s, loss=26.1]train epoch: 478:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.39it/s, loss=26.1]train epoch: 478:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.39it/s, loss=24.4]train epoch: 478:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.29it/s, loss=24.4]train epoch: 478:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.29it/s, loss=27.6]train epoch: 478:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=27.6]train epoch: 478:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s, loss=31.7]train epoch: 478:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.70it/s, loss=31.7]train epoch: 478:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.70it/s, loss=24.1]train epoch: 478:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.23it/s, loss=24.1]train epoch: 478:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.23it/s, loss=32.8]train epoch: 478:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=32.8]train epoch: 478:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=28.3]train epoch: 478: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=28.3]train epoch: 478: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=28.3]
[[032m2021-11-26 10:52:42,629[0m INFO] trainer.training_epoch Training epoch 478, num_steps 3832,  avg_loss: 27.2989, total_loss: 218.3916
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.55it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.17it/s]
[[032m2021-11-26 10:52:43,138[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:43,139[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:43,591[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:43,756[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 479:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 479:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.6]train epoch: 479:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=26.6]train epoch: 479:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.51it/s, loss=28.7]train epoch: 479:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.77it/s, loss=28.7]train epoch: 479:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.77it/s, loss=26.6]train epoch: 479:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.13it/s, loss=26.6]train epoch: 479:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.13it/s, loss=27]  train epoch: 479:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=27]train epoch: 479:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=30.4]train epoch: 479:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=30.4]train epoch: 479:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=23.5]train epoch: 479:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.65it/s, loss=23.5]train epoch: 479:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.65it/s, loss=29.8]train epoch: 479:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.53it/s, loss=29.8]train epoch: 479:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.53it/s, loss=18.7]train epoch: 479: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=18.7]train epoch: 479: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=18.7]
[[032m2021-11-26 10:52:46,594[0m INFO] trainer.training_epoch Training epoch 479, num_steps 3840,  avg_loss: 26.4233, total_loss: 211.3865
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.49it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.99it/s]
[[032m2021-11-26 10:52:47,044[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:47,044[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:47,386[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:47,730[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 480:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 480:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.6]train epoch: 480:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.73it/s, loss=26.6]train epoch: 480:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.73it/s, loss=30.4]train epoch: 480:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.67it/s, loss=30.4]train epoch: 480:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.67it/s, loss=30.7]train epoch: 480:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.14it/s, loss=30.7]train epoch: 480:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.14it/s, loss=21.4]train epoch: 480:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=21.4]train epoch: 480:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=28.6]train epoch: 480:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=28.6]train epoch: 480:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s, loss=26.1]train epoch: 480:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s, loss=26.1]train epoch: 480:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.39it/s, loss=20.1]train epoch: 480:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=20.1]train epoch: 480:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=34.8]train epoch: 480: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s, loss=34.8]train epoch: 480: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=34.8]
[[032m2021-11-26 10:52:50,317[0m INFO] trainer.training_epoch Training epoch 480, num_steps 3848,  avg_loss: 27.3419, total_loss: 218.7353
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.43it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.47it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.76it/s]
[[032m2021-11-26 10:52:50,894[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:50,894[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:51,117[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:51,257[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 481:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 481:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.8]train epoch: 481:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.19it/s, loss=22.8]train epoch: 481:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.19it/s, loss=23.8]train epoch: 481:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.46it/s, loss=23.8]train epoch: 481:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.46it/s, loss=22]  train epoch: 481:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=22]train epoch: 481:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=32.2]train epoch: 481:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=32.2]train epoch: 481:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=21.2]train epoch: 481:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.77it/s, loss=21.2]train epoch: 481:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.77it/s, loss=23.5]train epoch: 481:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.19it/s, loss=23.5]train epoch: 481:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.19it/s, loss=31.6]train epoch: 481:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.45it/s, loss=31.6]train epoch: 481:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.45it/s, loss=39.7]train epoch: 481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=39.7]train epoch: 481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.84it/s, loss=39.7]
[[032m2021-11-26 10:52:54,080[0m INFO] trainer.training_epoch Training epoch 481, num_steps 3856,  avg_loss: 27.0961, total_loss: 216.7689
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.07it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.53it/s]
[[032m2021-11-26 10:52:54,640[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:54,641[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:54,943[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:52:55,137[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 482:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 482:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 482:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.97it/s, loss=25]train epoch: 482:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.97it/s, loss=28.4]train epoch: 482:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.16it/s, loss=28.4]train epoch: 482:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.16it/s, loss=25.9]train epoch: 482:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.36it/s, loss=25.9]train epoch: 482:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.36it/s, loss=20.8]train epoch: 482:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=20.8]train epoch: 482:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=26.8]train epoch: 482:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.07it/s, loss=26.8]train epoch: 482:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.07it/s, loss=32.8]train epoch: 482:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.09it/s, loss=32.8]train epoch: 482:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.09it/s, loss=32.4]train epoch: 482:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.32it/s, loss=32.4]train epoch: 482:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.32it/s, loss=28.6]train epoch: 482: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.03it/s, loss=28.6]train epoch: 482: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.33it/s, loss=28.6]
[[032m2021-11-26 10:52:58,592[0m INFO] trainer.training_epoch Training epoch 482, num_steps 3864,  avg_loss: 27.5975, total_loss: 220.7802
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.54it/s]
[[032m2021-11-26 10:52:59,064[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:52:59,065[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:52:59,726[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:00,095[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 483:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 483:   0%|          | 0/8 [00:00<?, ?it/s, loss=27]train epoch: 483:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.29it/s, loss=27]train epoch: 483:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.29it/s, loss=25.3]train epoch: 483:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.03it/s, loss=25.3]train epoch: 483:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.03it/s, loss=28]  train epoch: 483:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.48it/s, loss=28]train epoch: 483:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.48it/s, loss=34.3]train epoch: 483:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.44it/s, loss=34.3]train epoch: 483:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.44it/s, loss=29.3]train epoch: 483:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.80it/s, loss=29.3]train epoch: 483:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.80it/s, loss=19.8]train epoch: 483:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.49it/s, loss=19.8]train epoch: 483:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.49it/s, loss=27.1]train epoch: 483:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.48it/s, loss=27.1]train epoch: 483:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.48it/s, loss=21.1]train epoch: 483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.66it/s, loss=21.1]train epoch: 483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s, loss=21.1]
[[032m2021-11-26 10:53:03,034[0m INFO] trainer.training_epoch Training epoch 483, num_steps 3872,  avg_loss: 26.4816, total_loss: 211.8528
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.97it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.57it/s]
[[032m2021-11-26 10:53:03,475[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:03,475[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:03,788[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:04,025[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 484:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 484:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.6]train epoch: 484:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.69it/s, loss=29.6]train epoch: 484:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.69it/s, loss=25.4]train epoch: 484:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=25.4]train epoch: 484:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.89it/s, loss=21.4]train epoch: 484:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.23it/s, loss=21.4]train epoch: 484:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.23it/s, loss=20.5]train epoch: 484:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=20.5]train epoch: 484:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=21.2]train epoch: 484:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=21.2]train epoch: 484:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.15it/s, loss=27.8]train epoch: 484:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=27.8]train epoch: 484:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=28.2]train epoch: 484:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.90it/s, loss=28.2]train epoch: 484:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.90it/s, loss=25.9]train epoch: 484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.30it/s, loss=25.9]train epoch: 484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.45it/s, loss=25.9]
[[032m2021-11-26 10:53:07,306[0m INFO] trainer.training_epoch Training epoch 484, num_steps 3880,  avg_loss: 25.0082, total_loss: 200.0659
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.97it/s]
[[032m2021-11-26 10:53:07,701[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:07,702[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:07,921[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:08,116[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 485:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 485:   0%|          | 0/8 [00:00<?, ?it/s, loss=32]train epoch: 485:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.87it/s, loss=32]train epoch: 485:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.87it/s, loss=22.2]train epoch: 485:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.77it/s, loss=22.2]train epoch: 485:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.77it/s, loss=33]  train epoch: 485:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=33]train epoch: 485:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=26.2]train epoch: 485:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=26.2]train epoch: 485:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=33.3]train epoch: 485:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.37it/s, loss=33.3]train epoch: 485:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.37it/s, loss=26.6]train epoch: 485:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=26.6]train epoch: 485:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=24.7]train epoch: 485:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=24.7]train epoch: 485:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.72it/s, loss=27.6]train epoch: 485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.65it/s, loss=27.6]train epoch: 485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.78it/s, loss=27.6]
[[032m2021-11-26 10:53:11,016[0m INFO] trainer.training_epoch Training epoch 485, num_steps 3888,  avg_loss: 28.1981, total_loss: 225.5848
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.00it/s]
[[032m2021-11-26 10:53:11,436[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:11,436[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:11,707[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:11,962[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 486:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 486:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.2]train epoch: 486:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.52it/s, loss=35.2]train epoch: 486:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.52it/s, loss=26.2]train epoch: 486:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.39it/s, loss=26.2]train epoch: 486:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.39it/s, loss=27]  train epoch: 486:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=27]train epoch: 486:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=34.2]train epoch: 486:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=34.2]train epoch: 486:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=19.2]train epoch: 486:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.31it/s, loss=19.2]train epoch: 486:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.31it/s, loss=22.1]train epoch: 486:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.60it/s, loss=22.1]train epoch: 486:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.60it/s, loss=18.6]train epoch: 486:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=18.6]train epoch: 486:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=18.8]train epoch: 486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=18.8]train epoch: 486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.09it/s, loss=18.8]
[[032m2021-11-26 10:53:14,572[0m INFO] trainer.training_epoch Training epoch 486, num_steps 3896,  avg_loss: 25.1957, total_loss: 201.5655
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.17it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.77it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.72it/s]
[[032m2021-11-26 10:53:15,458[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:15,458[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:15,901[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:16,050[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 487:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 487:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.7]train epoch: 487:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=27.7]train epoch: 487:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=30]  train epoch: 487:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=30]train epoch: 487:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.25it/s, loss=33.1]train epoch: 487:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.20it/s, loss=33.1]train epoch: 487:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.20it/s, loss=27.2]train epoch: 487:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.50it/s, loss=27.2]
model tensor([[0.3953, 0.6047],
        [0.7953, 0.2047],
        [0.5557, 0.4443],
        [0.7454, 0.2546],
        [0.3806, 0.6194],
        [0.5702, 0.4298],
        [0.3489, 0.6511],
        [0.3841, 0.6159]], device='cuda:0')

prompt tensor([[0.8325, 0.1675],
        [0.7559, 0.2441],
        [0.9213, 0.0787],
        [0.7012, 0.2988],
        [0.4744, 0.5256],
        [0.7315, 0.2685],
        [0.6968, 0.3032],
        [0.5056, 0.4944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 487:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.50it/s, loss=16.5]train epoch: 487:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=16.5]train epoch: 487:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.82it/s, loss=28.3]train epoch: 487:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.08it/s, loss=28.3]train epoch: 487:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.08it/s, loss=25.9]train epoch: 487:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=25.9]train epoch: 487:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=20.2]train epoch: 487: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.65it/s, loss=20.2]train epoch: 487: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s, loss=20.2]
[[032m2021-11-26 10:53:18,837[0m INFO] trainer.training_epoch Training epoch 487, num_steps 3904,  avg_loss: 26.0994, total_loss: 208.7953
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.16it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.52it/s]
[[032m2021-11-26 10:53:19,524[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:19,525[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:19,781[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:19,892[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 488:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 488:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.6]train epoch: 488:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.69it/s, loss=30.6]train epoch: 488:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.69it/s, loss=30]  train epoch: 488:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=30]train epoch: 488:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.99it/s, loss=24.1]train epoch: 488:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.76it/s, loss=24.1]train epoch: 488:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.76it/s, loss=26.2]train epoch: 488:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=26.2]train epoch: 488:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=23.3]train epoch: 488:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=23.3]train epoch: 488:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=20.2]train epoch: 488:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.22it/s, loss=20.2]train epoch: 488:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=21.3]train epoch: 488:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.29it/s, loss=21.3]train epoch: 488:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.29it/s, loss=28.4]train epoch: 488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.31it/s, loss=28.4]train epoch: 488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.69it/s, loss=28.4]
[[032m2021-11-26 10:53:22,870[0m INFO] trainer.training_epoch Training epoch 488, num_steps 3912,  avg_loss: 25.5237, total_loss: 204.1893
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.69it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.40it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.23it/s]
[[032m2021-11-26 10:53:23,470[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:23,471[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:23,708[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:23,841[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 489:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 489:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.8]train epoch: 489:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.45it/s, loss=27.8]train epoch: 489:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.45it/s, loss=30]  train epoch: 489:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.80it/s, loss=30]train epoch: 489:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.80it/s, loss=30.7]train epoch: 489:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.50it/s, loss=30.7]train epoch: 489:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.50it/s, loss=26.1]train epoch: 489:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.01it/s, loss=26.1]train epoch: 489:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.01it/s, loss=32.8]train epoch: 489:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.71it/s, loss=32.8]train epoch: 489:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.71it/s, loss=28.1]train epoch: 489:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.64it/s, loss=28.1]train epoch: 489:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.64it/s, loss=25.3]train epoch: 489:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.91it/s, loss=25.3]train epoch: 489:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.91it/s, loss=27.5]train epoch: 489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.05it/s, loss=27.5]train epoch: 489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s, loss=27.5]
[[032m2021-11-26 10:53:26,474[0m INFO] trainer.training_epoch Training epoch 489, num_steps 3920,  avg_loss: 28.5536, total_loss: 228.4286
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.71it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.70it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.69it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.07it/s]
[[032m2021-11-26 10:53:27,200[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:27,200[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:27,553[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:27,708[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 490:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 490:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.1]train epoch: 490:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=27.1]train epoch: 490:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=24.5]train epoch: 490:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.56it/s, loss=24.5]train epoch: 490:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.56it/s, loss=24.8]train epoch: 490:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.79it/s, loss=24.8]train epoch: 490:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.79it/s, loss=25]  train epoch: 490:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=25]train epoch: 490:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=27]train epoch: 490:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=27]train epoch: 490:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=22.5]train epoch: 490:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.99it/s, loss=22.5]train epoch: 490:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.99it/s, loss=28.3]train epoch: 490:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=28.3]train epoch: 490:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.36it/s, loss=29.4]train epoch: 490: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=29.4]train epoch: 490: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=29.4]
[[032m2021-11-26 10:53:30,292[0m INFO] trainer.training_epoch Training epoch 490, num_steps 3928,  avg_loss: 26.0671, total_loss: 208.5368
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.79it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.16it/s]
[[032m2021-11-26 10:53:30,908[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:30,908[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:31,325[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:31,602[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 491:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 491:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.9]train epoch: 491:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.02it/s, loss=26.9]train epoch: 491:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.02it/s, loss=37.4]train epoch: 491:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=37.4]train epoch: 491:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=23.8]train epoch: 491:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.35it/s, loss=23.8]train epoch: 491:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.35it/s, loss=25.4]train epoch: 491:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.40it/s, loss=25.4]train epoch: 491:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.40it/s, loss=31.3]train epoch: 491:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=31.3]train epoch: 491:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=28.7]train epoch: 491:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.10it/s, loss=28.7]train epoch: 491:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.10it/s, loss=21.8]train epoch: 491:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=21.8]train epoch: 491:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=26.5]train epoch: 491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.49it/s, loss=26.5]train epoch: 491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=26.5]
[[032m2021-11-26 10:53:33,969[0m INFO] trainer.training_epoch Training epoch 491, num_steps 3936,  avg_loss: 27.7149, total_loss: 221.7190
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.06it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.98it/s]
[[032m2021-11-26 10:53:34,697[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:34,698[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:35,386[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:35,639[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 492:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 492:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.8]train epoch: 492:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.49it/s, loss=25.8]train epoch: 492:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.49it/s, loss=29.2]train epoch: 492:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=29.2]train epoch: 492:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=27.6]train epoch: 492:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.00it/s, loss=27.6]train epoch: 492:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.00it/s, loss=21.7]train epoch: 492:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=21.7]train epoch: 492:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=24.7]train epoch: 492:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=24.7]train epoch: 492:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.25it/s, loss=24.6]train epoch: 492:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.47it/s, loss=24.6]train epoch: 492:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.47it/s, loss=25.2]train epoch: 492:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.04it/s, loss=25.2]train epoch: 492:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.04it/s, loss=22.4]train epoch: 492: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.96it/s, loss=22.4]train epoch: 492: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=22.4]
[[032m2021-11-26 10:53:38,225[0m INFO] trainer.training_epoch Training epoch 492, num_steps 3944,  avg_loss: 25.1472, total_loss: 201.1778
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.19it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.51it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.24it/s]
[[032m2021-11-26 10:53:38,922[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:38,923[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:39,223[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:39,364[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 493:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 493:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.6]train epoch: 493:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.42it/s, loss=29.6]train epoch: 493:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.42it/s, loss=30.7]train epoch: 493:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.75it/s, loss=30.7]train epoch: 493:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.75it/s, loss=37.2]train epoch: 493:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.65it/s, loss=37.2]train epoch: 493:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.65it/s, loss=30.1]train epoch: 493:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=30.1]train epoch: 493:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=29.3]train epoch: 493:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.64it/s, loss=29.3]train epoch: 493:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.64it/s, loss=32.2]train epoch: 493:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=32.2]train epoch: 493:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=27.5]train epoch: 493:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.83it/s, loss=27.5]train epoch: 493:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.83it/s, loss=18.2]train epoch: 493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.45it/s, loss=18.2]train epoch: 493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.68it/s, loss=18.2]
[[032m2021-11-26 10:53:42,350[0m INFO] trainer.training_epoch Training epoch 493, num_steps 3952,  avg_loss: 29.3513, total_loss: 234.8107
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.88it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.33it/s]
[[032m2021-11-26 10:53:43,388[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:53:43,389[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:43,660[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 494:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 494:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.6]train epoch: 494:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=20.6]train epoch: 494:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=28.2]train epoch: 494:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.24it/s, loss=28.2]train epoch: 494:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.24it/s, loss=31.7]train epoch: 494:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.10it/s, loss=31.7]train epoch: 494:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.10it/s, loss=24.3]train epoch: 494:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=24.3]train epoch: 494:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=19.1]train epoch: 494:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.70it/s, loss=19.1]train epoch: 494:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.70it/s, loss=28.6]train epoch: 494:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.97it/s, loss=28.6]train epoch: 494:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.97it/s, loss=26]  train epoch: 494:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=26]train epoch: 494:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=32.1]train epoch: 494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=32.1]train epoch: 494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.07it/s, loss=32.1]
[[032m2021-11-26 10:53:46,270[0m INFO] trainer.training_epoch Training epoch 494, num_steps 3960,  avg_loss: 26.3322, total_loss: 210.6575
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.61it/s]
[[032m2021-11-26 10:53:46,763[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:46,763[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:46,996[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:47,093[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 495:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 495:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.4]train epoch: 495:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=21.4]train epoch: 495:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.79it/s, loss=25.1]train epoch: 495:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=25.1]train epoch: 495:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.37it/s, loss=22.7]train epoch: 495:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.13it/s, loss=22.7]train epoch: 495:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.13it/s, loss=28.4]train epoch: 495:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=28.4]train epoch: 495:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=19.6]train epoch: 495:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=19.6]train epoch: 495:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=30.8]train epoch: 495:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.82it/s, loss=30.8]train epoch: 495:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.82it/s, loss=36.3]train epoch: 495:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=36.3]train epoch: 495:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=30.3]train epoch: 495: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=30.3]train epoch: 495: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=30.3]
[[032m2021-11-26 10:53:49,617[0m INFO] trainer.training_epoch Training epoch 495, num_steps 3968,  avg_loss: 26.8227, total_loss: 214.5815
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.37it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.35it/s]
[[032m2021-11-26 10:53:50,425[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:50,425[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:51,012[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:51,118[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 496:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 496:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.7]train epoch: 496:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.04it/s, loss=22.7]train epoch: 496:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.04it/s, loss=24.9]train epoch: 496:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=24.9]train epoch: 496:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=26.5]train epoch: 496:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.85it/s, loss=26.5]train epoch: 496:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=31.3]train epoch: 496:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=31.3]train epoch: 496:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=23.7]train epoch: 496:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=23.7]train epoch: 496:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=32]  train epoch: 496:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=32]train epoch: 496:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=27.4]train epoch: 496:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=27.4]train epoch: 496:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=22]  train epoch: 496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=22]train epoch: 496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=22]
[[032m2021-11-26 10:53:53,655[0m INFO] trainer.training_epoch Training epoch 496, num_steps 3976,  avg_loss: 26.2862, total_loss: 210.2899
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.81it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.60it/s]
[[032m2021-11-26 10:53:54,146[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:54,152[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:54,901[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:55,065[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 497:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 497:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.4]train epoch: 497:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=22.4]train epoch: 497:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.36it/s, loss=23.7]train epoch: 497:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.69it/s, loss=23.7]train epoch: 497:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.69it/s, loss=32.2]train epoch: 497:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=32.2]train epoch: 497:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.99it/s, loss=25.3]train epoch: 497:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.59it/s, loss=25.3]train epoch: 497:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.59it/s, loss=32.2]train epoch: 497:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.20it/s, loss=32.2]train epoch: 497:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.20it/s, loss=27.7]train epoch: 497:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.27it/s, loss=27.7]train epoch: 497:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.27it/s, loss=34.5]train epoch: 497:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=34.5]train epoch: 497:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=23.5]train epoch: 497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s, loss=23.5]train epoch: 497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.31it/s, loss=23.5]
[[032m2021-11-26 10:53:57,489[0m INFO] trainer.training_epoch Training epoch 497, num_steps 3984,  avg_loss: 27.6887, total_loss: 221.5098
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.63it/s]
[[032m2021-11-26 10:53:57,932[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:53:57,933[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:53:58,568[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:53:58,993[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 498:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 498:   0%|          | 0/8 [00:00<?, ?it/s, loss=30]train epoch: 498:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.75it/s, loss=30]train epoch: 498:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.75it/s, loss=27.5]train epoch: 498:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.96it/s, loss=27.5]train epoch: 498:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.96it/s, loss=29.1]train epoch: 498:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=29.1]train epoch: 498:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.73it/s, loss=22.7]train epoch: 498:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=22.7]train epoch: 498:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=21.8]train epoch: 498:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.44it/s, loss=21.8]train epoch: 498:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.44it/s, loss=27.4]train epoch: 498:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=27.4]train epoch: 498:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=34]  train epoch: 498:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=34]train epoch: 498:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=23.5]train epoch: 498: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s, loss=23.5]train epoch: 498: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s, loss=23.5]
[[032m2021-11-26 10:54:01,780[0m INFO] trainer.training_epoch Training epoch 498, num_steps 3992,  avg_loss: 27.0051, total_loss: 216.0408
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.47it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.63it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.87it/s]
[[032m2021-11-26 10:54:02,252[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:02,252[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:02,736[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:02,890[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 499:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 499:   0%|          | 0/8 [00:00<?, ?it/s, loss=28]train epoch: 499:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.86it/s, loss=28]train epoch: 499:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.86it/s, loss=28.9]train epoch: 499:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=28.9]train epoch: 499:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=28.4]train epoch: 499:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.48it/s, loss=28.4]train epoch: 499:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.48it/s, loss=30]  train epoch: 499:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.44it/s, loss=30]train epoch: 499:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.44it/s, loss=23.7]train epoch: 499:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=23.7]train epoch: 499:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.38it/s, loss=22.6]train epoch: 499:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s, loss=22.6]train epoch: 499:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.36it/s, loss=27.5]train epoch: 499:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.16it/s, loss=27.5]train epoch: 499:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.16it/s, loss=25.5]train epoch: 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=25.5]train epoch: 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=25.5]
[[032m2021-11-26 10:54:05,227[0m INFO] trainer.training_epoch Training epoch 499, num_steps 4000,  avg_loss: 26.8291, total_loss: 214.6326
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.35it/s]
[[032m2021-11-26 10:54:05,741[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:05,742[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:05,995[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:06,100[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 500:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3206, 0.6794],
        [0.4013, 0.5987],
        [0.4808, 0.5192],
        [0.4383, 0.5617],
        [0.4667, 0.5333],
        [0.2828, 0.7172],
        [0.5715, 0.4285],
        [0.7342, 0.2658]], device='cuda:0')

prompt tensor([[0.4372, 0.5628],
        [0.4989, 0.5011],
        [0.3298, 0.6702],
        [0.6916, 0.3084],
        [0.5169, 0.4831],
        [0.4039, 0.5961],
        [0.6789, 0.3211],
        [0.3496, 0.6504]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 500:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.2]train epoch: 500:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.43it/s, loss=26.2]train epoch: 500:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.43it/s, loss=21.8]train epoch: 500:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.73it/s, loss=21.8]train epoch: 500:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.73it/s, loss=27.6]train epoch: 500:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.97it/s, loss=27.6]train epoch: 500:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.97it/s, loss=25.9]train epoch: 500:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=25.9]train epoch: 500:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=32.1]train epoch: 500:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=32.1]train epoch: 500:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=29.6]train epoch: 500:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s, loss=29.6]train epoch: 500:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.32it/s, loss=28]  train epoch: 500:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.48it/s, loss=28]train epoch: 500:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.48it/s, loss=29.2]train epoch: 500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=29.2]train epoch: 500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=29.2]
[[032m2021-11-26 10:54:08,542[0m INFO] trainer.training_epoch Training epoch 500, num_steps 4008,  avg_loss: 27.5716, total_loss: 220.5727
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.59it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.66it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.94it/s]
[[032m2021-11-26 10:54:09,088[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:09,088[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:09,349[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:09,465[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 501:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 501:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.3]train epoch: 501:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=34.3]train epoch: 501:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.87it/s, loss=28.5]train epoch: 501:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.91it/s, loss=28.5]train epoch: 501:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.91it/s, loss=26.2]train epoch: 501:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.87it/s, loss=26.2]train epoch: 501:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.87it/s, loss=22.7]train epoch: 501:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=22.7]train epoch: 501:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.00it/s, loss=23.1]train epoch: 501:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=23.1]train epoch: 501:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=22.3]train epoch: 501:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.11it/s, loss=22.3]train epoch: 501:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.11it/s, loss=27.8]train epoch: 501:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=27.8]train epoch: 501:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.07it/s, loss=20.8]train epoch: 501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=20.8]train epoch: 501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.09it/s, loss=20.8]
[[032m2021-11-26 10:54:12,057[0m INFO] trainer.training_epoch Training epoch 501, num_steps 4016,  avg_loss: 25.7238, total_loss: 205.7906
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.18it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.49it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.22it/s]
[[032m2021-11-26 10:54:12,627[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:12,627[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:12,922[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:13,020[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 502:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 502:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.7]train epoch: 502:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=25.7]train epoch: 502:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.12it/s, loss=27.4]train epoch: 502:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.28it/s, loss=27.4]train epoch: 502:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.28it/s, loss=26.8]train epoch: 502:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.48it/s, loss=26.8]train epoch: 502:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.48it/s, loss=16.5]train epoch: 502:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=16.5]train epoch: 502:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=24.1]train epoch: 502:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.83it/s, loss=24.1]train epoch: 502:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.83it/s, loss=22]  train epoch: 502:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.01it/s, loss=22]train epoch: 502:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.01it/s, loss=29.8]train epoch: 502:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.17it/s, loss=29.8]train epoch: 502:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.17it/s, loss=27.7]train epoch: 502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=27.7]train epoch: 502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=27.7]
[[032m2021-11-26 10:54:15,591[0m INFO] trainer.training_epoch Training epoch 502, num_steps 4024,  avg_loss: 24.9923, total_loss: 199.9388
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.30it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.82it/s]
[[032m2021-11-26 10:54:16,198[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:16,199[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:16,464[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:16,579[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 503:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 503:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.6]train epoch: 503:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=28.6]train epoch: 503:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=28.4]train epoch: 503:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=28.4]train epoch: 503:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=21.7]train epoch: 503:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.20it/s, loss=21.7]train epoch: 503:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.20it/s, loss=23.8]train epoch: 503:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.48it/s, loss=23.8]train epoch: 503:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.48it/s, loss=27.9]train epoch: 503:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.74it/s, loss=27.9]train epoch: 503:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.74it/s, loss=27.7]train epoch: 503:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=27.7]train epoch: 503:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.88it/s, loss=24.2]train epoch: 503:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s, loss=24.2]train epoch: 503:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s, loss=24.4]train epoch: 503: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.77it/s, loss=24.4]train epoch: 503: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=24.4]
[[032m2021-11-26 10:54:19,301[0m INFO] trainer.training_epoch Training epoch 503, num_steps 4032,  avg_loss: 25.8537, total_loss: 206.8292
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.80it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.02it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.68it/s]
[[032m2021-11-26 10:54:19,919[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:19,920[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:20,139[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:20,239[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 504:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 504:   0%|          | 0/8 [00:00<?, ?it/s, loss=21]train epoch: 504:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=21]train epoch: 504:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=26.1]train epoch: 504:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=26.1]train epoch: 504:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=20.8]train epoch: 504:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.08it/s, loss=20.8]train epoch: 504:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.08it/s, loss=25.1]train epoch: 504:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=25.1]train epoch: 504:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=21.6]train epoch: 504:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=21.6]train epoch: 504:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=29]  train epoch: 504:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.09it/s, loss=29]train epoch: 504:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.09it/s, loss=26]train epoch: 504:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.34it/s, loss=26]train epoch: 504:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.34it/s, loss=31.8]train epoch: 504: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=31.8]train epoch: 504: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s, loss=31.8]
[[032m2021-11-26 10:54:22,786[0m INFO] trainer.training_epoch Training epoch 504, num_steps 4040,  avg_loss: 25.1600, total_loss: 201.2800
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.44it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.40it/s]
[[032m2021-11-26 10:54:23,343[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:54:23,343[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:23,646[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 505:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 505:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.1]train epoch: 505:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=22.1]train epoch: 505:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.99it/s, loss=25.6]train epoch: 505:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.60it/s, loss=25.6]train epoch: 505:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.60it/s, loss=18.4]train epoch: 505:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=18.4]train epoch: 505:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=23.1]train epoch: 505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.89it/s, loss=23.1]train epoch: 505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.89it/s, loss=28.4]train epoch: 505:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=28.4]train epoch: 505:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=27.5]train epoch: 505:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.17it/s, loss=27.5]train epoch: 505:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.17it/s, loss=23.8]train epoch: 505:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.44it/s, loss=23.8]train epoch: 505:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=22.5]train epoch: 505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=22.5]train epoch: 505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=22.5]
[[032m2021-11-26 10:54:25,850[0m INFO] trainer.training_epoch Training epoch 505, num_steps 4048,  avg_loss: 23.9359, total_loss: 191.4875
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.92it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.27it/s]
[[032m2021-11-26 10:54:26,641[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:26,645[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:26,917[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:27,100[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 506:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 506:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.5]train epoch: 506:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=23.5]train epoch: 506:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=20]  train epoch: 506:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.70it/s, loss=20]train epoch: 506:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.70it/s, loss=29.5]train epoch: 506:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.95it/s, loss=29.5]train epoch: 506:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.95it/s, loss=28.9]train epoch: 506:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.09it/s, loss=28.9]train epoch: 506:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.09it/s, loss=26.4]train epoch: 506:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=26.4]train epoch: 506:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=27.1]train epoch: 506:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.21it/s, loss=27.1]train epoch: 506:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.21it/s, loss=33.8]train epoch: 506:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=33.8]train epoch: 506:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.09it/s, loss=18.4]train epoch: 506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=18.4]train epoch: 506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=18.4]
[[032m2021-11-26 10:54:29,621[0m INFO] trainer.training_epoch Training epoch 506, num_steps 4056,  avg_loss: 25.9286, total_loss: 207.4285
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.67it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.34it/s]
[[032m2021-11-26 10:54:30,064[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:30,065[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:30,407[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:30,539[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 507:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 507:   0%|          | 0/8 [00:00<?, ?it/s, loss=29]train epoch: 507:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=29]train epoch: 507:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.22it/s, loss=28.1]train epoch: 507:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.99it/s, loss=28.1]train epoch: 507:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.99it/s, loss=26.3]train epoch: 507:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.84it/s, loss=26.3]train epoch: 507:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.84it/s, loss=23.5]train epoch: 507:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=23.5]train epoch: 507:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=26.4]train epoch: 507:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=26.4]train epoch: 507:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=23.3]train epoch: 507:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.25it/s, loss=23.3]train epoch: 507:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.25it/s, loss=35.7]train epoch: 507:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=35.7]train epoch: 507:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=30]  train epoch: 507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.85it/s, loss=30]train epoch: 507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.96it/s, loss=30]
[[032m2021-11-26 10:54:33,257[0m INFO] trainer.training_epoch Training epoch 507, num_steps 4064,  avg_loss: 27.7725, total_loss: 222.1804
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.03it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.89it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29it/s]
[[032m2021-11-26 10:54:33,760[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:33,761[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:34,019[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:34,121[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 508:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 508:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.3]train epoch: 508:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.62it/s, loss=28.3]train epoch: 508:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.62it/s, loss=27.2]train epoch: 508:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.41it/s, loss=27.2]train epoch: 508:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.41it/s, loss=26.2]train epoch: 508:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.12it/s, loss=26.2]train epoch: 508:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.12it/s, loss=25.3]train epoch: 508:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=25.3]train epoch: 508:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=26]  train epoch: 508:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=26]train epoch: 508:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=27.6]train epoch: 508:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.23it/s, loss=27.6]train epoch: 508:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.23it/s, loss=27.1]train epoch: 508:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=27.1]train epoch: 508:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.50it/s, loss=31.2]train epoch: 508: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=31.2]train epoch: 508: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=31.2]
[[032m2021-11-26 10:54:36,596[0m INFO] trainer.training_epoch Training epoch 508, num_steps 4072,  avg_loss: 27.3734, total_loss: 218.9874
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.36it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.50it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.23it/s]
[[032m2021-11-26 10:54:37,245[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:37,245[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:37,770[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:37,938[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 509:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 509:   0%|          | 0/8 [00:00<?, ?it/s, loss=41.2]train epoch: 509:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.65it/s, loss=41.2]train epoch: 509:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.65it/s, loss=23.6]train epoch: 509:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.24it/s, loss=23.6]train epoch: 509:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.24it/s, loss=27.1]train epoch: 509:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=27.1]train epoch: 509:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=27.1]train epoch: 509:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=27.1]train epoch: 509:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=32.4]train epoch: 509:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.18it/s, loss=32.4]train epoch: 509:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.18it/s, loss=23.3]train epoch: 509:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.55it/s, loss=23.3]train epoch: 509:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.55it/s, loss=17.3]train epoch: 509:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.84it/s, loss=17.3]train epoch: 509:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.84it/s, loss=23.8]train epoch: 509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.69it/s, loss=23.8]train epoch: 509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s, loss=23.8]
[[032m2021-11-26 10:54:40,303[0m INFO] trainer.training_epoch Training epoch 509, num_steps 4080,  avg_loss: 26.9798, total_loss: 215.8387
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.06it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.60it/s]
[[032m2021-11-26 10:54:40,944[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:40,945[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:41,315[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:41,455[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 510:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 510:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.4]train epoch: 510:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.56it/s, loss=31.4]train epoch: 510:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.56it/s, loss=29.3]train epoch: 510:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.30it/s, loss=29.3]train epoch: 510:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.30it/s, loss=26]  train epoch: 510:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.90it/s, loss=26]train epoch: 510:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.90it/s, loss=26.8]train epoch: 510:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=26.8]train epoch: 510:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=24.7]train epoch: 510:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.88it/s, loss=24.7]train epoch: 510:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.88it/s, loss=30.5]train epoch: 510:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.15it/s, loss=30.5]train epoch: 510:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.15it/s, loss=29.2]train epoch: 510:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=29.2]train epoch: 510:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=34.5]train epoch: 510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.66it/s, loss=34.5]train epoch: 510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=34.5]
[[032m2021-11-26 10:54:44,299[0m INFO] trainer.training_epoch Training epoch 510, num_steps 4088,  avg_loss: 29.0425, total_loss: 232.3401
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.82it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.15it/s]
[[032m2021-11-26 10:54:44,890[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:44,890[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:45,118[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:45,231[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 511:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 511:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.6]train epoch: 511:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.73it/s, loss=31.6]train epoch: 511:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.73it/s, loss=28.7]train epoch: 511:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.18it/s, loss=28.7]train epoch: 511:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.18it/s, loss=26.7]train epoch: 511:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=26.7]train epoch: 511:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.53it/s, loss=20.4]train epoch: 511:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=20.4]train epoch: 511:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.85it/s, loss=28.2]train epoch: 511:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=28.2]train epoch: 511:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.14it/s, loss=22.2]train epoch: 511:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.74it/s, loss=22.2]train epoch: 511:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.74it/s, loss=29.6]train epoch: 511:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=29.6]train epoch: 511:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=31.1]train epoch: 511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s, loss=31.1]train epoch: 511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s, loss=31.1]
[[032m2021-11-26 10:54:47,917[0m INFO] trainer.training_epoch Training epoch 511, num_steps 4096,  avg_loss: 27.3052, total_loss: 218.4418
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.79it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.62it/s]
[[032m2021-11-26 10:54:48,590[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:48,590[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:48,860[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:49,024[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 512:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 512:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.4]train epoch: 512:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.66it/s, loss=22.4]train epoch: 512:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:04,  1.66it/s, loss=28.4]train epoch: 512:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.04it/s, loss=28.4]train epoch: 512:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.04it/s, loss=23.7]train epoch: 512:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=23.7]train epoch: 512:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=24.3]train epoch: 512:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=24.3]
model tensor([[0.7454, 0.2546],
        [0.4667, 0.5333],
        [0.4335, 0.5665],
        [0.5715, 0.4285],
        [0.4201, 0.5799],
        [0.3295, 0.6705],
        [0.2477, 0.7523],
        [0.6731, 0.3269]], device='cuda:0')

prompt tensor([[0.6705, 0.3295],
        [0.6082, 0.3918],
        [0.5068, 0.4932],
        [0.7271, 0.2729],
        [0.3936, 0.6064],
        [0.3966, 0.6034],
        [0.3741, 0.6259],
        [0.6470, 0.3530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 512:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=25]  train epoch: 512:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.35it/s, loss=25]train epoch: 512:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.35it/s, loss=29]train epoch: 512:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.40it/s, loss=29]train epoch: 512:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.40it/s, loss=32]train epoch: 512:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=32]train epoch: 512:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=22.4]train epoch: 512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=22.4]train epoch: 512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=22.4]
[[032m2021-11-26 10:54:51,915[0m INFO] trainer.training_epoch Training epoch 512, num_steps 4104,  avg_loss: 25.9085, total_loss: 207.2684
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.66it/s]
[[032m2021-11-26 10:54:52,358[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:54:52,359[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:52,612[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:54:52,760[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 513:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 513:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.1]train epoch: 513:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=23.1]train epoch: 513:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=21]  train epoch: 513:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=21]train epoch: 513:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.31it/s, loss=29.9]train epoch: 513:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.32it/s, loss=29.9]train epoch: 513:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.32it/s, loss=24.9]train epoch: 513:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.59it/s, loss=24.9]train epoch: 513:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.59it/s, loss=29.2]train epoch: 513:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=29.2]train epoch: 513:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.80it/s, loss=30.5]train epoch: 513:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=30.5]train epoch: 513:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=28.8]train epoch: 513:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.97it/s, loss=28.8]train epoch: 513:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.97it/s, loss=30.8]train epoch: 513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.93it/s, loss=30.8]train epoch: 513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=30.8]
[[032m2021-11-26 10:54:54,866[0m INFO] trainer.training_epoch Training epoch 513, num_steps 4112,  avg_loss: 27.2740, total_loss: 218.1919
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.31it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.79it/s]
[[032m2021-11-26 10:54:55,440[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:54:55,441[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:55,953[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 514:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 514:   0%|          | 0/8 [00:00<?, ?it/s, loss=23]train epoch: 514:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=23]train epoch: 514:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=27.6]train epoch: 514:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=27.6]train epoch: 514:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.28it/s, loss=27.6]train epoch: 514:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.09it/s, loss=27.6]train epoch: 514:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.09it/s, loss=23.5]train epoch: 514:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.79it/s, loss=23.5]train epoch: 514:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.79it/s, loss=29.2]train epoch: 514:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.04it/s, loss=29.2]train epoch: 514:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.04it/s, loss=23]  train epoch: 514:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=23]train epoch: 514:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=27.5]train epoch: 514:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=27.5]train epoch: 514:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=27.3]train epoch: 514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=27.3]train epoch: 514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=27.3]
[[032m2021-11-26 10:54:58,477[0m INFO] trainer.training_epoch Training epoch 514, num_steps 4120,  avg_loss: 26.0888, total_loss: 208.7106
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.60it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.69it/s]
[[032m2021-11-26 10:54:59,100[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:54:59,100[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:54:59,586[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 515:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 515:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.9]train epoch: 515:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.75it/s, loss=32.9]train epoch: 515:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.75it/s, loss=27.8]train epoch: 515:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=27.8]train epoch: 515:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=21.1]train epoch: 515:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.82it/s, loss=21.1]train epoch: 515:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.82it/s, loss=26.2]train epoch: 515:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.05it/s, loss=26.2]train epoch: 515:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.05it/s, loss=21.9]train epoch: 515:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=21.9]train epoch: 515:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.24it/s, loss=22.1]train epoch: 515:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.18it/s, loss=22.1]train epoch: 515:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.18it/s, loss=22.9]train epoch: 515:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.98it/s, loss=22.9]train epoch: 515:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.98it/s, loss=24.7]train epoch: 515: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=24.7]train epoch: 515: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=24.7]
[[032m2021-11-26 10:55:02,056[0m INFO] trainer.training_epoch Training epoch 515, num_steps 4128,  avg_loss: 24.9579, total_loss: 199.6632
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.35it/s]
[[032m2021-11-26 10:55:02,573[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:55:02,574[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:03,093[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 516:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 516:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.4]train epoch: 516:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.96it/s, loss=20.4]train epoch: 516:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.96it/s, loss=27.8]train epoch: 516:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.47it/s, loss=27.8]train epoch: 516:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.47it/s, loss=26.9]train epoch: 516:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=26.9]train epoch: 516:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.80it/s, loss=31.6]train epoch: 516:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.25it/s, loss=31.6]train epoch: 516:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.25it/s, loss=27.3]train epoch: 516:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=27.3]train epoch: 516:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=33.5]train epoch: 516:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=33.5]train epoch: 516:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.43it/s, loss=30.9]train epoch: 516:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=30.9]train epoch: 516:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=23.5]train epoch: 516: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.44it/s, loss=23.5]train epoch: 516: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s, loss=23.5]
[[032m2021-11-26 10:55:05,607[0m INFO] trainer.training_epoch Training epoch 516, num_steps 4136,  avg_loss: 27.7284, total_loss: 221.8276
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.02it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.15it/s]
[[032m2021-11-26 10:55:06,326[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:55:06,327[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:06,848[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 517:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 517:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.8]train epoch: 517:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.97it/s, loss=23.8]train epoch: 517:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.97it/s, loss=30.7]train epoch: 517:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=30.7]train epoch: 517:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=32.8]train epoch: 517:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.89it/s, loss=32.8]train epoch: 517:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.89it/s, loss=24.4]train epoch: 517:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.36it/s, loss=24.4]train epoch: 517:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.36it/s, loss=30.4]train epoch: 517:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=30.4]train epoch: 517:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=25.4]train epoch: 517:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.07it/s, loss=25.4]train epoch: 517:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.07it/s, loss=35]  train epoch: 517:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=35]train epoch: 517:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.13it/s, loss=24.1]train epoch: 517: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=24.1]train epoch: 517: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.30it/s, loss=24.1]
[[032m2021-11-26 10:55:09,282[0m INFO] trainer.training_epoch Training epoch 517, num_steps 4144,  avg_loss: 28.3342, total_loss: 226.6732
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.54it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.05it/s]
[[032m2021-11-26 10:55:09,712[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:09,713[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:10,142[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:10,343[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 518:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 518:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.7]train epoch: 518:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.23it/s, loss=35.7]train epoch: 518:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.23it/s, loss=27.6]train epoch: 518:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  3.00it/s, loss=27.6]train epoch: 518:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  3.00it/s, loss=20.6]train epoch: 518:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.30it/s, loss=20.6]train epoch: 518:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.30it/s, loss=37.7]train epoch: 518:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.16it/s, loss=37.7]train epoch: 518:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.16it/s, loss=29.3]train epoch: 518:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.48it/s, loss=29.3]train epoch: 518:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.48it/s, loss=19.3]train epoch: 518:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.02it/s, loss=19.3]train epoch: 518:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.02it/s, loss=25.7]train epoch: 518:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.42it/s, loss=25.7]train epoch: 518:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.42it/s, loss=39.5]train epoch: 518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s, loss=39.5]train epoch: 518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=39.5]
[[032m2021-11-26 10:55:12,845[0m INFO] trainer.training_epoch Training epoch 518, num_steps 4152,  avg_loss: 29.4156, total_loss: 235.3251
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.33it/s]
[[032m2021-11-26 10:55:13,317[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:13,317[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:13,647[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:13,979[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 519:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 519:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.6]train epoch: 519:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.71it/s, loss=36.6]train epoch: 519:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.71it/s, loss=33.2]train epoch: 519:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.33it/s, loss=33.2]train epoch: 519:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.33it/s, loss=27.4]train epoch: 519:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=27.4]train epoch: 519:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.99it/s, loss=29.6]train epoch: 519:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.88it/s, loss=29.6]train epoch: 519:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.88it/s, loss=29.8]train epoch: 519:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.95it/s, loss=29.8]train epoch: 519:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.95it/s, loss=28.5]train epoch: 519:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.53it/s, loss=28.5]train epoch: 519:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.53it/s, loss=26.4]train epoch: 519:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=26.4]train epoch: 519:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=27.9]train epoch: 519: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=27.9]train epoch: 519: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=27.9]
[[032m2021-11-26 10:55:16,229[0m INFO] trainer.training_epoch Training epoch 519, num_steps 4160,  avg_loss: 29.9186, total_loss: 239.3488
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.47it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.49it/s]
[[032m2021-11-26 10:55:16,689[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:16,690[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:16,933[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:17,071[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 520:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 520:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.1]train epoch: 520:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=20.1]train epoch: 520:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.48it/s, loss=28.9]train epoch: 520:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.09it/s, loss=28.9]train epoch: 520:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.09it/s, loss=25]  train epoch: 520:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s, loss=25]train epoch: 520:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.13it/s, loss=28.7]train epoch: 520:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=28.7]train epoch: 520:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.63it/s, loss=22.2]train epoch: 520:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=22.2]train epoch: 520:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=28.3]train epoch: 520:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.04it/s, loss=28.3]train epoch: 520:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.04it/s, loss=29.7]train epoch: 520:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=29.7]train epoch: 520:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=27.7]train epoch: 520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.01it/s, loss=27.7]train epoch: 520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.29it/s, loss=27.7]
[[032m2021-11-26 10:55:19,504[0m INFO] trainer.training_epoch Training epoch 520, num_steps 4168,  avg_loss: 26.3300, total_loss: 210.6402
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.18it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.97it/s]
[[032m2021-11-26 10:55:20,213[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:20,213[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:20,491[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:20,640[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 521:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 521:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 521:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=27.3]train epoch: 521:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.53it/s, loss=25.7]train epoch: 521:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=25.7]train epoch: 521:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.54it/s, loss=24.8]train epoch: 521:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=24.8]train epoch: 521:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=21.5]train epoch: 521:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.01it/s, loss=21.5]train epoch: 521:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.01it/s, loss=25.2]train epoch: 521:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.95it/s, loss=25.2]train epoch: 521:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.95it/s, loss=23.9]train epoch: 521:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.28it/s, loss=23.9]train epoch: 521:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.28it/s, loss=23.8]train epoch: 521:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.30it/s, loss=23.8]train epoch: 521:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.30it/s, loss=18]  train epoch: 521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=18]train epoch: 521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=18]
[[032m2021-11-26 10:55:22,843[0m INFO] trainer.training_epoch Training epoch 521, num_steps 4176,  avg_loss: 23.7840, total_loss: 190.2724
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.04it/s]
[[032m2021-11-26 10:55:23,345[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:23,345[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:23,993[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:24,185[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 522:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 522:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 522:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.67it/s, loss=29.8]train epoch: 522:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.67it/s, loss=21.3]train epoch: 522:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.74it/s, loss=21.3]train epoch: 522:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.74it/s, loss=30.8]train epoch: 522:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.78it/s, loss=30.8]train epoch: 522:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.78it/s, loss=32]  train epoch: 522:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.86it/s, loss=32]train epoch: 522:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.86it/s, loss=21.5]train epoch: 522:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=21.5]train epoch: 522:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=31.5]train epoch: 522:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.01it/s, loss=31.5]train epoch: 522:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.01it/s, loss=27.5]train epoch: 522:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.65it/s, loss=27.5]train epoch: 522:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.65it/s, loss=25.8]train epoch: 522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=25.8]train epoch: 522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=25.8]
[[032m2021-11-26 10:55:26,755[0m INFO] trainer.training_epoch Training epoch 522, num_steps 4184,  avg_loss: 27.5361, total_loss: 220.2887
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.55it/s]
[[032m2021-11-26 10:55:27,280[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:27,281[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:27,658[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:28,153[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 523:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 523:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.4]train epoch: 523:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.76it/s, loss=23.4]train epoch: 523:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.76it/s, loss=26.5]train epoch: 523:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.42it/s, loss=26.5]train epoch: 523:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.42it/s, loss=23]  train epoch: 523:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.72it/s, loss=23]train epoch: 523:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.72it/s, loss=27.1]train epoch: 523:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=27.1]train epoch: 523:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=38.7]train epoch: 523:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.99it/s, loss=38.7]train epoch: 523:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.99it/s, loss=25.2]train epoch: 523:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.82it/s, loss=25.2]train epoch: 523:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.82it/s, loss=30.1]train epoch: 523:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.66it/s, loss=30.1]train epoch: 523:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.66it/s, loss=24]  train epoch: 523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s, loss=24]train epoch: 523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.96it/s, loss=24]
[[032m2021-11-26 10:55:30,863[0m INFO] trainer.training_epoch Training epoch 523, num_steps 4192,  avg_loss: 27.2655, total_loss: 218.1236
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.07it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.45it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.15it/s]
[[032m2021-11-26 10:55:31,454[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:31,455[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:32,410[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:32,670[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 524:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 524:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 524:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=27.3]train epoch: 524:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=28.1]train epoch: 524:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=28.1]train epoch: 524:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=26.7]train epoch: 524:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.84it/s, loss=26.7]train epoch: 524:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.84it/s, loss=28.7]train epoch: 524:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.36it/s, loss=28.7]train epoch: 524:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.36it/s, loss=24.7]train epoch: 524:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.17it/s, loss=24.7]train epoch: 524:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.17it/s, loss=32]  train epoch: 524:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=32]train epoch: 524:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.54it/s, loss=26.4]train epoch: 524:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=26.4]train epoch: 524:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.84it/s, loss=22]  train epoch: 524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s, loss=22]train epoch: 524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=22]
[[032m2021-11-26 10:55:35,540[0m INFO] trainer.training_epoch Training epoch 524, num_steps 4200,  avg_loss: 26.9842, total_loss: 215.8740
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.10it/s]
[[032m2021-11-26 10:55:36,353[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:36,353[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:36,862[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:37,061[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 525:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3884, 0.6116],
        [0.3295, 0.6705],
        [0.3690, 0.6310],
        [0.6731, 0.3269],
        [0.5501, 0.4499],
        [0.2156, 0.7844],
        [0.3049, 0.6951],
        [0.4404, 0.5596]], device='cuda:0')

prompt tensor([[0.3670, 0.6330],
        [0.5198, 0.4802],
        [0.4612, 0.5388],
        [0.5723, 0.4277],
        [0.6130, 0.3870],
        [0.4527, 0.5473],
        [0.2149, 0.7851],
        [0.6069, 0.3931]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 525:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.9]train epoch: 525:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.97it/s, loss=24.9]train epoch: 525:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.97it/s, loss=34.2]train epoch: 525:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.27it/s, loss=34.2]train epoch: 525:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.27it/s, loss=25]  train epoch: 525:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.95it/s, loss=25]train epoch: 525:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.95it/s, loss=28]train epoch: 525:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.63it/s, loss=28]train epoch: 525:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.63it/s, loss=27.4]train epoch: 525:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.41it/s, loss=27.4]train epoch: 525:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.41it/s, loss=23.3]train epoch: 525:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=23.3]train epoch: 525:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.83it/s, loss=29.7]train epoch: 525:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.16it/s, loss=29.7]train epoch: 525:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.16it/s, loss=28.3]train epoch: 525: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.08it/s, loss=28.3]train epoch: 525: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=28.3]
[[032m2021-11-26 10:55:39,785[0m INFO] trainer.training_epoch Training epoch 525, num_steps 4208,  avg_loss: 27.6049, total_loss: 220.8392
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.45it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.66it/s]
[[032m2021-11-26 10:55:40,282[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:40,282[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:40,742[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:40,935[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 526:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 526:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.2]train epoch: 526:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=32.2]train epoch: 526:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.20it/s, loss=22.8]train epoch: 526:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.58it/s, loss=22.8]train epoch: 526:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.58it/s, loss=22.7]train epoch: 526:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.94it/s, loss=22.7]train epoch: 526:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.94it/s, loss=26.5]train epoch: 526:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=26.5]train epoch: 526:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=28.3]train epoch: 526:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=28.3]train epoch: 526:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=18.9]train epoch: 526:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.04it/s, loss=18.9]train epoch: 526:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.04it/s, loss=22.1]train epoch: 526:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=22.1]train epoch: 526:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=21.3]train epoch: 526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=21.3]train epoch: 526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.96it/s, loss=21.3]
[[032m2021-11-26 10:55:43,646[0m INFO] trainer.training_epoch Training epoch 526, num_steps 4216,  avg_loss: 24.3423, total_loss: 194.7383
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.58it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.84it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.74it/s]
[[032m2021-11-26 10:55:44,394[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:44,394[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:44,765[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:45,019[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 527:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 527:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.1]train epoch: 527:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.89it/s, loss=29.1]train epoch: 527:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.89it/s, loss=26.7]train epoch: 527:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.76it/s, loss=26.7]train epoch: 527:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.76it/s, loss=19.6]train epoch: 527:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.53it/s, loss=19.6]train epoch: 527:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.53it/s, loss=25.5]train epoch: 527:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.91it/s, loss=25.5]train epoch: 527:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.91it/s, loss=28.7]train epoch: 527:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s, loss=28.7]train epoch: 527:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s, loss=22.6]train epoch: 527:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.66it/s, loss=22.6]train epoch: 527:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.66it/s, loss=27.1]train epoch: 527:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.64it/s, loss=27.1]train epoch: 527:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.64it/s, loss=22.5]train epoch: 527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=22.5]train epoch: 527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=22.5]
[[032m2021-11-26 10:55:47,275[0m INFO] trainer.training_epoch Training epoch 527, num_steps 4224,  avg_loss: 25.2378, total_loss: 201.9024
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.67it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.71it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.54it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.74it/s]
[[032m2021-11-26 10:55:47,764[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:47,765[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:47,982[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:48,185[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 528:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 528:   0%|          | 0/8 [00:00<?, ?it/s, loss=34.3]train epoch: 528:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=34.3]train epoch: 528:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=21.8]train epoch: 528:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.01it/s, loss=21.8]train epoch: 528:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.01it/s, loss=30.8]train epoch: 528:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=30.8]train epoch: 528:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.21it/s, loss=29.8]train epoch: 528:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.71it/s, loss=29.8]train epoch: 528:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.71it/s, loss=24]  train epoch: 528:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.22it/s, loss=24]train epoch: 528:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.22it/s, loss=28.8]train epoch: 528:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.70it/s, loss=28.8]train epoch: 528:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.70it/s, loss=29.7]train epoch: 528:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=29.7]train epoch: 528:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.00it/s, loss=19.6]train epoch: 528: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=19.6]train epoch: 528: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=19.6]
[[032m2021-11-26 10:55:50,580[0m INFO] trainer.training_epoch Training epoch 528, num_steps 4232,  avg_loss: 27.3553, total_loss: 218.8427
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.96it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.91it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.12it/s]
[[032m2021-11-26 10:55:51,160[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:51,161[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:51,432[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:51,645[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 529:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 529:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.7]train epoch: 529:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.34it/s, loss=21.7]train epoch: 529:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.34it/s, loss=21.4]train epoch: 529:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.81it/s, loss=21.4]train epoch: 529:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.81it/s, loss=27]  train epoch: 529:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.62it/s, loss=27]train epoch: 529:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.62it/s, loss=31.8]train epoch: 529:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=31.8]train epoch: 529:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=23.8]train epoch: 529:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.86it/s, loss=23.8]train epoch: 529:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.86it/s, loss=24.4]train epoch: 529:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.45it/s, loss=24.4]train epoch: 529:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.45it/s, loss=27.6]train epoch: 529:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=27.6]train epoch: 529:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.71it/s, loss=26]  train epoch: 529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.66it/s, loss=26]train epoch: 529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.84it/s, loss=26]
[[032m2021-11-26 10:55:54,483[0m INFO] trainer.training_epoch Training epoch 529, num_steps 4240,  avg_loss: 25.4538, total_loss: 203.6305
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.92it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.16it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.05it/s]
[[032m2021-11-26 10:55:55,129[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:55,134[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:55,356[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:55,654[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 530:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 530:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.9]train epoch: 530:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.24it/s, loss=23.9]train epoch: 530:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.24it/s, loss=26.7]train epoch: 530:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.04it/s, loss=26.7]train epoch: 530:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.04it/s, loss=30]  train epoch: 530:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.81it/s, loss=30]train epoch: 530:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.81it/s, loss=17.9]train epoch: 530:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=17.9]train epoch: 530:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=21.6]train epoch: 530:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=21.6]train epoch: 530:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=34.7]train epoch: 530:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.44it/s, loss=34.7]train epoch: 530:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.44it/s, loss=32.7]train epoch: 530:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.84it/s, loss=32.7]train epoch: 530:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.84it/s, loss=31.5]train epoch: 530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.77it/s, loss=31.5]train epoch: 530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.67it/s, loss=31.5]
[[032m2021-11-26 10:55:57,841[0m INFO] trainer.training_epoch Training epoch 530, num_steps 4248,  avg_loss: 27.3788, total_loss: 219.0304
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.75it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.42it/s]
[[032m2021-11-26 10:55:58,668[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:55:58,668[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:55:59,146[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:55:59,295[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 531:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 531:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.7]train epoch: 531:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.98it/s, loss=31.7]train epoch: 531:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.98it/s, loss=25.5]train epoch: 531:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.65it/s, loss=25.5]train epoch: 531:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.65it/s, loss=27.6]train epoch: 531:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=27.6]train epoch: 531:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.52it/s, loss=32.3]train epoch: 531:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=32.3]train epoch: 531:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=21.2]train epoch: 531:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.42it/s, loss=21.2]train epoch: 531:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.42it/s, loss=32]  train epoch: 531:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.84it/s, loss=32]train epoch: 531:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.84it/s, loss=27.3]train epoch: 531:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=27.3]train epoch: 531:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  3.05it/s, loss=30.5]train epoch: 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.37it/s, loss=30.5]train epoch: 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.62it/s, loss=30.5]
[[032m2021-11-26 10:56:02,352[0m INFO] trainer.training_epoch Training epoch 531, num_steps 4256,  avg_loss: 28.5054, total_loss: 228.0433
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.42it/s]
[[032m2021-11-26 10:56:02,899[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:02,899[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:03,290[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:03,421[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 532:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 532:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.2]train epoch: 532:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.84it/s, loss=24.2]train epoch: 532:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.84it/s, loss=26.5]train epoch: 532:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=26.5]train epoch: 532:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.00it/s, loss=22]  train epoch: 532:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=22]train epoch: 532:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.00it/s, loss=26.3]train epoch: 532:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=26.3]train epoch: 532:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.03it/s, loss=26.9]train epoch: 532:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=26.9]train epoch: 532:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=26.7]train epoch: 532:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s, loss=26.7]train epoch: 532:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.33it/s, loss=23.4]train epoch: 532:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.04it/s, loss=23.4]train epoch: 532:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.04it/s, loss=24.6]train epoch: 532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s, loss=24.6]train epoch: 532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=24.6]
[[032m2021-11-26 10:56:05,897[0m INFO] trainer.training_epoch Training epoch 532, num_steps 4264,  avg_loss: 25.0665, total_loss: 200.5319
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.39it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.31it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.03it/s]
[[032m2021-11-26 10:56:06,741[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:06,741[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:06,980[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:07,170[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 533:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 533:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 533:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.97it/s, loss=25]train epoch: 533:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.97it/s, loss=33.9]train epoch: 533:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.47it/s, loss=33.9]train epoch: 533:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.47it/s, loss=30.3]train epoch: 533:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.78it/s, loss=30.3]train epoch: 533:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.78it/s, loss=23.8]train epoch: 533:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=23.8]train epoch: 533:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.78it/s, loss=22.9]train epoch: 533:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=22.9]train epoch: 533:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=26.1]train epoch: 533:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.42it/s, loss=26.1]train epoch: 533:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.42it/s, loss=30.8]train epoch: 533:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=30.8]train epoch: 533:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=23.7]train epoch: 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.06it/s, loss=23.7]train epoch: 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=23.7]
[[032m2021-11-26 10:56:09,857[0m INFO] trainer.training_epoch Training epoch 533, num_steps 4272,  avg_loss: 27.0677, total_loss: 216.5417
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.75it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.13it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.36it/s]
[[032m2021-11-26 10:56:10,449[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:10,450[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:10,706[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:10,882[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 534:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 534:   0%|          | 0/8 [00:00<?, ?it/s, loss=33.1]train epoch: 534:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.81it/s, loss=33.1]train epoch: 534:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.81it/s, loss=26.8]train epoch: 534:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.11it/s, loss=26.8]train epoch: 534:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.11it/s, loss=27.4]train epoch: 534:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.47it/s, loss=27.4]train epoch: 534:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.47it/s, loss=22.7]train epoch: 534:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.08it/s, loss=22.7]train epoch: 534:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.08it/s, loss=23]  train epoch: 534:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=23]train epoch: 534:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.33it/s, loss=19.3]train epoch: 534:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.00it/s, loss=19.3]train epoch: 534:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.00it/s, loss=21.4]train epoch: 534:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=21.4]train epoch: 534:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=26.6]train epoch: 534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=26.6]train epoch: 534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s, loss=26.6]
[[032m2021-11-26 10:56:13,354[0m INFO] trainer.training_epoch Training epoch 534, num_steps 4280,  avg_loss: 25.0303, total_loss: 200.2423
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.64it/s]
[[032m2021-11-26 10:56:13,992[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:13,992[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:14,238[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:14,389[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 535:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 535:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.7]train epoch: 535:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.00it/s, loss=20.7]train epoch: 535:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.00it/s, loss=29.1]train epoch: 535:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.52it/s, loss=29.1]train epoch: 535:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.52it/s, loss=33.5]train epoch: 535:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.35it/s, loss=33.5]train epoch: 535:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.35it/s, loss=28.2]train epoch: 535:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.69it/s, loss=28.2]train epoch: 535:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.69it/s, loss=26.1]train epoch: 535:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.54it/s, loss=26.1]train epoch: 535:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.54it/s, loss=31.8]train epoch: 535:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=31.8]train epoch: 535:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=33.7]train epoch: 535:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=33.7]train epoch: 535:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.05it/s, loss=29.1]train epoch: 535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.85it/s, loss=29.1]train epoch: 535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.78it/s, loss=29.1]
[[032m2021-11-26 10:56:17,273[0m INFO] trainer.training_epoch Training epoch 535, num_steps 4288,  avg_loss: 29.0376, total_loss: 232.3010
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.98it/s]
[[032m2021-11-26 10:56:17,877[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:17,877[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:18,419[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:18,552[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 536:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 536:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.4]train epoch: 536:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.13it/s, loss=37.4]train epoch: 536:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.13it/s, loss=28.8]train epoch: 536:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.82it/s, loss=28.8]train epoch: 536:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.82it/s, loss=27.3]train epoch: 536:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=27.3]train epoch: 536:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.41it/s, loss=24.7]train epoch: 536:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=24.7]train epoch: 536:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.70it/s, loss=29.8]train epoch: 536:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=29.8]train epoch: 536:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=32.3]train epoch: 536:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.47it/s, loss=32.3]train epoch: 536:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.47it/s, loss=26.3]train epoch: 536:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.64it/s, loss=26.3]train epoch: 536:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.64it/s, loss=22.5]train epoch: 536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=22.5]train epoch: 536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s, loss=22.5]
[[032m2021-11-26 10:56:21,099[0m INFO] trainer.training_epoch Training epoch 536, num_steps 4296,  avg_loss: 28.6351, total_loss: 229.0804
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.96it/s]
[[032m2021-11-26 10:56:21,568[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:21,568[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:22,001[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:22,140[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 537:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 537:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.6]train epoch: 537:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=21.6]train epoch: 537:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.71it/s, loss=27.6]train epoch: 537:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.65it/s, loss=27.6]train epoch: 537:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.65it/s, loss=27.5]train epoch: 537:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.33it/s, loss=27.5]train epoch: 537:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.33it/s, loss=25.4]train epoch: 537:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=25.4]
model tensor([[0.3489, 0.6511],
        [0.8361, 0.1639],
        [0.3295, 0.6705],
        [0.4593, 0.5407],
        [0.7036, 0.2964],
        [0.3884, 0.6116],
        [0.3498, 0.6502],
        [0.2156, 0.7844]], device='cuda:0')

prompt tensor([[0.5759, 0.4241],
        [0.8928, 0.1072],
        [0.3396, 0.6604],
        [0.5905, 0.4095],
        [0.5210, 0.4790],
        [0.3565, 0.6435],
        [0.5474, 0.4526],
        [0.3562, 0.6438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 537:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s, loss=31.1]train epoch: 537:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.25it/s, loss=31.1]train epoch: 537:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.25it/s, loss=27.8]train epoch: 537:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=27.8]train epoch: 537:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.55it/s, loss=24]  train epoch: 537:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.47it/s, loss=24]train epoch: 537:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.47it/s, loss=21]train epoch: 537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.40it/s, loss=21]train epoch: 537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.58it/s, loss=21]
[[032m2021-11-26 10:56:25,241[0m INFO] trainer.training_epoch Training epoch 537, num_steps 4304,  avg_loss: 25.7654, total_loss: 206.1231
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.08it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.44it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.25it/s]
[[032m2021-11-26 10:56:26,044[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:26,044[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:26,365[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:26,553[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 538:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 538:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.8]train epoch: 538:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=26.8]train epoch: 538:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.40it/s, loss=28.7]train epoch: 538:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.45it/s, loss=28.7]train epoch: 538:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.45it/s, loss=22.9]train epoch: 538:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=22.9]train epoch: 538:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=26.4]train epoch: 538:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=26.4]train epoch: 538:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=27]  train epoch: 538:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=27]train epoch: 538:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.15it/s, loss=25.7]train epoch: 538:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=25.7]train epoch: 538:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.22it/s, loss=32.7]train epoch: 538:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.34it/s, loss=32.7]train epoch: 538:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.34it/s, loss=25.2]train epoch: 538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.30it/s, loss=25.2]train epoch: 538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s, loss=25.2]
[[032m2021-11-26 10:56:29,190[0m INFO] trainer.training_epoch Training epoch 538, num_steps 4312,  avg_loss: 26.9428, total_loss: 215.5422
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.42it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.05it/s]
[[032m2021-11-26 10:56:29,700[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:29,700[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:29,991[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:30,158[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 539:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 539:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 539:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.42it/s, loss=29.8]train epoch: 539:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.42it/s, loss=27.1]train epoch: 539:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.39it/s, loss=27.1]train epoch: 539:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.39it/s, loss=27.9]train epoch: 539:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.12it/s, loss=27.9]train epoch: 539:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.12it/s, loss=20.5]train epoch: 539:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=20.5]train epoch: 539:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.02it/s, loss=18.6]train epoch: 539:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.34it/s, loss=18.6]train epoch: 539:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.34it/s, loss=19.2]train epoch: 539:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s, loss=19.2]train epoch: 539:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.38it/s, loss=31.1]train epoch: 539:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=31.1]train epoch: 539:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.08it/s, loss=25.4]train epoch: 539: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s, loss=25.4]train epoch: 539: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s, loss=25.4]
[[032m2021-11-26 10:56:32,689[0m INFO] trainer.training_epoch Training epoch 539, num_steps 4320,  avg_loss: 24.9594, total_loss: 199.6755
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.53it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.70it/s]
[[032m2021-11-26 10:56:33,433[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:33,433[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:33,759[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:33,965[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 540:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 540:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.5]train epoch: 540:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.53it/s, loss=23.5]train epoch: 540:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.53it/s, loss=33.7]train epoch: 540:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.52it/s, loss=33.7]train epoch: 540:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.52it/s, loss=33.3]train epoch: 540:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.92it/s, loss=33.3]train epoch: 540:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.92it/s, loss=28.4]train epoch: 540:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=28.4]train epoch: 540:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.16it/s, loss=30.9]train epoch: 540:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.64it/s, loss=30.9]train epoch: 540:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.64it/s, loss=22.1]train epoch: 540:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=22.1]train epoch: 540:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.85it/s, loss=20.4]train epoch: 540:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=20.4]train epoch: 540:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.89it/s, loss=20.6]train epoch: 540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s, loss=20.6]train epoch: 540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.87it/s, loss=20.6]
[[032m2021-11-26 10:56:36,757[0m INFO] trainer.training_epoch Training epoch 540, num_steps 4328,  avg_loss: 26.6147, total_loss: 212.9176
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.92it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.45it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.44it/s]
[[032m2021-11-26 10:56:37,530[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:37,530[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:37,788[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:37,994[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 541:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 541:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.6]train epoch: 541:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.91it/s, loss=21.6]train epoch: 541:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.91it/s, loss=21.2]train epoch: 541:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.24it/s, loss=21.2]train epoch: 541:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.24it/s, loss=23.2]train epoch: 541:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.63it/s, loss=23.2]train epoch: 541:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.63it/s, loss=26.4]train epoch: 541:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.09it/s, loss=26.4]train epoch: 541:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.09it/s, loss=29.6]train epoch: 541:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=29.6]train epoch: 541:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=29]  train epoch: 541:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.04it/s, loss=29]train epoch: 541:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.04it/s, loss=24.3]train epoch: 541:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=24.3]train epoch: 541:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=33.5]train epoch: 541: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s, loss=33.5]train epoch: 541: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.96it/s, loss=33.5]
[[032m2021-11-26 10:56:40,715[0m INFO] trainer.training_epoch Training epoch 541, num_steps 4336,  avg_loss: 26.0976, total_loss: 208.7809
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.90it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.77it/s]
[[032m2021-11-26 10:56:41,229[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:41,229[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:41,936[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:42,240[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 542:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 542:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.6]train epoch: 542:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.26it/s, loss=24.6]train epoch: 542:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.26it/s, loss=25.1]train epoch: 542:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.84it/s, loss=25.1]train epoch: 542:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.84it/s, loss=25.1]train epoch: 542:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.99it/s, loss=25.1]train epoch: 542:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.99it/s, loss=20.9]train epoch: 542:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=20.9]train epoch: 542:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=28.5]train epoch: 542:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.34it/s, loss=28.5]train epoch: 542:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.34it/s, loss=30.1]train epoch: 542:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.01it/s, loss=30.1]train epoch: 542:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.01it/s, loss=24.4]train epoch: 542:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=24.4]train epoch: 542:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s, loss=25.8]train epoch: 542: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=25.8]train epoch: 542: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s, loss=25.8]
[[032m2021-11-26 10:56:44,787[0m INFO] trainer.training_epoch Training epoch 542, num_steps 4344,  avg_loss: 25.5607, total_loss: 204.4858
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.89it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.39it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.49it/s]
[[032m2021-11-26 10:56:45,461[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:45,461[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:45,943[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:46,064[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 543:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 543:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.3]train epoch: 543:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=23.3]train epoch: 543:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.18it/s, loss=29.6]train epoch: 543:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=29.6]train epoch: 543:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=30.8]train epoch: 543:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.72it/s, loss=30.8]train epoch: 543:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.72it/s, loss=18.8]train epoch: 543:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=18.8]train epoch: 543:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.11it/s, loss=32.7]train epoch: 543:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s, loss=32.7]train epoch: 543:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s, loss=27.1]train epoch: 543:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.52it/s, loss=27.1]train epoch: 543:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.52it/s, loss=29.9]train epoch: 543:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.70it/s, loss=29.9]train epoch: 543:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.70it/s, loss=23.2]train epoch: 543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=23.2]train epoch: 543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.61it/s, loss=23.2]
[[032m2021-11-26 10:56:48,284[0m INFO] trainer.training_epoch Training epoch 543, num_steps 4352,  avg_loss: 26.9068, total_loss: 215.2542
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.42it/s]
[[032m2021-11-26 10:56:48,729[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:48,730[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:49,036[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:49,202[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 544:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 544:   0%|          | 0/8 [00:00<?, ?it/s, loss=24]train epoch: 544:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=24]train epoch: 544:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=24.8]train epoch: 544:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=24.8]train epoch: 544:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.49it/s, loss=33.6]train epoch: 544:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.30it/s, loss=33.6]train epoch: 544:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.30it/s, loss=33]  train epoch: 544:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=33]train epoch: 544:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=30.3]train epoch: 544:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.47it/s, loss=30.3]train epoch: 544:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.47it/s, loss=30.7]train epoch: 544:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.61it/s, loss=30.7]train epoch: 544:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.61it/s, loss=22.9]train epoch: 544:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.79it/s, loss=22.9]train epoch: 544:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.79it/s, loss=25.4]train epoch: 544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.09it/s, loss=25.4]train epoch: 544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s, loss=25.4]
[[032m2021-11-26 10:56:51,749[0m INFO] trainer.training_epoch Training epoch 544, num_steps 4360,  avg_loss: 28.0846, total_loss: 224.6764
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.46it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.25it/s]
[[032m2021-11-26 10:56:52,334[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:52,335[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:53,215[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:53,435[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 545:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 545:   0%|          | 0/8 [00:00<?, ?it/s, loss=22]train epoch: 545:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.47it/s, loss=22]train epoch: 545:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.47it/s, loss=27.1]train epoch: 545:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.39it/s, loss=27.1]train epoch: 545:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.39it/s, loss=34.2]train epoch: 545:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.51it/s, loss=34.2]train epoch: 545:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.51it/s, loss=25.6]train epoch: 545:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s, loss=25.6]train epoch: 545:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s, loss=37.8]train epoch: 545:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.02it/s, loss=37.8]train epoch: 545:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.02it/s, loss=24.2]train epoch: 545:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=24.2]train epoch: 545:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=36.3]train epoch: 545:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=36.3]train epoch: 545:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.81it/s, loss=23.9]train epoch: 545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s, loss=23.9]train epoch: 545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.09it/s, loss=23.9]
[[032m2021-11-26 10:56:56,029[0m INFO] trainer.training_epoch Training epoch 545, num_steps 4368,  avg_loss: 28.8973, total_loss: 231.1782
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.18it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.94it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.54it/s]
[[032m2021-11-26 10:56:56,774[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:56,774[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:56:57,172[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:56:57,288[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 546:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 546:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.4]train epoch: 546:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=25.4]train epoch: 546:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=21.4]train epoch: 546:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.82it/s, loss=21.4]train epoch: 546:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.82it/s, loss=28.2]train epoch: 546:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.51it/s, loss=28.2]train epoch: 546:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.51it/s, loss=29.5]train epoch: 546:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.30it/s, loss=29.5]train epoch: 546:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.30it/s, loss=28.1]train epoch: 546:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=28.1]train epoch: 546:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=28.3]train epoch: 546:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=28.3]train epoch: 546:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.68it/s, loss=18.1]train epoch: 546:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.68it/s, loss=18.1]train epoch: 546:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.68it/s, loss=31.1]train epoch: 546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=31.1]train epoch: 546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.66it/s, loss=31.1]
[[032m2021-11-26 10:56:59,481[0m INFO] trainer.training_epoch Training epoch 546, num_steps 4376,  avg_loss: 26.2437, total_loss: 209.9493
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.10it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.14it/s]
[[032m2021-11-26 10:56:59,945[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:56:59,945[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:00,324[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:00,586[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 547:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 547:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.8]train epoch: 547:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.37it/s, loss=28.8]train epoch: 547:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.37it/s, loss=27.1]train epoch: 547:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=27.1]train epoch: 547:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.72it/s, loss=32.2]train epoch: 547:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.59it/s, loss=32.2]train epoch: 547:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.59it/s, loss=23.3]train epoch: 547:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=23.3]train epoch: 547:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=23.9]train epoch: 547:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.64it/s, loss=23.9]train epoch: 547:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.64it/s, loss=19.7]train epoch: 547:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.40it/s, loss=19.7]train epoch: 547:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.40it/s, loss=36.7]train epoch: 547:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.69it/s, loss=36.7]train epoch: 547:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.69it/s, loss=32.8]train epoch: 547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.69it/s, loss=32.8]train epoch: 547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.78it/s, loss=32.8]
[[032m2021-11-26 10:57:03,474[0m INFO] trainer.training_epoch Training epoch 547, num_steps 4384,  avg_loss: 28.0595, total_loss: 224.4761
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.83it/s]
[[032m2021-11-26 10:57:04,075[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:04,075[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:04,326[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:04,585[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 548:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 548:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.6]train epoch: 548:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=20.6]train epoch: 548:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.57it/s, loss=26.1]train epoch: 548:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=26.1]train epoch: 548:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.97it/s, loss=29.3]train epoch: 548:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.28it/s, loss=29.3]train epoch: 548:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.28it/s, loss=24.9]train epoch: 548:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.27it/s, loss=24.9]train epoch: 548:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.27it/s, loss=20.9]train epoch: 548:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=20.9]train epoch: 548:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.42it/s, loss=30.7]train epoch: 548:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.21it/s, loss=30.7]train epoch: 548:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.21it/s, loss=27.5]train epoch: 548:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.46it/s, loss=27.5]train epoch: 548:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.46it/s, loss=34.6]train epoch: 548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s, loss=34.6]train epoch: 548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=34.6]
[[032m2021-11-26 10:57:06,892[0m INFO] trainer.training_epoch Training epoch 548, num_steps 4392,  avg_loss: 26.8050, total_loss: 214.4396
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.66it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.96it/s]
[[032m2021-11-26 10:57:07,442[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:07,442[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:08,102[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:08,231[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 549:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 549:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.2]train epoch: 549:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.74it/s, loss=20.2]train epoch: 549:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.74it/s, loss=28.4]train epoch: 549:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.43it/s, loss=28.4]train epoch: 549:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.43it/s, loss=25.6]train epoch: 549:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.39it/s, loss=25.6]train epoch: 549:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.39it/s, loss=18.8]train epoch: 549:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.45it/s, loss=18.8]train epoch: 549:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.45it/s, loss=27.5]train epoch: 549:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.80it/s, loss=27.5]train epoch: 549:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.80it/s, loss=27.2]train epoch: 549:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=27.2]train epoch: 549:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=38.4]train epoch: 549:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=38.4]train epoch: 549:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=21]  train epoch: 549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=21]train epoch: 549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s, loss=21]
[[032m2021-11-26 10:57:10,788[0m INFO] trainer.training_epoch Training epoch 549, num_steps 4400,  avg_loss: 25.8854, total_loss: 207.0830
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.08it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.46it/s]
[[032m2021-11-26 10:57:11,290[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:57:11,290[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:11,537[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 550:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.4383, 0.5617],
        [0.5501, 0.4499],
        [0.6761, 0.3239],
        [0.5258, 0.4742],
        [0.5445, 0.4555],
        [0.5702, 0.4298],
        [0.6717, 0.3283],
        [0.3489, 0.6511]], device='cuda:0')

prompt tensor([[0.3277, 0.6723],
        [0.4866, 0.5134],
        [0.7422, 0.2578],
        [0.4158, 0.5842],
        [0.5600, 0.4400],
        [0.5607, 0.4393],
        [0.8065, 0.1935],
        [0.4474, 0.5526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 550:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.1]train epoch: 550:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=31.1]train epoch: 550:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=21.7]train epoch: 550:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=21.7]train epoch: 550:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.08it/s, loss=25.6]train epoch: 550:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=25.6]train epoch: 550:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.15it/s, loss=23.4]train epoch: 550:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.04it/s, loss=23.4]train epoch: 550:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.04it/s, loss=38.7]train epoch: 550:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.54it/s, loss=38.7]train epoch: 550:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.54it/s, loss=36.5]train epoch: 550:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=36.5]train epoch: 550:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=24.5]train epoch: 550:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.31it/s, loss=24.5]train epoch: 550:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.31it/s, loss=23.6]train epoch: 550: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=23.6]train epoch: 550: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=23.6]
[[032m2021-11-26 10:57:13,789[0m INFO] trainer.training_epoch Training epoch 550, num_steps 4408,  avg_loss: 28.1447, total_loss: 225.1577
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.81it/s]
[[032m2021-11-26 10:57:14,267[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:57:14,268[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:14,667[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 551:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 551:   0%|          | 0/8 [00:00<?, ?it/s, loss=25]train epoch: 551:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.70it/s, loss=25]train epoch: 551:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.70it/s, loss=24.7]train epoch: 551:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.89it/s, loss=24.7]train epoch: 551:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.89it/s, loss=30.4]train epoch: 551:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.31it/s, loss=30.4]train epoch: 551:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.31it/s, loss=26.3]train epoch: 551:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.49it/s, loss=26.3]train epoch: 551:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.49it/s, loss=29.1]train epoch: 551:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=29.1]train epoch: 551:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=29.3]train epoch: 551:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.41it/s, loss=29.3]train epoch: 551:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.41it/s, loss=19.7]train epoch: 551:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.47it/s, loss=19.7]train epoch: 551:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.47it/s, loss=21.5]train epoch: 551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s, loss=21.5]train epoch: 551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.76it/s, loss=21.5]
[[032m2021-11-26 10:57:17,573[0m INFO] trainer.training_epoch Training epoch 551, num_steps 4416,  avg_loss: 25.7414, total_loss: 205.9309
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.10it/s]
[[032m2021-11-26 10:57:18,054[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:18,054[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:18,524[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:18,756[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 552:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 552:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.8]train epoch: 552:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.90it/s, loss=31.8]train epoch: 552:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  1.90it/s, loss=29.9]train epoch: 552:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.71it/s, loss=29.9]train epoch: 552:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.71it/s, loss=32.9]train epoch: 552:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.15it/s, loss=32.9]train epoch: 552:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.15it/s, loss=22.2]train epoch: 552:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=22.2]train epoch: 552:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.82it/s, loss=21.5]train epoch: 552:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.59it/s, loss=21.5]train epoch: 552:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.59it/s, loss=29.5]train epoch: 552:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=29.5]train epoch: 552:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.71it/s, loss=27.2]train epoch: 552:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=27.2]train epoch: 552:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.63it/s, loss=26.9]train epoch: 552: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.89it/s, loss=26.9]train epoch: 552: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s, loss=26.9]
[[032m2021-11-26 10:57:21,681[0m INFO] trainer.training_epoch Training epoch 552, num_steps 4424,  avg_loss: 27.7487, total_loss: 221.9899
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.00it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.41it/s]
[[032m2021-11-26 10:57:22,459[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:22,459[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:22,892[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:23,043[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 553:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 553:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.2]train epoch: 553:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=30.2]train epoch: 553:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.50it/s, loss=29.7]train epoch: 553:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.02it/s, loss=29.7]train epoch: 553:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.02it/s, loss=25]  train epoch: 553:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.72it/s, loss=25]train epoch: 553:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.72it/s, loss=26.3]train epoch: 553:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=26.3]train epoch: 553:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=27.8]train epoch: 553:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=27.8]train epoch: 553:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.09it/s, loss=27.2]train epoch: 553:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.28it/s, loss=27.2]train epoch: 553:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.28it/s, loss=30]  train epoch: 553:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=30]train epoch: 553:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=23.5]train epoch: 553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=23.5]train epoch: 553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=23.5]
[[032m2021-11-26 10:57:25,303[0m INFO] trainer.training_epoch Training epoch 553, num_steps 4432,  avg_loss: 27.4827, total_loss: 219.8614
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.15it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.49it/s]
[[032m2021-11-26 10:57:26,176[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:26,176[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:26,595[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:26,753[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 554:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 554:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.1]train epoch: 554:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.38it/s, loss=29.1]train epoch: 554:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.38it/s, loss=31.2]train epoch: 554:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.66it/s, loss=31.2]train epoch: 554:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.66it/s, loss=29.9]train epoch: 554:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.12it/s, loss=29.9]train epoch: 554:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.12it/s, loss=29.2]train epoch: 554:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=29.2]train epoch: 554:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.90it/s, loss=27.7]train epoch: 554:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=27.7]train epoch: 554:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=35.3]train epoch: 554:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.07it/s, loss=35.3]train epoch: 554:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.07it/s, loss=20.1]train epoch: 554:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=20.1]train epoch: 554:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.86it/s, loss=25.1]train epoch: 554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=25.1]train epoch: 554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s, loss=25.1]
[[032m2021-11-26 10:57:29,390[0m INFO] trainer.training_epoch Training epoch 554, num_steps 4440,  avg_loss: 28.4382, total_loss: 227.5056
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.06it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.97it/s]
[[032m2021-11-26 10:57:30,181[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:30,181[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:30,525[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:30,648[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 555:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 555:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.9]train epoch: 555:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.02it/s, loss=30.9]train epoch: 555:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.02it/s, loss=29.9]train epoch: 555:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.54it/s, loss=29.9]train epoch: 555:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.54it/s, loss=24.2]train epoch: 555:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.13it/s, loss=24.2]train epoch: 555:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.13it/s, loss=26.1]train epoch: 555:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=26.1]train epoch: 555:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=30.8]train epoch: 555:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.02it/s, loss=30.8]train epoch: 555:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.02it/s, loss=21.3]train epoch: 555:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s, loss=21.3]train epoch: 555:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.38it/s, loss=18.9]train epoch: 555:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.71it/s, loss=18.9]train epoch: 555:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.71it/s, loss=28.1]train epoch: 555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s, loss=28.1]train epoch: 555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=28.1]
[[032m2021-11-26 10:57:33,026[0m INFO] trainer.training_epoch Training epoch 555, num_steps 4448,  avg_loss: 26.2898, total_loss: 210.3185
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.71it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.09it/s]
[[032m2021-11-26 10:57:33,766[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:33,766[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:34,100[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:34,333[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 556:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 556:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 556:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.60it/s, loss=23.6]train epoch: 556:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.60it/s, loss=22.8]train epoch: 556:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.77it/s, loss=22.8]train epoch: 556:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.77it/s, loss=22.6]train epoch: 556:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.67it/s, loss=22.6]train epoch: 556:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.67it/s, loss=21.7]train epoch: 556:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=21.7]train epoch: 556:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=33.2]train epoch: 556:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=33.2]train epoch: 556:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=26.4]train epoch: 556:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.25it/s, loss=26.4]train epoch: 556:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.25it/s, loss=26.7]train epoch: 556:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.47it/s, loss=26.7]train epoch: 556:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.47it/s, loss=21.4]train epoch: 556: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=21.4]train epoch: 556: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=21.4]
[[032m2021-11-26 10:57:36,792[0m INFO] trainer.training_epoch Training epoch 556, num_steps 4456,  avg_loss: 24.8200, total_loss: 198.5600
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.11it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.57it/s]
[[032m2021-11-26 10:57:37,359[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:37,363[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:37,826[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:38,139[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 557:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 557:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.4]train epoch: 557:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.06it/s, loss=22.4]train epoch: 557:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.06it/s, loss=22]  train epoch: 557:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.61it/s, loss=22]train epoch: 557:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.61it/s, loss=28]train epoch: 557:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.38it/s, loss=28]train epoch: 557:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.38it/s, loss=26.7]train epoch: 557:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=26.7]train epoch: 557:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.58it/s, loss=20.4]train epoch: 557:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=20.4]train epoch: 557:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.01it/s, loss=35.7]train epoch: 557:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.32it/s, loss=35.7]train epoch: 557:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.32it/s, loss=27.9]train epoch: 557:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.73it/s, loss=27.9]train epoch: 557:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.73it/s, loss=33.6]train epoch: 557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.48it/s, loss=33.6]train epoch: 557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.66it/s, loss=33.6]
[[032m2021-11-26 10:57:41,169[0m INFO] trainer.training_epoch Training epoch 557, num_steps 4464,  avg_loss: 27.0813, total_loss: 216.6504
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.38it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.15it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.46it/s]
[[032m2021-11-26 10:57:41,725[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:41,725[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:41,976[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:42,186[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 558:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 558:   0%|          | 0/8 [00:00<?, ?it/s, loss=37.2]train epoch: 558:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.90it/s, loss=37.2]train epoch: 558:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.90it/s, loss=34.4]train epoch: 558:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.67it/s, loss=34.4]train epoch: 558:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.67it/s, loss=29.8]train epoch: 558:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.02it/s, loss=29.8]train epoch: 558:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.02it/s, loss=30.9]train epoch: 558:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.24it/s, loss=30.9]train epoch: 558:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.24it/s, loss=24.7]train epoch: 558:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.49it/s, loss=24.7]train epoch: 558:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.49it/s, loss=27.5]train epoch: 558:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.83it/s, loss=27.5]train epoch: 558:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.83it/s, loss=27.8]train epoch: 558:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.02it/s, loss=27.8]train epoch: 558:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.02it/s, loss=22.5]train epoch: 558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=22.5]train epoch: 558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.38it/s, loss=22.5]
[[032m2021-11-26 10:57:44,557[0m INFO] trainer.training_epoch Training epoch 558, num_steps 4472,  avg_loss: 29.3564, total_loss: 234.8514
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.08it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.00it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.48it/s]
[[032m2021-11-26 10:57:45,361[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:45,361[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:45,693[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:45,860[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 559:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 559:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.7]train epoch: 559:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=24.7]train epoch: 559:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=34.6]train epoch: 559:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.95it/s, loss=34.6]train epoch: 559:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.95it/s, loss=25.5]train epoch: 559:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  2.96it/s, loss=25.5]train epoch: 559:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.96it/s, loss=30.4]train epoch: 559:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=30.4]train epoch: 559:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=29.7]train epoch: 559:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.40it/s, loss=29.7]train epoch: 559:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.40it/s, loss=28.4]train epoch: 559:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=28.4]train epoch: 559:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=33.1]train epoch: 559:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=33.1]train epoch: 559:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.03it/s, loss=23.8]train epoch: 559: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.07it/s, loss=23.8]train epoch: 559: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.92it/s, loss=23.8]
[[032m2021-11-26 10:57:48,601[0m INFO] trainer.training_epoch Training epoch 559, num_steps 4480,  avg_loss: 28.7717, total_loss: 230.1739
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.29it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.30it/s]
[[032m2021-11-26 10:57:49,398[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:49,398[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:49,661[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:49,821[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 560:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 560:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.6]train epoch: 560:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=24.6]train epoch: 560:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.00it/s, loss=36.2]train epoch: 560:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.64it/s, loss=36.2]train epoch: 560:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.64it/s, loss=41.4]train epoch: 560:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.34it/s, loss=41.4]train epoch: 560:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.34it/s, loss=36.8]train epoch: 560:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.41it/s, loss=36.8]train epoch: 560:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.41it/s, loss=19.1]train epoch: 560:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.86it/s, loss=19.1]train epoch: 560:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.86it/s, loss=28.5]train epoch: 560:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.16it/s, loss=28.5]train epoch: 560:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.16it/s, loss=21.8]train epoch: 560:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=21.8]train epoch: 560:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.35it/s, loss=26.1]train epoch: 560: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=26.1]train epoch: 560: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.09it/s, loss=26.1]
[[032m2021-11-26 10:57:52,418[0m INFO] trainer.training_epoch Training epoch 560, num_steps 4488,  avg_loss: 29.3142, total_loss: 234.5136
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.14it/s]
[[032m2021-11-26 10:57:53,228[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:53,229[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:53,880[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:54,037[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 561:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 561:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.5]train epoch: 561:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.29it/s, loss=25.5]train epoch: 561:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.29it/s, loss=27]  train epoch: 561:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.75it/s, loss=27]train epoch: 561:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.75it/s, loss=39.6]train epoch: 561:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.35it/s, loss=39.6]train epoch: 561:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.35it/s, loss=26.5]train epoch: 561:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.29it/s, loss=26.5]train epoch: 561:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.29it/s, loss=28.9]train epoch: 561:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.54it/s, loss=28.9]train epoch: 561:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.54it/s, loss=22.3]train epoch: 561:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.91it/s, loss=22.3]train epoch: 561:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.91it/s, loss=31.4]train epoch: 561:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.75it/s, loss=31.4]train epoch: 561:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.75it/s, loss=28.4]train epoch: 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.60it/s, loss=28.4]train epoch: 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s, loss=28.4]
[[032m2021-11-26 10:57:57,103[0m INFO] trainer.training_epoch Training epoch 561, num_steps 4496,  avg_loss: 28.7176, total_loss: 229.7405
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.88it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.01it/s]
[[032m2021-11-26 10:57:57,697[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:57:57,697[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:57:58,013[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:57:58,158[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 562:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 562:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.6]train epoch: 562:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.30it/s, loss=22.6]train epoch: 562:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.30it/s, loss=24.1]train epoch: 562:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.66it/s, loss=24.1]train epoch: 562:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.66it/s, loss=22.9]train epoch: 562:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.15it/s, loss=22.9]train epoch: 562:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.15it/s, loss=27.3]train epoch: 562:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=27.3]
model tensor([[0.4593, 0.5407],
        [0.3053, 0.6947],
        [0.5501, 0.4499],
        [0.4201, 0.5799],
        [0.7645, 0.2355],
        [0.4587, 0.5413],
        [0.5951, 0.4049],
        [0.7036, 0.2964]], device='cuda:0')

prompt tensor([[0.5335, 0.4665],
        [0.3415, 0.6585],
        [0.6438, 0.3562],
        [0.5196, 0.4804],
        [0.6374, 0.3626],
        [0.3798, 0.6202],
        [0.4175, 0.5825],
        [0.6056, 0.3944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 562:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.86it/s, loss=27.4]train epoch: 562:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=27.4]train epoch: 562:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.98it/s, loss=33.4]train epoch: 562:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.69it/s, loss=33.4]train epoch: 562:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.69it/s, loss=31.4]train epoch: 562:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=31.4]train epoch: 562:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.92it/s, loss=30.8]train epoch: 562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.74it/s, loss=30.8]train epoch: 562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s, loss=30.8]
[[032m2021-11-26 10:58:01,031[0m INFO] trainer.training_epoch Training epoch 562, num_steps 4504,  avg_loss: 27.4850, total_loss: 219.8802
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.37it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.04it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.26it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.64it/s]
[[032m2021-11-26 10:58:01,704[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:01,704[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:01,915[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:02,466[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 563:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 563:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.5]train epoch: 563:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=31.5]train epoch: 563:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.60it/s, loss=29.1]train epoch: 563:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.75it/s, loss=29.1]train epoch: 563:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.75it/s, loss=22.3]train epoch: 563:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.37it/s, loss=22.3]train epoch: 563:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.37it/s, loss=28.1]train epoch: 563:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.55it/s, loss=28.1]train epoch: 563:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.55it/s, loss=18.9]train epoch: 563:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.65it/s, loss=18.9]train epoch: 563:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.65it/s, loss=29.9]train epoch: 563:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=29.9]train epoch: 563:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.67it/s, loss=25.6]train epoch: 563:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.58it/s, loss=25.6]train epoch: 563:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.58it/s, loss=21.9]train epoch: 563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s, loss=21.9]train epoch: 563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.87it/s, loss=21.9]
[[032m2021-11-26 10:58:05,269[0m INFO] trainer.training_epoch Training epoch 563, num_steps 4512,  avg_loss: 25.9196, total_loss: 207.3569
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.55it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.67it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.37it/s]
[[032m2021-11-26 10:58:05,841[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:05,842[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:06,589[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:06,704[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 564:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 564:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.6]train epoch: 564:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.98it/s, loss=20.6]train epoch: 564:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.98it/s, loss=28.1]train epoch: 564:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=28.1]train epoch: 564:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.16it/s, loss=28.2]train epoch: 564:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=28.2]train epoch: 564:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.16it/s, loss=24.7]train epoch: 564:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=24.7]train epoch: 564:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.23it/s, loss=31.5]train epoch: 564:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.02it/s, loss=31.5]train epoch: 564:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.02it/s, loss=24.6]train epoch: 564:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.03it/s, loss=24.6]train epoch: 564:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.03it/s, loss=28.5]train epoch: 564:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=28.5]train epoch: 564:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.28it/s, loss=31.5]train epoch: 564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=31.5]train epoch: 564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s, loss=31.5]
[[032m2021-11-26 10:58:09,015[0m INFO] trainer.training_epoch Training epoch 564, num_steps 4520,  avg_loss: 27.2097, total_loss: 217.6776
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.89it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.84it/s]
[[032m2021-11-26 10:58:09,612[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:09,613[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:10,147[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:10,293[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 565:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 565:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.4]train epoch: 565:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=32.4]train epoch: 565:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.85it/s, loss=29.3]train epoch: 565:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=29.3]train epoch: 565:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.29it/s, loss=27.7]train epoch: 565:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.18it/s, loss=27.7]train epoch: 565:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.18it/s, loss=28.2]train epoch: 565:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=28.2]train epoch: 565:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.69it/s, loss=28.2]train epoch: 565:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=28.2]train epoch: 565:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.11it/s, loss=23.5]train epoch: 565:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=23.5]train epoch: 565:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.14it/s, loss=20.4]train epoch: 565:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.44it/s, loss=20.4]train epoch: 565:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=24.5]train epoch: 565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.68it/s, loss=24.5]train epoch: 565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=24.5]
[[032m2021-11-26 10:58:12,511[0m INFO] trainer.training_epoch Training epoch 565, num_steps 4528,  avg_loss: 26.7790, total_loss: 214.2323
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.54it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.53it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.07it/s]
[[032m2021-11-26 10:58:13,113[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:13,113[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:13,384[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:13,728[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 566:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 566:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 566:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.93it/s, loss=29.3]train epoch: 566:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.93it/s, loss=23.9]train epoch: 566:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=23.9]train epoch: 566:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=31.5]train epoch: 566:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.49it/s, loss=31.5]train epoch: 566:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.49it/s, loss=25.8]train epoch: 566:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=25.8]train epoch: 566:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.88it/s, loss=25]  train epoch: 566:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=25]train epoch: 566:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=25.2]train epoch: 566:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.89it/s, loss=25.2]train epoch: 566:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.89it/s, loss=27.8]train epoch: 566:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s, loss=27.8]train epoch: 566:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s, loss=22.6]train epoch: 566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=22.6]train epoch: 566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=22.6]
[[032m2021-11-26 10:58:16,143[0m INFO] trainer.training_epoch Training epoch 566, num_steps 4536,  avg_loss: 26.3769, total_loss: 211.0152
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.33it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.03it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.10it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.73it/s]
[[032m2021-11-26 10:58:16,902[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:16,903[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:17,262[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:17,393[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 567:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 567:   0%|          | 0/8 [00:00<?, ?it/s, loss=23]train epoch: 567:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.70it/s, loss=23]train epoch: 567:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.70it/s, loss=24.6]train epoch: 567:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=24.6]train epoch: 567:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=29.3]train epoch: 567:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=29.3]train epoch: 567:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.21it/s, loss=28.2]train epoch: 567:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.05it/s, loss=28.2]train epoch: 567:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=25.5]train epoch: 567:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=25.5]train epoch: 567:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.95it/s, loss=25.6]train epoch: 567:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.05it/s, loss=25.6]train epoch: 567:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.05it/s, loss=29.4]train epoch: 567:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=29.4]train epoch: 567:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=27.7]train epoch: 567: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=27.7]train epoch: 567: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=27.7]
[[032m2021-11-26 10:58:19,653[0m INFO] trainer.training_epoch Training epoch 567, num_steps 4544,  avg_loss: 26.6662, total_loss: 213.3292
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.51it/s]
[[032m2021-11-26 10:58:20,124[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:20,124[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:20,618[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:20,803[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 568:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 568:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.2]train epoch: 568:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.60it/s, loss=22.2]train epoch: 568:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.60it/s, loss=17.9]train epoch: 568:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.15it/s, loss=17.9]train epoch: 568:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.15it/s, loss=27.3]train epoch: 568:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=27.3]train epoch: 568:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.39it/s, loss=31]  train epoch: 568:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.08it/s, loss=31]train epoch: 568:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.08it/s, loss=39]train epoch: 568:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=39]train epoch: 568:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=29.5]train epoch: 568:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.12it/s, loss=29.5]train epoch: 568:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.12it/s, loss=28.1]train epoch: 568:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.10it/s, loss=28.1]train epoch: 568:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.10it/s, loss=28.8]train epoch: 568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.42it/s, loss=28.8]train epoch: 568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=28.8]
[[032m2021-11-26 10:58:23,063[0m INFO] trainer.training_epoch Training epoch 568, num_steps 4552,  avg_loss: 27.9781, total_loss: 223.8249
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.20it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.89it/s]
[[032m2021-11-26 10:58:23,598[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:23,598[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:23,984[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:24,252[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 569:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 569:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.2]train epoch: 569:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.06it/s, loss=21.2]train epoch: 569:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.06it/s, loss=22.7]train epoch: 569:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.94it/s, loss=22.7]train epoch: 569:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.94it/s, loss=34.9]train epoch: 569:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=34.9]train epoch: 569:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.82it/s, loss=17.8]train epoch: 569:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=17.8]train epoch: 569:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=29]  train epoch: 569:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.84it/s, loss=29]train epoch: 569:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.84it/s, loss=26]train epoch: 569:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.81it/s, loss=26]train epoch: 569:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.81it/s, loss=19.4]train epoch: 569:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=19.4]train epoch: 569:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.96it/s, loss=28.3]train epoch: 569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s, loss=28.3]train epoch: 569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s, loss=28.3]
[[032m2021-11-26 10:58:26,945[0m INFO] trainer.training_epoch Training epoch 569, num_steps 4560,  avg_loss: 24.9047, total_loss: 199.2373
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.48it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.43it/s]
[[032m2021-11-26 10:58:27,416[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:27,416[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:27,806[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:27,916[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 570:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 570:   0%|          | 0/8 [00:00<?, ?it/s, loss=35.9]train epoch: 570:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.56it/s, loss=35.9]train epoch: 570:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.56it/s, loss=36.7]train epoch: 570:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.04it/s, loss=36.7]train epoch: 570:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  4.04it/s, loss=28.2]train epoch: 570:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.54it/s, loss=28.2]train epoch: 570:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.54it/s, loss=23.1]train epoch: 570:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=23.1]train epoch: 570:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.91it/s, loss=17.5]train epoch: 570:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.30it/s, loss=17.5]train epoch: 570:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.30it/s, loss=38.7]train epoch: 570:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=38.7]train epoch: 570:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.80it/s, loss=17.9]train epoch: 570:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.36it/s, loss=17.9]train epoch: 570:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.36it/s, loss=23.7]train epoch: 570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.26it/s, loss=23.7]train epoch: 570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.53it/s, loss=23.7]
[[032m2021-11-26 10:58:31,096[0m INFO] trainer.training_epoch Training epoch 570, num_steps 4568,  avg_loss: 27.6996, total_loss: 221.5965
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.01it/s]
[[032m2021-11-26 10:58:31,849[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:31,849[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:32,213[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:32,619[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 571:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 571:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.1]train epoch: 571:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.34it/s, loss=27.1]train epoch: 571:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.34it/s, loss=23.4]train epoch: 571:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.68it/s, loss=23.4]train epoch: 571:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.68it/s, loss=22.1]train epoch: 571:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.64it/s, loss=22.1]train epoch: 571:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.64it/s, loss=26.9]train epoch: 571:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.70it/s, loss=26.9]train epoch: 571:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.70it/s, loss=26.9]train epoch: 571:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s, loss=26.9]train epoch: 571:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s, loss=27.3]train epoch: 571:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.08it/s, loss=27.3]train epoch: 571:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.08it/s, loss=27.7]train epoch: 571:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=27.7]train epoch: 571:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.14it/s, loss=29.2]train epoch: 571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=29.2]train epoch: 571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=29.2]
[[032m2021-11-26 10:58:35,033[0m INFO] trainer.training_epoch Training epoch 571, num_steps 4576,  avg_loss: 26.3123, total_loss: 210.4982
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.77it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.40it/s]
[[032m2021-11-26 10:58:35,528[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:35,529[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:35,763[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:35,943[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 572:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 572:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.2]train epoch: 572:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.59it/s, loss=21.2]train epoch: 572:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.59it/s, loss=25.3]train epoch: 572:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.94it/s, loss=25.3]train epoch: 572:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.94it/s, loss=21.5]train epoch: 572:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=21.5]train epoch: 572:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=26.9]train epoch: 572:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=26.9]train epoch: 572:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.04it/s, loss=31.3]train epoch: 572:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=31.3]train epoch: 572:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=23.2]train epoch: 572:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.11it/s, loss=23.2]train epoch: 572:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.11it/s, loss=28]  train epoch: 572:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=28]train epoch: 572:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=34.2]train epoch: 572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.38it/s, loss=34.2]train epoch: 572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s, loss=34.2]
[[032m2021-11-26 10:58:38,466[0m INFO] trainer.training_epoch Training epoch 572, num_steps 4584,  avg_loss: 26.4315, total_loss: 211.4521
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.00it/s]
[[032m2021-11-26 10:58:38,964[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:38,965[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:39,272[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:39,418[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 573:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 573:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.1]train epoch: 573:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.54it/s, loss=22.1]train epoch: 573:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.54it/s, loss=22.4]train epoch: 573:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.84it/s, loss=22.4]train epoch: 573:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.84it/s, loss=20.6]train epoch: 573:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.25it/s, loss=20.6]train epoch: 573:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.25it/s, loss=23.8]train epoch: 573:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=23.8]train epoch: 573:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=28.9]train epoch: 573:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.16it/s, loss=28.9]train epoch: 573:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.16it/s, loss=23]  train epoch: 573:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.18it/s, loss=23]train epoch: 573:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.18it/s, loss=22.5]train epoch: 573:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=22.5]train epoch: 573:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s, loss=26]  train epoch: 573: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=26]train epoch: 573: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s, loss=26]
[[032m2021-11-26 10:58:41,982[0m INFO] trainer.training_epoch Training epoch 573, num_steps 4592,  avg_loss: 23.6624, total_loss: 189.2991
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.24it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.58it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.89it/s]
[[032m2021-11-26 10:58:42,564[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:42,565[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:43,028[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:43,202[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 574:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 574:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.3]train epoch: 574:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.51it/s, loss=30.3]train epoch: 574:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.51it/s, loss=32.5]train epoch: 574:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.47it/s, loss=32.5]train epoch: 574:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.47it/s, loss=20]  train epoch: 574:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.04it/s, loss=20]train epoch: 574:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.04it/s, loss=26.8]train epoch: 574:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.53it/s, loss=26.8]train epoch: 574:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.53it/s, loss=18.2]train epoch: 574:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.69it/s, loss=18.2]train epoch: 574:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.69it/s, loss=26]  train epoch: 574:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=26]train epoch: 574:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.44it/s, loss=18.9]train epoch: 574:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.59it/s, loss=18.9]train epoch: 574:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.59it/s, loss=24.2]train epoch: 574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.36it/s, loss=24.2]train epoch: 574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.42it/s, loss=24.2]
[[032m2021-11-26 10:58:46,512[0m INFO] trainer.training_epoch Training epoch 574, num_steps 4600,  avg_loss: 24.6091, total_loss: 196.8724
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.12it/s]
[[032m2021-11-26 10:58:46,931[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:46,932[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:47,177[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:47,584[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 575:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.3391, 0.6609],
        [0.5715, 0.4285],
        [0.4013, 0.5987],
        [0.5443, 0.4557],
        [0.3690, 0.6310],
        [0.6310, 0.3690],
        [0.6717, 0.3283],
        [0.7454, 0.2546]], device='cuda:0')

prompt tensor([[0.6585, 0.3415],
        [0.7534, 0.2466],
        [0.3533, 0.6467],
        [0.5949, 0.4051],
        [0.4470, 0.5530],
        [0.4252, 0.5748],
        [0.7353, 0.2647],
        [0.8218, 0.1782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 575:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.7]train epoch: 575:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.49it/s, loss=22.7]train epoch: 575:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.49it/s, loss=22.2]train epoch: 575:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.36it/s, loss=22.2]train epoch: 575:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.36it/s, loss=25.2]train epoch: 575:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.52it/s, loss=25.2]train epoch: 575:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.52it/s, loss=29]  train epoch: 575:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.72it/s, loss=29]train epoch: 575:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.72it/s, loss=27.5]train epoch: 575:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.81it/s, loss=27.5]train epoch: 575:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.81it/s, loss=30.6]train epoch: 575:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=30.6]train epoch: 575:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.37it/s, loss=27.3]train epoch: 575:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.45it/s, loss=27.3]train epoch: 575:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.45it/s, loss=34.2]train epoch: 575: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.81it/s, loss=34.2]train epoch: 575: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.83it/s, loss=34.2]
[[032m2021-11-26 10:58:50,450[0m INFO] trainer.training_epoch Training epoch 575, num_steps 4608,  avg_loss: 27.3167, total_loss: 218.5337
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.90it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.35it/s]
[[032m2021-11-26 10:58:50,931[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:50,931[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:51,376[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:51,712[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 576:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 576:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.2]train epoch: 576:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.63it/s, loss=28.2]train epoch: 576:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.63it/s, loss=25]  train epoch: 576:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=25]train epoch: 576:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=31.3]train epoch: 576:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.43it/s, loss=31.3]train epoch: 576:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.43it/s, loss=33]  train epoch: 576:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=33]train epoch: 576:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.42it/s, loss=27.9]train epoch: 576:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.83it/s, loss=27.9]train epoch: 576:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.83it/s, loss=40.6]train epoch: 576:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=40.6]train epoch: 576:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.87it/s, loss=31.8]train epoch: 576:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=31.8]train epoch: 576:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s, loss=35.5]train epoch: 576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=35.5]train epoch: 576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s, loss=35.5]
[[032m2021-11-26 10:58:54,306[0m INFO] trainer.training_epoch Training epoch 576, num_steps 4616,  avg_loss: 31.6649, total_loss: 253.3193
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.36it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.55it/s]
[[032m2021-11-26 10:58:54,918[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:54,918[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:55,537[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:55,706[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 577:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 577:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.3]train epoch: 577:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=24.3]train epoch: 577:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.30it/s, loss=22.4]train epoch: 577:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.13it/s, loss=22.4]train epoch: 577:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  4.13it/s, loss=31.2]train epoch: 577:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.56it/s, loss=31.2]train epoch: 577:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.56it/s, loss=31.7]train epoch: 577:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=31.7]train epoch: 577:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.57it/s, loss=27.7]train epoch: 577:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.74it/s, loss=27.7]train epoch: 577:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.74it/s, loss=23.2]train epoch: 577:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.19it/s, loss=23.2]train epoch: 577:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.19it/s, loss=27.6]train epoch: 577:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.48it/s, loss=27.6]train epoch: 577:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.48it/s, loss=21.6]train epoch: 577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=21.6]train epoch: 577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=21.6]
[[032m2021-11-26 10:58:58,164[0m INFO] trainer.training_epoch Training epoch 577, num_steps 4624,  avg_loss: 26.2142, total_loss: 209.7139
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.99it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.00it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.74it/s]
[[032m2021-11-26 10:58:58,948[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:58:58,949[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:58:59,416[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:58:59,575[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 578:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 578:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.2]train epoch: 578:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=26.2]train epoch: 578:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=37]  train epoch: 578:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.56it/s, loss=37]train epoch: 578:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.56it/s, loss=24]train epoch: 578:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.16it/s, loss=24]train epoch: 578:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.16it/s, loss=24.2]train epoch: 578:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=24.2]train epoch: 578:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=21.3]train epoch: 578:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.67it/s, loss=21.3]train epoch: 578:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.67it/s, loss=22.9]train epoch: 578:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.12it/s, loss=22.9]train epoch: 578:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.12it/s, loss=29.2]train epoch: 578:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=29.2]train epoch: 578:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.37it/s, loss=29.5]train epoch: 578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s, loss=29.5]train epoch: 578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=29.5]
[[032m2021-11-26 10:59:02,028[0m INFO] trainer.training_epoch Training epoch 578, num_steps 4632,  avg_loss: 26.7642, total_loss: 214.1137
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.84it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.69it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.20it/s]
[[032m2021-11-26 10:59:02,655[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:59:02,655[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:03,086[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 579:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 579:   0%|          | 0/8 [00:00<?, ?it/s, loss=26]train epoch: 579:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.04it/s, loss=26]train epoch: 579:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.04it/s, loss=27.4]train epoch: 579:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.01it/s, loss=27.4]train epoch: 579:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.01it/s, loss=27.8]train epoch: 579:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=27.8]train epoch: 579:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.00it/s, loss=35.7]train epoch: 579:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.98it/s, loss=35.7]train epoch: 579:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.98it/s, loss=18.8]train epoch: 579:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=18.8]train epoch: 579:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=35.7]train epoch: 579:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=35.7]train epoch: 579:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=23.6]train epoch: 579:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.40it/s, loss=23.6]train epoch: 579:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.40it/s, loss=26.9]train epoch: 579: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.70it/s, loss=26.9]train epoch: 579: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.69it/s, loss=26.9]
[[032m2021-11-26 10:59:05,259[0m INFO] trainer.training_epoch Training epoch 579, num_steps 4640,  avg_loss: 27.7294, total_loss: 221.8349
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.87it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.86it/s]
[[032m2021-11-26 10:59:05,863[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:05,864[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:06,376[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:59:06,592[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 580:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 580:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.6]train epoch: 580:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=31.6]train epoch: 580:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.22it/s, loss=23]  train epoch: 580:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.46it/s, loss=23]train epoch: 580:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.46it/s, loss=24.3]train epoch: 580:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.69it/s, loss=24.3]train epoch: 580:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.69it/s, loss=22.5]train epoch: 580:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=22.5]train epoch: 580:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.12it/s, loss=25.8]train epoch: 580:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=25.8]train epoch: 580:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.87it/s, loss=24.1]train epoch: 580:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.12it/s, loss=24.1]train epoch: 580:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.12it/s, loss=28.2]train epoch: 580:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=28.2]train epoch: 580:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.44it/s, loss=32.1]train epoch: 580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.56it/s, loss=32.1]train epoch: 580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=32.1]
[[032m2021-11-26 10:59:08,942[0m INFO] trainer.training_epoch Training epoch 580, num_steps 4648,  avg_loss: 26.4436, total_loss: 211.5490
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.20it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.90it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.17it/s]
[[032m2021-11-26 10:59:09,726[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:09,726[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:10,059[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:59:10,227[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 581:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 581:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.1]train epoch: 581:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.02it/s, loss=24.1]train epoch: 581:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.02it/s, loss=35.2]train epoch: 581:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.42it/s, loss=35.2]train epoch: 581:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.42it/s, loss=32.3]train epoch: 581:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.35it/s, loss=32.3]train epoch: 581:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.35it/s, loss=25]  train epoch: 581:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.67it/s, loss=25]train epoch: 581:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.67it/s, loss=28.1]train epoch: 581:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=28.1]train epoch: 581:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.14it/s, loss=29.1]train epoch: 581:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=29.1]train epoch: 581:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.43it/s, loss=25.5]train epoch: 581:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=25.5]train epoch: 581:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.58it/s, loss=23.3]train epoch: 581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=23.3]train epoch: 581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s, loss=23.3]
[[032m2021-11-26 10:59:12,761[0m INFO] trainer.training_epoch Training epoch 581, num_steps 4656,  avg_loss: 27.8265, total_loss: 222.6122
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.64it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.89it/s]
[[032m2021-11-26 10:59:13,495[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 10:59:13,495[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:13,765[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:59:13,900[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 582:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 582:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.4]train epoch: 582:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.94it/s, loss=31.4]train epoch: 582:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.94it/s, loss=26.4]train epoch: 582:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.78it/s, loss=26.4]train epoch: 582:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.78it/s, loss=34.6]train epoch: 582:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=34.6]train epoch: 582:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=31]  train epoch: 582:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.62it/s, loss=31]train epoch: 582:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.62it/s, loss=30]train epoch: 582:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.63it/s, loss=30]train epoch: 582:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.63it/s, loss=24.1]train epoch: 582:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.60it/s, loss=24.1]train epoch: 582:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.60it/s, loss=30.1]train epoch: 582:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.82it/s, loss=30.1]train epoch: 582:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.82it/s, loss=22.2]train epoch: 582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.10it/s, loss=22.2]train epoch: 582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=22.2]
[[032m2021-11-26 10:59:16,634[0m INFO] trainer.training_epoch Training epoch 582, num_steps 4664,  avg_loss: 28.7346, total_loss: 229.8768
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.99it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.07it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.73it/s]
[[032m2021-11-26 10:59:17,273[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 10:59:17,273[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:18,034[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 10:59:18,293[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 583:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 583:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.5]train epoch: 583:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.74it/s, loss=32.5]train epoch: 583:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.74it/s, loss=22.7]train epoch: 583:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=22.7]train epoch: 583:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=31.9]train epoch: 583:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.19it/s, loss=31.9]train epoch: 583:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.19it/s, loss=20.1]train epoch: 583:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=20.1]train epoch: 583:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=23.1]train epoch: 583:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=23.1]train epoch: 583:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.90it/s, loss=29.1]train epoch: 583:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.17it/s, loss=29.1]train epoch: 583:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.17it/s, loss=33.9]train epoch: 583:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.15it/s, loss=33.9]train epoch: 583:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.15it/s, loss=33.3]train epoch: 583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.53it/s, loss=33.3]train epoch: 583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.82it/s, loss=33.3]
[[032m2021-11-26 10:59:21,133[0m INFO] trainer.training_epoch Training epoch 583, num_steps 4672,  avg_loss: 28.3206, total_loss: 226.5647
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.42it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.48it/s]
[[032m2021-11-26 10:59:21,688[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:21,689[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:21,982[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 584:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 584:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.7]train epoch: 584:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=24.7]train epoch: 584:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=26]  train epoch: 584:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.41it/s, loss=26]train epoch: 584:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.41it/s, loss=33.3]train epoch: 584:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=33.3]train epoch: 584:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=32.3]train epoch: 584:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=32.3]train epoch: 584:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.72it/s, loss=25.1]train epoch: 584:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.06it/s, loss=25.1]train epoch: 584:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.06it/s, loss=30.7]train epoch: 584:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.47it/s, loss=30.7]train epoch: 584:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.47it/s, loss=35.7]train epoch: 584:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.75it/s, loss=35.7]train epoch: 584:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.75it/s, loss=38.7]train epoch: 584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.89it/s, loss=38.7]train epoch: 584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=38.7]
[[032m2021-11-26 10:59:24,385[0m INFO] trainer.training_epoch Training epoch 584, num_steps 4680,  avg_loss: 30.8015, total_loss: 246.4124
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.97it/s]
[[032m2021-11-26 10:59:24,895[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:24,895[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:25,135[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 585:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 585:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.3]train epoch: 585:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.29it/s, loss=29.3]train epoch: 585:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.29it/s, loss=23.8]train epoch: 585:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.71it/s, loss=23.8]train epoch: 585:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.71it/s, loss=23.7]train epoch: 585:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.54it/s, loss=23.7]train epoch: 585:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.54it/s, loss=22.6]train epoch: 585:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=22.6]train epoch: 585:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.81it/s, loss=27.3]train epoch: 585:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.08it/s, loss=27.3]train epoch: 585:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.08it/s, loss=25.9]train epoch: 585:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.35it/s, loss=25.9]train epoch: 585:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.35it/s, loss=26.8]train epoch: 585:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.47it/s, loss=26.8]train epoch: 585:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.47it/s, loss=26]  train epoch: 585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.51it/s, loss=26]train epoch: 585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.20it/s, loss=26]
[[032m2021-11-26 10:59:27,642[0m INFO] trainer.training_epoch Training epoch 585, num_steps 4688,  avg_loss: 25.6572, total_loss: 205.2574
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.66it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.05it/s]
[[032m2021-11-26 10:59:28,160[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:28,160[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:28,507[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 586:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 586:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.8]train epoch: 586:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.03it/s, loss=25.8]train epoch: 586:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.03it/s, loss=33.5]train epoch: 586:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.39it/s, loss=33.5]train epoch: 586:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.39it/s, loss=32.1]train epoch: 586:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.66it/s, loss=32.1]train epoch: 586:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.66it/s, loss=29.5]train epoch: 586:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.71it/s, loss=29.5]train epoch: 586:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.71it/s, loss=30.7]train epoch: 586:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.78it/s, loss=30.7]train epoch: 586:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.78it/s, loss=26.1]train epoch: 586:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.89it/s, loss=26.1]train epoch: 586:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.89it/s, loss=28.2]train epoch: 586:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.00it/s, loss=28.2]train epoch: 586:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.00it/s, loss=27.2]train epoch: 586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.86it/s, loss=27.2]train epoch: 586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=27.2]
[[032m2021-11-26 10:59:30,617[0m INFO] trainer.training_epoch Training epoch 586, num_steps 4696,  avg_loss: 29.1212, total_loss: 232.9694
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.51it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.63it/s]
[[032m2021-11-26 10:59:31,179[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:31,180[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:31,574[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 587:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 587:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.9]train epoch: 587:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.87it/s, loss=21.9]train epoch: 587:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.87it/s, loss=27]  train epoch: 587:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.69it/s, loss=27]train epoch: 587:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.69it/s, loss=28.9]train epoch: 587:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.02it/s, loss=28.9]train epoch: 587:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.02it/s, loss=25.3]train epoch: 587:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.40it/s, loss=25.3]
model tensor([[0.6731, 0.3269],
        [0.4988, 0.5012],
        [0.7342, 0.2658],
        [0.3053, 0.6947],
        [0.3295, 0.6705],
        [0.2477, 0.7523],
        [0.2534, 0.7466],
        [0.6054, 0.3946]], device='cuda:0')

prompt tensor([[0.5314, 0.4686],
        [0.4436, 0.5564],
        [0.6989, 0.3011],
        [0.5997, 0.4003],
        [0.6146, 0.3854],
        [0.5246, 0.4754],
        [0.5818, 0.4182],
        [0.4974, 0.5026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 587:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.40it/s, loss=27.1]train epoch: 587:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.68it/s, loss=27.1]train epoch: 587:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.68it/s, loss=23.9]train epoch: 587:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=23.9]train epoch: 587:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=31.2]train epoch: 587:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.12it/s, loss=31.2]train epoch: 587:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.12it/s, loss=27.2]train epoch: 587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.15it/s, loss=27.2]train epoch: 587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.70it/s, loss=27.2]
[[032m2021-11-26 10:59:33,741[0m INFO] trainer.training_epoch Training epoch 587, num_steps 4704,  avg_loss: 26.5718, total_loss: 212.5745
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.18it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.71it/s]
[[032m2021-11-26 10:59:34,622[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:34,622[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:35,090[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 588:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 588:   0%|          | 0/8 [00:00<?, ?it/s, loss=31]train epoch: 588:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.82it/s, loss=31]train epoch: 588:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.82it/s, loss=21.8]train epoch: 588:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=21.8]train epoch: 588:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.06it/s, loss=25.2]train epoch: 588:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.14it/s, loss=25.2]train epoch: 588:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.14it/s, loss=23.6]train epoch: 588:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.13it/s, loss=23.6]train epoch: 588:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.13it/s, loss=29.1]train epoch: 588:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=29.1]train epoch: 588:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.12it/s, loss=23.9]train epoch: 588:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=23.9]train epoch: 588:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.91it/s, loss=26]  train epoch: 588:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.18it/s, loss=26]train epoch: 588:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.18it/s, loss=20.5]train epoch: 588: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s, loss=20.5]train epoch: 588: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.98it/s, loss=20.5]
[[032m2021-11-26 10:59:37,107[0m INFO] trainer.training_epoch Training epoch 588, num_steps 4712,  avg_loss: 25.1294, total_loss: 201.0350
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.67it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.70it/s]
[[032m2021-11-26 10:59:37,654[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:37,655[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:37,993[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 589:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 589:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.4]train epoch: 589:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=23.4]train epoch: 589:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.55it/s, loss=24.9]train epoch: 589:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.71it/s, loss=24.9]train epoch: 589:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.71it/s, loss=29.7]train epoch: 589:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.96it/s, loss=29.7]train epoch: 589:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.96it/s, loss=21.8]train epoch: 589:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.09it/s, loss=21.8]train epoch: 589:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.09it/s, loss=33.4]train epoch: 589:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=33.4]train epoch: 589:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.23it/s, loss=28.3]train epoch: 589:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=28.3]train epoch: 589:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.29it/s, loss=27.6]train epoch: 589:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.99it/s, loss=27.6]train epoch: 589:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.99it/s, loss=21.7]train epoch: 589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=21.7]train epoch: 589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s, loss=21.7]
[[032m2021-11-26 10:59:40,042[0m INFO] trainer.training_epoch Training epoch 589, num_steps 4720,  avg_loss: 26.3520, total_loss: 210.8161
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.50it/s]
[[032m2021-11-26 10:59:40,605[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:40,605[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:40,967[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 590:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 590:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.2]train epoch: 590:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=28.2]train epoch: 590:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=19.1]train epoch: 590:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=19.1]train epoch: 590:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.41it/s, loss=31.8]train epoch: 590:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.95it/s, loss=31.8]train epoch: 590:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.95it/s, loss=27.2]train epoch: 590:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.21it/s, loss=27.2]train epoch: 590:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.21it/s, loss=27.6]train epoch: 590:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=27.6]train epoch: 590:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.04it/s, loss=23.8]train epoch: 590:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=23.8]train epoch: 590:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.19it/s, loss=24.6]train epoch: 590:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.05it/s, loss=24.6]train epoch: 590:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.05it/s, loss=27]  train epoch: 590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.97it/s, loss=27]train epoch: 590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.07it/s, loss=27]
[[032m2021-11-26 10:59:42,940[0m INFO] trainer.training_epoch Training epoch 590, num_steps 4728,  avg_loss: 26.1657, total_loss: 209.3252
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.98it/s]
[[032m2021-11-26 10:59:43,467[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:43,469[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:43,811[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 591:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 591:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.7]train epoch: 591:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.68it/s, loss=26.7]train epoch: 591:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.68it/s, loss=33.7]train epoch: 591:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.34it/s, loss=33.7]train epoch: 591:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.34it/s, loss=24.6]train epoch: 591:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=24.6]train epoch: 591:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=29.7]train epoch: 591:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.38it/s, loss=29.7]train epoch: 591:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.38it/s, loss=25.5]train epoch: 591:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.65it/s, loss=25.5]train epoch: 591:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.65it/s, loss=26.2]train epoch: 591:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.73it/s, loss=26.2]train epoch: 591:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.73it/s, loss=29.7]train epoch: 591:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.99it/s, loss=29.7]train epoch: 591:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.99it/s, loss=22.9]train epoch: 591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.07it/s, loss=22.9]train epoch: 591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.60it/s, loss=22.9]
[[032m2021-11-26 10:59:46,039[0m INFO] trainer.training_epoch Training epoch 591, num_steps 4736,  avg_loss: 27.3883, total_loss: 219.1066
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.26it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.40it/s]
[[032m2021-11-26 10:59:46,559[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:59:46,560[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:46,950[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 592:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 592:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.8]train epoch: 592:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.00it/s, loss=29.8]train epoch: 592:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.00it/s, loss=26.4]train epoch: 592:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.27it/s, loss=26.4]train epoch: 592:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.27it/s, loss=27.2]train epoch: 592:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.67it/s, loss=27.2]train epoch: 592:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.67it/s, loss=28.7]train epoch: 592:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.24it/s, loss=28.7]train epoch: 592:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.24it/s, loss=22.9]train epoch: 592:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s, loss=22.9]train epoch: 592:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s, loss=19.7]train epoch: 592:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.88it/s, loss=19.7]train epoch: 592:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.88it/s, loss=32.3]train epoch: 592:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.07it/s, loss=32.3]train epoch: 592:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.07it/s, loss=28.8]train epoch: 592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.07it/s, loss=28.8]train epoch: 592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=28.8]
[[032m2021-11-26 10:59:49,268[0m INFO] trainer.training_epoch Training epoch 592, num_steps 4744,  avg_loss: 26.9606, total_loss: 215.6850
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.71it/s]
[[032m2021-11-26 10:59:49,715[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:49,715[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:50,018[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 593:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 593:   0%|          | 0/8 [00:00<?, ?it/s, loss=29]train epoch: 593:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.67it/s, loss=29]train epoch: 593:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.67it/s, loss=35.6]train epoch: 593:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.67it/s, loss=35.6]train epoch: 593:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.67it/s, loss=28]  train epoch: 593:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=28]train epoch: 593:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.49it/s, loss=24.3]train epoch: 593:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.01it/s, loss=24.3]train epoch: 593:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.01it/s, loss=24.7]train epoch: 593:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.30it/s, loss=24.7]train epoch: 593:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.30it/s, loss=28.5]train epoch: 593:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.43it/s, loss=28.5]train epoch: 593:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.43it/s, loss=24.8]train epoch: 593:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.72it/s, loss=24.8]train epoch: 593:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.72it/s, loss=30.8]train epoch: 593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.86it/s, loss=30.8]train epoch: 593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.35it/s, loss=30.8]
[[032m2021-11-26 10:59:52,424[0m INFO] trainer.training_epoch Training epoch 593, num_steps 4752,  avg_loss: 28.2068, total_loss: 225.6546
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.81it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.50it/s]
[[032m2021-11-26 10:59:52,856[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:52,857[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:53,093[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 594:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 594:   0%|          | 0/8 [00:00<?, ?it/s, loss=20.1]train epoch: 594:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=20.1]train epoch: 594:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=17.6]train epoch: 594:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.83it/s, loss=17.6]train epoch: 594:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.83it/s, loss=24.2]train epoch: 594:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.34it/s, loss=24.2]train epoch: 594:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.34it/s, loss=26.9]train epoch: 594:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=26.9]train epoch: 594:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.89it/s, loss=30]  train epoch: 594:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.38it/s, loss=30]train epoch: 594:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.38it/s, loss=27.6]train epoch: 594:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.32it/s, loss=27.6]train epoch: 594:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.32it/s, loss=27.1]train epoch: 594:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.57it/s, loss=27.1]train epoch: 594:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.57it/s, loss=23.2]train epoch: 594: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.00it/s, loss=23.2]train epoch: 594: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s, loss=23.2]
[[032m2021-11-26 10:59:55,815[0m INFO] trainer.training_epoch Training epoch 594, num_steps 4760,  avg_loss: 24.5999, total_loss: 196.7994
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.60it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.87it/s]
[[032m2021-11-26 10:59:56,357[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 10:59:56,358[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:56,623[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 595:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 595:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.3]train epoch: 595:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.05it/s, loss=27.3]train epoch: 595:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.05it/s, loss=27.4]train epoch: 595:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.34it/s, loss=27.4]train epoch: 595:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.34it/s, loss=22]  train epoch: 595:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.67it/s, loss=22]train epoch: 595:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.67it/s, loss=36.5]train epoch: 595:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=36.5]train epoch: 595:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.74it/s, loss=23.3]train epoch: 595:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=23.3]train epoch: 595:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.89it/s, loss=27.7]train epoch: 595:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.18it/s, loss=27.7]train epoch: 595:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.18it/s, loss=28.9]train epoch: 595:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=28.9]train epoch: 595:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.38it/s, loss=31.6]train epoch: 595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.64it/s, loss=31.6]train epoch: 595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.36it/s, loss=31.6]
[[032m2021-11-26 10:59:59,010[0m INFO] trainer.training_epoch Training epoch 595, num_steps 4768,  avg_loss: 28.0812, total_loss: 224.6496
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.89it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.37it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.02it/s]
[[032m2021-11-26 10:59:59,573[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 10:59:59,573[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 10:59:59,823[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 596:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 596:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.4]train epoch: 596:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.05it/s, loss=30.4]train epoch: 596:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.05it/s, loss=26.2]train epoch: 596:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.22it/s, loss=26.2]train epoch: 596:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.22it/s, loss=25.5]train epoch: 596:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.23it/s, loss=25.5]train epoch: 596:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.23it/s, loss=30.1]train epoch: 596:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.21it/s, loss=30.1]train epoch: 596:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.21it/s, loss=27.6]train epoch: 596:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=27.6]train epoch: 596:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  3.00it/s, loss=39]  train epoch: 596:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.16it/s, loss=39]train epoch: 596:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.16it/s, loss=18.6]train epoch: 596:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.52it/s, loss=18.6]train epoch: 596:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.52it/s, loss=18.9]train epoch: 596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.58it/s, loss=18.9]train epoch: 596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.38it/s, loss=18.9]
[[032m2021-11-26 11:00:02,198[0m INFO] trainer.training_epoch Training epoch 596, num_steps 4776,  avg_loss: 27.0463, total_loss: 216.3708
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.38it/s]
[[032m2021-11-26 11:00:02,667[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:02,667[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:02,857[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 597:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 597:   0%|          | 0/8 [00:00<?, ?it/s, loss=27.9]train epoch: 597:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.44it/s, loss=27.9]train epoch: 597:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.44it/s, loss=24.9]train epoch: 597:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.78it/s, loss=24.9]train epoch: 597:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.78it/s, loss=22.8]train epoch: 597:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.75it/s, loss=22.8]train epoch: 597:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.75it/s, loss=30.8]train epoch: 597:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.14it/s, loss=30.8]train epoch: 597:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.14it/s, loss=32]  train epoch: 597:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=32]train epoch: 597:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.41it/s, loss=27.9]train epoch: 597:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.47it/s, loss=27.9]train epoch: 597:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.47it/s, loss=26.9]train epoch: 597:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.45it/s, loss=26.9]train epoch: 597:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.45it/s, loss=24.7]train epoch: 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.58it/s, loss=24.7]train epoch: 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=24.7]
[[032m2021-11-26 11:00:05,256[0m INFO] trainer.training_epoch Training epoch 597, num_steps 4784,  avg_loss: 27.2405, total_loss: 217.9243
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.17it/s]
[[032m2021-11-26 11:00:05,652[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:05,652[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:05,856[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 598:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 598:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.8]train epoch: 598:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.96it/s, loss=22.8]train epoch: 598:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.96it/s, loss=26.9]train epoch: 598:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=26.9]train epoch: 598:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.08it/s, loss=22]  train epoch: 598:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.11it/s, loss=22]train epoch: 598:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.11it/s, loss=21.7]train epoch: 598:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.26it/s, loss=21.7]train epoch: 598:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.26it/s, loss=23.3]train epoch: 598:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.56it/s, loss=23.3]train epoch: 598:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.56it/s, loss=21.5]train epoch: 598:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=21.5]train epoch: 598:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=28.5]train epoch: 598:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.30it/s, loss=28.5]train epoch: 598:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.30it/s, loss=30.9]train epoch: 598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=30.9]train epoch: 598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s, loss=30.9]
[[032m2021-11-26 11:00:08,423[0m INFO] trainer.training_epoch Training epoch 598, num_steps 4792,  avg_loss: 24.7163, total_loss: 197.7302
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.77it/s]
[[032m2021-11-26 11:00:08,982[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:08,983[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:09,226[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 599:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 599:   0%|          | 0/8 [00:00<?, ?it/s, loss=23.6]train epoch: 599:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.39it/s, loss=23.6]train epoch: 599:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.39it/s, loss=24.8]train epoch: 599:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.25it/s, loss=24.8]train epoch: 599:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.25it/s, loss=20.8]train epoch: 599:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=20.8]train epoch: 599:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.46it/s, loss=21.7]train epoch: 599:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=21.7]train epoch: 599:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.45it/s, loss=28]  train epoch: 599:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.74it/s, loss=28]train epoch: 599:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.74it/s, loss=31.4]train epoch: 599:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=31.4]train epoch: 599:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.96it/s, loss=25.2]train epoch: 599:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=25.2]train epoch: 599:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=20.5]train epoch: 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.44it/s, loss=20.5]train epoch: 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s, loss=20.5]
[[032m2021-11-26 11:00:11,958[0m INFO] trainer.training_epoch Training epoch 599, num_steps 4800,  avg_loss: 24.4955, total_loss: 195.9643
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.56it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.75it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.94it/s]
[[032m2021-11-26 11:00:12,348[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:12,348[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:12,545[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 600:   0%|          | 0/8 [00:00<?, ?it/s]
model tensor([[0.6054, 0.3946],
        [0.4716, 0.5284],
        [0.4404, 0.5596],
        [0.6731, 0.3269],
        [0.5560, 0.4440],
        [0.7342, 0.2658],
        [0.5445, 0.4555],
        [0.3295, 0.6705]], device='cuda:0')

prompt tensor([[0.7198, 0.2802],
        [0.6461, 0.3539],
        [0.4744, 0.5256],
        [0.8876, 0.1124],
        [0.7045, 0.2955],
        [0.8583, 0.1417],
        [0.7090, 0.2910],
        [0.4217, 0.5783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 600:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.1]train epoch: 600:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.33it/s, loss=30.1]train epoch: 600:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.33it/s, loss=27.3]train epoch: 600:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.68it/s, loss=27.3]train epoch: 600:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.68it/s, loss=27.6]train epoch: 600:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=27.6]train epoch: 600:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.64it/s, loss=22.8]train epoch: 600:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=22.8]train epoch: 600:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.68it/s, loss=27.8]train epoch: 600:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.03it/s, loss=27.8]train epoch: 600:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:00,  3.03it/s, loss=38]  train epoch: 600:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.18it/s, loss=38]train epoch: 600:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.18it/s, loss=24.9]train epoch: 600:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=24.9]train epoch: 600:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.51it/s, loss=23.9]train epoch: 600: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=23.9]train epoch: 600: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s, loss=23.9]
[[032m2021-11-26 11:00:15,013[0m INFO] trainer.training_epoch Training epoch 600, num_steps 4808,  avg_loss: 27.8165, total_loss: 222.5321
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.71it/s]
[[032m2021-11-26 11:00:15,545[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:15,545[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:16,064[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 601:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 601:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.3]train epoch: 601:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.27it/s, loss=28.3]train epoch: 601:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.27it/s, loss=29.3]train epoch: 601:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.06it/s, loss=29.3]train epoch: 601:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.06it/s, loss=23]  train epoch: 601:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.62it/s, loss=23]train epoch: 601:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.62it/s, loss=25.2]train epoch: 601:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=25.2]train epoch: 601:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.13it/s, loss=21.2]train epoch: 601:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.54it/s, loss=21.2]train epoch: 601:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.54it/s, loss=21.7]train epoch: 601:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.71it/s, loss=21.7]train epoch: 601:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.71it/s, loss=37.9]train epoch: 601:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.91it/s, loss=37.9]train epoch: 601:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.91it/s, loss=23]  train epoch: 601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=23]train epoch: 601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s, loss=23]
[[032m2021-11-26 11:00:18,444[0m INFO] trainer.training_epoch Training epoch 601, num_steps 4816,  avg_loss: 26.1910, total_loss: 209.5281
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.88it/s]
[[032m2021-11-26 11:00:19,100[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:19,101[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:19,526[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 602:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 602:   0%|          | 0/8 [00:00<?, ?it/s, loss=36.4]train epoch: 602:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.71it/s, loss=36.4]train epoch: 602:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:04,  1.71it/s, loss=32.3]train epoch: 602:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.26it/s, loss=32.3]train epoch: 602:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.26it/s, loss=24.3]train epoch: 602:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=24.3]train epoch: 602:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.85it/s, loss=25.4]train epoch: 602:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=25.4]train epoch: 602:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.26it/s, loss=32.2]train epoch: 602:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=32.2]train epoch: 602:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s, loss=26.4]train epoch: 602:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.59it/s, loss=26.4]train epoch: 602:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.59it/s, loss=38.5]train epoch: 602:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.62it/s, loss=38.5]train epoch: 602:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.62it/s, loss=33.7]train epoch: 602: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.90it/s, loss=33.7]train epoch: 602: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s, loss=33.7]
[[032m2021-11-26 11:00:21,935[0m INFO] trainer.training_epoch Training epoch 602, num_steps 4824,  avg_loss: 31.1498, total_loss: 249.1985
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.98it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.68it/s]
[[032m2021-11-26 11:00:22,451[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:22,451[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:22,862[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 603:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 603:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.3]train epoch: 603:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.77it/s, loss=31.3]train epoch: 603:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.77it/s, loss=26.5]train epoch: 603:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.73it/s, loss=26.5]train epoch: 603:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.73it/s, loss=28.4]train epoch: 603:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.59it/s, loss=28.4]train epoch: 603:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.59it/s, loss=32.1]train epoch: 603:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.76it/s, loss=32.1]train epoch: 603:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.76it/s, loss=25.1]train epoch: 603:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=25.1]train epoch: 603:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=19.6]train epoch: 603:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.04it/s, loss=19.6]train epoch: 603:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.04it/s, loss=25.6]train epoch: 603:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.81it/s, loss=25.6]train epoch: 603:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.81it/s, loss=19.8]train epoch: 603: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.01it/s, loss=19.8]train epoch: 603: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.89it/s, loss=19.8]
[[032m2021-11-26 11:00:24,924[0m INFO] trainer.training_epoch Training epoch 603, num_steps 4832,  avg_loss: 26.0497, total_loss: 208.3979
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.61it/s]
[[032m2021-11-26 11:00:25,288[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:25,288[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:25,515[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 604:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 604:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.2]train epoch: 604:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.03it/s, loss=29.2]train epoch: 604:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.03it/s, loss=25.5]train epoch: 604:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.12it/s, loss=25.5]train epoch: 604:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.12it/s, loss=19.7]train epoch: 604:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.10it/s, loss=19.7]train epoch: 604:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.10it/s, loss=29.4]train epoch: 604:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=29.4]train epoch: 604:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.75it/s, loss=28.1]train epoch: 604:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=28.1]train epoch: 604:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.94it/s, loss=28.7]train epoch: 604:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.06it/s, loss=28.7]train epoch: 604:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.06it/s, loss=29.9]train epoch: 604:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=29.9]train epoch: 604:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.39it/s, loss=23.8]train epoch: 604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.62it/s, loss=23.8]train epoch: 604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.28it/s, loss=23.8]
[[032m2021-11-26 11:00:27,956[0m INFO] trainer.training_epoch Training epoch 604, num_steps 4840,  avg_loss: 26.7985, total_loss: 214.3883
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.58it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.62it/s]
[[032m2021-11-26 11:00:28,322[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:28,323[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:28,546[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 605:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 605:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.6]train epoch: 605:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.34it/s, loss=25.6]train epoch: 605:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.34it/s, loss=32.7]train epoch: 605:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=32.7]train epoch: 605:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.75it/s, loss=27.5]train epoch: 605:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.07it/s, loss=27.5]train epoch: 605:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.07it/s, loss=29.2]train epoch: 605:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.21it/s, loss=29.2]train epoch: 605:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.21it/s, loss=31.4]train epoch: 605:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.40it/s, loss=31.4]train epoch: 605:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.40it/s, loss=23.9]train epoch: 605:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=23.9]train epoch: 605:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=31]  train epoch: 605:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=31]train epoch: 605:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=23.1]train epoch: 605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s, loss=23.1]train epoch: 605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=23.1]
[[032m2021-11-26 11:00:31,204[0m INFO] trainer.training_epoch Training epoch 605, num_steps 4848,  avg_loss: 28.0527, total_loss: 224.4216
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.24it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.40it/s]
[[032m2021-11-26 11:00:31,667[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:31,667[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:31,925[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 606:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 606:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.3]train epoch: 606:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.18it/s, loss=25.3]train epoch: 606:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.18it/s, loss=29.3]train epoch: 606:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.19it/s, loss=29.3]train epoch: 606:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.19it/s, loss=21.5]train epoch: 606:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.26it/s, loss=21.5]train epoch: 606:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.26it/s, loss=28.6]train epoch: 606:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.28it/s, loss=28.6]train epoch: 606:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.28it/s, loss=28.4]train epoch: 606:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=28.4]train epoch: 606:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.78it/s, loss=26.4]train epoch: 606:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.01it/s, loss=26.4]train epoch: 606:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.01it/s, loss=25]  train epoch: 606:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=25]train epoch: 606:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.32it/s, loss=27.9]train epoch: 606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.74it/s, loss=27.9]train epoch: 606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.34it/s, loss=27.9]
[[032m2021-11-26 11:00:34,338[0m INFO] trainer.training_epoch Training epoch 606, num_steps 4856,  avg_loss: 26.5490, total_loss: 212.3923
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.28it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.20it/s]
[[032m2021-11-26 11:00:34,780[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:34,781[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:35,026[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 607:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 607:   0%|          | 0/8 [00:00<?, ?it/s, loss=32.2]train epoch: 607:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=32.2]train epoch: 607:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.39it/s, loss=22.1]train epoch: 607:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=22.1]train epoch: 607:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=23.8]train epoch: 607:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.04it/s, loss=23.8]train epoch: 607:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.04it/s, loss=33.6]train epoch: 607:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=33.6]train epoch: 607:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.47it/s, loss=28.2]train epoch: 607:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.61it/s, loss=28.2]train epoch: 607:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.61it/s, loss=26.8]train epoch: 607:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=26.8]train epoch: 607:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.92it/s, loss=25.1]train epoch: 607:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=25.1]train epoch: 607:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=15.8]train epoch: 607: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=15.8]train epoch: 607: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.20it/s, loss=15.8]
[[032m2021-11-26 11:00:37,536[0m INFO] trainer.training_epoch Training epoch 607, num_steps 4864,  avg_loss: 25.9622, total_loss: 207.6974
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.69it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.69it/s]
[[032m2021-11-26 11:00:37,985[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:37,986[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:38,215[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 608:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 608:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.8]train epoch: 608:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=25.8]train epoch: 608:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.93it/s, loss=20.9]train epoch: 608:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.03it/s, loss=20.9]train epoch: 608:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  4.03it/s, loss=27]  train epoch: 608:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.60it/s, loss=27]train epoch: 608:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.60it/s, loss=30]train epoch: 608:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=30]train epoch: 608:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.73it/s, loss=32.5]train epoch: 608:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=32.5]train epoch: 608:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.15it/s, loss=28.2]train epoch: 608:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.46it/s, loss=28.2]train epoch: 608:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.46it/s, loss=29.1]train epoch: 608:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=29.1]train epoch: 608:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.69it/s, loss=40.1]train epoch: 608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.93it/s, loss=40.1]train epoch: 608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.50it/s, loss=40.1]
[[032m2021-11-26 11:00:40,507[0m INFO] trainer.training_epoch Training epoch 608, num_steps 4872,  avg_loss: 29.2025, total_loss: 233.6197
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.90it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.82it/s]
[[032m2021-11-26 11:00:41,085[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:41,085[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:41,563[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 609:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 609:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.9]train epoch: 609:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.60it/s, loss=30.9]train epoch: 609:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.60it/s, loss=23.8]train epoch: 609:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.90it/s, loss=23.8]train epoch: 609:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.90it/s, loss=25.7]train epoch: 609:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.46it/s, loss=25.7]train epoch: 609:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.46it/s, loss=28.1]train epoch: 609:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=28.1]train epoch: 609:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.41it/s, loss=24]  train epoch: 609:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=24]train epoch: 609:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=26.8]train epoch: 609:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.96it/s, loss=26.8]train epoch: 609:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.96it/s, loss=23.1]train epoch: 609:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=23.1]train epoch: 609:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.16it/s, loss=23.5]train epoch: 609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.22it/s, loss=23.5]train epoch: 609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.88it/s, loss=23.5]
[[032m2021-11-26 11:00:43,631[0m INFO] trainer.training_epoch Training epoch 609, num_steps 4880,  avg_loss: 25.7527, total_loss: 206.0214
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.18it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.71it/s]
[[032m2021-11-26 11:00:44,195[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:44,195[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:44,736[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 610:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 610:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.7]train epoch: 610:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.85it/s, loss=26.7]train epoch: 610:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.85it/s, loss=24.4]train epoch: 610:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=24.4]train epoch: 610:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.91it/s, loss=19.4]train epoch: 610:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.36it/s, loss=19.4]train epoch: 610:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.36it/s, loss=25]  train epoch: 610:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.72it/s, loss=25]train epoch: 610:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.72it/s, loss=27.2]train epoch: 610:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=27.2]train epoch: 610:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=21.9]train epoch: 610:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.03it/s, loss=21.9]train epoch: 610:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.03it/s, loss=34]  train epoch: 610:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.02it/s, loss=34]train epoch: 610:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.02it/s, loss=23.2]train epoch: 610: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.91it/s, loss=23.2]train epoch: 610: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.73it/s, loss=23.2]
[[032m2021-11-26 11:00:46,889[0m INFO] trainer.training_epoch Training epoch 610, num_steps 4888,  avg_loss: 25.2106, total_loss: 201.6846
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.25it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.75it/s]
[[032m2021-11-26 11:00:47,378[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:47,378[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:48,082[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 611:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 611:   0%|          | 0/8 [00:00<?, ?it/s, loss=29.7]train epoch: 611:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.59it/s, loss=29.7]train epoch: 611:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.59it/s, loss=30.6]train epoch: 611:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.50it/s, loss=30.6]train epoch: 611:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.50it/s, loss=26.4]train epoch: 611:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.78it/s, loss=26.4]train epoch: 611:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.78it/s, loss=26]  train epoch: 611:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.79it/s, loss=26]train epoch: 611:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.79it/s, loss=20.3]train epoch: 611:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.99it/s, loss=20.3]train epoch: 611:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.99it/s, loss=38.6]train epoch: 611:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.05it/s, loss=38.6]train epoch: 611:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.05it/s, loss=30.6]train epoch: 611:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.22it/s, loss=30.6]train epoch: 611:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.22it/s, loss=28.5]train epoch: 611: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.83it/s, loss=28.5]train epoch: 611: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=28.5]
[[032m2021-11-26 11:00:50,189[0m INFO] trainer.training_epoch Training epoch 611, num_steps 4896,  avg_loss: 28.8226, total_loss: 230.5807
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.14it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.42it/s]
[[032m2021-11-26 11:00:51,064[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:51,070[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:51,448[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 612:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 612:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.8]train epoch: 612:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=26.8]train epoch: 612:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=26.5]train epoch: 612:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.59it/s, loss=26.5]train epoch: 612:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.59it/s, loss=21.6]train epoch: 612:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=21.6]train epoch: 612:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.33it/s, loss=31]  train epoch: 612:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.34it/s, loss=31]
model tensor([[0.5951, 0.4049],
        [0.5501, 0.4499],
        [0.4013, 0.5987],
        [0.3391, 0.6609],
        [0.5650, 0.4350],
        [0.7454, 0.2546],
        [0.4335, 0.5665],
        [0.5964, 0.4036]], device='cuda:0')

prompt tensor([[0.8795, 0.1205],
        [0.6784, 0.3216],
        [0.5107, 0.4893],
        [0.4488, 0.5512],
        [0.6241, 0.3759],
        [0.8611, 0.1389],
        [0.6655, 0.3345],
        [0.7565, 0.2435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 612:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.34it/s, loss=23.1]train epoch: 612:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=23.1]train epoch: 612:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.40it/s, loss=31.2]train epoch: 612:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.50it/s, loss=31.2]train epoch: 612:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.50it/s, loss=24.8]train epoch: 612:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=24.8]train epoch: 612:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.16it/s, loss=19.6]train epoch: 612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.82it/s, loss=19.6]train epoch: 612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.14it/s, loss=19.6]
[[032m2021-11-26 11:00:53,384[0m INFO] trainer.training_epoch Training epoch 612, num_steps 4904,  avg_loss: 25.5757, total_loss: 204.6057
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.56it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.54it/s]
[[032m2021-11-26 11:00:54,181[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:00:54,181[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:54,463[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 613:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 613:   0%|          | 0/8 [00:00<?, ?it/s, loss=22.8]train epoch: 613:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=22.8]train epoch: 613:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=29.7]train epoch: 613:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.90it/s, loss=29.7]train epoch: 613:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.90it/s, loss=25.3]train epoch: 613:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=25.3]train epoch: 613:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s, loss=23.5]train epoch: 613:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.24it/s, loss=23.5]train epoch: 613:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.24it/s, loss=28.4]train epoch: 613:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.02it/s, loss=28.4]train epoch: 613:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.02it/s, loss=30.4]train epoch: 613:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.53it/s, loss=30.4]train epoch: 613:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.53it/s, loss=21.7]train epoch: 613:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.27it/s, loss=21.7]train epoch: 613:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s, loss=27.6]train epoch: 613: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s, loss=27.6]train epoch: 613: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=27.6]
[[032m2021-11-26 11:00:56,732[0m INFO] trainer.training_epoch Training epoch 613, num_steps 4912,  avg_loss: 26.1745, total_loss: 209.3963
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.97it/s]
[[032m2021-11-26 11:00:57,239[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:00:57,239[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:00:57,476[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 614:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 614:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.5]train epoch: 614:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=30.5]train epoch: 614:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.32it/s, loss=32.4]train epoch: 614:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=32.4]train epoch: 614:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=25]  train epoch: 614:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=25]train epoch: 614:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=32.4]train epoch: 614:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.21it/s, loss=32.4]train epoch: 614:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.21it/s, loss=32.6]train epoch: 614:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=32.6]train epoch: 614:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.34it/s, loss=21.8]train epoch: 614:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=21.8]train epoch: 614:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.44it/s, loss=22]  train epoch: 614:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.30it/s, loss=22]train epoch: 614:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.30it/s, loss=21.9]train epoch: 614: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s, loss=21.9]train epoch: 614: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.70it/s, loss=21.9]
[[032m2021-11-26 11:00:59,644[0m INFO] trainer.training_epoch Training epoch 614, num_steps 4920,  avg_loss: 27.3396, total_loss: 218.7166
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.43it/s]
[[032m2021-11-26 11:01:00,185[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:01:00,186[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:00,427[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 615:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 615:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.3]train epoch: 615:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=21.3]train epoch: 615:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.15it/s, loss=18.6]train epoch: 615:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.42it/s, loss=18.6]train epoch: 615:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.42it/s, loss=22.2]train epoch: 615:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=22.2]train epoch: 615:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s, loss=26.1]train epoch: 615:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.46it/s, loss=26.1]train epoch: 615:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.46it/s, loss=24.3]train epoch: 615:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.21it/s, loss=24.3]train epoch: 615:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.21it/s, loss=27.7]train epoch: 615:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=27.7]train epoch: 615:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=24.3]train epoch: 615:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.00it/s, loss=24.3]train epoch: 615:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.00it/s, loss=32.1]train epoch: 615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s, loss=32.1]train epoch: 615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.76it/s, loss=32.1]
[[032m2021-11-26 11:01:02,560[0m INFO] trainer.training_epoch Training epoch 615, num_steps 4928,  avg_loss: 24.5662, total_loss: 196.5296
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.95it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.85it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.05it/s]
[[032m2021-11-26 11:01:03,100[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:01:03,100[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:03,358[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 616:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 616:   0%|          | 0/8 [00:00<?, ?it/s, loss=28.9]train epoch: 616:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=28.9]train epoch: 616:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.75it/s, loss=28.9]train epoch: 616:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=28.9]train epoch: 616:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=27.5]train epoch: 616:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=27.5]train epoch: 616:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.10it/s, loss=28.9]train epoch: 616:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.04it/s, loss=28.9]train epoch: 616:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.04it/s, loss=26.7]train epoch: 616:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.56it/s, loss=26.7]train epoch: 616:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.56it/s, loss=27.5]train epoch: 616:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.75it/s, loss=27.5]train epoch: 616:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.75it/s, loss=25.3]train epoch: 616:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.32it/s, loss=25.3]train epoch: 616:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.32it/s, loss=26.1]train epoch: 616: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.57it/s, loss=26.1]train epoch: 616: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s, loss=26.1]
[[032m2021-11-26 11:01:06,056[0m INFO] trainer.training_epoch Training epoch 616, num_steps 4936,  avg_loss: 27.4951, total_loss: 219.9609
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.64it/s]
[[032m2021-11-26 11:01:06,488[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:01:06,489[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:06,716[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 617:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 617:   0%|          | 0/8 [00:00<?, ?it/s, loss=18.9]train epoch: 617:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=18.9]train epoch: 617:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.41it/s, loss=23.4]train epoch: 617:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=23.4]train epoch: 617:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=30.6]train epoch: 617:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.70it/s, loss=30.6]train epoch: 617:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.70it/s, loss=23.4]train epoch: 617:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=23.4]train epoch: 617:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.80it/s, loss=30.2]train epoch: 617:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.59it/s, loss=30.2]train epoch: 617:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.59it/s, loss=23.1]train epoch: 617:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.98it/s, loss=23.1]train epoch: 617:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.98it/s, loss=25.5]train epoch: 617:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=25.5]train epoch: 617:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.02it/s, loss=27.2]train epoch: 617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s, loss=27.2]train epoch: 617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s, loss=27.2]
[[032m2021-11-26 11:01:09,250[0m INFO] trainer.training_epoch Training epoch 617, num_steps 4944,  avg_loss: 25.3044, total_loss: 202.4352
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.69it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.08it/s]
[[032m2021-11-26 11:01:09,718[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:01:09,718[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:09,947[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 618:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 618:   0%|          | 0/8 [00:00<?, ?it/s, loss=31.7]train epoch: 618:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.45it/s, loss=31.7]train epoch: 618:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.45it/s, loss=26.1]train epoch: 618:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.03it/s, loss=26.1]train epoch: 618:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.03it/s, loss=30.6]train epoch: 618:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.36it/s, loss=30.6]train epoch: 618:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.36it/s, loss=25.1]train epoch: 618:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s, loss=25.1]train epoch: 618:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s, loss=25.2]train epoch: 618:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=25.2]train epoch: 618:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=19.9]train epoch: 618:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.64it/s, loss=19.9]train epoch: 618:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.64it/s, loss=27.3]train epoch: 618:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.91it/s, loss=27.3]train epoch: 618:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.91it/s, loss=32.4]train epoch: 618: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s, loss=32.4]train epoch: 618: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s, loss=32.4]
[[032m2021-11-26 11:01:12,437[0m INFO] trainer.training_epoch Training epoch 618, num_steps 4952,  avg_loss: 27.2917, total_loss: 218.3334
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.17it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.47it/s]
[[032m2021-11-26 11:01:12,845[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:01:12,845[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:13,061[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 619:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 619:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.9]train epoch: 619:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.44it/s, loss=25.9]train epoch: 619:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.44it/s, loss=27.9]train epoch: 619:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=27.9]train epoch: 619:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.18it/s, loss=28.3]train epoch: 619:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.48it/s, loss=28.3]train epoch: 619:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.48it/s, loss=33.1]train epoch: 619:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=33.1]train epoch: 619:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.22it/s, loss=27.8]train epoch: 619:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=27.8]train epoch: 619:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.98it/s, loss=27.3]train epoch: 619:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s, loss=27.3]train epoch: 619:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.41it/s, loss=26.9]train epoch: 619:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.47it/s, loss=26.9]train epoch: 619:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.47it/s, loss=28.4]train epoch: 619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s, loss=28.4]train epoch: 619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.48it/s, loss=28.4]
[[032m2021-11-26 11:01:15,369[0m INFO] trainer.training_epoch Training epoch 619, num_steps 4960,  avg_loss: 28.1955, total_loss: 225.5637
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.08it/s]
[[032m2021-11-26 11:01:15,810[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:01:15,810[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:16,018[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 620:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 620:   0%|          | 0/8 [00:00<?, ?it/s, loss=25.7]train epoch: 620:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.97it/s, loss=25.7]train epoch: 620:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.97it/s, loss=29.3]train epoch: 620:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=29.3]train epoch: 620:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.34it/s, loss=30.6]train epoch: 620:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.42it/s, loss=30.6]train epoch: 620:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.42it/s, loss=29.8]train epoch: 620:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.19it/s, loss=29.8]train epoch: 620:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.19it/s, loss=26]  train epoch: 620:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=26]train epoch: 620:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.01it/s, loss=26.1]train epoch: 620:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.04it/s, loss=26.1]train epoch: 620:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.04it/s, loss=24]  train epoch: 620:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.98it/s, loss=24]train epoch: 620:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.98it/s, loss=29.8]train epoch: 620: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s, loss=29.8]train epoch: 620: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s, loss=29.8]
[[032m2021-11-26 11:01:18,600[0m INFO] trainer.training_epoch Training epoch 620, num_steps 4968,  avg_loss: 27.6657, total_loss: 221.3254
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.31it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.97it/s]
[[032m2021-11-26 11:01:19,094[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.53125)])
[[032m2021-11-26 11:01:19,094[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:19,309[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 621:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 621:   0%|          | 0/8 [00:00<?, ?it/s, loss=24.2]train epoch: 621:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.35it/s, loss=24.2]train epoch: 621:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.35it/s, loss=26.4]train epoch: 621:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.24it/s, loss=26.4]train epoch: 621:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.24it/s, loss=30.5]train epoch: 621:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.28it/s, loss=30.5]train epoch: 621:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.28it/s, loss=28.2]train epoch: 621:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=28.2]train epoch: 621:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.77it/s, loss=26.5]train epoch: 621:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.13it/s, loss=26.5]train epoch: 621:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.13it/s, loss=27.6]train epoch: 621:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s, loss=27.6]train epoch: 621:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.40it/s, loss=24.9]train epoch: 621:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.49it/s, loss=24.9]train epoch: 621:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.49it/s, loss=21.5]train epoch: 621: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.65it/s, loss=21.5]train epoch: 621: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.53it/s, loss=21.5]
[[032m2021-11-26 11:01:21,580[0m INFO] trainer.training_epoch Training epoch 621, num_steps 4976,  avg_loss: 26.2317, total_loss: 209.8535
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.89it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.01it/s]
[[032m2021-11-26 11:01:21,985[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:21,985[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:22,208[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 622:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 622:   0%|          | 0/8 [00:00<?, ?it/s, loss=21.9]train epoch: 622:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.99it/s, loss=21.9]train epoch: 622:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.99it/s, loss=31.5]train epoch: 622:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=31.5]train epoch: 622:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.22it/s, loss=22.7]train epoch: 622:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.22it/s, loss=22.7]train epoch: 622:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.22it/s, loss=31.6]train epoch: 622:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.33it/s, loss=31.6]train epoch: 622:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.33it/s, loss=22.7]train epoch: 622:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.08it/s, loss=22.7]train epoch: 622:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.08it/s, loss=28.2]train epoch: 622:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.04it/s, loss=28.2]train epoch: 622:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.04it/s, loss=28]  train epoch: 622:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.29it/s, loss=28]train epoch: 622:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.29it/s, loss=21.2]train epoch: 622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.57it/s, loss=21.2]train epoch: 622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.48it/s, loss=21.2]
[[032m2021-11-26 11:01:24,513[0m INFO] trainer.training_epoch Training epoch 622, num_steps 4984,  avg_loss: 25.9873, total_loss: 207.8985
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.72it/s]
[[032m2021-11-26 11:01:24,918[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:24,919[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:25,139[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 623:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 623:   0%|          | 0/8 [00:00<?, ?it/s, loss=30.8]train epoch: 623:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.64it/s, loss=30.8]train epoch: 623:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.64it/s, loss=25]  train epoch: 623:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.81it/s, loss=25]train epoch: 623:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.81it/s, loss=24.1]train epoch: 623:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.26it/s, loss=24.1]train epoch: 623:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.26it/s, loss=26.6]train epoch: 623:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.09it/s, loss=26.6]train epoch: 623:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:01,  2.09it/s, loss=26.2]train epoch: 623:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.32it/s, loss=26.2]train epoch: 623:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.32it/s, loss=24.1]train epoch: 623:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.72it/s, loss=24.1]train epoch: 623:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.72it/s, loss=23.6]train epoch: 623:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=23.6]train epoch: 623:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.11it/s, loss=25.2]train epoch: 623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s, loss=25.2]train epoch: 623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.92it/s, loss=25.2]
[[032m2021-11-26 11:01:27,886[0m INFO] trainer.training_epoch Training epoch 623, num_steps 4992,  avg_loss: 25.7036, total_loss: 205.6287
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.47it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.41it/s]
[[032m2021-11-26 11:01:28,484[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:28,485[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:28,783[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 624:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 624:   0%|          | 0/8 [00:00<?, ?it/s, loss=26.2]train epoch: 624:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.88it/s, loss=26.2]train epoch: 624:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.88it/s, loss=33.2]train epoch: 624:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.42it/s, loss=33.2]train epoch: 624:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:01,  3.42it/s, loss=31.9]train epoch: 624:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.76it/s, loss=31.9]train epoch: 624:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.76it/s, loss=33.5]train epoch: 624:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=33.5]train epoch: 624:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.87it/s, loss=26.2]train epoch: 624:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.10it/s, loss=26.2]train epoch: 624:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.10it/s, loss=30.3]train epoch: 624:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s, loss=30.3]train epoch: 624:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  3.37it/s, loss=24.5]train epoch: 624:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.60it/s, loss=24.5]train epoch: 624:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.60it/s, loss=29.2]train epoch: 624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.85it/s, loss=29.2]train epoch: 624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s, loss=29.2]
[[032m2021-11-26 11:01:31,124[0m INFO] trainer.training_epoch Training epoch 624, num_steps 5000,  avg_loss: 29.3780, total_loss: 235.0237
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.00it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.23it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.12it/s]
[[032m2021-11-26 11:01:31,643[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:31,643[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:31,892[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 625:   0%|          | 0/8 [00:00<?, ?it/s][[032m2021-11-26 11:01:31,898[0m INFO] distillation_utils.training_step Begin propmt tuning only.

prompt tensor([[0.6286, 0.3714],
        [0.6959, 0.3041],
        [0.6994, 0.3006],
        [0.7218, 0.2782],
        [0.4878, 0.5122],
        [0.2271, 0.7729],
        [0.3885, 0.6115],
        [0.5611, 0.4389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 625:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.657]train epoch: 625:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.92it/s, loss=0.657]train epoch: 625:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.92it/s, loss=0.898]train epoch: 625:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.09it/s, loss=0.898]train epoch: 625:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.09it/s, loss=0.663]train epoch: 625:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=0.663]train epoch: 625:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=0.696]train epoch: 625:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.67it/s, loss=0.696]train epoch: 625:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.67it/s, loss=0.753]train epoch: 625:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=0.753]train epoch: 625:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s, loss=0.896]train epoch: 625:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=0.896]train epoch: 625:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=0.63] train epoch: 625:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.20it/s, loss=0.63]train epoch: 625:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.20it/s, loss=0.945]train epoch: 625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.68it/s, loss=0.945]train epoch: 625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.44it/s, loss=0.945]
[[032m2021-11-26 11:01:33,698[0m INFO] trainer.training_epoch Training epoch 625, num_steps 5008,  avg_loss: 0.7673, total_loss: 6.1381
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.27it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.80it/s]
[[032m2021-11-26 11:01:34,148[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:34,149[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:34,361[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 626:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 626:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.859]train epoch: 626:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.82it/s, loss=0.859]train epoch: 626:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.82it/s, loss=0.666]train epoch: 626:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.10it/s, loss=0.666]train epoch: 626:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.10it/s, loss=0.826]train epoch: 626:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.72it/s, loss=0.826]train epoch: 626:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.72it/s, loss=1.04] train epoch: 626:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.34it/s, loss=1.04]train epoch: 626:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.34it/s, loss=0.678]train epoch: 626:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.87it/s, loss=0.678]train epoch: 626:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.87it/s, loss=0.694]train epoch: 626:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.26it/s, loss=0.694]train epoch: 626:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.26it/s, loss=0.89] train epoch: 626:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.25it/s, loss=0.89]train epoch: 626:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s, loss=0.715]train epoch: 626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.75it/s, loss=0.715]train epoch: 626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.88it/s, loss=0.715]
[[032m2021-11-26 11:01:36,430[0m INFO] trainer.training_epoch Training epoch 626, num_steps 5016,  avg_loss: 0.7966, total_loss: 6.3725
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.85it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.48it/s]
[[032m2021-11-26 11:01:36,830[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:36,830[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:37,045[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 627:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 627:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.835]train epoch: 627:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.69it/s, loss=0.835]train epoch: 627:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.69it/s, loss=0.797]train epoch: 627:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.21it/s, loss=0.797]train epoch: 627:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.21it/s, loss=0.563]train epoch: 627:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.40it/s, loss=0.563]train epoch: 627:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.40it/s, loss=0.735]train epoch: 627:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.07it/s, loss=0.735]train epoch: 627:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.07it/s, loss=0.907]train epoch: 627:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.67it/s, loss=0.907]train epoch: 627:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.67it/s, loss=0.788]train epoch: 627:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.54it/s, loss=0.788]train epoch: 627:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.54it/s, loss=0.779]train epoch: 627:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.28it/s, loss=0.779]train epoch: 627:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.28it/s, loss=0.723]train epoch: 627: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.79it/s, loss=0.723]train epoch: 627: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.60it/s, loss=0.723]
[[032m2021-11-26 11:01:38,791[0m INFO] trainer.training_epoch Training epoch 627, num_steps 5024,  avg_loss: 0.7661, total_loss: 6.1284
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.67it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.53it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.22it/s]
[[032m2021-11-26 11:01:39,322[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:39,322[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:39,548[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 628:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 628:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.632]train epoch: 628:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.66it/s, loss=0.632]train epoch: 628:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.66it/s, loss=0.766]train epoch: 628:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.73it/s, loss=0.766]train epoch: 628:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.73it/s, loss=0.441]train epoch: 628:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.47it/s, loss=0.441]train epoch: 628:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.47it/s, loss=0.671]train epoch: 628:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.18it/s, loss=0.671]train epoch: 628:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.18it/s, loss=0.898]train epoch: 628:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.06it/s, loss=0.898]train epoch: 628:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.06it/s, loss=0.97] train epoch: 628:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  5.93it/s, loss=0.97]train epoch: 628:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.93it/s, loss=0.868]train epoch: 628:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.93it/s, loss=0.868]train epoch: 628:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.93it/s, loss=0.698]train epoch: 628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.56it/s, loss=0.698]train epoch: 628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s, loss=0.698]
[[032m2021-11-26 11:01:41,061[0m INFO] trainer.training_epoch Training epoch 628, num_steps 5032,  avg_loss: 0.7429, total_loss: 5.9429
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.40it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.85it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.90it/s]
[[032m2021-11-26 11:01:41,619[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:41,619[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:41,852[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 629:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 629:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.832]train epoch: 629:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.46it/s, loss=0.832]train epoch: 629:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.46it/s, loss=0.823]train epoch: 629:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.81it/s, loss=0.823]train epoch: 629:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.81it/s, loss=0.682]train epoch: 629:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.13it/s, loss=0.682]train epoch: 629:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.13it/s, loss=0.614]train epoch: 629:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.03it/s, loss=0.614]train epoch: 629:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.03it/s, loss=0.773]train epoch: 629:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.05it/s, loss=0.773]train epoch: 629:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.05it/s, loss=0.837]train epoch: 629:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  6.22it/s, loss=0.837]train epoch: 629:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.22it/s, loss=0.981]train epoch: 629:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.39it/s, loss=0.981]train epoch: 629:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.39it/s, loss=0.576]train epoch: 629: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.37it/s, loss=0.576]train epoch: 629: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.19it/s, loss=0.576]
[[032m2021-11-26 11:01:43,150[0m INFO] trainer.training_epoch Training epoch 629, num_steps 5040,  avg_loss: 0.7647, total_loss: 6.1172
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.09it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.85it/s]
[[032m2021-11-26 11:01:43,680[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:43,681[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:44,441[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 630:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 630:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.765]train epoch: 630:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.72it/s, loss=0.765]train epoch: 630:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.72it/s, loss=0.801]train epoch: 630:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.78it/s, loss=0.801]train epoch: 630:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.78it/s, loss=0.632]train epoch: 630:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.06it/s, loss=0.632]train epoch: 630:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.06it/s, loss=0.733]train epoch: 630:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.25it/s, loss=0.733]train epoch: 630:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.25it/s, loss=0.762]train epoch: 630:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.70it/s, loss=0.762]train epoch: 630:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.70it/s, loss=0.805]train epoch: 630:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.65it/s, loss=0.805]train epoch: 630:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.65it/s, loss=0.66] train epoch: 630:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.89it/s, loss=0.66]train epoch: 630:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.89it/s, loss=0.75]train epoch: 630: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.88it/s, loss=0.75]train epoch: 630: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s, loss=0.75]
[[032m2021-11-26 11:01:45,873[0m INFO] trainer.training_epoch Training epoch 630, num_steps 5048,  avg_loss: 0.7387, total_loss: 5.9098
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.57it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.55it/s]
[[032m2021-11-26 11:01:46,312[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:46,313[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:46,723[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 631:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 631:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.757]train epoch: 631:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.53it/s, loss=0.757]train epoch: 631:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.53it/s, loss=0.781]train epoch: 631:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.35it/s, loss=0.781]train epoch: 631:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.35it/s, loss=0.612]train epoch: 631:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.44it/s, loss=0.612]train epoch: 631:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.44it/s, loss=0.552]train epoch: 631:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.97it/s, loss=0.552]train epoch: 631:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s, loss=0.735]train epoch: 631:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.35it/s, loss=0.735]train epoch: 631:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.35it/s, loss=0.898]train epoch: 631:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.80it/s, loss=0.898]train epoch: 631:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.80it/s, loss=0.921]train epoch: 631:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.74it/s, loss=0.921]train epoch: 631:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.74it/s, loss=0.694]train epoch: 631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s, loss=0.694]train epoch: 631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.69it/s, loss=0.694]
[[032m2021-11-26 11:01:48,436[0m INFO] trainer.training_epoch Training epoch 631, num_steps 5056,  avg_loss: 0.7437, total_loss: 5.9496
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.27it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.99it/s]
[[032m2021-11-26 11:01:48,884[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:48,885[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:49,240[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 632:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 632:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.73]train epoch: 632:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.33it/s, loss=0.73]train epoch: 632:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.33it/s, loss=0.885]train epoch: 632:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=0.885]train epoch: 632:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.52it/s, loss=0.928]train epoch: 632:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.04it/s, loss=0.928]train epoch: 632:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.04it/s, loss=0.648]train epoch: 632:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.26it/s, loss=0.648]train epoch: 632:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.26it/s, loss=0.676]train epoch: 632:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.84it/s, loss=0.676]train epoch: 632:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.84it/s, loss=0.808]train epoch: 632:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.03it/s, loss=0.808]train epoch: 632:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.03it/s, loss=0.695]train epoch: 632:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.50it/s, loss=0.695]train epoch: 632:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.50it/s, loss=0.799]train epoch: 632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.72it/s, loss=0.799]train epoch: 632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.15it/s, loss=0.799]
[[032m2021-11-26 11:01:50,800[0m INFO] trainer.training_epoch Training epoch 632, num_steps 5064,  avg_loss: 0.7711, total_loss: 6.1689
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.76it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.66it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.76it/s]
[[032m2021-11-26 11:01:51,210[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:51,211[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:51,432[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 633:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 633:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.668]train epoch: 633:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.24it/s, loss=0.668]train epoch: 633:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.24it/s, loss=0.79] train epoch: 633:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.59it/s, loss=0.79]train epoch: 633:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.59it/s, loss=0.744]train epoch: 633:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.98it/s, loss=0.744]train epoch: 633:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.98it/s, loss=0.68] train epoch: 633:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.64it/s, loss=0.68]train epoch: 633:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.64it/s, loss=0.79]train epoch: 633:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.73it/s, loss=0.79]train epoch: 633:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.73it/s, loss=0.782]train epoch: 633:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.51it/s, loss=0.782]train epoch: 633:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.51it/s, loss=0.742]train epoch: 633:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.79it/s, loss=0.742]train epoch: 633:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.79it/s, loss=0.734]train epoch: 633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.10it/s, loss=0.734]train epoch: 633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.27it/s, loss=0.734]
[[032m2021-11-26 11:01:53,313[0m INFO] trainer.training_epoch Training epoch 633, num_steps 5072,  avg_loss: 0.7415, total_loss: 5.9316
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.17it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.30it/s]
[[032m2021-11-26 11:01:53,801[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:53,802[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:54,027[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 634:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 634:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.614]train epoch: 634:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.99it/s, loss=0.614]train epoch: 634:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.99it/s, loss=0.569]train epoch: 634:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.22it/s, loss=0.569]train epoch: 634:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.22it/s, loss=0.534]train epoch: 634:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.20it/s, loss=0.534]train epoch: 634:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.20it/s, loss=0.846]train epoch: 634:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.15it/s, loss=0.846]train epoch: 634:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.15it/s, loss=0.9]  train epoch: 634:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.07it/s, loss=0.9]train epoch: 634:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.07it/s, loss=0.799]train epoch: 634:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  5.94it/s, loss=0.799]train epoch: 634:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.94it/s, loss=0.722]train epoch: 634:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.64it/s, loss=0.722]train epoch: 634:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.64it/s, loss=0.936]train epoch: 634: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.44it/s, loss=0.936]train epoch: 634: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.79it/s, loss=0.936]
[[032m2021-11-26 11:01:55,413[0m INFO] trainer.training_epoch Training epoch 634, num_steps 5080,  avg_loss: 0.7401, total_loss: 5.9205
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.67it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.06it/s]
[[032m2021-11-26 11:01:55,994[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:55,994[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:56,439[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 635:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 635:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.947]train epoch: 635:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=0.947]train epoch: 635:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.08it/s, loss=0.675]train epoch: 635:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.56it/s, loss=0.675]train epoch: 635:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.56it/s, loss=0.619]train epoch: 635:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.23it/s, loss=0.619]train epoch: 635:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.23it/s, loss=0.75] train epoch: 635:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.37it/s, loss=0.75]train epoch: 635:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.37it/s, loss=0.644]train epoch: 635:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.84it/s, loss=0.644]train epoch: 635:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.84it/s, loss=0.719]train epoch: 635:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.19it/s, loss=0.719]train epoch: 635:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.19it/s, loss=0.761]train epoch: 635:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.54it/s, loss=0.761]train epoch: 635:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.54it/s, loss=0.721]train epoch: 635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.76it/s, loss=0.721]train epoch: 635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.05it/s, loss=0.721]
[[032m2021-11-26 11:01:58,036[0m INFO] trainer.training_epoch Training epoch 635, num_steps 5088,  avg_loss: 0.7293, total_loss: 5.8348
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.07it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.87it/s]
[[032m2021-11-26 11:01:58,480[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:01:58,481[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:01:58,859[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 636:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 636:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.649]train epoch: 636:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=0.649]train epoch: 636:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.79it/s, loss=0.753]train epoch: 636:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.02it/s, loss=0.753]train epoch: 636:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.02it/s, loss=0.71] train epoch: 636:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=0.71]train epoch: 636:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s, loss=0.877]train epoch: 636:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.10it/s, loss=0.877]train epoch: 636:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  5.10it/s, loss=0.841]train epoch: 636:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.27it/s, loss=0.841]train epoch: 636:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.27it/s, loss=0.73] train epoch: 636:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.60it/s, loss=0.73]train epoch: 636:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.60it/s, loss=0.768]train epoch: 636:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.79it/s, loss=0.768]train epoch: 636:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.79it/s, loss=0.612]train epoch: 636: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.76it/s, loss=0.612]train epoch: 636: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.28it/s, loss=0.612]
[[032m2021-11-26 11:02:00,385[0m INFO] trainer.training_epoch Training epoch 636, num_steps 5096,  avg_loss: 0.7427, total_loss: 5.9414
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.87it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.33it/s]
[[032m2021-11-26 11:02:00,919[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:00,919[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:01,287[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 637:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 637:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.84]train epoch: 637:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.17it/s, loss=0.84]train epoch: 637:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.17it/s, loss=0.778]train epoch: 637:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.00it/s, loss=0.778]train epoch: 637:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.00it/s, loss=1.17] train epoch: 637:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.85it/s, loss=1.17]train epoch: 637:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.85it/s, loss=0.79]train epoch: 637:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.80it/s, loss=0.79]
prompt tensor([[0.7138, 0.2862],
        [0.5543, 0.4457],
        [0.4939, 0.5061],
        [0.7056, 0.2944],
        [0.4592, 0.5408],
        [0.6352, 0.3648],
        [0.7095, 0.2905],
        [0.5234, 0.4766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 637:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.80it/s, loss=0.616]train epoch: 637:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.28it/s, loss=0.616]train epoch: 637:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.28it/s, loss=0.719]train epoch: 637:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.31it/s, loss=0.719]train epoch: 637:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.31it/s, loss=0.965]train epoch: 637:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.77it/s, loss=0.965]train epoch: 637:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.77it/s, loss=0.869]train epoch: 637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.05it/s, loss=0.869]train epoch: 637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.08it/s, loss=0.869]
[[032m2021-11-26 11:02:02,868[0m INFO] trainer.training_epoch Training epoch 637, num_steps 5104,  avg_loss: 0.8433, total_loss: 6.7460
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.32it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.17it/s]
[[032m2021-11-26 11:02:03,309[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:03,309[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:03,541[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 638:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 638:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.504]train epoch: 638:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.24it/s, loss=0.504]train epoch: 638:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.24it/s, loss=0.663]train epoch: 638:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=0.663]train epoch: 638:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.99it/s, loss=0.701]train epoch: 638:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.58it/s, loss=0.701]train epoch: 638:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.58it/s, loss=0.698]train epoch: 638:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=0.698]train epoch: 638:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=0.657]train epoch: 638:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=0.657]train epoch: 638:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.96it/s, loss=0.84] train epoch: 638:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.03it/s, loss=0.84]train epoch: 638:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.03it/s, loss=0.716]train epoch: 638:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.48it/s, loss=0.716]train epoch: 638:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.48it/s, loss=0.953]train epoch: 638: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.36it/s, loss=0.953]train epoch: 638: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.17it/s, loss=0.953]
[[032m2021-11-26 11:02:05,467[0m INFO] trainer.training_epoch Training epoch 638, num_steps 5112,  avg_loss: 0.7165, total_loss: 5.7320
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.06it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.65it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.18it/s]
[[032m2021-11-26 11:02:06,040[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:06,041[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:06,284[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 639:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 639:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.585]train epoch: 639:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.78it/s, loss=0.585]train epoch: 639:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.78it/s, loss=0.708]train epoch: 639:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.07it/s, loss=0.708]train epoch: 639:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.07it/s, loss=0.953]train epoch: 639:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.46it/s, loss=0.953]train epoch: 639:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.46it/s, loss=0.591]train epoch: 639:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.10it/s, loss=0.591]train epoch: 639:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  5.10it/s, loss=0.754]train epoch: 639:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.52it/s, loss=0.754]train epoch: 639:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.52it/s, loss=0.741]train epoch: 639:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.97it/s, loss=0.741]train epoch: 639:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.97it/s, loss=0.684]train epoch: 639:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.54it/s, loss=0.684]train epoch: 639:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.54it/s, loss=0.749]train epoch: 639: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.42it/s, loss=0.749]train epoch: 639: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s, loss=0.749]
[[032m2021-11-26 11:02:08,280[0m INFO] trainer.training_epoch Training epoch 639, num_steps 5120,  avg_loss: 0.7207, total_loss: 5.7654
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.46it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.88it/s]
[[032m2021-11-26 11:02:08,827[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:08,828[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:09,049[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:09,169[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 640:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 640:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.63]train epoch: 640:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.37it/s, loss=0.63]train epoch: 640:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.37it/s, loss=0.769]train epoch: 640:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.20it/s, loss=0.769]train epoch: 640:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.20it/s, loss=0.773]train epoch: 640:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.02it/s, loss=0.773]train epoch: 640:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.02it/s, loss=0.846]train epoch: 640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.17it/s, loss=0.846]train epoch: 640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.17it/s, loss=0.985]train epoch: 640:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.01it/s, loss=0.985]train epoch: 640:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.01it/s, loss=0.78] train epoch: 640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.05it/s, loss=0.78]train epoch: 640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.05it/s, loss=0.734]train epoch: 640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.94it/s, loss=0.734]train epoch: 640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.94it/s, loss=0.876]train epoch: 640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.04it/s, loss=0.876]train epoch: 640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.53it/s, loss=0.876]
[[032m2021-11-26 11:02:10,940[0m INFO] trainer.training_epoch Training epoch 640, num_steps 5128,  avg_loss: 0.7990, total_loss: 6.3922
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.04it/s]
[[032m2021-11-26 11:02:11,586[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:11,586[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:11,806[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 641:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 641:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.862]train epoch: 641:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.11it/s, loss=0.862]train epoch: 641:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.11it/s, loss=0.653]train epoch: 641:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.62it/s, loss=0.653]train epoch: 641:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.62it/s, loss=0.862]train epoch: 641:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.21it/s, loss=0.862]train epoch: 641:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.21it/s, loss=0.742]train epoch: 641:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.02it/s, loss=0.742]train epoch: 641:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.02it/s, loss=0.65] train epoch: 641:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.79it/s, loss=0.65]train epoch: 641:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.79it/s, loss=0.649]train epoch: 641:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  5.98it/s, loss=0.649]train epoch: 641:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.98it/s, loss=0.863]train epoch: 641:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.74it/s, loss=0.863]train epoch: 641:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.74it/s, loss=0.752]train epoch: 641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s, loss=0.752]train epoch: 641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.72it/s, loss=0.752]
[[032m2021-11-26 11:02:13,212[0m INFO] trainer.training_epoch Training epoch 641, num_steps 5136,  avg_loss: 0.7542, total_loss: 6.0334
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.49it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.44it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.88it/s]
[[032m2021-11-26 11:02:13,844[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:13,844[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:14,291[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 642:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 642:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.612]train epoch: 642:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.67it/s, loss=0.612]train epoch: 642:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.67it/s, loss=0.705]train epoch: 642:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.49it/s, loss=0.705]train epoch: 642:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.49it/s, loss=0.632]train epoch: 642:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.97it/s, loss=0.632]train epoch: 642:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.97it/s, loss=0.646]train epoch: 642:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.08it/s, loss=0.646]train epoch: 642:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.08it/s, loss=0.482]train epoch: 642:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.85it/s, loss=0.482]train epoch: 642:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.85it/s, loss=0.592]train epoch: 642:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  5.88it/s, loss=0.592]train epoch: 642:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.88it/s, loss=0.634]train epoch: 642:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.48it/s, loss=0.634]train epoch: 642:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.48it/s, loss=0.782]train epoch: 642: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.32it/s, loss=0.782]train epoch: 642: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.70it/s, loss=0.782]
[[032m2021-11-26 11:02:15,700[0m INFO] trainer.training_epoch Training epoch 642, num_steps 5144,  avg_loss: 0.6358, total_loss: 5.0860
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.16it/s]
[[032m2021-11-26 11:02:16,343[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:16,343[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:16,990[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 643:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 643:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.821]train epoch: 643:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.30it/s, loss=0.821]train epoch: 643:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.30it/s, loss=0.684]train epoch: 643:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.80it/s, loss=0.684]train epoch: 643:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.80it/s, loss=0.728]train epoch: 643:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.53it/s, loss=0.728]train epoch: 643:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.53it/s, loss=0.779]train epoch: 643:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.79it/s, loss=0.779]train epoch: 643:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.79it/s, loss=0.8]  train epoch: 643:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.94it/s, loss=0.8]train epoch: 643:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.94it/s, loss=0.921]train epoch: 643:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.90it/s, loss=0.921]train epoch: 643:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.90it/s, loss=0.946]train epoch: 643:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.73it/s, loss=0.946]train epoch: 643:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.73it/s, loss=0.536]train epoch: 643: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s, loss=0.536]train epoch: 643: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.72it/s, loss=0.536]
[[032m2021-11-26 11:02:18,394[0m INFO] trainer.training_epoch Training epoch 643, num_steps 5152,  avg_loss: 0.7768, total_loss: 6.2142
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.55it/s]
[[032m2021-11-26 11:02:18,929[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:18,929[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:19,770[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 644:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 644:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.643]train epoch: 644:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.89it/s, loss=0.643]train epoch: 644:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.89it/s, loss=0.461]train epoch: 644:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=0.461]train epoch: 644:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.57it/s, loss=0.831]train epoch: 644:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.73it/s, loss=0.831]train epoch: 644:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.73it/s, loss=0.699]train epoch: 644:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.16it/s, loss=0.699]train epoch: 644:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.16it/s, loss=0.93] train epoch: 644:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.68it/s, loss=0.93]train epoch: 644:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.68it/s, loss=1.01]train epoch: 644:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.12it/s, loss=1.01]train epoch: 644:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.12it/s, loss=0.864]train epoch: 644:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.19it/s, loss=0.864]train epoch: 644:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.19it/s, loss=0.786]train epoch: 644: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.32it/s, loss=0.786]train epoch: 644: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.71it/s, loss=0.786]
[[032m2021-11-26 11:02:21,472[0m INFO] trainer.training_epoch Training epoch 644, num_steps 5160,  avg_loss: 0.7774, total_loss: 6.2194
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.48it/s]
[[032m2021-11-26 11:02:21,903[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:21,903[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:22,286[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 645:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 645:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.703]train epoch: 645:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=0.703]train epoch: 645:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=0.659]train epoch: 645:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.83it/s, loss=0.659]train epoch: 645:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.83it/s, loss=0.694]train epoch: 645:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.23it/s, loss=0.694]train epoch: 645:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.23it/s, loss=0.797]train epoch: 645:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.85it/s, loss=0.797]train epoch: 645:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.85it/s, loss=0.558]train epoch: 645:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.27it/s, loss=0.558]train epoch: 645:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.27it/s, loss=0.781]train epoch: 645:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.41it/s, loss=0.781]train epoch: 645:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.41it/s, loss=0.619]train epoch: 645:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.59it/s, loss=0.619]train epoch: 645:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.59it/s, loss=0.913]train epoch: 645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.66it/s, loss=0.913]train epoch: 645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.36it/s, loss=0.913]
[[032m2021-11-26 11:02:23,800[0m INFO] trainer.training_epoch Training epoch 645, num_steps 5168,  avg_loss: 0.7155, total_loss: 5.7237
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.78it/s]
[[032m2021-11-26 11:02:24,278[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:24,279[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:24,523[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 646:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 646:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.766]train epoch: 646:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.12it/s, loss=0.766]train epoch: 646:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.12it/s, loss=0.587]train epoch: 646:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.69it/s, loss=0.587]train epoch: 646:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.69it/s, loss=0.788]train epoch: 646:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.57it/s, loss=0.788]train epoch: 646:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.57it/s, loss=0.633]train epoch: 646:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.08it/s, loss=0.633]train epoch: 646:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.08it/s, loss=0.724]train epoch: 646:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.18it/s, loss=0.724]train epoch: 646:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.18it/s, loss=0.75] train epoch: 646:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=0.75]train epoch: 646:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.92it/s, loss=0.648]train epoch: 646:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.49it/s, loss=0.648]train epoch: 646:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.49it/s, loss=0.873]train epoch: 646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.74it/s, loss=0.873]train epoch: 646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.80it/s, loss=0.873]
[[032m2021-11-26 11:02:26,194[0m INFO] trainer.training_epoch Training epoch 646, num_steps 5176,  avg_loss: 0.7210, total_loss: 5.7684
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.88it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.19it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.24it/s]
[[032m2021-11-26 11:02:26,693[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:26,693[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:26,919[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 647:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 647:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.672]train epoch: 647:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.22it/s, loss=0.672]train epoch: 647:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.22it/s, loss=0.752]train epoch: 647:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.27it/s, loss=0.752]train epoch: 647:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.27it/s, loss=0.835]train epoch: 647:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.88it/s, loss=0.835]train epoch: 647:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.88it/s, loss=0.638]train epoch: 647:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.17it/s, loss=0.638]train epoch: 647:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.17it/s, loss=0.653]train epoch: 647:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.52it/s, loss=0.653]train epoch: 647:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.52it/s, loss=0.638]train epoch: 647:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.25it/s, loss=0.638]train epoch: 647:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.25it/s, loss=0.754]train epoch: 647:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.28it/s, loss=0.754]train epoch: 647:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.28it/s, loss=0.682]train epoch: 647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.90it/s, loss=0.682]train epoch: 647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.59it/s, loss=0.682]
[[032m2021-11-26 11:02:28,668[0m INFO] trainer.training_epoch Training epoch 647, num_steps 5184,  avg_loss: 0.7028, total_loss: 5.6220
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.89it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.42it/s]
[[032m2021-11-26 11:02:29,114[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:29,115[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:29,416[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 648:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 648:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.664]train epoch: 648:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.84it/s, loss=0.664]train epoch: 648:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.84it/s, loss=0.575]train epoch: 648:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.28it/s, loss=0.575]train epoch: 648:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.28it/s, loss=0.599]train epoch: 648:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.05it/s, loss=0.599]train epoch: 648:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.05it/s, loss=0.94] train epoch: 648:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.94]train epoch: 648:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.761]train epoch: 648:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.23it/s, loss=0.761]train epoch: 648:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.23it/s, loss=0.709]train epoch: 648:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.94it/s, loss=0.709]train epoch: 648:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.94it/s, loss=0.813]train epoch: 648:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.15it/s, loss=0.813]train epoch: 648:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.15it/s, loss=0.625]train epoch: 648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.55it/s, loss=0.625]train epoch: 648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.96it/s, loss=0.625]
[[032m2021-11-26 11:02:31,034[0m INFO] trainer.training_epoch Training epoch 648, num_steps 5192,  avg_loss: 0.7107, total_loss: 5.6859
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.08it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.32it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.65it/s]
[[032m2021-11-26 11:02:31,790[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:31,791[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:32,096[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 649:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 649:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.945]train epoch: 649:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.65it/s, loss=0.945]train epoch: 649:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.65it/s, loss=0.699]train epoch: 649:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.33it/s, loss=0.699]train epoch: 649:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.33it/s, loss=0.758]train epoch: 649:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.53it/s, loss=0.758]train epoch: 649:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.53it/s, loss=0.853]train epoch: 649:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.56it/s, loss=0.853]train epoch: 649:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.56it/s, loss=0.438]train epoch: 649:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.23it/s, loss=0.438]train epoch: 649:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.23it/s, loss=0.822]train epoch: 649:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  6.02it/s, loss=0.822]train epoch: 649:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.02it/s, loss=0.797]train epoch: 649:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.97it/s, loss=0.797]train epoch: 649:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.97it/s, loss=0.514]train epoch: 649: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.40it/s, loss=0.514]train epoch: 649: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.89it/s, loss=0.514]
[[032m2021-11-26 11:02:33,461[0m INFO] trainer.training_epoch Training epoch 649, num_steps 5200,  avg_loss: 0.7283, total_loss: 5.8266
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.58it/s]
[[032m2021-11-26 11:02:34,092[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:02:34,092[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:34,722[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 650:   0%|          | 0/8 [00:00<?, ?it/s]
prompt tensor([[0.6478, 0.3522],
        [0.1286, 0.8714],
        [0.5480, 0.4520],
        [0.6293, 0.3707],
        [0.4781, 0.5219],
        [0.4911, 0.5089],
        [0.5259, 0.4741],
        [0.5887, 0.4113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 650:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.673]train epoch: 650:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.54it/s, loss=0.673]train epoch: 650:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.54it/s, loss=0.713]train epoch: 650:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.97it/s, loss=0.713]train epoch: 650:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.97it/s, loss=0.65] train epoch: 650:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.02it/s, loss=0.65]train epoch: 650:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.02it/s, loss=0.85]train epoch: 650:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.99it/s, loss=0.85]train epoch: 650:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.99it/s, loss=0.833]train epoch: 650:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.09it/s, loss=0.833]train epoch: 650:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.09it/s, loss=0.821]train epoch: 650:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.89it/s, loss=0.821]train epoch: 650:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.89it/s, loss=0.63] train epoch: 650:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.95it/s, loss=0.63]train epoch: 650:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.95it/s, loss=0.774]train epoch: 650: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.65it/s, loss=0.774]train epoch: 650: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.83it/s, loss=0.774]
[[032m2021-11-26 11:02:36,104[0m INFO] trainer.training_epoch Training epoch 650, num_steps 5208,  avg_loss: 0.7429, total_loss: 5.9429
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.62it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.09it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.14it/s]
[[032m2021-11-26 11:02:36,570[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:36,571[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:36,997[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:37,210[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 651:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 651:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.725]train epoch: 651:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=0.725]train epoch: 651:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.43it/s, loss=0.647]train epoch: 651:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.51it/s, loss=0.647]train epoch: 651:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.51it/s, loss=0.985]train epoch: 651:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.93it/s, loss=0.985]train epoch: 651:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.93it/s, loss=0.82] train epoch: 651:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.83it/s, loss=0.82]train epoch: 651:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.83it/s, loss=0.624]train epoch: 651:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.27it/s, loss=0.624]train epoch: 651:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.27it/s, loss=0.678]train epoch: 651:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.48it/s, loss=0.678]train epoch: 651:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.48it/s, loss=0.838]train epoch: 651:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.79it/s, loss=0.838]train epoch: 651:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.79it/s, loss=0.664]train epoch: 651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.91it/s, loss=0.664]train epoch: 651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.41it/s, loss=0.664]
[[032m2021-11-26 11:02:38,707[0m INFO] trainer.training_epoch Training epoch 651, num_steps 5216,  avg_loss: 0.7477, total_loss: 5.9814
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.65it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.22it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.61it/s]
[[032m2021-11-26 11:02:39,139[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:39,140[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:39,361[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:39,579[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 652:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 652:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.655]train epoch: 652:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=0.655]train epoch: 652:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.15it/s, loss=0.992]train epoch: 652:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.40it/s, loss=0.992]train epoch: 652:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:02,  2.40it/s, loss=0.749]train epoch: 652:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.14it/s, loss=0.749]train epoch: 652:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.14it/s, loss=1.05] train epoch: 652:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=1.05]train epoch: 652:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.56it/s, loss=0.844]train epoch: 652:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.46it/s, loss=0.844]train epoch: 652:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.46it/s, loss=0.577]train epoch: 652:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.98it/s, loss=0.577]train epoch: 652:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.98it/s, loss=0.748]train epoch: 652:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=0.748]train epoch: 652:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.17it/s, loss=0.943]train epoch: 652: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.57it/s, loss=0.943]train epoch: 652: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.81it/s, loss=0.943]
[[032m2021-11-26 11:02:41,685[0m INFO] trainer.training_epoch Training epoch 652, num_steps 5224,  avg_loss: 0.8192, total_loss: 6.5533
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.65it/s]
[[032m2021-11-26 11:02:42,125[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:42,125[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:42,346[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:42,554[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 653:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 653:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.739]train epoch: 653:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.50it/s, loss=0.739]train epoch: 653:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.50it/s, loss=0.866]train epoch: 653:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.23it/s, loss=0.866]train epoch: 653:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.23it/s, loss=0.813]train epoch: 653:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.64it/s, loss=0.813]train epoch: 653:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.64it/s, loss=0.722]train epoch: 653:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=0.722]train epoch: 653:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.32it/s, loss=0.701]train epoch: 653:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.97it/s, loss=0.701]train epoch: 653:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.97it/s, loss=0.655]train epoch: 653:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.85it/s, loss=0.655]train epoch: 653:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.85it/s, loss=0.478]train epoch: 653:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.88it/s, loss=0.478]train epoch: 653:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.88it/s, loss=0.841]train epoch: 653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.00it/s, loss=0.841]train epoch: 653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s, loss=0.841]
[[032m2021-11-26 11:02:44,568[0m INFO] trainer.training_epoch Training epoch 653, num_steps 5232,  avg_loss: 0.7269, total_loss: 5.8150
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.10it/s]
[[032m2021-11-26 11:02:44,998[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:44,998[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:45,220[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:45,334[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 654:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 654:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.924]train epoch: 654:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.98it/s, loss=0.924]train epoch: 654:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.98it/s, loss=0.793]train epoch: 654:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.34it/s, loss=0.793]train epoch: 654:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.34it/s, loss=0.806]train epoch: 654:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.47it/s, loss=0.806]train epoch: 654:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.47it/s, loss=0.82] train epoch: 654:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.06it/s, loss=0.82]train epoch: 654:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.06it/s, loss=0.681]train epoch: 654:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=0.681]train epoch: 654:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=0.853]train epoch: 654:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.12it/s, loss=0.853]train epoch: 654:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.12it/s, loss=0.59] train epoch: 654:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.57it/s, loss=0.59]train epoch: 654:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.57it/s, loss=0.742]train epoch: 654: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.30it/s, loss=0.742]train epoch: 654: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.47it/s, loss=0.742]
[[032m2021-11-26 11:02:47,128[0m INFO] trainer.training_epoch Training epoch 654, num_steps 5240,  avg_loss: 0.7760, total_loss: 6.2079
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.05it/s]
[[032m2021-11-26 11:02:47,680[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:47,680[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:47,927[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:48,044[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 655:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 655:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.84]train epoch: 655:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.05it/s, loss=0.84]train epoch: 655:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.05it/s, loss=1.06]train epoch: 655:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.60it/s, loss=1.06]train epoch: 655:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.60it/s, loss=0.712]train epoch: 655:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.27it/s, loss=0.712]train epoch: 655:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.27it/s, loss=0.868]train epoch: 655:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.96it/s, loss=0.868]train epoch: 655:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s, loss=0.74] train epoch: 655:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.69it/s, loss=0.74]train epoch: 655:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.69it/s, loss=0.648]train epoch: 655:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.15it/s, loss=0.648]train epoch: 655:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.15it/s, loss=0.695]train epoch: 655:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.83it/s, loss=0.695]train epoch: 655:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.83it/s, loss=0.691]train epoch: 655: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.75it/s, loss=0.691]train epoch: 655: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.69it/s, loss=0.691]
[[032m2021-11-26 11:02:49,760[0m INFO] trainer.training_epoch Training epoch 655, num_steps 5248,  avg_loss: 0.7812, total_loss: 6.2495
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.72it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.50it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.83it/s]
[[032m2021-11-26 11:02:50,246[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:50,246[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:50,515[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:50,709[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 656:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 656:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.651]train epoch: 656:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.41it/s, loss=0.651]train epoch: 656:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.41it/s, loss=1]    train epoch: 656:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.47it/s, loss=1]train epoch: 656:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.47it/s, loss=0.663]train epoch: 656:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.88it/s, loss=0.663]train epoch: 656:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.88it/s, loss=0.594]train epoch: 656:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.82it/s, loss=0.594]train epoch: 656:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.82it/s, loss=0.589]train epoch: 656:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.74it/s, loss=0.589]train epoch: 656:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.74it/s, loss=0.839]train epoch: 656:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.06it/s, loss=0.839]train epoch: 656:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.06it/s, loss=0.743]train epoch: 656:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.63it/s, loss=0.743]train epoch: 656:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.63it/s, loss=0.804]train epoch: 656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.07it/s, loss=0.804]train epoch: 656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.80it/s, loss=0.804]
[[032m2021-11-26 11:02:52,383[0m INFO] trainer.training_epoch Training epoch 656, num_steps 5256,  avg_loss: 0.7356, total_loss: 5.8848
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.78it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.38it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.20it/s]
[[032m2021-11-26 11:02:53,112[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:53,113[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:53,339[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:53,471[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 657:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 657:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.669]train epoch: 657:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.78it/s, loss=0.669]train epoch: 657:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.78it/s, loss=0.737]train epoch: 657:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.28it/s, loss=0.737]train epoch: 657:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.28it/s, loss=0.937]train epoch: 657:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.42it/s, loss=0.937]train epoch: 657:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.42it/s, loss=0.653]train epoch: 657:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.12it/s, loss=0.653]train epoch: 657:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.12it/s, loss=0.778]train epoch: 657:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.69it/s, loss=0.778]train epoch: 657:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.69it/s, loss=0.974]train epoch: 657:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.49it/s, loss=0.974]train epoch: 657:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.49it/s, loss=0.783]train epoch: 657:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.28it/s, loss=0.783]train epoch: 657:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.28it/s, loss=0.711]train epoch: 657: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.12it/s, loss=0.711]train epoch: 657: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s, loss=0.711]
[[032m2021-11-26 11:02:55,073[0m INFO] trainer.training_epoch Training epoch 657, num_steps 5264,  avg_loss: 0.7803, total_loss: 6.2425
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.03it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.97it/s]
[[032m2021-11-26 11:02:55,669[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:55,669[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:56,209[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:56,370[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 658:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 658:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.651]train epoch: 658:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.07it/s, loss=0.651]train epoch: 658:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.07it/s, loss=0.734]train epoch: 658:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s, loss=0.734]train epoch: 658:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s, loss=0.698]train epoch: 658:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.19it/s, loss=0.698]train epoch: 658:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.19it/s, loss=0.657]train epoch: 658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.71it/s, loss=0.657]train epoch: 658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.71it/s, loss=0.684]train epoch: 658:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.83it/s, loss=0.684]train epoch: 658:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.83it/s, loss=0.884]train epoch: 658:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.95it/s, loss=0.884]train epoch: 658:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.95it/s, loss=0.812]train epoch: 658:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.65it/s, loss=0.812]train epoch: 658:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.65it/s, loss=0.653]train epoch: 658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s, loss=0.653]train epoch: 658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s, loss=0.653]
[[032m2021-11-26 11:02:57,840[0m INFO] trainer.training_epoch Training epoch 658, num_steps 5272,  avg_loss: 0.7216, total_loss: 5.7731
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.32it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.54it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.62it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.06it/s]
[[032m2021-11-26 11:02:58,418[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:02:58,418[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:02:58,685[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:02:59,086[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 659:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 659:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.912]train epoch: 659:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.83it/s, loss=0.912]train epoch: 659:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.83it/s, loss=0.843]train epoch: 659:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.57it/s, loss=0.843]train epoch: 659:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.57it/s, loss=0.885]train epoch: 659:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.58it/s, loss=0.885]train epoch: 659:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.58it/s, loss=0.58] train epoch: 659:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.10it/s, loss=0.58]train epoch: 659:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.10it/s, loss=0.908]train epoch: 659:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.44it/s, loss=0.908]train epoch: 659:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.44it/s, loss=0.737]train epoch: 659:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.74it/s, loss=0.737]train epoch: 659:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.74it/s, loss=0.473]train epoch: 659:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.61it/s, loss=0.473]train epoch: 659:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.61it/s, loss=0.728]train epoch: 659: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.02it/s, loss=0.728]train epoch: 659: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.66it/s, loss=0.728]
[[032m2021-11-26 11:03:00,518[0m INFO] trainer.training_epoch Training epoch 659, num_steps 5280,  avg_loss: 0.7583, total_loss: 6.0662
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.37it/s]
[[032m2021-11-26 11:03:01,067[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:01,067[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:01,378[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:01,542[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 660:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 660:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.707]train epoch: 660:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.98it/s, loss=0.707]train epoch: 660:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.98it/s, loss=1.05] train epoch: 660:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.74it/s, loss=1.05]train epoch: 660:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.74it/s, loss=0.751]train epoch: 660:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.35it/s, loss=0.751]train epoch: 660:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.35it/s, loss=0.75] train epoch: 660:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.68it/s, loss=0.75]train epoch: 660:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.68it/s, loss=0.69]train epoch: 660:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.02it/s, loss=0.69]train epoch: 660:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.02it/s, loss=1.01]train epoch: 660:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.34it/s, loss=1.01]train epoch: 660:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.34it/s, loss=0.765]train epoch: 660:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.44it/s, loss=0.765]train epoch: 660:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.44it/s, loss=0.538]train epoch: 660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.29it/s, loss=0.538]train epoch: 660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s, loss=0.538]
[[032m2021-11-26 11:03:03,065[0m INFO] trainer.training_epoch Training epoch 660, num_steps 5288,  avg_loss: 0.7816, total_loss: 6.2526
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.51it/s]
[[032m2021-11-26 11:03:03,466[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:03,467[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:03,701[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 661:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 661:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.905]train epoch: 661:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.18it/s, loss=0.905]train epoch: 661:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.18it/s, loss=0.579]train epoch: 661:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.48it/s, loss=0.579]train epoch: 661:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.48it/s, loss=0.694]train epoch: 661:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.64it/s, loss=0.694]train epoch: 661:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.64it/s, loss=0.753]train epoch: 661:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.97it/s, loss=0.753]train epoch: 661:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s, loss=0.763]train epoch: 661:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=0.763]train epoch: 661:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.32it/s, loss=0.987]train epoch: 661:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.42it/s, loss=0.987]train epoch: 661:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.42it/s, loss=0.967]train epoch: 661:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.67it/s, loss=0.967]train epoch: 661:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.67it/s, loss=0.665]train epoch: 661: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.23it/s, loss=0.665]train epoch: 661: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s, loss=0.665]
[[032m2021-11-26 11:03:05,721[0m INFO] trainer.training_epoch Training epoch 661, num_steps 5296,  avg_loss: 0.7890, total_loss: 6.3122
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]
[[032m2021-11-26 11:03:06,166[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:06,167[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:06,389[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 662:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 662:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.788]train epoch: 662:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.34it/s, loss=0.788]train epoch: 662:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.34it/s, loss=0.74] train epoch: 662:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.59it/s, loss=0.74]train epoch: 662:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.59it/s, loss=0.802]train epoch: 662:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.67it/s, loss=0.802]train epoch: 662:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.67it/s, loss=1.02] train epoch: 662:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.84it/s, loss=1.02]
prompt tensor([[0.4953, 0.5047],
        [0.5118, 0.4882],
        [0.4622, 0.5378],
        [0.4704, 0.5296],
        [0.5570, 0.4430],
        [0.6213, 0.3787],
        [0.1991, 0.8009],
        [0.6309, 0.3691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 662:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.84it/s, loss=0.632]train epoch: 662:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.04it/s, loss=0.632]train epoch: 662:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.04it/s, loss=0.794]train epoch: 662:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.63it/s, loss=0.794]train epoch: 662:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.63it/s, loss=0.704]train epoch: 662:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.25it/s, loss=0.704]train epoch: 662:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.25it/s, loss=0.858]train epoch: 662: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.80it/s, loss=0.858]train epoch: 662: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.85it/s, loss=0.858]
[[032m2021-11-26 11:03:08,043[0m INFO] trainer.training_epoch Training epoch 662, num_steps 5304,  avg_loss: 0.7925, total_loss: 6.3401
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.74it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.18it/s]
[[032m2021-11-26 11:03:08,515[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:08,516[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:08,749[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 663:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 663:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.683]train epoch: 663:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.30it/s, loss=0.683]train epoch: 663:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.30it/s, loss=0.654]train epoch: 663:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.30it/s, loss=0.654]train epoch: 663:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.30it/s, loss=0.799]train epoch: 663:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.64it/s, loss=0.799]train epoch: 663:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.64it/s, loss=1.02] train epoch: 663:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.03it/s, loss=1.02]train epoch: 663:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.03it/s, loss=0.715]train epoch: 663:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.23it/s, loss=0.715]train epoch: 663:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.23it/s, loss=0.743]train epoch: 663:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.57it/s, loss=0.743]train epoch: 663:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.57it/s, loss=0.617]train epoch: 663:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.69it/s, loss=0.617]train epoch: 663:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.69it/s, loss=0.749]train epoch: 663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.97it/s, loss=0.749]train epoch: 663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s, loss=0.749]
[[032m2021-11-26 11:03:10,228[0m INFO] trainer.training_epoch Training epoch 663, num_steps 5312,  avg_loss: 0.7481, total_loss: 5.9850
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.02it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.41it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.33it/s]
[[032m2021-11-26 11:03:10,795[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:10,802[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:11,065[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 664:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 664:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.67]train epoch: 664:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.37it/s, loss=0.67]train epoch: 664:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.37it/s, loss=0.67]train epoch: 664:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.54it/s, loss=0.67]train epoch: 664:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.54it/s, loss=0.979]train epoch: 664:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.99it/s, loss=0.979]train epoch: 664:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.99it/s, loss=0.906]train epoch: 664:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.906]train epoch: 664:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.719]train epoch: 664:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.96it/s, loss=0.719]train epoch: 664:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.96it/s, loss=0.957]train epoch: 664:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.84it/s, loss=0.957]train epoch: 664:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.84it/s, loss=0.552]train epoch: 664:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.28it/s, loss=0.552]train epoch: 664:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.28it/s, loss=0.676]train epoch: 664: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.43it/s, loss=0.676]train epoch: 664: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s, loss=0.676]
[[032m2021-11-26 11:03:12,502[0m INFO] trainer.training_epoch Training epoch 664, num_steps 5320,  avg_loss: 0.7661, total_loss: 6.1289
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.99it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.42it/s]
[[032m2021-11-26 11:03:13,267[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:13,267[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:13,602[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:13,790[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 665:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 665:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.85]train epoch: 665:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.55it/s, loss=0.85]train epoch: 665:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.55it/s, loss=0.648]train epoch: 665:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.31it/s, loss=0.648]train epoch: 665:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.31it/s, loss=0.557]train epoch: 665:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.60it/s, loss=0.557]train epoch: 665:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.60it/s, loss=0.877]train epoch: 665:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.57it/s, loss=0.877]train epoch: 665:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.57it/s, loss=0.821]train epoch: 665:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.79it/s, loss=0.821]train epoch: 665:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.79it/s, loss=0.869]train epoch: 665:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.91it/s, loss=0.869]train epoch: 665:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.91it/s, loss=1.06] train epoch: 665:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.88it/s, loss=1.06]train epoch: 665:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.88it/s, loss=0.86]train epoch: 665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.81it/s, loss=0.86]train epoch: 665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.74it/s, loss=0.86]
[[032m2021-11-26 11:03:15,196[0m INFO] trainer.training_epoch Training epoch 665, num_steps 5328,  avg_loss: 0.8184, total_loss: 6.5472
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.50it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.55it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.73it/s]
[[032m2021-11-26 11:03:15,821[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:15,821[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:16,566[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:16,804[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 666:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 666:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.677]train epoch: 666:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.73it/s, loss=0.677]train epoch: 666:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.73it/s, loss=0.914]train epoch: 666:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.36it/s, loss=0.914]train epoch: 666:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.36it/s, loss=0.829]train epoch: 666:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.67it/s, loss=0.829]train epoch: 666:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.67it/s, loss=0.78] train epoch: 666:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.75it/s, loss=0.78]train epoch: 666:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.75it/s, loss=0.872]train epoch: 666:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.98it/s, loss=0.872]train epoch: 666:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.98it/s, loss=0.773]train epoch: 666:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.17it/s, loss=0.773]train epoch: 666:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.17it/s, loss=0.868]train epoch: 666:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.97it/s, loss=0.868]train epoch: 666:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.97it/s, loss=0.494]train epoch: 666: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.69it/s, loss=0.494]train epoch: 666: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.78it/s, loss=0.494]
[[032m2021-11-26 11:03:18,200[0m INFO] trainer.training_epoch Training epoch 666, num_steps 5336,  avg_loss: 0.7759, total_loss: 6.2073
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.15it/s]
[[032m2021-11-26 11:03:18,706[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:18,706[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:19,149[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:19,434[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 667:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 667:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.814]train epoch: 667:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.69it/s, loss=0.814]train epoch: 667:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.69it/s, loss=0.459]train epoch: 667:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=0.459]train epoch: 667:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.55it/s, loss=0.573]train epoch: 667:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.18it/s, loss=0.573]train epoch: 667:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.18it/s, loss=0.906]train epoch: 667:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.75it/s, loss=0.906]train epoch: 667:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.75it/s, loss=0.726]train epoch: 667:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.86it/s, loss=0.726]train epoch: 667:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.86it/s, loss=0.615]train epoch: 667:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.54it/s, loss=0.615]train epoch: 667:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.54it/s, loss=0.616]train epoch: 667:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.80it/s, loss=0.616]train epoch: 667:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.80it/s, loss=0.75] train epoch: 667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.50it/s, loss=0.75]train epoch: 667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.49it/s, loss=0.75]
[[032m2021-11-26 11:03:21,232[0m INFO] trainer.training_epoch Training epoch 667, num_steps 5344,  avg_loss: 0.6824, total_loss: 5.4588
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.80it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.86it/s]
[[032m2021-11-26 11:03:21,930[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:21,931[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:22,366[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:22,520[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 668:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 668:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.742]train epoch: 668:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=0.742]train epoch: 668:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.73it/s, loss=1.16] train epoch: 668:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.66it/s, loss=1.16]train epoch: 668:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.66it/s, loss=1]   train epoch: 668:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.89it/s, loss=1]train epoch: 668:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.89it/s, loss=0.795]train epoch: 668:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.83it/s, loss=0.795]train epoch: 668:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.83it/s, loss=0.715]train epoch: 668:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.12it/s, loss=0.715]train epoch: 668:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.12it/s, loss=0.794]train epoch: 668:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.21it/s, loss=0.794]train epoch: 668:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.21it/s, loss=0.993]train epoch: 668:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.94it/s, loss=0.993]train epoch: 668:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.94it/s, loss=0.523]train epoch: 668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.72it/s, loss=0.523]train epoch: 668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.81it/s, loss=0.523]
[[032m2021-11-26 11:03:23,909[0m INFO] trainer.training_epoch Training epoch 668, num_steps 5352,  avg_loss: 0.8405, total_loss: 6.7243
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.94it/s]
[[032m2021-11-26 11:03:24,480[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:24,481[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:24,798[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:24,942[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 669:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 669:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.847]train epoch: 669:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.12it/s, loss=0.847]train epoch: 669:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.12it/s, loss=0.823]train epoch: 669:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.87it/s, loss=0.823]train epoch: 669:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.87it/s, loss=0.858]train epoch: 669:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s, loss=0.858]train epoch: 669:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s, loss=0.624]train epoch: 669:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.37it/s, loss=0.624]train epoch: 669:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.37it/s, loss=0.714]train epoch: 669:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.85it/s, loss=0.714]train epoch: 669:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.85it/s, loss=0.775]train epoch: 669:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.27it/s, loss=0.775]train epoch: 669:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.27it/s, loss=0.912]train epoch: 669:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.47it/s, loss=0.912]train epoch: 669:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.47it/s, loss=0.739]train epoch: 669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.19it/s, loss=0.739]train epoch: 669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s, loss=0.739]
[[032m2021-11-26 11:03:26,549[0m INFO] trainer.training_epoch Training epoch 669, num_steps 5360,  avg_loss: 0.7866, total_loss: 6.2927
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.79it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.30it/s]
[[032m2021-11-26 11:03:27,111[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:27,115[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:27,443[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:27,803[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 670:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 670:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.442]train epoch: 670:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.27it/s, loss=0.442]train epoch: 670:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.27it/s, loss=0.675]train epoch: 670:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=0.675]train epoch: 670:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.27it/s, loss=0.613]train epoch: 670:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.69it/s, loss=0.613]train epoch: 670:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.69it/s, loss=0.799]train epoch: 670:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.10it/s, loss=0.799]train epoch: 670:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  5.10it/s, loss=0.831]train epoch: 670:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.16it/s, loss=0.831]train epoch: 670:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.16it/s, loss=0.43] train epoch: 670:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.34it/s, loss=0.43]train epoch: 670:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.34it/s, loss=0.644]train epoch: 670:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.59it/s, loss=0.644]train epoch: 670:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.59it/s, loss=0.596]train epoch: 670: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.37it/s, loss=0.596]train epoch: 670: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.07it/s, loss=0.596]
[[032m2021-11-26 11:03:29,410[0m INFO] trainer.training_epoch Training epoch 670, num_steps 5368,  avg_loss: 0.6288, total_loss: 5.0303
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.25it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.67it/s]
[[032m2021-11-26 11:03:29,931[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:29,931[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:30,249[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:30,614[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 671:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 671:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.82]train epoch: 671:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.74it/s, loss=0.82]train epoch: 671:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.74it/s, loss=0.688]train epoch: 671:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s, loss=0.688]train epoch: 671:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s, loss=0.873]train epoch: 671:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.75it/s, loss=0.873]train epoch: 671:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.75it/s, loss=0.62] train epoch: 671:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.45it/s, loss=0.62]train epoch: 671:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.45it/s, loss=0.641]train epoch: 671:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.43it/s, loss=0.641]train epoch: 671:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.43it/s, loss=0.636]train epoch: 671:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.70it/s, loss=0.636]train epoch: 671:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.70it/s, loss=0.727]train epoch: 671:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.84it/s, loss=0.727]train epoch: 671:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.84it/s, loss=0.683]train epoch: 671: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.96it/s, loss=0.683]train epoch: 671: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.78it/s, loss=0.683]
[[032m2021-11-26 11:03:32,009[0m INFO] trainer.training_epoch Training epoch 671, num_steps 5376,  avg_loss: 0.7110, total_loss: 5.6878
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.42it/s]
[[032m2021-11-26 11:03:32,549[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:32,550[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:32,943[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 672:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 672:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.918]train epoch: 672:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.97it/s, loss=0.918]train epoch: 672:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.97it/s, loss=0.724]train epoch: 672:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.36it/s, loss=0.724]train epoch: 672:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.36it/s, loss=0.738]train epoch: 672:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=0.738]train epoch: 672:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.01it/s, loss=0.612]train epoch: 672:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.66it/s, loss=0.612]train epoch: 672:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.66it/s, loss=0.493]train epoch: 672:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.93it/s, loss=0.493]train epoch: 672:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.93it/s, loss=0.739]train epoch: 672:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.92it/s, loss=0.739]train epoch: 672:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.92it/s, loss=0.652]train epoch: 672:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.29it/s, loss=0.652]train epoch: 672:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.29it/s, loss=0.644]train epoch: 672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s, loss=0.644]train epoch: 672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.93it/s, loss=0.644]
[[032m2021-11-26 11:03:34,577[0m INFO] trainer.training_epoch Training epoch 672, num_steps 5384,  avg_loss: 0.6899, total_loss: 5.5194
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.13it/s]
[[032m2021-11-26 11:03:34,958[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:34,959[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:35,189[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 673:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 673:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.712]train epoch: 673:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=0.712]train epoch: 673:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.01it/s, loss=0.767]train epoch: 673:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.67it/s, loss=0.767]train epoch: 673:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.67it/s, loss=0.584]train epoch: 673:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=0.584]train epoch: 673:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.49it/s, loss=0.866]train epoch: 673:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.27it/s, loss=0.866]train epoch: 673:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.27it/s, loss=0.903]train epoch: 673:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.73it/s, loss=0.903]train epoch: 673:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.73it/s, loss=0.757]train epoch: 673:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.18it/s, loss=0.757]train epoch: 673:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.18it/s, loss=0.895]train epoch: 673:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.50it/s, loss=0.895]train epoch: 673:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.50it/s, loss=0.937]train epoch: 673: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.67it/s, loss=0.937]train epoch: 673: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.40it/s, loss=0.937]
[[032m2021-11-26 11:03:37,014[0m INFO] trainer.training_epoch Training epoch 673, num_steps 5392,  avg_loss: 0.8025, total_loss: 6.4201
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.02it/s]
[[032m2021-11-26 11:03:37,480[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:37,480[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:37,706[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 674:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 674:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.658]train epoch: 674:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.64it/s, loss=0.658]train epoch: 674:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.64it/s, loss=0.828]train epoch: 674:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.98it/s, loss=0.828]train epoch: 674:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.98it/s, loss=0.645]train epoch: 674:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.50it/s, loss=0.645]train epoch: 674:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:00,  5.50it/s, loss=0.689]train epoch: 674:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.24it/s, loss=0.689]train epoch: 674:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.24it/s, loss=0.687]train epoch: 674:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=0.687]train epoch: 674:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.91it/s, loss=0.724]train epoch: 674:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  2.89it/s, loss=0.724]train epoch: 674:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.89it/s, loss=0.561]train epoch: 674:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=0.561]train epoch: 674:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.99it/s, loss=0.933]train epoch: 674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.41it/s, loss=0.933]train epoch: 674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s, loss=0.933]
[[032m2021-11-26 11:03:40,024[0m INFO] trainer.training_epoch Training epoch 674, num_steps 5400,  avg_loss: 0.7157, total_loss: 5.7256
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.73it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.67it/s]
[[032m2021-11-26 11:03:40,424[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:40,425[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:40,659[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 675:   0%|          | 0/8 [00:00<?, ?it/s]
prompt tensor([[0.4864, 0.5136],
        [0.4768, 0.5232],
        [0.6936, 0.3064],
        [0.6198, 0.3802],
        [0.3622, 0.6378],
        [0.3134, 0.6866],
        [0.6275, 0.3725],
        [0.4474, 0.5526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 675:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.687]train epoch: 675:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.82it/s, loss=0.687]train epoch: 675:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.82it/s, loss=0.577]train epoch: 675:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.12it/s, loss=0.577]train epoch: 675:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.12it/s, loss=0.772]train epoch: 675:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.30it/s, loss=0.772]train epoch: 675:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.30it/s, loss=1.09] train epoch: 675:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.98it/s, loss=1.09]train epoch: 675:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.98it/s, loss=0.562]train epoch: 675:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.08it/s, loss=0.562]train epoch: 675:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.08it/s, loss=0.715]train epoch: 675:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.05it/s, loss=0.715]train epoch: 675:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.05it/s, loss=0.555]train epoch: 675:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.64it/s, loss=0.555]train epoch: 675:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.64it/s, loss=0.812]train epoch: 675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.77it/s, loss=0.812]train epoch: 675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.21it/s, loss=0.812]
[[032m2021-11-26 11:03:42,199[0m INFO] trainer.training_epoch Training epoch 675, num_steps 5408,  avg_loss: 0.7209, total_loss: 5.7675
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.11it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.62it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.14it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.66it/s]
[[032m2021-11-26 11:03:42,832[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:42,832[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:43,065[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 676:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 676:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.759]train epoch: 676:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.30it/s, loss=0.759]train epoch: 676:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.30it/s, loss=0.602]train epoch: 676:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.12it/s, loss=0.602]train epoch: 676:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.12it/s, loss=1.1]  train epoch: 676:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.80it/s, loss=1.1]train epoch: 676:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.80it/s, loss=1.04]train epoch: 676:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.02it/s, loss=1.04]train epoch: 676:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.02it/s, loss=0.804]train epoch: 676:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.55it/s, loss=0.804]train epoch: 676:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.55it/s, loss=0.769]train epoch: 676:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.60it/s, loss=0.769]train epoch: 676:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.60it/s, loss=0.736]train epoch: 676:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.70it/s, loss=0.736]train epoch: 676:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.70it/s, loss=0.76] train epoch: 676: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.93it/s, loss=0.76]train epoch: 676: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.84it/s, loss=0.76]
[[032m2021-11-26 11:03:44,442[0m INFO] trainer.training_epoch Training epoch 676, num_steps 5416,  avg_loss: 0.8214, total_loss: 6.5711
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.45it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.35it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.77it/s]
[[032m2021-11-26 11:03:45,001[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:45,001[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:45,373[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 677:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 677:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.616]train epoch: 677:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.34it/s, loss=0.616]train epoch: 677:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.34it/s, loss=0.905]train epoch: 677:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.02it/s, loss=0.905]train epoch: 677:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.02it/s, loss=0.869]train epoch: 677:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.60it/s, loss=0.869]train epoch: 677:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.60it/s, loss=0.602]train epoch: 677:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.86it/s, loss=0.602]train epoch: 677:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.86it/s, loss=0.611]train epoch: 677:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=0.611]train epoch: 677:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.93it/s, loss=0.985]train epoch: 677:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.53it/s, loss=0.985]train epoch: 677:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.53it/s, loss=1.02] train epoch: 677:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.87it/s, loss=1.02]train epoch: 677:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.87it/s, loss=0.731]train epoch: 677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.99it/s, loss=0.731]train epoch: 677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.45it/s, loss=0.731]
[[032m2021-11-26 11:03:47,180[0m INFO] trainer.training_epoch Training epoch 677, num_steps 5424,  avg_loss: 0.7921, total_loss: 6.3368
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.90it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.28it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.21it/s]
[[032m2021-11-26 11:03:47,569[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:47,570[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:47,788[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 678:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 678:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.726]train epoch: 678:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.23it/s, loss=0.726]train epoch: 678:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.23it/s, loss=0.638]train epoch: 678:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.86it/s, loss=0.638]train epoch: 678:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.86it/s, loss=0.564]train epoch: 678:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.21it/s, loss=0.564]train epoch: 678:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.21it/s, loss=0.587]train epoch: 678:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.58it/s, loss=0.587]train epoch: 678:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.58it/s, loss=1.03] train epoch: 678:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.53it/s, loss=1.03]train epoch: 678:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.53it/s, loss=0.734]train epoch: 678:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=0.734]train epoch: 678:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.99it/s, loss=0.825]train epoch: 678:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.42it/s, loss=0.825]train epoch: 678:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.42it/s, loss=0.628]train epoch: 678: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.64it/s, loss=0.628]train epoch: 678: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.11it/s, loss=0.628]
[[032m2021-11-26 11:03:49,741[0m INFO] trainer.training_epoch Training epoch 678, num_steps 5432,  avg_loss: 0.7169, total_loss: 5.7350
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.33it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.55it/s]
[[032m2021-11-26 11:03:50,249[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:50,250[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:50,502[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 679:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 679:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.848]train epoch: 679:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.16it/s, loss=0.848]train epoch: 679:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.16it/s, loss=0.568]train epoch: 679:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.77it/s, loss=0.568]train epoch: 679:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.77it/s, loss=0.981]train epoch: 679:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.54it/s, loss=0.981]train epoch: 679:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.54it/s, loss=0.639]train epoch: 679:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.40it/s, loss=0.639]train epoch: 679:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.40it/s, loss=0.715]train epoch: 679:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  4.98it/s, loss=0.715]train epoch: 679:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.98it/s, loss=0.597]train epoch: 679:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.09it/s, loss=0.597]train epoch: 679:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.09it/s, loss=1.09] train epoch: 679:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.93it/s, loss=1.09]train epoch: 679:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.93it/s, loss=0.862]train epoch: 679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.76it/s, loss=0.862]train epoch: 679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.37it/s, loss=0.862]
[[032m2021-11-26 11:03:52,340[0m INFO] trainer.training_epoch Training epoch 679, num_steps 5440,  avg_loss: 0.7876, total_loss: 6.3010
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.74it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.09it/s]
[[032m2021-11-26 11:03:52,920[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.546875)])
[[032m2021-11-26 11:03:52,920[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:53,184[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 680:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 680:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.01]train epoch: 680:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.44it/s, loss=1.01]train epoch: 680:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.44it/s, loss=0.835]train epoch: 680:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.84it/s, loss=0.835]train epoch: 680:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.84it/s, loss=0.611]train epoch: 680:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.83it/s, loss=0.611]train epoch: 680:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.83it/s, loss=0.969]train epoch: 680:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.95it/s, loss=0.969]train epoch: 680:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.95it/s, loss=0.734]train epoch: 680:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.40it/s, loss=0.734]train epoch: 680:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.40it/s, loss=0.827]train epoch: 680:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.56it/s, loss=0.827]train epoch: 680:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.56it/s, loss=0.764]train epoch: 680:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.27it/s, loss=0.764]train epoch: 680:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.27it/s, loss=0.787]train epoch: 680: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.98it/s, loss=0.787]train epoch: 680: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.64it/s, loss=0.787]
[[032m2021-11-26 11:03:54,917[0m INFO] trainer.training_epoch Training epoch 680, num_steps 5448,  avg_loss: 0.8171, total_loss: 6.5369
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.56it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.96it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.24it/s]
[[032m2021-11-26 11:03:55,463[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:55,463[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:55,704[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:55,886[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 681:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 681:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.654]train epoch: 681:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.62it/s, loss=0.654]train epoch: 681:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.62it/s, loss=0.728]train epoch: 681:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.78it/s, loss=0.728]train epoch: 681:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.78it/s, loss=0.999]train epoch: 681:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.64it/s, loss=0.999]train epoch: 681:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.64it/s, loss=0.917]train epoch: 681:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.51it/s, loss=0.917]train epoch: 681:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.51it/s, loss=0.736]train epoch: 681:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.42it/s, loss=0.736]train epoch: 681:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.42it/s, loss=0.655]train epoch: 681:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.21it/s, loss=0.655]train epoch: 681:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.21it/s, loss=0.536]train epoch: 681:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.41it/s, loss=0.536]train epoch: 681:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.41it/s, loss=0.879]train epoch: 681: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.66it/s, loss=0.879]train epoch: 681: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s, loss=0.879]
[[032m2021-11-26 11:03:57,338[0m INFO] trainer.training_epoch Training epoch 681, num_steps 5456,  avg_loss: 0.7632, total_loss: 6.1058
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.21it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.35it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.85it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.25it/s]
[[032m2021-11-26 11:03:58,028[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:03:58,029[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:03:58,721[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:03:58,920[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 682:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 682:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.73]train epoch: 682:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.12it/s, loss=0.73]train epoch: 682:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.12it/s, loss=0.856]train epoch: 682:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.51it/s, loss=0.856]train epoch: 682:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.51it/s, loss=0.742]train epoch: 682:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.35it/s, loss=0.742]train epoch: 682:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.35it/s, loss=0.524]train epoch: 682:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.27it/s, loss=0.524]train epoch: 682:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.27it/s, loss=0.729]train epoch: 682:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.23it/s, loss=0.729]train epoch: 682:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.23it/s, loss=0.758]train epoch: 682:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.61it/s, loss=0.758]train epoch: 682:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.61it/s, loss=0.637]train epoch: 682:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.60it/s, loss=0.637]train epoch: 682:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.60it/s, loss=0.853]train epoch: 682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.81it/s, loss=0.853]train epoch: 682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s, loss=0.853]
[[032m2021-11-26 11:04:00,354[0m INFO] trainer.training_epoch Training epoch 682, num_steps 5464,  avg_loss: 0.7288, total_loss: 5.8301
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.18it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.84it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.12it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.94it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.24it/s]
[[032m2021-11-26 11:04:00,927[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:00,927[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:01,538[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:01,971[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 683:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 683:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.882]train epoch: 683:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=0.882]train epoch: 683:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.08it/s, loss=0.692]train epoch: 683:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=0.692]train epoch: 683:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=0.894]train epoch: 683:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s, loss=0.894]train epoch: 683:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s, loss=0.718]train epoch: 683:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.02it/s, loss=0.718]train epoch: 683:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  5.02it/s, loss=0.602]train epoch: 683:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.03it/s, loss=0.602]train epoch: 683:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.03it/s, loss=0.776]train epoch: 683:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.47it/s, loss=0.776]train epoch: 683:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.47it/s, loss=0.68] train epoch: 683:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.56it/s, loss=0.68]train epoch: 683:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.56it/s, loss=0.813]train epoch: 683: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s, loss=0.813]train epoch: 683: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.11it/s, loss=0.813]
[[032m2021-11-26 11:04:03,553[0m INFO] trainer.training_epoch Training epoch 683, num_steps 5472,  avg_loss: 0.7573, total_loss: 6.0587
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.83it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.95it/s]
[[032m2021-11-26 11:04:04,176[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:04,177[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:04,707[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:04,954[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 684:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 684:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.635]train epoch: 684:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.33it/s, loss=0.635]train epoch: 684:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.33it/s, loss=0.7]  train epoch: 684:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.44it/s, loss=0.7]train epoch: 684:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.44it/s, loss=0.677]train epoch: 684:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.08it/s, loss=0.677]train epoch: 684:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.08it/s, loss=0.622]train epoch: 684:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.64it/s, loss=0.622]train epoch: 684:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.64it/s, loss=0.636]train epoch: 684:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.87it/s, loss=0.636]train epoch: 684:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.87it/s, loss=0.791]train epoch: 684:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.10it/s, loss=0.791]train epoch: 684:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.10it/s, loss=0.583]train epoch: 684:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.91it/s, loss=0.583]train epoch: 684:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.91it/s, loss=0.901]train epoch: 684: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.48it/s, loss=0.901]train epoch: 684: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.68it/s, loss=0.901]
[[032m2021-11-26 11:04:06,382[0m INFO] trainer.training_epoch Training epoch 684, num_steps 5480,  avg_loss: 0.6933, total_loss: 5.5461
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.40it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.99it/s]
[[032m2021-11-26 11:04:07,112[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:07,112[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:07,637[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:07,865[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 685:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 685:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.664]train epoch: 685:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.35it/s, loss=0.664]train epoch: 685:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.35it/s, loss=0.53] train epoch: 685:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.92it/s, loss=0.53]train epoch: 685:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.92it/s, loss=1.06]train epoch: 685:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.10it/s, loss=1.06]train epoch: 685:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.10it/s, loss=0.719]train epoch: 685:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.38it/s, loss=0.719]train epoch: 685:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.38it/s, loss=0.822]train epoch: 685:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.05it/s, loss=0.822]train epoch: 685:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.05it/s, loss=0.816]train epoch: 685:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.17it/s, loss=0.816]train epoch: 685:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.17it/s, loss=0.695]train epoch: 685:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.75it/s, loss=0.695]train epoch: 685:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.75it/s, loss=0.614]train epoch: 685: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.10it/s, loss=0.614]train epoch: 685: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.10it/s, loss=0.614]
[[032m2021-11-26 11:04:09,445[0m INFO] trainer.training_epoch Training epoch 685, num_steps 5488,  avg_loss: 0.7404, total_loss: 5.9232
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.59it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.22it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]
[[032m2021-11-26 11:04:09,950[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:09,950[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:10,608[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:10,875[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 686:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 686:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.755]train epoch: 686:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.01it/s, loss=0.755]train epoch: 686:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.01it/s, loss=0.614]train epoch: 686:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.35it/s, loss=0.614]train epoch: 686:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.35it/s, loss=0.916]train epoch: 686:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.95it/s, loss=0.916]train epoch: 686:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.95it/s, loss=0.739]train epoch: 686:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.14it/s, loss=0.739]train epoch: 686:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.14it/s, loss=0.983]train epoch: 686:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.01it/s, loss=0.983]train epoch: 686:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.01it/s, loss=0.596]train epoch: 686:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  5.95it/s, loss=0.596]train epoch: 686:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.95it/s, loss=0.944]train epoch: 686:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.42it/s, loss=0.944]train epoch: 686:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.42it/s, loss=0.587]train epoch: 686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.40it/s, loss=0.587]train epoch: 686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.73it/s, loss=0.587]
[[032m2021-11-26 11:04:12,276[0m INFO] trainer.training_epoch Training epoch 686, num_steps 5496,  avg_loss: 0.7667, total_loss: 6.1339
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.97it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.26it/s]
[[032m2021-11-26 11:04:12,778[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:12,778[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:13,219[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:13,492[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 687:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 687:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.795]train epoch: 687:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.53it/s, loss=0.795]train epoch: 687:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.53it/s, loss=0.76] train epoch: 687:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s, loss=0.76]train epoch: 687:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s, loss=0.651]train epoch: 687:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.12it/s, loss=0.651]train epoch: 687:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.12it/s, loss=0.728]train epoch: 687:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.75it/s, loss=0.728]
prompt tensor([[0.4978, 0.5022],
        [0.6875, 0.3125],
        [0.5393, 0.4607],
        [0.4327, 0.5673],
        [0.7333, 0.2667],
        [0.6866, 0.3134],
        [0.6580, 0.3420],
        [0.5846, 0.4154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 687:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.75it/s, loss=0.709]train epoch: 687:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.82it/s, loss=0.709]train epoch: 687:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.82it/s, loss=0.908]train epoch: 687:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.79it/s, loss=0.908]train epoch: 687:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.79it/s, loss=0.967]train epoch: 687:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.16it/s, loss=0.967]train epoch: 687:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.16it/s, loss=0.801]train epoch: 687: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.36it/s, loss=0.801]train epoch: 687: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s, loss=0.801]
[[032m2021-11-26 11:04:14,920[0m INFO] trainer.training_epoch Training epoch 687, num_steps 5504,  avg_loss: 0.7899, total_loss: 6.3189
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.21it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.77it/s]
[[032m2021-11-26 11:04:15,484[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:15,484[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:16,039[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:16,228[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 688:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 688:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.798]train epoch: 688:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=0.798]train epoch: 688:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.95it/s, loss=0.877]train epoch: 688:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.91it/s, loss=0.877]train epoch: 688:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.91it/s, loss=0.699]train epoch: 688:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.32it/s, loss=0.699]train epoch: 688:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.32it/s, loss=0.665]train epoch: 688:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.41it/s, loss=0.665]train epoch: 688:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.41it/s, loss=0.59] train epoch: 688:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.52it/s, loss=0.59]train epoch: 688:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.52it/s, loss=0.825]train epoch: 688:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.83it/s, loss=0.825]train epoch: 688:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.83it/s, loss=0.832]train epoch: 688:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.73it/s, loss=0.832]train epoch: 688:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.73it/s, loss=0.749]train epoch: 688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s, loss=0.749]train epoch: 688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s, loss=0.749]
[[032m2021-11-26 11:04:17,699[0m INFO] trainer.training_epoch Training epoch 688, num_steps 5512,  avg_loss: 0.7542, total_loss: 6.0339
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.60it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.75it/s]
[[032m2021-11-26 11:04:18,255[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:18,255[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:18,723[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:19,021[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 689:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 689:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.716]train epoch: 689:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.75it/s, loss=0.716]train epoch: 689:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.75it/s, loss=0.657]train epoch: 689:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.02it/s, loss=0.657]train epoch: 689:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.02it/s, loss=0.601]train epoch: 689:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.54it/s, loss=0.601]train epoch: 689:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.54it/s, loss=0.705]train epoch: 689:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.60it/s, loss=0.705]train epoch: 689:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.60it/s, loss=0.875]train epoch: 689:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.78it/s, loss=0.875]train epoch: 689:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.78it/s, loss=0.843]train epoch: 689:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.79it/s, loss=0.843]train epoch: 689:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.79it/s, loss=0.589]train epoch: 689:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.76it/s, loss=0.589]train epoch: 689:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.76it/s, loss=0.902]train epoch: 689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.38it/s, loss=0.902]train epoch: 689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s, loss=0.902]
[[032m2021-11-26 11:04:20,476[0m INFO] trainer.training_epoch Training epoch 689, num_steps 5520,  avg_loss: 0.7358, total_loss: 5.8867
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.00it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.12it/s]
[[032m2021-11-26 11:04:20,865[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:20,865[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:21,483[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:21,730[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 690:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 690:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.674]train epoch: 690:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.16it/s, loss=0.674]train epoch: 690:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.16it/s, loss=0.846]train epoch: 690:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.21it/s, loss=0.846]train epoch: 690:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.21it/s, loss=0.655]train epoch: 690:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.95it/s, loss=0.655]train epoch: 690:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.95it/s, loss=0.664]train epoch: 690:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.07it/s, loss=0.664]train epoch: 690:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  5.07it/s, loss=0.864]train epoch: 690:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.20it/s, loss=0.864]train epoch: 690:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.20it/s, loss=0.65] train epoch: 690:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.23it/s, loss=0.65]train epoch: 690:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.23it/s, loss=0.779]train epoch: 690:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.17it/s, loss=0.779]train epoch: 690:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.17it/s, loss=0.673]train epoch: 690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.21it/s, loss=0.673]train epoch: 690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.97it/s, loss=0.673]
[[032m2021-11-26 11:04:23,357[0m INFO] trainer.training_epoch Training epoch 690, num_steps 5528,  avg_loss: 0.7258, total_loss: 5.8067
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.10it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.78it/s]
[[032m2021-11-26 11:04:23,790[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:23,791[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:24,418[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:24,678[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 691:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 691:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.789]train epoch: 691:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.68it/s, loss=0.789]train epoch: 691:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.68it/s, loss=0.749]train epoch: 691:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=0.749]train epoch: 691:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.48it/s, loss=0.592]train epoch: 691:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.91it/s, loss=0.592]train epoch: 691:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.91it/s, loss=0.666]train epoch: 691:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.31it/s, loss=0.666]train epoch: 691:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.31it/s, loss=0.91] train epoch: 691:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.44it/s, loss=0.91]train epoch: 691:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.44it/s, loss=0.857]train epoch: 691:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.23it/s, loss=0.857]train epoch: 691:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.23it/s, loss=0.667]train epoch: 691:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.28it/s, loss=0.667]train epoch: 691:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.28it/s, loss=0.972]train epoch: 691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s, loss=0.972]train epoch: 691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.33it/s, loss=0.972]
[[032m2021-11-26 11:04:26,185[0m INFO] trainer.training_epoch Training epoch 691, num_steps 5536,  avg_loss: 0.7751, total_loss: 6.2008
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.62it/s]
[[032m2021-11-26 11:04:26,662[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:26,662[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:27,094[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:27,446[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 692:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 692:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.69]train epoch: 692:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.64it/s, loss=0.69]train epoch: 692:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.64it/s, loss=0.785]train epoch: 692:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.33it/s, loss=0.785]train epoch: 692:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.33it/s, loss=0.682]train epoch: 692:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.80it/s, loss=0.682]train epoch: 692:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.80it/s, loss=0.802]train epoch: 692:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.23it/s, loss=0.802]train epoch: 692:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.23it/s, loss=0.698]train epoch: 692:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.44it/s, loss=0.698]train epoch: 692:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.44it/s, loss=0.666]train epoch: 692:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.59it/s, loss=0.666]train epoch: 692:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.59it/s, loss=0.758]train epoch: 692:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.82it/s, loss=0.758]train epoch: 692:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.82it/s, loss=0.931]train epoch: 692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.75it/s, loss=0.931]train epoch: 692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.34it/s, loss=0.931]
[[032m2021-11-26 11:04:28,957[0m INFO] trainer.training_epoch Training epoch 692, num_steps 5544,  avg_loss: 0.7514, total_loss: 6.0110
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.26it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.09it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.58it/s]
[[032m2021-11-26 11:04:29,496[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:29,496[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:29,895[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:30,052[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 693:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 693:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.753]train epoch: 693:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.09it/s, loss=0.753]train epoch: 693:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.09it/s, loss=0.77] train epoch: 693:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=0.77]train epoch: 693:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.57it/s, loss=0.705]train epoch: 693:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.97it/s, loss=0.705]train epoch: 693:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.97it/s, loss=0.77] train epoch: 693:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.11it/s, loss=0.77]train epoch: 693:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.11it/s, loss=0.694]train epoch: 693:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.46it/s, loss=0.694]train epoch: 693:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.46it/s, loss=0.775]train epoch: 693:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.42it/s, loss=0.775]train epoch: 693:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.42it/s, loss=0.85] train epoch: 693:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.58it/s, loss=0.85]train epoch: 693:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.58it/s, loss=0.579]train epoch: 693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.65it/s, loss=0.579]train epoch: 693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.33it/s, loss=0.579]
[[032m2021-11-26 11:04:31,569[0m INFO] trainer.training_epoch Training epoch 693, num_steps 5552,  avg_loss: 0.7370, total_loss: 5.8957
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.11it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.44it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.06it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.79it/s]
[[032m2021-11-26 11:04:32,072[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:32,073[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:32,787[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:33,063[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 694:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 694:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.25]train epoch: 694:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.42it/s, loss=1.25]train epoch: 694:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.42it/s, loss=0.599]train epoch: 694:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=0.599]train epoch: 694:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.31it/s, loss=0.69] train epoch: 694:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.56it/s, loss=0.69]train epoch: 694:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.56it/s, loss=0.598]train epoch: 694:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.18it/s, loss=0.598]train epoch: 694:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.18it/s, loss=0.792]train epoch: 694:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.36it/s, loss=0.792]train epoch: 694:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.36it/s, loss=0.814]train epoch: 694:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.40it/s, loss=0.814]train epoch: 694:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.40it/s, loss=0.732]train epoch: 694:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.64it/s, loss=0.732]train epoch: 694:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.64it/s, loss=0.775]train epoch: 694: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.66it/s, loss=0.775]train epoch: 694: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.33it/s, loss=0.775]
[[032m2021-11-26 11:04:34,580[0m INFO] trainer.training_epoch Training epoch 694, num_steps 5560,  avg_loss: 0.7808, total_loss: 6.2468
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.46it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.57it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.04it/s]
[[032m2021-11-26 11:04:34,999[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:34,999[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:35,293[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:35,495[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 695:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 695:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.741]train epoch: 695:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.07it/s, loss=0.741]train epoch: 695:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.07it/s, loss=0.559]train epoch: 695:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.35it/s, loss=0.559]train epoch: 695:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.35it/s, loss=0.555]train epoch: 695:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=0.555]train epoch: 695:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=0.635]train epoch: 695:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.36it/s, loss=0.635]train epoch: 695:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.36it/s, loss=0.908]train epoch: 695:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.83it/s, loss=0.908]train epoch: 695:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.83it/s, loss=0.696]train epoch: 695:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.10it/s, loss=0.696]train epoch: 695:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.10it/s, loss=0.634]train epoch: 695:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.12it/s, loss=0.634]train epoch: 695:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.12it/s, loss=0.743]train epoch: 695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.40it/s, loss=0.743]train epoch: 695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.88it/s, loss=0.743]
[[032m2021-11-26 11:04:37,144[0m INFO] trainer.training_epoch Training epoch 695, num_steps 5568,  avg_loss: 0.6840, total_loss: 5.4717
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.72it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.56it/s]
[[032m2021-11-26 11:04:37,560[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.5625)])
[[032m2021-11-26 11:04:37,560[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:37,784[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:37,911[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 696:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 696:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.758]train epoch: 696:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.53it/s, loss=0.758]train epoch: 696:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.53it/s, loss=0.668]train epoch: 696:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.32it/s, loss=0.668]train epoch: 696:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.32it/s, loss=0.615]train epoch: 696:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.13it/s, loss=0.615]train epoch: 696:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.13it/s, loss=0.931]train epoch: 696:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.931]train epoch: 696:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.76] train epoch: 696:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.56it/s, loss=0.76]train epoch: 696:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.56it/s, loss=0.693]train epoch: 696:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.71it/s, loss=0.693]train epoch: 696:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.71it/s, loss=0.91] train epoch: 696:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.97it/s, loss=0.91]train epoch: 696:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.97it/s, loss=0.649]train epoch: 696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s, loss=0.649]train epoch: 696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.75it/s, loss=0.649]
[[032m2021-11-26 11:04:39,308[0m INFO] trainer.training_epoch Training epoch 696, num_steps 5576,  avg_loss: 0.7480, total_loss: 5.9840
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.56it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.49it/s]
[[032m2021-11-26 11:04:39,714[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:39,715[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:40,018[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:40,143[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 697:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 697:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.645]train epoch: 697:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.75it/s, loss=0.645]train epoch: 697:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.75it/s, loss=0.722]train epoch: 697:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.28it/s, loss=0.722]train epoch: 697:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.28it/s, loss=0.643]train epoch: 697:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.75it/s, loss=0.643]train epoch: 697:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.75it/s, loss=0.517]train epoch: 697:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.22it/s, loss=0.517]train epoch: 697:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.22it/s, loss=0.614]train epoch: 697:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.45it/s, loss=0.614]train epoch: 697:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.45it/s, loss=0.6]  train epoch: 697:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.32it/s, loss=0.6]train epoch: 697:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.32it/s, loss=0.615]train epoch: 697:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.70it/s, loss=0.615]train epoch: 697:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.70it/s, loss=1.14] train epoch: 697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.95it/s, loss=1.14]train epoch: 697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.61it/s, loss=1.14]
[[032m2021-11-26 11:04:41,885[0m INFO] trainer.training_epoch Training epoch 697, num_steps 5584,  avg_loss: 0.6876, total_loss: 5.5006
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.04it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.05it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.11it/s]
[[032m2021-11-26 11:04:42,457[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:42,458[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:42,747[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:42,909[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 698:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 698:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.705]train epoch: 698:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.93it/s, loss=0.705]train epoch: 698:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.93it/s, loss=0.518]train epoch: 698:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.52it/s, loss=0.518]train epoch: 698:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.52it/s, loss=0.801]train epoch: 698:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.99it/s, loss=0.801]train epoch: 698:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.99it/s, loss=0.856]train epoch: 698:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.856]train epoch: 698:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.84it/s, loss=0.749]train epoch: 698:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.44it/s, loss=0.749]train epoch: 698:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.44it/s, loss=0.524]train epoch: 698:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.80it/s, loss=0.524]train epoch: 698:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.80it/s, loss=0.825]train epoch: 698:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.03it/s, loss=0.825]train epoch: 698:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.03it/s, loss=0.572]train epoch: 698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.00it/s, loss=0.572]train epoch: 698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.96it/s, loss=0.572]
[[032m2021-11-26 11:04:44,259[0m INFO] trainer.training_epoch Training epoch 698, num_steps 5592,  avg_loss: 0.6937, total_loss: 5.5497
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.96it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.99it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.56it/s]
[[032m2021-11-26 11:04:44,934[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:44,934[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:45,398[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:45,572[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 699:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 699:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.661]train epoch: 699:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.61it/s, loss=0.661]train epoch: 699:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.61it/s, loss=0.661]train epoch: 699:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s, loss=0.661]train epoch: 699:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s, loss=0.867]train epoch: 699:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.10it/s, loss=0.867]train epoch: 699:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.10it/s, loss=0.668]train epoch: 699:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.90it/s, loss=0.668]train epoch: 699:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.90it/s, loss=0.709]train epoch: 699:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.98it/s, loss=0.709]train epoch: 699:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.98it/s, loss=0.607]train epoch: 699:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.62it/s, loss=0.607]train epoch: 699:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.62it/s, loss=0.671]train epoch: 699:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.33it/s, loss=0.671]train epoch: 699:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.33it/s, loss=0.852]train epoch: 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.75it/s, loss=0.852]train epoch: 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.35it/s, loss=0.852]
[[032m2021-11-26 11:04:47,073[0m INFO] trainer.training_epoch Training epoch 699, num_steps 5600,  avg_loss: 0.7122, total_loss: 5.6976
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.98it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.69it/s]
[[032m2021-11-26 11:04:47,747[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:47,749[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:48,549[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:48,660[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 700:   0%|          | 0/8 [00:00<?, ?it/s]
prompt tensor([[0.6347, 0.3653],
        [0.3682, 0.6318],
        [0.3912, 0.6088],
        [0.5069, 0.4931],
        [0.4992, 0.5008],
        [0.4151, 0.5849],
        [0.4866, 0.5134],
        [0.4296, 0.5704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 700:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.838]train epoch: 700:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=0.838]train epoch: 700:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.03it/s, loss=0.853]train epoch: 700:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.48it/s, loss=0.853]train epoch: 700:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.48it/s, loss=0.678]train epoch: 700:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.69it/s, loss=0.678]train epoch: 700:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.69it/s, loss=0.547]train epoch: 700:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.04it/s, loss=0.547]train epoch: 700:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.04it/s, loss=0.622]train epoch: 700:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.95it/s, loss=0.622]train epoch: 700:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.95it/s, loss=0.754]train epoch: 700:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.02it/s, loss=0.754]train epoch: 700:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.02it/s, loss=1.16] train epoch: 700:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.81it/s, loss=1.16]train epoch: 700:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.81it/s, loss=0.479]train epoch: 700: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.92it/s, loss=0.479]train epoch: 700: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.84it/s, loss=0.479]
[[032m2021-11-26 11:04:50,035[0m INFO] trainer.training_epoch Training epoch 700, num_steps 5608,  avg_loss: 0.7413, total_loss: 5.9308
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.59it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.13it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.87it/s]
[[032m2021-11-26 11:04:50,599[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:50,599[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:50,943[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:51,651[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 701:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 701:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.624]train epoch: 701:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.15it/s, loss=0.624]train epoch: 701:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.15it/s, loss=0.665]train epoch: 701:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.24it/s, loss=0.665]train epoch: 701:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.24it/s, loss=0.998]train epoch: 701:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.67it/s, loss=0.998]train epoch: 701:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.67it/s, loss=1.01] train epoch: 701:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.88it/s, loss=1.01]train epoch: 701:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.88it/s, loss=0.694]train epoch: 701:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.08it/s, loss=0.694]train epoch: 701:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.08it/s, loss=0.644]train epoch: 701:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.68it/s, loss=0.644]train epoch: 701:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.68it/s, loss=0.727]train epoch: 701:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.79it/s, loss=0.727]train epoch: 701:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.79it/s, loss=1.02] train epoch: 701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.69it/s, loss=1.02]train epoch: 701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.74it/s, loss=1.02]
[[032m2021-11-26 11:04:53,051[0m INFO] trainer.training_epoch Training epoch 701, num_steps 5616,  avg_loss: 0.7977, total_loss: 6.3815
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.56it/s]
[[032m2021-11-26 11:04:53,496[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:53,496[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:53,919[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:54,190[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 702:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 702:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.815]train epoch: 702:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.78it/s, loss=0.815]train epoch: 702:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.78it/s, loss=0.633]train epoch: 702:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=0.633]train epoch: 702:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.35it/s, loss=0.83] train epoch: 702:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.98it/s, loss=0.83]train epoch: 702:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.98it/s, loss=0.719]train epoch: 702:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.19it/s, loss=0.719]train epoch: 702:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.19it/s, loss=0.572]train epoch: 702:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.31it/s, loss=0.572]train epoch: 702:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.31it/s, loss=0.715]train epoch: 702:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.40it/s, loss=0.715]train epoch: 702:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.40it/s, loss=0.582]train epoch: 702:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.67it/s, loss=0.582]train epoch: 702:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.67it/s, loss=0.965]train epoch: 702: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.65it/s, loss=0.965]train epoch: 702: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.29it/s, loss=0.965]
[[032m2021-11-26 11:04:55,716[0m INFO] trainer.training_epoch Training epoch 702, num_steps 5624,  avg_loss: 0.7288, total_loss: 5.8303
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.53it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.95it/s]
[[032m2021-11-26 11:04:56,873[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:56,873[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:57,309[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:04:57,441[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 703:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 703:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.718]train epoch: 703:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.95it/s, loss=0.718]train epoch: 703:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.95it/s, loss=0.718]train epoch: 703:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.38it/s, loss=0.718]train epoch: 703:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.38it/s, loss=0.766]train epoch: 703:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.87it/s, loss=0.766]train epoch: 703:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.87it/s, loss=0.994]train epoch: 703:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.47it/s, loss=0.994]train epoch: 703:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.47it/s, loss=0.518]train epoch: 703:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.33it/s, loss=0.518]train epoch: 703:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.33it/s, loss=0.896]train epoch: 703:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.48it/s, loss=0.896]train epoch: 703:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.48it/s, loss=0.642]train epoch: 703:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.35it/s, loss=0.642]train epoch: 703:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.35it/s, loss=0.812]train epoch: 703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.43it/s, loss=0.812]train epoch: 703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s, loss=0.812]
[[032m2021-11-26 11:04:58,887[0m INFO] trainer.training_epoch Training epoch 703, num_steps 5632,  avg_loss: 0.7579, total_loss: 6.0633
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.24it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.70it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.69it/s]
[[032m2021-11-26 11:04:59,388[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:04:59,388[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:04:59,834[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:00,157[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 704:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 704:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.955]train epoch: 704:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.20it/s, loss=0.955]train epoch: 704:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.20it/s, loss=0.619]train epoch: 704:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.44it/s, loss=0.619]train epoch: 704:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.44it/s, loss=0.629]train epoch: 704:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.53it/s, loss=0.629]train epoch: 704:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.53it/s, loss=0.806]train epoch: 704:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.82it/s, loss=0.806]train epoch: 704:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.82it/s, loss=0.813]train epoch: 704:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.01it/s, loss=0.813]train epoch: 704:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.01it/s, loss=0.839]train epoch: 704:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.45it/s, loss=0.839]train epoch: 704:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.45it/s, loss=0.749]train epoch: 704:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.58it/s, loss=0.749]train epoch: 704:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.58it/s, loss=0.787]train epoch: 704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.16it/s, loss=0.787]train epoch: 704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s, loss=0.787]
[[032m2021-11-26 11:05:01,629[0m INFO] trainer.training_epoch Training epoch 704, num_steps 5640,  avg_loss: 0.7743, total_loss: 6.1947
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.65it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.20it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.04it/s]
[[032m2021-11-26 11:05:02,120[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:02,121[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:02,382[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:02,552[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 705:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 705:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.991]train epoch: 705:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.18it/s, loss=0.991]train epoch: 705:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.18it/s, loss=0.751]train epoch: 705:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.32it/s, loss=0.751]train epoch: 705:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.32it/s, loss=0.774]train epoch: 705:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s, loss=0.774]train epoch: 705:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s, loss=0.77] train epoch: 705:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.37it/s, loss=0.77]train epoch: 705:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.37it/s, loss=0.854]train epoch: 705:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.64it/s, loss=0.854]train epoch: 705:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.64it/s, loss=0.737]train epoch: 705:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.79it/s, loss=0.737]train epoch: 705:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.79it/s, loss=0.645]train epoch: 705:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.14it/s, loss=0.645]train epoch: 705:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.14it/s, loss=0.554]train epoch: 705: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.71it/s, loss=0.554]train epoch: 705: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.33it/s, loss=0.554]
[[032m2021-11-26 11:05:04,411[0m INFO] trainer.training_epoch Training epoch 705, num_steps 5648,  avg_loss: 0.7597, total_loss: 6.0774
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.04it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.69it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.62it/s]
[[032m2021-11-26 11:05:04,929[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:04,930[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:05,174[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:05,336[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 706:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 706:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.995]train epoch: 706:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.67it/s, loss=0.995]train epoch: 706:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.67it/s, loss=0.728]train epoch: 706:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.93it/s, loss=0.728]train epoch: 706:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.93it/s, loss=0.843]train epoch: 706:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=0.843]train epoch: 706:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s, loss=0.892]train epoch: 706:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.87it/s, loss=0.892]train epoch: 706:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.87it/s, loss=0.594]train epoch: 706:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.04it/s, loss=0.594]train epoch: 706:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.04it/s, loss=0.801]train epoch: 706:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.07it/s, loss=0.801]train epoch: 706:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.07it/s, loss=0.643]train epoch: 706:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=0.643]train epoch: 706:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.17it/s, loss=0.766]train epoch: 706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.62it/s, loss=0.766]train epoch: 706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.64it/s, loss=0.766]
[[032m2021-11-26 11:05:07,064[0m INFO] trainer.training_epoch Training epoch 706, num_steps 5656,  avg_loss: 0.7826, total_loss: 6.2611
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.97it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.74it/s]
[[032m2021-11-26 11:05:07,489[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:07,489[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:07,715[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:07,855[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 707:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 707:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.03]train epoch: 707:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.23it/s, loss=1.03]train epoch: 707:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.23it/s, loss=0.815]train epoch: 707:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.38it/s, loss=0.815]train epoch: 707:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.38it/s, loss=0.858]train epoch: 707:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.54it/s, loss=0.858]train epoch: 707:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.54it/s, loss=0.602]train epoch: 707:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.32it/s, loss=0.602]train epoch: 707:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  5.32it/s, loss=0.614]train epoch: 707:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.16it/s, loss=0.614]train epoch: 707:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.16it/s, loss=0.699]train epoch: 707:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=0.699]train epoch: 707:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=0.603]train epoch: 707:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.61it/s, loss=0.603]train epoch: 707:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.61it/s, loss=0.75] train epoch: 707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.36it/s, loss=0.75]train epoch: 707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.61it/s, loss=0.75]
[[032m2021-11-26 11:05:09,596[0m INFO] trainer.training_epoch Training epoch 707, num_steps 5664,  avg_loss: 0.7467, total_loss: 5.9734
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.87it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.71it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.36it/s]
[[032m2021-11-26 11:05:10,019[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:10,020[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:10,265[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:10,402[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 708:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 708:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.718]train epoch: 708:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.61it/s, loss=0.718]train epoch: 708:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.61it/s, loss=0.546]train epoch: 708:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s, loss=0.546]train epoch: 708:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s, loss=0.731]train epoch: 708:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.05it/s, loss=0.731]train epoch: 708:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.05it/s, loss=0.776]train epoch: 708:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.23it/s, loss=0.776]train epoch: 708:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.23it/s, loss=0.783]train epoch: 708:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.04it/s, loss=0.783]train epoch: 708:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.04it/s, loss=0.575]train epoch: 708:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.98it/s, loss=0.575]train epoch: 708:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.98it/s, loss=0.735]train epoch: 708:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.99it/s, loss=0.735]train epoch: 708:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.99it/s, loss=0.616]train epoch: 708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.41it/s, loss=0.616]train epoch: 708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s, loss=0.616]
[[032m2021-11-26 11:05:11,847[0m INFO] trainer.training_epoch Training epoch 708, num_steps 5672,  avg_loss: 0.6851, total_loss: 5.4809
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.06it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.02it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.88it/s]
[[032m2021-11-26 11:05:12,380[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:12,380[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:12,624[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:12,785[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 709:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 709:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.76]train epoch: 709:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.21it/s, loss=0.76]train epoch: 709:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.21it/s, loss=0.895]train epoch: 709:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.47it/s, loss=0.895]train epoch: 709:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.47it/s, loss=0.962]train epoch: 709:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.36it/s, loss=0.962]train epoch: 709:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.36it/s, loss=0.79] train epoch: 709:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.99it/s, loss=0.79]train epoch: 709:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.99it/s, loss=0.686]train epoch: 709:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.04it/s, loss=0.686]train epoch: 709:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.04it/s, loss=0.507]train epoch: 709:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  5.98it/s, loss=0.507]train epoch: 709:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.98it/s, loss=0.746]train epoch: 709:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.96it/s, loss=0.746]train epoch: 709:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.96it/s, loss=0.594]train epoch: 709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.94it/s, loss=0.594]train epoch: 709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.04it/s, loss=0.594]
[[032m2021-11-26 11:05:14,116[0m INFO] trainer.training_epoch Training epoch 709, num_steps 5680,  avg_loss: 0.7425, total_loss: 5.9399
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.93it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.92it/s]
[[032m2021-11-26 11:05:14,680[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:14,681[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:15,295[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:15,521[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 710:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 710:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.738]train epoch: 710:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.08it/s, loss=0.738]train epoch: 710:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.08it/s, loss=0.715]train epoch: 710:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.77it/s, loss=0.715]train epoch: 710:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.77it/s, loss=0.926]train epoch: 710:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.93it/s, loss=0.926]train epoch: 710:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.93it/s, loss=0.634]train epoch: 710:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.29it/s, loss=0.634]train epoch: 710:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.29it/s, loss=0.784]train epoch: 710:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.60it/s, loss=0.784]train epoch: 710:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.60it/s, loss=0.761]train epoch: 710:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.59it/s, loss=0.761]train epoch: 710:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.59it/s, loss=0.952]train epoch: 710:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.82it/s, loss=0.952]train epoch: 710:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.82it/s, loss=0.816]train epoch: 710: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.07it/s, loss=0.816]train epoch: 710: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s, loss=0.816]
[[032m2021-11-26 11:05:17,044[0m INFO] trainer.training_epoch Training epoch 710, num_steps 5688,  avg_loss: 0.7908, total_loss: 6.3267
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.58it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.49it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.47it/s]
[[032m2021-11-26 11:05:17,485[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:17,485[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:17,985[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:18,132[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 711:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 711:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.828]train epoch: 711:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.43it/s, loss=0.828]train epoch: 711:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.43it/s, loss=0.65] train epoch: 711:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.32it/s, loss=0.65]train epoch: 711:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.32it/s, loss=0.786]train epoch: 711:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.57it/s, loss=0.786]train epoch: 711:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.57it/s, loss=0.713]train epoch: 711:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.90it/s, loss=0.713]train epoch: 711:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.90it/s, loss=0.653]train epoch: 711:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.20it/s, loss=0.653]train epoch: 711:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.20it/s, loss=0.712]train epoch: 711:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.50it/s, loss=0.712]train epoch: 711:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.50it/s, loss=0.564]train epoch: 711:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.61it/s, loss=0.564]train epoch: 711:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.61it/s, loss=0.973]train epoch: 711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.34it/s, loss=0.973]train epoch: 711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.28it/s, loss=0.973]
[[032m2021-11-26 11:05:19,652[0m INFO] trainer.training_epoch Training epoch 711, num_steps 5696,  avg_loss: 0.7347, total_loss: 5.8778
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.86it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.53it/s]
[[032m2021-11-26 11:05:20,172[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:20,172[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:20,405[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:20,725[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 712:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 712:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.57]train epoch: 712:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.49it/s, loss=0.57]train epoch: 712:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.49it/s, loss=0.51]train epoch: 712:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s, loss=0.51]train epoch: 712:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s, loss=0.77]train epoch: 712:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.78it/s, loss=0.77]train epoch: 712:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.78it/s, loss=0.79]train epoch: 712:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.31it/s, loss=0.79]
prompt tensor([[0.5898, 0.4102],
        [0.8457, 0.1543],
        [0.5304, 0.4696],
        [0.5474, 0.4526],
        [0.3621, 0.6379],
        [0.6543, 0.3457],
        [0.6017, 0.3983],
        [0.3420, 0.6580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 712:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  5.31it/s, loss=0.916]train epoch: 712:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.46it/s, loss=0.916]train epoch: 712:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.46it/s, loss=0.728]train epoch: 712:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.86it/s, loss=0.728]train epoch: 712:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.86it/s, loss=0.998]train epoch: 712:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.90it/s, loss=0.998]train epoch: 712:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.90it/s, loss=0.831]train epoch: 712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s, loss=0.831]train epoch: 712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.20it/s, loss=0.831]
[[032m2021-11-26 11:05:22,280[0m INFO] trainer.training_epoch Training epoch 712, num_steps 5704,  avg_loss: 0.7641, total_loss: 6.1126
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.14it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.42it/s]
[[032m2021-11-26 11:05:22,685[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:22,686[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:22,917[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:23,085[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 713:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 713:   0%|          | 0/8 [00:00<?, ?it/s, loss=1]train epoch: 713:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.39it/s, loss=1]train epoch: 713:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.39it/s, loss=0.739]train epoch: 713:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.63it/s, loss=0.739]train epoch: 713:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.63it/s, loss=0.572]train epoch: 713:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.33it/s, loss=0.572]train epoch: 713:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.33it/s, loss=0.616]train epoch: 713:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=0.616]train epoch: 713:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.92it/s, loss=0.753]train epoch: 713:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s, loss=0.753]train epoch: 713:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s, loss=0.741]train epoch: 713:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.75it/s, loss=0.741]train epoch: 713:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.75it/s, loss=0.868]train epoch: 713:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.26it/s, loss=0.868]train epoch: 713:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.26it/s, loss=0.553]train epoch: 713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.59it/s, loss=0.553]train epoch: 713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.96it/s, loss=0.553]
[[032m2021-11-26 11:05:25,114[0m INFO] trainer.training_epoch Training epoch 713, num_steps 5712,  avg_loss: 0.7301, total_loss: 5.8411
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.42it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.55it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.52it/s]
[[032m2021-11-26 11:05:25,480[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:25,480[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:25,707[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:25,898[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 714:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 714:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.915]train epoch: 714:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.06it/s, loss=0.915]train epoch: 714:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.06it/s, loss=0.793]train epoch: 714:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.83it/s, loss=0.793]train epoch: 714:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.83it/s, loss=0.717]train epoch: 714:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.79it/s, loss=0.717]train epoch: 714:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.79it/s, loss=0.858]train epoch: 714:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.65it/s, loss=0.858]train epoch: 714:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.65it/s, loss=0.874]train epoch: 714:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=0.874]train epoch: 714:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=0.633]train epoch: 714:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.67it/s, loss=0.633]train epoch: 714:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.67it/s, loss=0.69] train epoch: 714:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.13it/s, loss=0.69]train epoch: 714:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.13it/s, loss=0.484]train epoch: 714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.49it/s, loss=0.484]train epoch: 714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.68it/s, loss=0.484]
[[032m2021-11-26 11:05:27,614[0m INFO] trainer.training_epoch Training epoch 714, num_steps 5720,  avg_loss: 0.7455, total_loss: 5.9638
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.77it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.87it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.78it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.56it/s]
[[032m2021-11-26 11:05:28,166[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:28,167[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:28,426[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:28,536[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 715:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 715:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.821]train epoch: 715:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.63it/s, loss=0.821]train epoch: 715:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.63it/s, loss=0.55] train epoch: 715:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.33it/s, loss=0.55]train epoch: 715:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.33it/s, loss=0.811]train epoch: 715:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.60it/s, loss=0.811]train epoch: 715:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.60it/s, loss=1.03] train epoch: 715:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.62it/s, loss=1.03]train epoch: 715:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.62it/s, loss=0.787]train epoch: 715:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.05it/s, loss=0.787]train epoch: 715:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.05it/s, loss=0.682]train epoch: 715:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s, loss=0.682]train epoch: 715:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s, loss=0.747]train epoch: 715:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.74it/s, loss=0.747]train epoch: 715:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.74it/s, loss=0.792]train epoch: 715: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.82it/s, loss=0.792]train epoch: 715: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.21it/s, loss=0.792]
[[032m2021-11-26 11:05:30,443[0m INFO] trainer.training_epoch Training epoch 715, num_steps 5728,  avg_loss: 0.7779, total_loss: 6.2234
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.61it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.52it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.06it/s]
[[032m2021-11-26 11:05:31,023[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:31,023[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:31,272[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:31,366[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 716:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 716:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.694]train epoch: 716:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.73it/s, loss=0.694]train epoch: 716:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.73it/s, loss=0.646]train epoch: 716:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.44it/s, loss=0.646]train epoch: 716:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.44it/s, loss=0.796]train epoch: 716:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.95it/s, loss=0.796]train epoch: 716:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.95it/s, loss=0.78] train epoch: 716:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.57it/s, loss=0.78]train epoch: 716:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.57it/s, loss=0.862]train epoch: 716:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.79it/s, loss=0.862]train epoch: 716:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.79it/s, loss=0.883]train epoch: 716:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.78it/s, loss=0.883]train epoch: 716:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.78it/s, loss=0.728]train epoch: 716:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.18it/s, loss=0.728]train epoch: 716:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.18it/s, loss=0.755]train epoch: 716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.11it/s, loss=0.755]train epoch: 716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.85it/s, loss=0.755]
[[032m2021-11-26 11:05:33,022[0m INFO] trainer.training_epoch Training epoch 716, num_steps 5736,  avg_loss: 0.7678, total_loss: 6.1426
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.55it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.87it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.45it/s]
[[032m2021-11-26 11:05:33,667[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:33,667[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:34,030[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:34,254[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 717:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 717:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.593]train epoch: 717:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.11it/s, loss=0.593]train epoch: 717:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.11it/s, loss=0.782]train epoch: 717:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.63it/s, loss=0.782]train epoch: 717:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.63it/s, loss=0.57] train epoch: 717:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.83it/s, loss=0.57]train epoch: 717:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.83it/s, loss=0.606]train epoch: 717:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.18it/s, loss=0.606]train epoch: 717:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.18it/s, loss=0.837]train epoch: 717:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.17it/s, loss=0.837]train epoch: 717:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.17it/s, loss=0.951]train epoch: 717:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.92it/s, loss=0.951]train epoch: 717:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.92it/s, loss=0.894]train epoch: 717:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.77it/s, loss=0.894]train epoch: 717:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.77it/s, loss=0.822]train epoch: 717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.90it/s, loss=0.822]train epoch: 717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.92it/s, loss=0.822]
[[032m2021-11-26 11:05:35,612[0m INFO] trainer.training_epoch Training epoch 717, num_steps 5744,  avg_loss: 0.7568, total_loss: 6.0542
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.29it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.85it/s]
[[032m2021-11-26 11:05:36,274[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:36,275[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:37,002[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:37,244[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 718:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 718:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.699]train epoch: 718:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.90it/s, loss=0.699]train epoch: 718:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.90it/s, loss=0.657]train epoch: 718:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.70it/s, loss=0.657]train epoch: 718:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.70it/s, loss=0.686]train epoch: 718:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.87it/s, loss=0.686]train epoch: 718:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.87it/s, loss=0.859]train epoch: 718:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.00it/s, loss=0.859]train epoch: 718:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.00it/s, loss=0.559]train epoch: 718:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.09it/s, loss=0.559]train epoch: 718:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.09it/s, loss=0.897]train epoch: 718:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  6.09it/s, loss=0.897]train epoch: 718:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  6.09it/s, loss=0.805]train epoch: 718:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.06it/s, loss=0.805]train epoch: 718:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.06it/s, loss=0.719]train epoch: 718: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s, loss=0.719]train epoch: 718: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.79it/s, loss=0.719]
[[032m2021-11-26 11:05:38,630[0m INFO] trainer.training_epoch Training epoch 718, num_steps 5752,  avg_loss: 0.7351, total_loss: 5.8809
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.96it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.17it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.31it/s]
[[032m2021-11-26 11:05:39,152[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:39,152[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:39,839[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:40,028[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 719:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 719:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.646]train epoch: 719:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.00it/s, loss=0.646]train epoch: 719:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.00it/s, loss=0.897]train epoch: 719:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.59it/s, loss=0.897]train epoch: 719:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.59it/s, loss=0.798]train epoch: 719:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=0.798]train epoch: 719:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.26it/s, loss=0.919]train epoch: 719:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.46it/s, loss=0.919]train epoch: 719:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.46it/s, loss=0.862]train epoch: 719:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.73it/s, loss=0.862]train epoch: 719:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.73it/s, loss=0.46] train epoch: 719:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.00it/s, loss=0.46]train epoch: 719:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.00it/s, loss=0.723]train epoch: 719:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.97it/s, loss=0.723]train epoch: 719:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.97it/s, loss=0.868]train epoch: 719: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s, loss=0.868]train epoch: 719: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.69it/s, loss=0.868]
[[032m2021-11-26 11:05:41,746[0m INFO] trainer.training_epoch Training epoch 719, num_steps 5760,  avg_loss: 0.7715, total_loss: 6.1717
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.78it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.07it/s]
[[032m2021-11-26 11:05:42,253[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:42,254[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:42,513[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:42,682[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 720:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 720:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.822]train epoch: 720:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.25it/s, loss=0.822]train epoch: 720:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.25it/s, loss=0.742]train epoch: 720:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.87it/s, loss=0.742]train epoch: 720:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.87it/s, loss=0.759]train epoch: 720:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.88it/s, loss=0.759]train epoch: 720:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.88it/s, loss=0.629]train epoch: 720:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.68it/s, loss=0.629]train epoch: 720:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.68it/s, loss=0.649]train epoch: 720:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=0.649]train epoch: 720:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.17it/s, loss=0.824]train epoch: 720:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.47it/s, loss=0.824]train epoch: 720:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.47it/s, loss=0.69] train epoch: 720:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.62it/s, loss=0.69]train epoch: 720:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.62it/s, loss=0.593]train epoch: 720: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.05it/s, loss=0.593]train epoch: 720: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.56it/s, loss=0.593]
[[032m2021-11-26 11:05:44,442[0m INFO] trainer.training_epoch Training epoch 720, num_steps 5768,  avg_loss: 0.7134, total_loss: 5.7073
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.11it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.31it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.27it/s]
[[032m2021-11-26 11:05:44,813[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:44,813[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:45,041[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:45,249[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 721:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 721:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.74]train epoch: 721:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.39it/s, loss=0.74]train epoch: 721:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.39it/s, loss=0.541]train epoch: 721:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.06it/s, loss=0.541]train epoch: 721:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.06it/s, loss=0.776]train epoch: 721:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.24it/s, loss=0.776]train epoch: 721:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.24it/s, loss=0.707]train epoch: 721:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.12it/s, loss=0.707]train epoch: 721:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.12it/s, loss=0.685]train epoch: 721:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.24it/s, loss=0.685]train epoch: 721:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.24it/s, loss=0.835]train epoch: 721:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.27it/s, loss=0.835]train epoch: 721:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.27it/s, loss=0.613]train epoch: 721:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=0.613]train epoch: 721:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=0.921]train epoch: 721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  3.84it/s, loss=0.921]train epoch: 721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.33it/s, loss=0.921]
[[032m2021-11-26 11:05:47,101[0m INFO] trainer.training_epoch Training epoch 721, num_steps 5776,  avg_loss: 0.7271, total_loss: 5.8172
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.61it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.33it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.36it/s]
[[032m2021-11-26 11:05:47,502[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:47,502[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:47,723[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:47,827[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 722:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 722:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.841]train epoch: 722:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.37it/s, loss=0.841]train epoch: 722:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.37it/s, loss=0.849]train epoch: 722:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s, loss=0.849]train epoch: 722:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s, loss=0.691]train epoch: 722:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.21it/s, loss=0.691]train epoch: 722:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.21it/s, loss=0.767]train epoch: 722:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.27it/s, loss=0.767]train epoch: 722:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.27it/s, loss=0.78] train epoch: 722:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.94it/s, loss=0.78]train epoch: 722:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.94it/s, loss=0.716]train epoch: 722:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.47it/s, loss=0.716]train epoch: 722:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.47it/s, loss=0.623]train epoch: 722:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.29it/s, loss=0.623]train epoch: 722:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.29it/s, loss=0.668]train epoch: 722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.97it/s, loss=0.668]train epoch: 722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.45it/s, loss=0.668]
[[032m2021-11-26 11:05:49,301[0m INFO] trainer.training_epoch Training epoch 722, num_steps 5784,  avg_loss: 0.7420, total_loss: 5.9361
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.08it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.98it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.48it/s]
[[032m2021-11-26 11:05:49,884[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:49,885[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:50,359[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:50,566[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 723:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 723:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.743]train epoch: 723:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=0.743]train epoch: 723:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.30it/s, loss=0.826]train epoch: 723:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.85it/s, loss=0.826]train epoch: 723:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.85it/s, loss=0.543]train epoch: 723:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.72it/s, loss=0.543]train epoch: 723:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.72it/s, loss=0.767]train epoch: 723:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.89it/s, loss=0.767]train epoch: 723:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.89it/s, loss=0.897]train epoch: 723:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.97it/s, loss=0.897]train epoch: 723:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.97it/s, loss=0.815]train epoch: 723:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.99it/s, loss=0.815]train epoch: 723:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.99it/s, loss=0.547]train epoch: 723:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.05it/s, loss=0.547]train epoch: 723:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.05it/s, loss=0.65] train epoch: 723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.75it/s, loss=0.65]train epoch: 723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.83it/s, loss=0.65]
[[032m2021-11-26 11:05:51,945[0m INFO] trainer.training_epoch Training epoch 723, num_steps 5792,  avg_loss: 0.7236, total_loss: 5.7891
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.32it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.35it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.76it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.82it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.83it/s]
[[032m2021-11-26 11:05:52,698[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:52,698[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:53,461[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:53,603[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 724:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 724:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.682]train epoch: 724:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.18it/s, loss=0.682]train epoch: 724:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.18it/s, loss=0.766]train epoch: 724:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s, loss=0.766]train epoch: 724:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s, loss=0.717]train epoch: 724:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.95it/s, loss=0.717]train epoch: 724:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.95it/s, loss=0.87] train epoch: 724:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.47it/s, loss=0.87]train epoch: 724:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.47it/s, loss=1.01]train epoch: 724:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.63it/s, loss=1.01]train epoch: 724:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.63it/s, loss=0.703]train epoch: 724:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.56it/s, loss=0.703]train epoch: 724:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.56it/s, loss=0.734]train epoch: 724:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.14it/s, loss=0.734]train epoch: 724:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.14it/s, loss=0.829]train epoch: 724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.38it/s, loss=0.829]train epoch: 724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s, loss=0.829]
[[032m2021-11-26 11:05:55,057[0m INFO] trainer.training_epoch Training epoch 724, num_steps 5800,  avg_loss: 0.7884, total_loss: 6.3070
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.80it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.90it/s]
[[032m2021-11-26 11:05:55,513[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:55,513[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:55,958[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:56,213[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 725:   0%|          | 0/8 [00:00<?, ?it/s]
prompt tensor([[0.4192, 0.5808],
        [0.8533, 0.1467],
        [0.6424, 0.3576],
        [0.2176, 0.7824],
        [0.3939, 0.6061],
        [0.6900, 0.3100],
        [0.7553, 0.2447],
        [0.3500, 0.6500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 725:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.544]train epoch: 725:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=0.544]train epoch: 725:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.74it/s, loss=0.76] train epoch: 725:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.46it/s, loss=0.76]train epoch: 725:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.46it/s, loss=0.888]train epoch: 725:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.38it/s, loss=0.888]train epoch: 725:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.38it/s, loss=0.96] train epoch: 725:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=0.96]train epoch: 725:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.05it/s, loss=0.611]train epoch: 725:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=0.611]train epoch: 725:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.26it/s, loss=0.824]train epoch: 725:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.66it/s, loss=0.824]train epoch: 725:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.66it/s, loss=0.925]train epoch: 725:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.55it/s, loss=0.925]train epoch: 725:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.55it/s, loss=0.879]train epoch: 725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s, loss=0.879]train epoch: 725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.43it/s, loss=0.879]
[[032m2021-11-26 11:05:58,030[0m INFO] trainer.training_epoch Training epoch 725, num_steps 5808,  avg_loss: 0.7987, total_loss: 6.3896
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.83it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.34it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.15it/s]
[[032m2021-11-26 11:05:58,432[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:05:58,432[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:05:58,659[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:05:58,889[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 726:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 726:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.906]train epoch: 726:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=0.906]train epoch: 726:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  3.01it/s, loss=0.685]train epoch: 726:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.56it/s, loss=0.685]train epoch: 726:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.56it/s, loss=0.804]train epoch: 726:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.21it/s, loss=0.804]train epoch: 726:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.21it/s, loss=0.792]train epoch: 726:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.39it/s, loss=0.792]train epoch: 726:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.39it/s, loss=0.958]train epoch: 726:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.78it/s, loss=0.958]train epoch: 726:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.78it/s, loss=0.683]train epoch: 726:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=0.683]train epoch: 726:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.86it/s, loss=0.788]train epoch: 726:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.45it/s, loss=0.788]train epoch: 726:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  4.45it/s, loss=0.823]train epoch: 726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  4.93it/s, loss=0.823]train epoch: 726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.96it/s, loss=0.823]
[[032m2021-11-26 11:06:00,924[0m INFO] trainer.training_epoch Training epoch 726, num_steps 5816,  avg_loss: 0.8050, total_loss: 6.4404
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.84it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.44it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.49it/s]
[[032m2021-11-26 11:06:01,368[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:06:01,369[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:01,598[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:01,712[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 727:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 727:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.505]train epoch: 727:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.26it/s, loss=0.505]train epoch: 727:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.26it/s, loss=0.605]train epoch: 727:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.79it/s, loss=0.605]train epoch: 727:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.79it/s, loss=0.731]train epoch: 727:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.13it/s, loss=0.731]train epoch: 727:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.13it/s, loss=0.764]train epoch: 727:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.96it/s, loss=0.764]train epoch: 727:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.96it/s, loss=0.921]train epoch: 727:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  4.78it/s, loss=0.921]train epoch: 727:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.78it/s, loss=0.784]train epoch: 727:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=0.784]train epoch: 727:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.17it/s, loss=0.724]train epoch: 727:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.41it/s, loss=0.724]train epoch: 727:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.41it/s, loss=0.944]train epoch: 727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.77it/s, loss=0.944]train epoch: 727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.83it/s, loss=0.944]
[[032m2021-11-26 11:06:03,375[0m INFO] trainer.training_epoch Training epoch 727, num_steps 5824,  avg_loss: 0.7474, total_loss: 5.9791
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.21it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.16it/s]
[[032m2021-11-26 11:06:03,921[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.578125)])
[[032m2021-11-26 11:06:03,921[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:04,239[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:04,379[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 728:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 728:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.723]train epoch: 728:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.41it/s, loss=0.723]train epoch: 728:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.41it/s, loss=0.702]train epoch: 728:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.60it/s, loss=0.702]train epoch: 728:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.60it/s, loss=0.904]train epoch: 728:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.69it/s, loss=0.904]train epoch: 728:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.69it/s, loss=0.724]train epoch: 728:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.43it/s, loss=0.724]train epoch: 728:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.43it/s, loss=0.68] train epoch: 728:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.39it/s, loss=0.68]train epoch: 728:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.39it/s, loss=0.839]train epoch: 728:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.63it/s, loss=0.839]train epoch: 728:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.63it/s, loss=0.82] train epoch: 728:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.58it/s, loss=0.82]train epoch: 728:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.58it/s, loss=0.969]train epoch: 728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.00it/s, loss=0.969]train epoch: 728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.83it/s, loss=0.969]
[[032m2021-11-26 11:06:06,040[0m INFO] trainer.training_epoch Training epoch 728, num_steps 5832,  avg_loss: 0.7951, total_loss: 6.3605
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.93it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.75it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.63it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.96it/s]
[[032m2021-11-26 11:06:06,772[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:06,772[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:07,116[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:07,256[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 729:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 729:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.999]train epoch: 729:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.36it/s, loss=0.999]train epoch: 729:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.36it/s, loss=0.724]train epoch: 729:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.01it/s, loss=0.724]train epoch: 729:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.01it/s, loss=0.609]train epoch: 729:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.46it/s, loss=0.609]train epoch: 729:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.46it/s, loss=0.779]train epoch: 729:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.46it/s, loss=0.779]train epoch: 729:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.46it/s, loss=0.664]train epoch: 729:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.71it/s, loss=0.664]train epoch: 729:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.71it/s, loss=0.759]train epoch: 729:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.70it/s, loss=0.759]train epoch: 729:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.70it/s, loss=0.82] train epoch: 729:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.10it/s, loss=0.82]train epoch: 729:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.10it/s, loss=0.78]train epoch: 729: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.39it/s, loss=0.78]train epoch: 729: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.44it/s, loss=0.78]
[[032m2021-11-26 11:06:08,740[0m INFO] trainer.training_epoch Training epoch 729, num_steps 5840,  avg_loss: 0.7668, total_loss: 6.1341
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.72it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.95it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.12it/s]
[[032m2021-11-26 11:06:09,151[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:09,151[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:09,694[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:09,890[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 730:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 730:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.782]train epoch: 730:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.13it/s, loss=0.782]train epoch: 730:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.13it/s, loss=0.823]train epoch: 730:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=0.823]train epoch: 730:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.87it/s, loss=0.719]train epoch: 730:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.84it/s, loss=0.719]train epoch: 730:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.84it/s, loss=0.866]train epoch: 730:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.74it/s, loss=0.866]train epoch: 730:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.74it/s, loss=0.664]train epoch: 730:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.16it/s, loss=0.664]train epoch: 730:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.16it/s, loss=0.635]train epoch: 730:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.36it/s, loss=0.635]train epoch: 730:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.36it/s, loss=0.653]train epoch: 730:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.68it/s, loss=0.653]train epoch: 730:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.68it/s, loss=0.766]train epoch: 730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.80it/s, loss=0.766]train epoch: 730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s, loss=0.766]
[[032m2021-11-26 11:06:11,402[0m INFO] trainer.training_epoch Training epoch 730, num_steps 5848,  avg_loss: 0.7386, total_loss: 5.9089
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.98it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.68it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.46it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.07it/s]
[[032m2021-11-26 11:06:11,873[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:11,874[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:12,098[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:12,202[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 731:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 731:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.984]train epoch: 731:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.85it/s, loss=0.984]train epoch: 731:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  3.85it/s, loss=0.697]train epoch: 731:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.63it/s, loss=0.697]train epoch: 731:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  3.63it/s, loss=0.792]train epoch: 731:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.18it/s, loss=0.792]train epoch: 731:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  4.18it/s, loss=0.858]train epoch: 731:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s, loss=0.858]train epoch: 731:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s, loss=0.565]train epoch: 731:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.95it/s, loss=0.565]train epoch: 731:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.95it/s, loss=0.751]train epoch: 731:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.83it/s, loss=0.751]train epoch: 731:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.83it/s, loss=0.743]train epoch: 731:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=0.743]train epoch: 731:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.95it/s, loss=0.834]train epoch: 731: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.28it/s, loss=0.834]train epoch: 731: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.05it/s, loss=0.834]
[[032m2021-11-26 11:06:14,184[0m INFO] trainer.training_epoch Training epoch 731, num_steps 5856,  avg_loss: 0.7781, total_loss: 6.2245
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.39it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 10.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.20it/s]
[[032m2021-11-26 11:06:14,736[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:14,737[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:14,987[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:15,112[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 732:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 732:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.635]train epoch: 732:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.75it/s, loss=0.635]train epoch: 732:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.75it/s, loss=0.867]train epoch: 732:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.73it/s, loss=0.867]train epoch: 732:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.73it/s, loss=0.677]train epoch: 732:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.03it/s, loss=0.677]train epoch: 732:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.03it/s, loss=0.843]train epoch: 732:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.99it/s, loss=0.843]train epoch: 732:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.99it/s, loss=0.794]train epoch: 732:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  4.93it/s, loss=0.794]train epoch: 732:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.93it/s, loss=0.669]train epoch: 732:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s, loss=0.669]train epoch: 732:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s, loss=0.778]train epoch: 732:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.56it/s, loss=0.778]train epoch: 732:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.56it/s, loss=0.65] train epoch: 732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s, loss=0.65]train epoch: 732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.78it/s, loss=0.65]
[[032m2021-11-26 11:06:17,234[0m INFO] trainer.training_epoch Training epoch 732, num_steps 5864,  avg_loss: 0.7391, total_loss: 5.9130
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.70it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.44it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.74it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.12it/s]
[[032m2021-11-26 11:06:17,892[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:17,893[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:18,129[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:18,243[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 733:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 733:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.88]train epoch: 733:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.41it/s, loss=0.88]train epoch: 733:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.41it/s, loss=0.788]train epoch: 733:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.68it/s, loss=0.788]train epoch: 733:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.68it/s, loss=0.958]train epoch: 733:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.60it/s, loss=0.958]train epoch: 733:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.60it/s, loss=0.817]train epoch: 733:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.23it/s, loss=0.817]train epoch: 733:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.23it/s, loss=0.81] train epoch: 733:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  6.07it/s, loss=0.81]train epoch: 733:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  6.07it/s, loss=0.827]train epoch: 733:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.40it/s, loss=0.827]train epoch: 733:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.40it/s, loss=0.659]train epoch: 733:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.25it/s, loss=0.659]train epoch: 733:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.25it/s, loss=0.561]train epoch: 733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.12it/s, loss=0.561]train epoch: 733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.84it/s, loss=0.561]
[[032m2021-11-26 11:06:19,903[0m INFO] trainer.training_epoch Training epoch 733, num_steps 5872,  avg_loss: 0.7876, total_loss: 6.3011
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.76it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.64it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.86it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.72it/s]
[[032m2021-11-26 11:06:20,404[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:20,405[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:20,799[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:21,027[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 734:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 734:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.72]train epoch: 734:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.33it/s, loss=0.72]train epoch: 734:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  4.33it/s, loss=0.674]train epoch: 734:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.37it/s, loss=0.674]train epoch: 734:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.37it/s, loss=0.855]train epoch: 734:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.73it/s, loss=0.855]train epoch: 734:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.73it/s, loss=0.751]train epoch: 734:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.94it/s, loss=0.751]train epoch: 734:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.94it/s, loss=0.728]train epoch: 734:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.99it/s, loss=0.728]train epoch: 734:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.99it/s, loss=0.728]train epoch: 734:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.86it/s, loss=0.728]train epoch: 734:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.86it/s, loss=0.68] train epoch: 734:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.26it/s, loss=0.68]train epoch: 734:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.26it/s, loss=0.637]train epoch: 734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.42it/s, loss=0.637]train epoch: 734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s, loss=0.637]
[[032m2021-11-26 11:06:22,484[0m INFO] trainer.training_epoch Training epoch 734, num_steps 5880,  avg_loss: 0.7218, total_loss: 5.7743
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.92it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.20it/s]
[[032m2021-11-26 11:06:23,087[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:23,087[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:23,477[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:23,650[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 735:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 735:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.511]train epoch: 735:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.51it/s, loss=0.511]train epoch: 735:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.51it/s, loss=0.824]train epoch: 735:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.73it/s, loss=0.824]train epoch: 735:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.73it/s, loss=0.707]train epoch: 735:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.37it/s, loss=0.707]train epoch: 735:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.37it/s, loss=0.74] train epoch: 735:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.36it/s, loss=0.74]train epoch: 735:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.36it/s, loss=0.929]train epoch: 735:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.62it/s, loss=0.929]train epoch: 735:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.62it/s, loss=0.817]train epoch: 735:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.88it/s, loss=0.817]train epoch: 735:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.88it/s, loss=0.72] train epoch: 735:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.86it/s, loss=0.72]train epoch: 735:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.86it/s, loss=0.503]train epoch: 735: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s, loss=0.503]train epoch: 735: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s, loss=0.503]
[[032m2021-11-26 11:06:25,113[0m INFO] trainer.training_epoch Training epoch 735, num_steps 5888,  avg_loss: 0.7186, total_loss: 5.7492
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.03it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.88it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.90it/s]
[[032m2021-11-26 11:06:25,508[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:25,509[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:25,731[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:25,918[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 736:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 736:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.713]train epoch: 736:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=0.713]train epoch: 736:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.13it/s, loss=0.862]train epoch: 736:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.68it/s, loss=0.862]train epoch: 736:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.68it/s, loss=0.83] train epoch: 736:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.76it/s, loss=0.83]train epoch: 736:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.76it/s, loss=0.981]train epoch: 736:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.07it/s, loss=0.981]train epoch: 736:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.07it/s, loss=0.694]train epoch: 736:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=0.694]train epoch: 736:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.83it/s, loss=0.645]train epoch: 736:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.14it/s, loss=0.645]train epoch: 736:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.14it/s, loss=0.499]train epoch: 736:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.58it/s, loss=0.499]train epoch: 736:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.58it/s, loss=0.913]train epoch: 736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s, loss=0.913]train epoch: 736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.62it/s, loss=0.913]
[[032m2021-11-26 11:06:27,654[0m INFO] trainer.training_epoch Training epoch 736, num_steps 5896,  avg_loss: 0.7672, total_loss: 6.1378
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.48it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.25it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.32it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.56it/s]
[[032m2021-11-26 11:06:28,193[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:28,194[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:28,420[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:28,533[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 737:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 737:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.639]train epoch: 737:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.70it/s, loss=0.639]train epoch: 737:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.70it/s, loss=0.781]train epoch: 737:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.80it/s, loss=0.781]train epoch: 737:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.80it/s, loss=0.678]train epoch: 737:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.59it/s, loss=0.678]train epoch: 737:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.59it/s, loss=0.829]train epoch: 737:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.48it/s, loss=0.829]
prompt tensor([[0.6669, 0.3331],
        [0.6512, 0.3488],
        [0.4532, 0.5468],
        [0.4102, 0.5898],
        [0.6310, 0.3690],
        [0.6830, 0.3170],
        [0.4057, 0.5943],
        [0.5274, 0.4726]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
train epoch: 737:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.48it/s, loss=0.674]train epoch: 737:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=0.674]train epoch: 737:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.28it/s, loss=0.787]train epoch: 737:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.47it/s, loss=0.787]train epoch: 737:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.47it/s, loss=0.62] train epoch: 737:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.03it/s, loss=0.62]train epoch: 737:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.03it/s, loss=0.719]train epoch: 737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.05it/s, loss=0.719]train epoch: 737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.58it/s, loss=0.719]
[[032m2021-11-26 11:06:30,287[0m INFO] trainer.training_epoch Training epoch 737, num_steps 5904,  avg_loss: 0.7159, total_loss: 5.7273
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.48it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.30it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.51it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.27it/s]
[[032m2021-11-26 11:06:30,801[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:30,801[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:31,036[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:31,158[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 738:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 738:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.702]train epoch: 738:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.70it/s, loss=0.702]train epoch: 738:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.70it/s, loss=0.793]train epoch: 738:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.35it/s, loss=0.793]train epoch: 738:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.35it/s, loss=0.623]train epoch: 738:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.47it/s, loss=0.623]train epoch: 738:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.47it/s, loss=0.671]train epoch: 738:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.54it/s, loss=0.671]train epoch: 738:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.54it/s, loss=0.657]train epoch: 738:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.51it/s, loss=0.657]train epoch: 738:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.51it/s, loss=0.791]train epoch: 738:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.81it/s, loss=0.791]train epoch: 738:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.81it/s, loss=0.572]train epoch: 738:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.98it/s, loss=0.572]train epoch: 738:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.98it/s, loss=0.762]train epoch: 738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.06it/s, loss=0.762]train epoch: 738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s, loss=0.762]
[[032m2021-11-26 11:06:32,670[0m INFO] trainer.training_epoch Training epoch 738, num_steps 5912,  avg_loss: 0.6963, total_loss: 5.5707
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.13it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.82it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.39it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.80it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.53it/s]
[[032m2021-11-26 11:06:33,267[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:33,267[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:33,652[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:33,831[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 739:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 739:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.547]train epoch: 739:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.41it/s, loss=0.547]train epoch: 739:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.41it/s, loss=0.532]train epoch: 739:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.40it/s, loss=0.532]train epoch: 739:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.40it/s, loss=0.712]train epoch: 739:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.26it/s, loss=0.712]train epoch: 739:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.26it/s, loss=0.575]train epoch: 739:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.85it/s, loss=0.575]train epoch: 739:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.85it/s, loss=0.855]train epoch: 739:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.56it/s, loss=0.855]train epoch: 739:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.56it/s, loss=0.749]train epoch: 739:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.37it/s, loss=0.749]train epoch: 739:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.37it/s, loss=0.644]train epoch: 739:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.51it/s, loss=0.644]train epoch: 739:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.51it/s, loss=0.713]train epoch: 739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.00it/s, loss=0.713]train epoch: 739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.44it/s, loss=0.713]
[[032m2021-11-26 11:06:35,307[0m INFO] trainer.training_epoch Training epoch 739, num_steps 5920,  avg_loss: 0.6659, total_loss: 5.3275
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.15it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.74it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.95it/s]
[[032m2021-11-26 11:06:36,135[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:36,135[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:36,457[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:36,590[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 740:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 740:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.657]train epoch: 740:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.09it/s, loss=0.657]train epoch: 740:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.09it/s, loss=0.75] train epoch: 740:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.00it/s, loss=0.75]train epoch: 740:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.00it/s, loss=0.697]train epoch: 740:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.83it/s, loss=0.697]train epoch: 740:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.83it/s, loss=0.591]train epoch: 740:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.69it/s, loss=0.591]train epoch: 740:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.69it/s, loss=0.865]train epoch: 740:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.83it/s, loss=0.865]train epoch: 740:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.83it/s, loss=0.78] train epoch: 740:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.95it/s, loss=0.78]train epoch: 740:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.95it/s, loss=1.01]train epoch: 740:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.81it/s, loss=1.01]train epoch: 740:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.81it/s, loss=0.762]train epoch: 740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s, loss=0.762]train epoch: 740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.70it/s, loss=0.762]
[[032m2021-11-26 11:06:37,999[0m INFO] trainer.training_epoch Training epoch 740, num_steps 5928,  avg_loss: 0.7640, total_loss: 6.1123
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.84it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.71it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.81it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.38it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.05it/s]
[[032m2021-11-26 11:06:38,649[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:38,649[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:39,338[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:39,542[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 741:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 741:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.707]train epoch: 741:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.49it/s, loss=0.707]train epoch: 741:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.49it/s, loss=0.689]train epoch: 741:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.11it/s, loss=0.689]train epoch: 741:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.11it/s, loss=0.788]train epoch: 741:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.29it/s, loss=0.788]train epoch: 741:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.29it/s, loss=0.927]train epoch: 741:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.37it/s, loss=0.927]train epoch: 741:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  6.37it/s, loss=0.859]train epoch: 741:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.57it/s, loss=0.859]train epoch: 741:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.57it/s, loss=0.791]train epoch: 741:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.85it/s, loss=0.791]train epoch: 741:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.85it/s, loss=0.635]train epoch: 741:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.95it/s, loss=0.635]train epoch: 741:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.95it/s, loss=0.757]train epoch: 741: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.98it/s, loss=0.757]train epoch: 741: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.00it/s, loss=0.757]
[[032m2021-11-26 11:06:40,884[0m INFO] trainer.training_epoch Training epoch 741, num_steps 5936,  avg_loss: 0.7692, total_loss: 6.1532
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.57it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  6.20it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.15it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.19it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.58it/s]
[[032m2021-11-26 11:06:41,549[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:41,549[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:42,290[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:42,528[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 742:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 742:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.758]train epoch: 742:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.95it/s, loss=0.758]train epoch: 742:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.95it/s, loss=0.762]train epoch: 742:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.48it/s, loss=0.762]train epoch: 742:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.48it/s, loss=0.87] train epoch: 742:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.71it/s, loss=0.87]train epoch: 742:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.71it/s, loss=0.753]train epoch: 742:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.91it/s, loss=0.753]train epoch: 742:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.91it/s, loss=0.872]train epoch: 742:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.87it/s, loss=0.872]train epoch: 742:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.87it/s, loss=0.725]train epoch: 742:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.92it/s, loss=0.725]train epoch: 742:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.92it/s, loss=0.63] train epoch: 742:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.00it/s, loss=0.63]train epoch: 742:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.00it/s, loss=0.743]train epoch: 742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.01it/s, loss=0.743]train epoch: 742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.94it/s, loss=0.743]
[[032m2021-11-26 11:06:43,880[0m INFO] trainer.training_epoch Training epoch 742, num_steps 5944,  avg_loss: 0.7640, total_loss: 6.1121
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.79it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.43it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.62it/s]
[[032m2021-11-26 11:06:44,369[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:44,370[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:45,050[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:45,408[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 743:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 743:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.619]train epoch: 743:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.73it/s, loss=0.619]train epoch: 743:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.73it/s, loss=0.762]train epoch: 743:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.16it/s, loss=0.762]train epoch: 743:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.16it/s, loss=0.681]train epoch: 743:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.41it/s, loss=0.681]train epoch: 743:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.41it/s, loss=0.654]train epoch: 743:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.63it/s, loss=0.654]train epoch: 743:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.63it/s, loss=0.915]train epoch: 743:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.78it/s, loss=0.915]train epoch: 743:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.78it/s, loss=0.923]train epoch: 743:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.86it/s, loss=0.923]train epoch: 743:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.86it/s, loss=0.866]train epoch: 743:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.75it/s, loss=0.866]train epoch: 743:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.75it/s, loss=0.571]train epoch: 743: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.85it/s, loss=0.571]train epoch: 743: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.72it/s, loss=0.571]
[[032m2021-11-26 11:06:46,861[0m INFO] trainer.training_epoch Training epoch 743, num_steps 5952,  avg_loss: 0.7489, total_loss: 5.9912
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.03it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.42it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.77it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.33it/s]
[[032m2021-11-26 11:06:47,312[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:47,312[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:47,537[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:47,666[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 744:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 744:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.747]train epoch: 744:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.71it/s, loss=0.747]train epoch: 744:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  5.71it/s, loss=0.676]train epoch: 744:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.02it/s, loss=0.676]train epoch: 744:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.02it/s, loss=0.502]train epoch: 744:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  3.35it/s, loss=0.502]train epoch: 744:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  3.35it/s, loss=0.701]train epoch: 744:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.65it/s, loss=0.701]train epoch: 744:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.65it/s, loss=0.846]train epoch: 744:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=0.846]train epoch: 744:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.77it/s, loss=0.741]train epoch: 744:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.75it/s, loss=0.741]train epoch: 744:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.75it/s, loss=0.761]train epoch: 744:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.39it/s, loss=0.761]train epoch: 744:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.39it/s, loss=0.9]  train epoch: 744: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.86it/s, loss=0.9]train epoch: 744: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.28it/s, loss=0.9]
[[032m2021-11-26 11:06:49,542[0m INFO] trainer.training_epoch Training epoch 744, num_steps 5960,  avg_loss: 0.7343, total_loss: 5.8741
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 11.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.14it/s]
[[032m2021-11-26 11:06:49,925[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:49,925[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:50,150[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:50,357[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 745:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 745:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.887]train epoch: 745:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.34it/s, loss=0.887]train epoch: 745:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.34it/s, loss=0.757]train epoch: 745:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s, loss=0.757]train epoch: 745:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s, loss=0.696]train epoch: 745:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.32it/s, loss=0.696]train epoch: 745:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.32it/s, loss=0.988]train epoch: 745:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.48it/s, loss=0.988]train epoch: 745:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:00,  4.48it/s, loss=0.917]train epoch: 745:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=0.917]train epoch: 745:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  4.06it/s, loss=0.605]train epoch: 745:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.23it/s, loss=0.605]train epoch: 745:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.23it/s, loss=0.716]train epoch: 745:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.27it/s, loss=0.716]train epoch: 745:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  4.27it/s, loss=0.617]train epoch: 745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.71it/s, loss=0.617]train epoch: 745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.67it/s, loss=0.617]
[[032m2021-11-26 11:06:52,076[0m INFO] trainer.training_epoch Training epoch 745, num_steps 5968,  avg_loss: 0.7730, total_loss: 6.1838
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.98it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.91it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.99it/s]
[[032m2021-11-26 11:06:52,499[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:52,499[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:52,720[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:52,829[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 746:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 746:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.652]train epoch: 746:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.01it/s, loss=0.652]train epoch: 746:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.01it/s, loss=0.698]train epoch: 746:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.86it/s, loss=0.698]train epoch: 746:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.86it/s, loss=0.626]train epoch: 746:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.86it/s, loss=0.626]train epoch: 746:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.86it/s, loss=0.593]train epoch: 746:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.86it/s, loss=0.593]train epoch: 746:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.86it/s, loss=0.734]train epoch: 746:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.25it/s, loss=0.734]train epoch: 746:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.25it/s, loss=0.775]train epoch: 746:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.77it/s, loss=0.775]train epoch: 746:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  4.77it/s, loss=1.01] train epoch: 746:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.21it/s, loss=1.01]train epoch: 746:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.21it/s, loss=0.858]train epoch: 746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.64it/s, loss=0.858]train epoch: 746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.08it/s, loss=0.858]
[[032m2021-11-26 11:06:54,410[0m INFO] trainer.training_epoch Training epoch 746, num_steps 5976,  avg_loss: 0.7436, total_loss: 5.9487
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.92it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.01it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.10it/s]
[[032m2021-11-26 11:06:54,921[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:54,921[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:55,240[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:55,513[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 747:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 747:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.676]train epoch: 747:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.01it/s, loss=0.676]train epoch: 747:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.01it/s, loss=0.608]train epoch: 747:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.41it/s, loss=0.608]train epoch: 747:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.41it/s, loss=0.76] train epoch: 747:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.47it/s, loss=0.76]train epoch: 747:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.47it/s, loss=0.69]train epoch: 747:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.78it/s, loss=0.69]train epoch: 747:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.78it/s, loss=0.757]train epoch: 747:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.89it/s, loss=0.757]train epoch: 747:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.89it/s, loss=0.986]train epoch: 747:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.95it/s, loss=0.986]train epoch: 747:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.95it/s, loss=0.759]train epoch: 747:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.16it/s, loss=0.759]train epoch: 747:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  6.16it/s, loss=0.97] train epoch: 747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.99it/s, loss=0.97]train epoch: 747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.92it/s, loss=0.97]
[[032m2021-11-26 11:06:56,871[0m INFO] trainer.training_epoch Training epoch 747, num_steps 5984,  avg_loss: 0.7758, total_loss: 6.2063
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.12it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.36it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.16it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.07it/s]
[[032m2021-11-26 11:06:57,559[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:06:57,559[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:06:57,923[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:06:58,107[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 748:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 748:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.728]train epoch: 748:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.06it/s, loss=0.728]train epoch: 748:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:01,  6.06it/s, loss=0.927]train epoch: 748:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.71it/s, loss=0.927]train epoch: 748:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.71it/s, loss=0.697]train epoch: 748:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.37it/s, loss=0.697]train epoch: 748:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  6.37it/s, loss=0.867]train epoch: 748:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.88it/s, loss=0.867]train epoch: 748:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.88it/s, loss=0.769]train epoch: 748:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.76it/s, loss=0.769]train epoch: 748:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.76it/s, loss=0.598]train epoch: 748:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.57it/s, loss=0.598]train epoch: 748:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.57it/s, loss=0.696]train epoch: 748:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.60it/s, loss=0.696]train epoch: 748:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.60it/s, loss=0.888]train epoch: 748: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s, loss=0.888]train epoch: 748: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.75it/s, loss=0.888]
[[032m2021-11-26 11:06:59,504[0m INFO] trainer.training_epoch Training epoch 748, num_steps 5992,  avg_loss: 0.7712, total_loss: 6.1697
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  5.91it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.59it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.41it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.49it/s]
[[032m2021-11-26 11:07:00,204[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:07:00,204[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:07:00,824[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:07:01,089[0m INFO] trainer.save_checkpoint Save Checkpoint finished
train epoch: 749:   0%|          | 0/8 [00:00<?, ?it/s]train epoch: 749:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.739]train epoch: 749:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.14it/s, loss=0.739]train epoch: 749:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.14it/s, loss=0.654]train epoch: 749:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.73it/s, loss=0.654]train epoch: 749:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.73it/s, loss=0.721]train epoch: 749:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.58it/s, loss=0.721]train epoch: 749:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  5.58it/s, loss=0.972]train epoch: 749:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.44it/s, loss=0.972]train epoch: 749:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  5.44it/s, loss=0.515]train epoch: 749:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  5.03it/s, loss=0.515]train epoch: 749:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  5.03it/s, loss=0.754]train epoch: 749:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.09it/s, loss=0.754]train epoch: 749:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  5.09it/s, loss=0.701]train epoch: 749:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.26it/s, loss=0.701]train epoch: 749:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  5.26it/s, loss=0.719]train epoch: 749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s, loss=0.719][[032m2021-11-26 11:07:02,565[0m INFO] trainer.training_epoch Training epoch 749, num_steps 6000, avg_loss: 0.7220, total_loss: 5.7760
train epoch: 749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.45it/s, loss=0.719]
validation:   0%|          | 0/4 [00:00<?, ?it/s]validation:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.19it/s]validation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.14it/s]validation:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  9.45it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.53it/s]validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.71it/s]
[[032m2021-11-26 11:07:03,051[0m INFO] trainer.inference_epoch validation Performance: OrderedDict([('micro-f1', 0.59375)])
[[032m2021-11-26 11:07:03,052[0m INFO] trainer.save_checkpoint Saving checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt...
[[032m2021-11-26 11:07:03,791[0m INFO] trainer.save_checkpoint Copying checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/last.ckpt to logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:07:04,045[0m INFO] trainer.save_checkpoint Save Checkpoint finished
[[032m2021-11-26 11:07:04,045[0m INFO] trainer.fit Stop training by reaching maximum num_training_steps
[[032m2021-11-26 11:07:04,045[0m INFO] trainer.load_checkpoint Loading Checkpoint logs/super_glue.boolq_t5-large_soft_template_manual_verbalizer_1126094109615273/seed-123/checkpoints/best.ckpt...
[[032m2021-11-26 11:07:04,163[0m INFO] trainer.load_checkpoint Load Checkpoint finished, the current validation metric: 0.59375
test:   0%|          | 0/205 [00:00<?, ?it/s]test:   1%|          | 2/205 [00:00<00:22,  8.96it/s]test:   2%|â–         | 4/205 [00:00<00:20,  9.87it/s]test:   3%|â–Ž         | 6/205 [00:00<00:20,  9.71it/s]test:   4%|â–         | 8/205 [00:00<00:18, 10.47it/s]test:   5%|â–         | 10/205 [00:00<00:17, 10.84it/s]test:   6%|â–Œ         | 12/205 [00:01<00:17, 11.04it/s]test:   7%|â–‹         | 14/205 [00:01<00:17, 11.22it/s]test:   8%|â–Š         | 16/205 [00:01<00:16, 11.13it/s]test:   9%|â–‰         | 18/205 [00:01<00:17, 10.62it/s]test:  10%|â–‰         | 20/205 [00:01<00:18, 10.17it/s]test:  11%|â–ˆ         | 22/205 [00:02<00:19,  9.25it/s]test:  11%|â–ˆ         | 23/205 [00:02<00:22,  8.12it/s]test:  12%|â–ˆâ–        | 24/205 [00:02<00:23,  7.74it/s]test:  12%|â–ˆâ–        | 25/205 [00:02<00:23,  7.76it/s]test:  13%|â–ˆâ–Ž        | 27/205 [00:02<00:20,  8.53it/s]test:  14%|â–ˆâ–        | 29/205 [00:03<00:18,  9.42it/s]test:  15%|â–ˆâ–Œ        | 31/205 [00:03<00:17,  9.97it/s]test:  16%|â–ˆâ–Œ        | 33/205 [00:03<00:16, 10.52it/s]test:  17%|â–ˆâ–‹        | 35/205 [00:03<00:16, 10.31it/s]test:  18%|â–ˆâ–Š        | 37/205 [00:03<00:15, 10.73it/s]test:  19%|â–ˆâ–‰        | 39/205 [00:03<00:15, 10.74it/s]test:  20%|â–ˆâ–ˆ        | 41/205 [00:04<00:15, 10.93it/s]test:  21%|â–ˆâ–ˆ        | 43/205 [00:04<00:14, 10.98it/s]test:  22%|â–ˆâ–ˆâ–       | 45/205 [00:04<00:18,  8.77it/s]test:  22%|â–ˆâ–ˆâ–       | 46/205 [00:04<00:20,  7.92it/s]test:  23%|â–ˆâ–ˆâ–Ž       | 47/205 [00:04<00:20,  7.55it/s]test:  24%|â–ˆâ–ˆâ–       | 49/205 [00:05<00:20,  7.60it/s]test:  24%|â–ˆâ–ˆâ–       | 50/205 [00:05<00:20,  7.65it/s]test:  25%|â–ˆâ–ˆâ–       | 51/205 [00:05<00:19,  8.02it/s]test:  25%|â–ˆâ–ˆâ–Œ       | 52/205 [00:05<00:21,  6.99it/s]test:  26%|â–ˆâ–ˆâ–Œ       | 53/205 [00:05<00:23,  6.57it/s]test:  26%|â–ˆâ–ˆâ–‹       | 54/205 [00:05<00:21,  6.87it/s]test:  27%|â–ˆâ–ˆâ–‹       | 56/205 [00:06<00:17,  8.33it/s]test:  28%|â–ˆâ–ˆâ–Š       | 58/205 [00:06<00:16,  9.12it/s]test:  29%|â–ˆâ–ˆâ–‰       | 60/205 [00:06<00:15,  9.56it/s]test:  30%|â–ˆâ–ˆâ–ˆ       | 62/205 [00:06<00:14,  9.91it/s]test:  31%|â–ˆâ–ˆâ–ˆ       | 63/205 [00:06<00:15,  9.00it/s]test:  32%|â–ˆâ–ˆâ–ˆâ–      | 65/205 [00:07<00:14,  9.64it/s]test:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/205 [00:07<00:13, 10.25it/s]test:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 69/205 [00:07<00:12, 10.63it/s]test:  35%|â–ˆâ–ˆâ–ˆâ–      | 71/205 [00:07<00:12, 10.89it/s]test:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 73/205 [00:07<00:11, 11.13it/s]test:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 75/205 [00:07<00:11, 11.35it/s]test:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/205 [00:08<00:13,  9.77it/s]test:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 79/205 [00:08<00:13,  9.32it/s]test:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 80/205 [00:08<00:15,  8.08it/s]test:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 81/205 [00:08<00:16,  7.46it/s]test:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/205 [00:08<00:18,  6.80it/s]test:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 83/205 [00:09<00:18,  6.51it/s]test:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 84/205 [00:09<00:17,  6.79it/s]test:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/205 [00:09<00:19,  6.16it/s]test:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/205 [00:09<00:18,  6.29it/s]test:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 88/205 [00:09<00:15,  7.76it/s]test:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 89/205 [00:09<00:14,  8.01it/s]test:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 91/205 [00:10<00:12,  9.04it/s]test:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 92/205 [00:10<00:12,  8.85it/s]test:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 94/205 [00:10<00:11,  9.69it/s]test:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 96/205 [00:10<00:10, 10.26it/s]test:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 98/205 [00:10<00:10, 10.68it/s]test:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 100/205 [00:10<00:09, 10.61it/s]test:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 102/205 [00:11<00:09, 10.86it/s]test:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 104/205 [00:11<00:09, 10.17it/s]test:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 106/205 [00:11<00:10,  9.20it/s]test:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/205 [00:11<00:12,  7.72it/s]test:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 108/205 [00:11<00:13,  7.19it/s]test:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 109/205 [00:12<00:13,  7.03it/s]test:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 110/205 [00:12<00:13,  7.04it/s]test:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 111/205 [00:12<00:12,  7.30it/s]test:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 112/205 [00:12<00:11,  7.76it/s]test:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 114/205 [00:12<00:10,  8.94it/s]test:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 116/205 [00:12<00:09,  9.44it/s]test:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 118/205 [00:13<00:09,  9.37it/s]test:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 120/205 [00:13<00:08,  9.91it/s]test:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 122/205 [00:13<00:08, 10.03it/s]test:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 124/205 [00:13<00:08, 10.05it/s]test:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126/205 [00:13<00:07, 10.35it/s]test:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/205 [00:14<00:07, 10.78it/s]test:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 130/205 [00:14<00:06, 10.92it/s]test:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 132/205 [00:14<00:06, 10.86it/s]test:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 134/205 [00:14<00:07,  9.82it/s]test:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 136/205 [00:14<00:08,  8.27it/s]test:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 137/205 [00:15<00:09,  7.53it/s]test:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 138/205 [00:15<00:08,  7.86it/s]test:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 139/205 [00:15<00:08,  7.96it/s]test:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 140/205 [00:15<00:09,  7.07it/s]test:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 141/205 [00:15<00:09,  6.76it/s]test:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 142/205 [00:15<00:09,  6.45it/s]test:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 144/205 [00:16<00:07,  7.68it/s]test:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 146/205 [00:16<00:06,  8.81it/s]test:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/205 [00:16<00:05,  9.64it/s]test:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 150/205 [00:16<00:05, 10.31it/s]test:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 152/205 [00:16<00:04, 10.64it/s]test:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 154/205 [00:16<00:04, 10.90it/s]test:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 156/205 [00:17<00:04, 10.87it/s]test:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 158/205 [00:17<00:04, 10.47it/s]test:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 160/205 [00:17<00:04, 10.93it/s]test:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 162/205 [00:17<00:03, 11.17it/s]test:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 164/205 [00:17<00:03, 11.16it/s]test:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 166/205 [00:18<00:04,  9.20it/s]test:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 167/205 [00:18<00:04,  8.99it/s]test:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/205 [00:18<00:04,  7.47it/s]test:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/205 [00:18<00:04,  7.41it/s]test:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 170/205 [00:18<00:05,  6.59it/s]test:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 172/205 [00:19<00:04,  7.55it/s]test:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 173/205 [00:19<00:04,  7.82it/s]test:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 174/205 [00:19<00:03,  8.20it/s]test:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 176/205 [00:19<00:03,  8.80it/s]test:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 178/205 [00:19<00:02,  9.49it/s]test:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 180/205 [00:19<00:02,  9.94it/s]test:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 182/205 [00:20<00:02, 10.15it/s]test:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 184/205 [00:20<00:02, 10.23it/s]test:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 186/205 [00:20<00:01, 10.42it/s]test:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/205 [00:20<00:01,  9.50it/s]test:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/205 [00:20<00:01,  9.07it/s]test:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 190/205 [00:20<00:01,  9.02it/s]test:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 191/205 [00:21<00:01,  8.43it/s]test:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 192/205 [00:21<00:01,  8.41it/s]test:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 193/205 [00:21<00:01,  8.43it/s]test:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 194/205 [00:21<00:01,  7.30it/s]test:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 195/205 [00:21<00:01,  7.74it/s]test:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 196/205 [00:21<00:01,  7.57it/s]test:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 197/205 [00:21<00:01,  6.78it/s]test:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 198/205 [00:22<00:00,  7.10it/s]test:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 200/205 [00:22<00:00,  8.38it/s]test:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 202/205 [00:22<00:00,  9.43it/s]test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 204/205 [00:22<00:00,  9.85it/s]test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 205/205 [00:22<00:00,  9.05it/s]
[[032m2021-11-26 11:07:26,898[0m INFO] trainer.inference_epoch test Performance: OrderedDict([('micro-f1', 0.5146788990825688)])
metric: 0.5146788990825688
